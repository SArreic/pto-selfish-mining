2024-04-24 14:38:55,757 - MainProcess - INFO - text_logger.py - 51 - Starting to train trainer:
instance(SynchronizedMultiProcessOrchestrator):
  Type: typing.Literal['single_process', 'multi_process', 'synced_multi_process'],
  agent: {'type': 'MCTSAgent', 'exploration_mechanism': {'type': 'EpsilonGreedyExploration', 'epsilon_schedule': {'type': 'ParameterSchedule', 'starting_parameter': 0.05, 'step_change': 0, 'end_parameter': 0}}, 'depth': 5, 'simulations': 25, 'ground_initial_state': False, 'value_clip': 0, 'nn_factor': 0.0001},
  algorithm: instance(MCTSAlgorithm):
    agent: {'type': 'MCTSAgent', 'exploration_mechanism': {'type': 'EpsilonGreedyExploration', 'epsilon_schedule': {'type': 'ParameterSchedule', 'starting_parameter': 0.05, 'step_change': 0, 'end_parameter': 0}}, 'depth': 5, 'simulations': 25, 'ground_initial_state': False, 'value_clip': 0, 'nn_factor': 0.0001},
    approximator: MCTSApproximator(
  (model): Sequential(
    (0): Linear(in_features=46, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=88, bias=True)
  )
),
    blockchain_model: BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01, 10),
    creation_args: {
      'batch_size': 100,
      'bind_all': False,
      'build_info': None,
      'bva_smart_init': 0.47111710906028753,
      'depth': 5,
      'dropout': 0,
      'epoch_shuffles': 2,
      'epsilon_step': 0,
      'evaluate_episode_length': 100,
      'ground_initial_state': False,
      'learning_rate': 0.0002,
      'length_factor': 10,
      'lower_priority': True,
      'lr_decay_epoch': 1000,
      'mc_simulations': 25,
      'nn_factor': 0.0001,
      'normalize_target_values': True,
      'num_of_episodes_for_average': 1000,
      'num_of_epochs': 5001,
      'number_of_evaluation_agents': 2,
      'number_of_training_agents': 5,
      'output_profile': False,
      'output_root': None,
      'prune_tree_rate': 250,
      'starting_epsilon': 0.05,
      'train_episode_length': 100,
      'use_base_approximation': True,
      'use_cached_values': False,
    },
    device: device(type='cpu'),
    loss_fn: MCTSLossFunction(
  (approximator): MCTSApproximator(
    (model): Sequential(
      (0): Linear(in_features=46, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=88, bias=True)
    )
  )
),
    lr_scheduler: instance(StepLR):
      base_lrs: [0.0002],
      gamma: 0.1,
      last_epoch: 0,
      optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0002
    lr: 0.0002
    weight_decay: 0
),
      step_size: 1000,
      verbose: False,
    optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0002
    lr: 0.0002
    weight_decay: 0
),
    simulator: instance(MDPBlockchainSimulator):
      action_space: instance(MultiDimensionalDiscreteSpace):
        dimension: 2,
        intervals: [
          instance(Interval):
            boundaries: (0, 3),
            enum: class(Action):
              Adopt: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Adopt',
                numerator: 1,
                real: 1,
                value: 1,
              Illegal: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Illegal',
                numerator: 0,
                real: 0,
                value: 0,
              Mine: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Mine',
                numerator: 3,
                real: 3,
                value: 3,
              Reveal: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Reveal',
                numerator: 2,
                real: 2,
                value: 2,
            size: 4
          instance(Interval):
            boundaries: (0, 10),
            enum: None,
            size: 11
        ],
        size: 44,
      check_valid_states: False,
      device: device(type='cpu'),
      expected_horizon: 10000,
      final_state: (
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Fork):
          denominator: 1,
          imag: 0,
          name: 'Irrelevant',
          numerator: 0,
          real: 0,
          value: 0
        -1,
        -1,
        -1,
        -1,
        -1,
      ),
      include_transition_info: True,
      initial_state: (
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Fork):
          denominator: 1,
          imag: 0,
          name: 'Irrelevant',
          numerator: 0,
          real: 0,
          value: 0
        0,
        0,
        0,
        0,
        0,
      ),
      num_of_actions: 44,
      num_of_states: 531232341494857729,
      state_space: instance(DefaultValueSpace):
        default_value: (
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Fork):
            denominator: 1,
            imag: 0,
            name: 'Irrelevant',
            numerator: 0,
            real: 0,
            value: 0
          -1,
          -1,
          -1,
          -1,
          -1,
        ),
        dimension: 46,
        size: 531232341494857729,
        underlying_space: instance(MultiDimensionalDiscreteSpace):
          dimension: 46,
          intervals: [
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 2),
              enum: class(Fork):
                Active: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Active',
                  numerator: 2,
                  real: 2,
                  value: 2,
                Irrelevant: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Irrelevant',
                  numerator: 0,
                  real: 0,
                  value: 0,
                Relevant: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Relevant',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 3
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
          ],
          size: 531232341494857728,
      state_space_dim: 46,
  approximator: MCTSApproximator(
  (model): Sequential(
    (0): Linear(in_features=46, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=88, bias=True)
  )
),
  batch_size: 100,
  bind_all: False,
  blockchain_model: BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01, 10),
  build_info: None,
  callback: instance(CompositionCallback):
    callbacks: (
      instance(CompositionCallback):
        callbacks: (
          instance(TextLoggingCallback):
            logger: instance(TextLogger):
              file_name: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                          10)_20240424-143838\\log.txt',
              logger: <Logger multiprocessing (INFO)>,
              output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                           10)_20240424-143838',
            logger_name: 'text',
            orchestrator: <Recursion on instance(SynchronizedMultiProcessOrchestrator) with id=1966738173712>,
            output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                         10)_20240424-143838'
          instance(TensorboardLoggingCallback):
            bind_all: False,
            logger: None,
            logger_name: 'tensorboard',
            max_num_of_agents: 5,
            max_number_of_actions: 3,
            num_of_q_values_in_approximator: 0,
            orchestrator: None,
            tensorboard_popen: None
          instance(BVACallback):
            agent: None,
            episode_values: deque([], maxlen=1000),
            episode_values_synchronizer: None,
            epoch_history: [],
            num_of_episodes_for_average: 1000,
            own_sync_manager: False,
            smart_init: 0.47111710906028753,
            sort_episodes: True,
            stop_goal: None,
            sync_dict: None,
            sync_manager: None
          instance(BVATextLoggingCallback):
            agent: None,
            bva_callback: instance(BVACallback):
              agent: None,
              episode_values: deque([], maxlen=1000),
              episode_values_synchronizer: None,
              epoch_history: [],
              num_of_episodes_for_average: 1000,
              own_sync_manager: False,
              smart_init: 0.47111710906028753,
              sort_episodes: True,
              stop_goal: None,
              sync_dict: None,
              sync_manager: None,
            logger: None,
            logger_name: 'text'
          instance(BVATensorboardLoggingCallback):
            bva_callback: instance(BVACallback):
              agent: None,
              episode_values: deque([], maxlen=1000),
              episode_values_synchronizer: None,
              epoch_history: [],
              num_of_episodes_for_average: 1000,
              own_sync_manager: False,
              smart_init: 0.47111710906028753,
              sort_episodes: True,
              stop_goal: None,
              sync_dict: None,
              sync_manager: None,
            logger: None,
            logger_name: 'tensorboard'
          instance(CheckpointCallback):
            bva_before: 0,
            bva_callback: instance(BVACallback):
              agent: None,
              episode_values: deque([], maxlen=1000),
              episode_values_synchronizer: None,
              epoch_history: [],
              num_of_episodes_for_average: 1000,
              own_sync_manager: False,
              smart_init: 0.47111710906028753,
              sort_episodes: True,
              stop_goal: None,
              sync_dict: None,
              sync_manager: None,
            latest_approximator: None,
            load_epoch: None,
            load_experiment: None,
            load_seed: True,
            nn_state_before: None,
            orchestrator: None,
            output_dir: None,
            own_sync_manager: False,
            random_seed_dict: None,
            save_rate: 100,
            sync_dict: None,
            sync_manager: None
          instance(PolicyRevenueCallback):
            agent: None,
            confidence: 0.99,
            dump_path: '',
            dump_trajectories: False,
            episode_values: None,
            episode_values_synchronizer: None,
            length_factor: 10,
            long_simulation_rate: 100,
            num_of_agents: 0,
            num_of_evaluation_agents: 0,
            orchestrator: None,
            own_sync_manager: False,
            policy_revenue: 0,
            policy_revenue_confidence_radius: 0,
            policy_test_revenue: 0,
            policy_test_revenue_confidence_radius: 0,
            repeats: 1,
            sync_dict: None,
            sync_manager: None,
            test_episode_values: None,
            test_episode_values_synchronizer: None
          instance(PolicyRevenueTextLoggingCallback):
            logger: None,
            logger_name: 'text',
            policy_revenue_callback: instance(PolicyRevenueCallback):
              agent: None,
              confidence: 0.99,
              dump_path: '',
              dump_trajectories: False,
              episode_values: None,
              episode_values_synchronizer: None,
              length_factor: 10,
              long_simulation_rate: 100,
              num_of_agents: 0,
              num_of_evaluation_agents: 0,
              orchestrator: None,
              own_sync_manager: False,
              policy_revenue: 0,
              policy_revenue_confidence_radius: 0,
              policy_test_revenue: 0,
              policy_test_revenue_confidence_radius: 0,
              repeats: 1,
              sync_dict: None,
              sync_manager: None,
              test_episode_values: None,
              test_episode_values_synchronizer: None
          instance(PolicyRevenueTensorboardLoggingCallback):
            logger: None,
            logger_name: 'tensorboard',
            policy_revenue_callback: instance(PolicyRevenueCallback):
              agent: None,
              confidence: 0.99,
              dump_path: '',
              dump_trajectories: False,
              episode_values: None,
              episode_values_synchronizer: None,
              length_factor: 10,
              long_simulation_rate: 100,
              num_of_agents: 0,
              num_of_evaluation_agents: 0,
              orchestrator: None,
              own_sync_manager: False,
              policy_revenue: 0,
              policy_revenue_confidence_radius: 0,
              policy_test_revenue: 0,
              policy_test_revenue_confidence_radius: 0,
              repeats: 1,
              sync_dict: None,
              sync_manager: None,
              test_episode_values: None,
              test_episode_values_synchronizer: None
        )
      instance(MCTSTensorboardLoggingCallback):
        agent: None,
        logger: None,
        logger_name: 'tensorboard',
        max_num_of_agents: 5,
        orchestrator: None
    ),
  creation_args: {
    'bva_smart_init': 0.47111710906028753,
    'depth': 5,
    'device': device(type='cpu')
    'dropout': 0,
    'epsilon_step': 0,
    'ground_initial_state': False,
    'length_factor': 10,
    'lr_decay_epoch': 1000,
    'mc_simulations': 25,
    'nn_factor': 0.0001,
    'normalize_target_values': True,
    'num_of_episodes_for_average': 1000,
    'prune_tree_rate': 250,
    'simulator': instance(MDPBlockchainSimulator):
      action_space: instance(MultiDimensionalDiscreteSpace):
        dimension: 2,
        intervals: [
          instance(Interval):
            boundaries: (0, 3),
            enum: class(Action):
              Adopt: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Adopt',
                numerator: 1,
                real: 1,
                value: 1,
              Illegal: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Illegal',
                numerator: 0,
                real: 0,
                value: 0,
              Mine: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Mine',
                numerator: 3,
                real: 3,
                value: 3,
              Reveal: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Reveal',
                numerator: 2,
                real: 2,
                value: 2,
            size: 4
          instance(Interval):
            boundaries: (0, 10),
            enum: None,
            size: 11
        ],
        size: 44,
      check_valid_states: False,
      device: device(type='cpu'),
      expected_horizon: 10000,
      final_state: (
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Fork):
          denominator: 1,
          imag: 0,
          name: 'Irrelevant',
          numerator: 0,
          real: 0,
          value: 0
        -1,
        -1,
        -1,
        -1,
        -1,
      ),
      include_transition_info: True,
      initial_state: (
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Fork):
          denominator: 1,
          imag: 0,
          name: 'Irrelevant',
          numerator: 0,
          real: 0,
          value: 0
        0,
        0,
        0,
        0,
        0,
      ),
      num_of_actions: 44,
      num_of_states: 531232341494857729,
      state_space: instance(DefaultValueSpace):
        default_value: (
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Fork):
            denominator: 1,
            imag: 0,
            name: 'Irrelevant',
            numerator: 0,
            real: 0,
            value: 0
          -1,
          -1,
          -1,
          -1,
          -1,
        ),
        dimension: 46,
        size: 531232341494857729,
        underlying_space: instance(MultiDimensionalDiscreteSpace):
          dimension: 46,
          intervals: [
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 2),
              enum: class(Fork):
                Active: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Active',
                  numerator: 2,
                  real: 2,
                  value: 2,
                Irrelevant: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Irrelevant',
                  numerator: 0,
                  real: 0,
                  value: 0,
                Relevant: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Relevant',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 3
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
          ],
          size: 531232341494857728,
      state_space_dim: 46
    'starting_epsilon': 0.05,
    'use_base_approximation': True,
    'use_cached_values': False,
  },
  episode_reset_rate: 10,
  episode_synchronizer: {'type': 'BufferSynchronizer', 'target_buffer': <reinforcement_learning.base.utility.dummy_buffer.DummyBuffer object at 0x000001C9EAC66700>},
  epoch_length: 1000,
  epoch_size: 2000,
  evaluate_episode_length: 100,
  expected_horizon: 10000,
  experiment_name: 'BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                    10)_20240424-143838',
  learning_rate: 0.0002,
  loggers: {
    'tensorboard': instance(SynchronizedLogger):
      base_logger: instance(TensorboardLogger):
        flush_secs: 15,
        hparam_dict: {
        },
        hparam_domain_discrete: {
        },
        layout: {
        },
        metric_dict: {
        },
        output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                     10)_20240424-143838',
        started_logging: False,
        tensorboard_writer: instance(SummaryWriter):
          all_writers: {
            'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01, 10)_20240424-143838': instance(FileWriter):
              event_writer: instance(EventFileWriter)
          },
          default_bins: [-9.920775621859783e+19, -9.018886928963438e+19, -8.198988117239489e+19, -7.453625561126807e+19, -6.776023237388005e+19, -6.160021124898186e+19, -5.600019204452896e+19, -5.090926549502632e+19, -4.628115045002392e+19, -4.2073773136385384e+19, -3.824888466944125e+19, -3.477171333585568e+19, -3.1610648487141528e+19, -2.873695317012866e+19, -2.6124502881935143e+19, -2.3749548074486493e+19, -2.1590498249533174e+19, -1.962772568139379e+19, -1.7843386983085265e+19, -1.6221260893713875e+19, -1.4746600812467157e+19, -1.3406000738606506e+19, -1.2187273398733187e+19, -1.1079339453393805e+19, -1.0072126775812549e+19, -9.156478887102316e+18, -8.324071715547559e+18, -7.567337923225053e+18, -6.879398112022775e+18, -6.253998283657068e+18, -5.685452985142788e+18, -5.16859362285708e+18, -4.698721475324618e+18, -4.271564977567834e+18, -3.8832408886980306e+18, -3.530218989725482e+18, -3.2092899906595287e+18, -2.917536355145026e+18, -2.652305777404569e+18, -2.41118707036779e+18, -2.1919882457888998e+18, -1.992716587080818e+18, -1.8115605337098342e+18, -1.6468732124634854e+18, -1.4971574658758958e+18, -1.3610522417053596e+18, -1.237320219732145e+18, -1.1248365633928589e+18, -1.022578693993508e+18, -9.296169945395526e+17, -8.451063586723205e+17, -7.682785078839277e+17, -6.984350071672069e+17, -6.349409156065517e+17, -5.772190141877742e+17, -5.247445583525219e+17, -4.770405075932017e+17, -4.336731887210924e+17, -3.9424835338281126e+17, -3.584075939843738e+17, -3.2582508544033984e+17, -2.9620462312758163e+17, -2.6927693011598326e+17, -2.447972091963484e+17, -2.2254291745122582e+17, -2.02311743137478e+17, -1.8391976648861635e+17, -1.6719978771692394e+17, -1.5199980701538538e+17, -1.3818164274125942e+17, -1.2561967521932674e+17, -1.1419970474484248e+17, -1.0381791340440224e+17, -9.43799212767293e+16, -8.579992843339026e+16, -7.799993493944568e+16, -7.090903176313243e+16, -6.446275614830221e+16, -5.860250558936564e+16, -5.327500508124149e+16, -4.843182280112862e+16, -4.402892981920784e+16, -4.002629983564349e+16, -3.638754530513044e+16, -3.3079586641027668e+16, -3.0072351491843332e+16, -2.733850135622121e+16, -2.4853183051110188e+16, -2.2593802773736532e+16, -2.0539820703396844e+16, -1.867256427581531e+16, -1.6975058432559372e+16, -1.54318713023267e+16, -1.402897391120609e+16, -1.275361264655099e+16, -1.1594193315046354e+16, -1.054017574095123e+16, -9581977946319300.0, -8710889042108454.0, -7918990038280412.0, -7199081852982192.0, -6544619866347447.0, -5949654423952224.0, -5408776749047476.0, -4917069771861341.0, -4470063428964855.0, -4063694026331686.0, -3694267296665169.0, -3358424815150153.5, -3053113468318321.0, -2775557698471200.5, -2523234271337455.0, -2293849337579504.5, -2085317579617731.2, -1895743254197937.2, -1723402958361761.0, -1566729962147055.2, -1424299965588232.0, -1294818150534756.2, -1177107409577051.0, -1070097645070046.2, -972816040972769.2, -884378219066153.8, -803980199151048.8, -730891090137317.0, -664446445579379.0, -604042223253980.9, -549129293867255.25, -499208448970232.0, -453825862700210.9, -412568966091100.75, -375062696446455.2, -340966087678595.6, -309969170616905.06, -281790155106277.3, -256172868278433.9, -232884425707667.16, -211713114279697.4, -192466467526997.62, -174969515933634.2, -159063196303303.78, -144602905730276.16, -131457187027523.78, -119506533661385.25, -108642303328532.03, -98765730298665.47, -89787027544241.33, -81624570494764.84, -74204154995240.77, -67458322722946.15, -61325747929951.04, -55750679936319.125, -50682436305744.66, -46074942096131.5, -41886310996483.18, -38078464542257.43, -34616785947506.754, -31469805406824.32, -28608914006203.926, -26008103642003.566, -23643730583639.605, -21494300530581.457, -19540273209619.504, -17763884736017.73, -16148986123652.482, -14680896476047.71, -13346269523679.736, -12132972294254.305, -11029974812958.457, -10027249829962.232, -9115681663602.03, -8286983330547.298, -7533621209588.452, -6848746554171.319, -6226133231064.835, -5660121119149.85, -5145564653772.59, -4677786048884.172, -4252532771712.8833, -3865938883375.348, -3514489893977.589, -3194990812706.899, -2904537102460.817, -2640488274964.379, -2400443886331.2534, -2182221714846.594, -1983837922587.8125, -1803489020534.3748, -1639535473213.0679, -1490486793830.0615, -1354987994390.9648, -1231807267628.1497, -1119824788752.8633, -1018022535229.8757, -925475032027.1597, -841340938206.5087, -764855398369.5532, -695323089426.8665, -632111899478.9695, -574647181344.5177, -522406528495.01605, -474915025904.56, -431740932640.50903, -392491756945.9173, -356810688132.65204, -324373352847.8655, -294884866225.3322, -268077151113.93835, -243706501012.6712, -221551364556.97382, -201410331415.43073, -183100301286.7552, -166454819351.5956, -151322563046.9051, -137565966406.27734, -125059969460.25212, -113690881327.50192, -103355346661.36537, -93959406055.7867, -85417641868.89699, -77652401698.99725, -70593092453.63387, -64175538594.21259, -58341398722.011444, -53037635201.82858, -48216032001.662346, -43832756365.14758, -39847960331.95235, -36225418483.59304, -32932198621.448215, -29938362383.13474, -27216693075.577034, -24742448250.524574, -22493134773.204155, -20448304339.276505, -18589367581.160458, -16899425073.782234, -15363113703.438393, -13966467003.12581, -12696788184.659826, -11542534713.327114, -10493213375.75192, -9539284887.0472, -8672077170.042908, -7883706518.220825, -7167005925.655295, -6515459932.413904, -5923145393.103549, -5384677630.094135, -4895161481.903759, -4450146801.73069, -4045588001.5733542, -3677807274.1575947, -3343461158.3250856, -3039510143.9318957, -2763191039.938087, -2511991854.4891696, -2283628958.626518, -2076026326.0241067, -1887296660.021915, -1715724236.383559, -1559749305.8032353, -1417953914.3665774, -1289049013.0605247, -1171862739.1459315, -1065329762.8599375, -968481602.5999432, -880437820.5454028, -800398018.6776388, -727634562.434217, -661485965.8492881, -601350878.0448073, -546682616.4043702, -496984196.7312456, -451803815.2102232, -410730741.10020286, -373391582.8183662, -339446893.471242, -308588084.97385633, -280534622.70350575, -255031475.1850052, -231846795.62273198, -210769814.2024836, -191608922.0022578, -174189929.0929616, -158354480.99360144, -143958619.08509222, -130871471.89553836, -118974065.35958032, -108158241.2359821, -98325673.85089281, -89386976.22808437, -81260887.4800767, -73873534.072797, -67157758.24799727, -61052507.49817933, -55502279.543799385, -50456617.76709034, -45869652.51553667, -41699684.10503334, -37908803.731848486, -34462548.847134985, -31329589.861031804, -28481445.32821073, -25892223.025646117, -23538384.568769194, -21398531.426153813, -19453210.387412556, -17684736.715829596, -16077033.378026905, -14615484.889115367, -13286804.444650333, -12078913.131500302, -10980830.119545728, -9982572.835950661, -9075066.2145006, -8250060.195000546, -7500054.722727768, -6818231.566116152, -6198392.332832865, -5634902.1207571495, -5122638.291597408, -4656943.901452189, -4233585.364956535, -3848713.9681423046, -3498830.8801293676, -3180755.345572152, -2891595.768701956, -2628723.426092687, -2389748.56917517, -2172498.699250154, -1974998.81750014, -1795453.4704546726, -1632230.427686066, -1483845.8433509688, -1348950.7666826989, -1226318.8788024534, -1114835.3443658666, -1013486.6766962423, -921351.5242693111, -837592.2947902827, -761447.5407184388, -692225.0370167625, -629295.4881970568, -572086.8074518698, -520078.91586533614, -472799.0144230328, -429817.2858391207, -390742.98712647334, -355220.897387703, -322928.0885342754, -293570.989576614, -266882.7177969218, -242620.65254265617, -220564.22958423287, -200512.93598566623, -182284.48725969656, -165713.17023608775, -150648.33657826157, -136953.03325296505, -124502.75750269549, -113184.32500245044, -102894.84091131858, -93540.76446483507, -85037.05860439551, -77306.41691308682, -70278.56083007893, -63889.60075461721, -58081.45523147019, -52801.32293770016, -48001.20267063651, -43637.45697330591, -39670.415430278095, -36064.01402752554, -32785.46729775049, -29804.97027068226, -27095.427518802055, -24632.206835274592, -22392.915304795082, -20357.19573163189, -18506.54157421081, -16824.128703828006, -15294.66245802546, -13904.238598204962, -12640.216907459055, -11491.10627950823, -10446.46025409839, -9496.782049180354, -8633.438226527594, -7848.580205934176, -7135.072914485614, -6486.429922259648, -5896.754474781498, -5360.685886164998, -4873.350805604543, -4430.3189141859475, -4027.5626492599517, -3661.4205902363196, -3328.5641729421086, -3025.9674299473713, -2750.8794817703374, -2500.799528882125, -2273.454117165568, -2066.776470150516, -1878.8877001368326, -1708.0797273971205, -1552.7997521792004, -1411.6361383447274, -1283.3055803133884, -1166.6414366485349, -1060.5831242259408, -964.166476569037, -876.5149786991244, -796.8317988173858, -724.3925443794416, -658.5386767085832, -598.6715242805302, -544.2468402550275, -494.76985477729767, -449.79077707027056, -408.9007064275187, -371.72791493410784, -337.9344681219162, -307.2131528381056, -279.2846843982778, -253.89516763479799, -230.81378875890724, -209.830717053552, -190.7551973214109, -173.41381574673716, -157.64892340612468, -143.31720309647696, -130.28836645134268, -118.44396950122061, -107.67633591020055, -97.88757810018231, -88.98870736380209, -80.89882487618371, -73.54438625107609, -66.85853295552371, -60.78048450502155, -55.25498591365595, -50.23180537605086, -45.66527761459169, -41.513888740537894, -37.73989885503445, -34.30899895912222, -31.18999905374747, -28.35454459431588, -25.77685872210534, -23.43350792918667, -21.303189026533335, -19.366535478666666, -17.60594134424242, -16.005401222038564, -14.550364747307786, -13.22760431573435, -12.025094832485772, -10.931904393168884, -9.938094902880803, -9.034631729891638, -8.213301572628762, -7.466637793298873, -6.7878525393626115, -6.1707750357841915, -5.609795487076537, -5.099814079160488, -4.636194617418625, -4.214722379471477, -3.8315657995195243, -3.48324163592684, -3.1665833053880363, -2.8787120958073054, -2.6170109961884593, -2.379100905625872, -2.1628190051144287, -1.9661990955585713, -1.7874537232350647, -1.624957930213695, -1.47723448201245, -1.3429404381931362, -1.220854943811942, -1.109868130738129, -1.0089710279437536, -0.917246389039776, -0.8338603536725235, -0.7580548669750213, -0.6891407881591103, -0.6264916255991911, -0.56953784145381, -0.5177616740489182, -0.47069243095356195, -0.42790220995778355, -0.38900200905253046, -0.35363819004775493, -0.3214892636797772, -0.29226296698161564, -0.2656936063469233, -0.24153964213356663, -0.2195814928486969, -0.19961953895336082, -0.18147230813941892, -0.16497482558128992, -0.14997711416480902, -0.13634283105891729, -0.12394802823537933, -0.11268002566852665, -0.10243638697138786, -0.09312398815580714, -0.08465817105073375, -0.07696197368248522, -0.06996543062044111, -0.06360493692767373, -0.057822669934248845, -0.052566063576589855, -0.04778733052417259, -0.043443027749247805, -0.03949366159022527, -0.035903328718386605, -0.03263938974398782, -0.02967217249453438, -0.026974702267758523, -0.0245224566070532, -0.022293142370048362, -0.02026649306368033, -0.018424084603345752, -0.01674916782122341, -0.01522651620111219, -0.013842287455556535, -0.012583897686869577, -0.01143990698806325, -0.010399915443693864, -0.00945446858517624, -0.008594971441069308, -0.007813610400972098, -0.007103282182701907, -0.006457529257001733, -0.005870481142728848, -0.005336801038844407, -0.00485163730804037, -0.00441057937094579, -0.004009617609950718, -0.0036451069181370156, -0.003313733561942741, -0.0030124850563115826, -0.002738622778465075, -0.0024896570713318863, -0.0022633246103017147, -0.0020575678275470133, -0.001870516206860921, -0.0017004692789644735, -0.0015458811626949758, -0.001405346511540887, -0.0012775877377644426, -0.001161443397967675, -0.001055857634516068, -0.0009598705768327891, -0.0008726096153025355, -0.0007932814684568504, -0.0007211649713244094, -0.0006556045193858267, -0.0005960041085325697, -0.0005418219168477906, -0.0004925653789525368, -0.0004477867081386698, -0.0004070788255806089, -0.0003700716596187353, -0.00033642878147157755, -0.0003058443467923432, -0.0002780403152657665, -0.00025276392296887866, -0.0002297853845171624, -0.00020889580410651126, -0.00018990527646046477, -0.00017264116041860433, -0.00015694650947145847, -0.00014267864497405315, -0.00012970785906732103, -0.00011791623551574639, -0.00010719657774158762, -9.745143431053419e-05, -8.859221300957652e-05, -8.053837546325138e-05, -7.321670496659217e-05, -6.656064087872014e-05, -6.050967352610922e-05, -5.500879411464474e-05, -5.000799464967703e-05, -4.546181331788821e-05, -4.132892119808019e-05, -3.757174654370926e-05, -3.415613322155387e-05, -3.1051030201412604e-05, -2.822820927401146e-05, -2.5662008430919505e-05, -2.3329098573563184e-05, -2.1208271430511985e-05, -1.9280246755010893e-05, -1.7527497050009902e-05, -1.593408822728173e-05, -1.44855347520743e-05, -1.316866795643118e-05, -1.1971516324028345e-05, -1.0883196658207586e-05, -9.893815143825077e-06, -8.994377403477343e-06, -8.176706730433948e-06, -7.4333697549399525e-06, -6.757608868127229e-06, -6.143280789206572e-06, -5.584800717460519e-06, -5.077091561327744e-06, -4.615537783025222e-06, -4.1959434391138375e-06, -3.8144940355580335e-06, -3.467721850507303e-06, -3.1524744095520932e-06, -2.865885826865539e-06, -2.605350751695944e-06, -2.368500683359949e-06, -2.153182439418135e-06, -1.9574385812892137e-06, -1.7794896193538304e-06, -1.6177178357762093e-06, -1.470652577978372e-06, -1.3369568890712472e-06, -1.2154153537011338e-06, -1.1049230488192125e-06, -1.0044754989265568e-06, -9.131595444786879e-07, -8.301450404351707e-07, -7.546773094865188e-07, -6.860702813513807e-07, -6.237002557739824e-07, -5.670002325218022e-07, -5.15454756838002e-07, -4.6859523348909267e-07, -4.2599566680826603e-07, -3.8726878800751456e-07, -3.5206253455228594e-07, -3.200568495929872e-07, -2.909607723572611e-07, -2.645097930520555e-07, -2.4046344822914135e-07, -2.1860313475376482e-07, -1.9873012250342254e-07, -1.8066374773038411e-07, -1.6423977066398553e-07, -1.4930888242180502e-07, -1.3573534765618637e-07, -1.2339577059653305e-07, -1.1217797326957548e-07, -1.0197997569961407e-07, -9.270906881783097e-08, -8.42809716525736e-08, -7.661906513870326e-08, -6.965369558063933e-08, -6.332154143694484e-08, -5.756503766994985e-08, -5.2331852427227134e-08, -4.757441129747921e-08, -4.324946481589019e-08, -3.9317695287172896e-08, -3.574335935197536e-08, -3.249396304725032e-08, -2.95399664065912e-08, -2.6854514915082908e-08, -2.4413195377348097e-08, -2.219381397940736e-08, -2.017619452673396e-08, -1.83419950243036e-08, -1.667454093118509e-08, -1.5158673573804625e-08, -1.3780612339822385e-08, -1.2527829399838531e-08, -1.1388935818035027e-08, -1.0353578016395478e-08, -9.412343651268615e-09, -8.556676046607832e-09, -7.778796406007119e-09, -7.071633096370107e-09, -6.428757360336461e-09, -5.8443248730331455e-09, -5.313022611848313e-09, -4.830020556225739e-09, -4.390927778387036e-09, -3.991752525806396e-09, -3.628865932551268e-09, -3.2989690295920617e-09, -2.9990627541746013e-09, -2.7264206856132736e-09, -2.47856425964843e-09, -2.253240236044027e-09, -2.048400214585479e-09, -1.8621820132595262e-09, -1.6928927393268418e-09, -1.5389933993880379e-09, -1.3990849085345797e-09, -1.2718953713950723e-09, -1.1562685194500657e-09, -1.0511531995000597e-09, -9.55593817727327e-10, -8.68721652479388e-10, -7.897469567994436e-10, -7.179517789085851e-10, -6.52683435371441e-10, -5.933485776104008e-10, -5.394077978276371e-10, -4.903707252978519e-10, -4.4579156845259254e-10, -4.0526506222962957e-10, -3.684227838451178e-10, -3.349298034955616e-10, -3.0448163954141963e-10, -2.7680149049219964e-10, -2.516377186292724e-10, -2.287615623902476e-10, -2.079650567184069e-10, -1.89059142471279e-10, -1.718719477011627e-10, -1.5624722518287518e-10, -1.4204293198443196e-10, -1.291299381676654e-10, -1.173908528796958e-10, -1.067189571633598e-10, -9.701723378487254e-11, -8.819748525897503e-11, -8.017953205361366e-11, -7.289048368510333e-11, -6.626407607736665e-11, -6.02400691612424e-11, -5.4763699237493095e-11, -4.978518112499372e-11, -4.5259255568176104e-11, -4.1144777789251e-11, -3.7404343444773633e-11, -3.400394858615785e-11, -3.091268053287077e-11, -2.8102436848064334e-11, -2.5547669861876665e-11, -2.3225154419887876e-11, -2.111377674535261e-11, -1.91943424957751e-11, -1.7449402268886454e-11, -1.5863092971714956e-11, -1.4420993610649957e-11, -1.310999419149996e-11, -1.1918176537727236e-11, -1.0834705943388396e-11, -9.849732675807632e-12, -8.954302432552392e-12, -8.140274938683992e-12, -7.400249944258175e-12, -6.727499949325613e-12, -6.115909044841466e-12, -5.559917313492241e-12, -5.054470284992946e-12, -4.594972986357223e-12, -4.177248169415657e-12, -3.797498335832415e-12, -3.452271214393104e-12, -3.1384283767210032e-12, -2.8531167061100027e-12, -2.593742460100002e-12, -2.357947691000002e-12, -2.1435888100000016e-12, -1.9487171000000014e-12, -1.771561000000001e-12, -1.6105100000000008e-12, -1.4641000000000006e-12, -1.3310000000000005e-12, -1.2100000000000003e-12, -1.1000000000000002e-12, -1e-12, 0, 1e-12, 1.1000000000000002e-12, 1.2100000000000003e-12, 1.3310000000000005e-12, 1.4641000000000006e-12, 1.6105100000000008e-12, 1.771561000000001e-12, 1.9487171000000014e-12, 2.1435888100000016e-12, 2.357947691000002e-12, 2.593742460100002e-12, 2.8531167061100027e-12, 3.1384283767210032e-12, 3.452271214393104e-12, 3.797498335832415e-12, 4.177248169415657e-12, 4.594972986357223e-12, 5.054470284992946e-12, 5.559917313492241e-12, 6.115909044841466e-12, 6.727499949325613e-12, 7.400249944258175e-12, 8.140274938683992e-12, 8.954302432552392e-12, 9.849732675807632e-12, 1.0834705943388396e-11, 1.1918176537727236e-11, 1.310999419149996e-11, 1.4420993610649957e-11, 1.5863092971714956e-11, 1.7449402268886454e-11, 1.91943424957751e-11, 2.111377674535261e-11, 2.3225154419887876e-11, 2.5547669861876665e-11, 2.8102436848064334e-11, 3.091268053287077e-11, 3.400394858615785e-11, 3.7404343444773633e-11, 4.1144777789251e-11, 4.5259255568176104e-11, 4.978518112499372e-11, 5.4763699237493095e-11, 6.02400691612424e-11, 6.626407607736665e-11, 7.289048368510333e-11, 8.017953205361366e-11, 8.819748525897503e-11, 9.701723378487254e-11, 1.067189571633598e-10, 1.173908528796958e-10, 1.291299381676654e-10, 1.4204293198443196e-10, 1.5624722518287518e-10, 1.718719477011627e-10, 1.89059142471279e-10, 2.079650567184069e-10, 2.287615623902476e-10, 2.516377186292724e-10, 2.7680149049219964e-10, 3.0448163954141963e-10, 3.349298034955616e-10, 3.684227838451178e-10, 4.0526506222962957e-10, 4.4579156845259254e-10, 4.903707252978519e-10, 5.394077978276371e-10, 5.933485776104008e-10, 6.52683435371441e-10, 7.179517789085851e-10, 7.897469567994436e-10, 8.68721652479388e-10, 9.55593817727327e-10, 1.0511531995000597e-09, 1.1562685194500657e-09, 1.2718953713950723e-09, 1.3990849085345797e-09, 1.5389933993880379e-09, 1.6928927393268418e-09, 1.8621820132595262e-09, 2.048400214585479e-09, 2.253240236044027e-09, 2.47856425964843e-09, 2.7264206856132736e-09, 2.9990627541746013e-09, 3.2989690295920617e-09, 3.628865932551268e-09, 3.991752525806396e-09, 4.390927778387036e-09, 4.830020556225739e-09, 5.313022611848313e-09, 5.8443248730331455e-09, 6.428757360336461e-09, 7.071633096370107e-09, 7.778796406007119e-09, 8.556676046607832e-09, 9.412343651268615e-09, 1.0353578016395478e-08, 1.1388935818035027e-08, 1.2527829399838531e-08, 1.3780612339822385e-08, 1.5158673573804625e-08, 1.667454093118509e-08, 1.83419950243036e-08, 2.017619452673396e-08, 2.219381397940736e-08, 2.4413195377348097e-08, 2.6854514915082908e-08, 2.95399664065912e-08, 3.249396304725032e-08, 3.574335935197536e-08, 3.9317695287172896e-08, 4.324946481589019e-08, 4.757441129747921e-08, 5.2331852427227134e-08, 5.756503766994985e-08, 6.332154143694484e-08, 6.965369558063933e-08, 7.661906513870326e-08, 8.42809716525736e-08, 9.270906881783097e-08, 1.0197997569961407e-07, 1.1217797326957548e-07, 1.2339577059653305e-07, 1.3573534765618637e-07, 1.4930888242180502e-07, 1.6423977066398553e-07, 1.8066374773038411e-07, 1.9873012250342254e-07, 2.1860313475376482e-07, 2.4046344822914135e-07, 2.645097930520555e-07, 2.909607723572611e-07, 3.200568495929872e-07, 3.5206253455228594e-07, 3.8726878800751456e-07, 4.2599566680826603e-07, 4.6859523348909267e-07, 5.15454756838002e-07, 5.670002325218022e-07, 6.237002557739824e-07, 6.860702813513807e-07, 7.546773094865188e-07, 8.301450404351707e-07, 9.131595444786879e-07, 1.0044754989265568e-06, 1.1049230488192125e-06, 1.2154153537011338e-06, 1.3369568890712472e-06, 1.470652577978372e-06, 1.6177178357762093e-06, 1.7794896193538304e-06, 1.9574385812892137e-06, 2.153182439418135e-06, 2.368500683359949e-06, 2.605350751695944e-06, 2.865885826865539e-06, 3.1524744095520932e-06, 3.467721850507303e-06, 3.8144940355580335e-06, 4.1959434391138375e-06, 4.615537783025222e-06, 5.077091561327744e-06, 5.584800717460519e-06, 6.143280789206572e-06, 6.757608868127229e-06, 7.4333697549399525e-06, 8.176706730433948e-06, 8.994377403477343e-06, 9.893815143825077e-06, 1.0883196658207586e-05, 1.1971516324028345e-05, 1.316866795643118e-05, 1.44855347520743e-05, 1.593408822728173e-05, 1.7527497050009902e-05, 1.9280246755010893e-05, 2.1208271430511985e-05, 2.3329098573563184e-05, 2.5662008430919505e-05, 2.822820927401146e-05, 3.1051030201412604e-05, 3.415613322155387e-05, 3.757174654370926e-05, 4.132892119808019e-05, 4.546181331788821e-05, 5.000799464967703e-05, 5.500879411464474e-05, 6.050967352610922e-05, 6.656064087872014e-05, 7.321670496659217e-05, 8.053837546325138e-05, 8.859221300957652e-05, 9.745143431053419e-05, 0.00010719657774158762, 0.00011791623551574639, 0.00012970785906732103, 0.00014267864497405315, 0.00015694650947145847, 0.00017264116041860433, 0.00018990527646046477, 0.00020889580410651126, 0.0002297853845171624, 0.00025276392296887866, 0.0002780403152657665, 0.0003058443467923432, 0.00033642878147157755, 0.0003700716596187353, 0.0004070788255806089, 0.0004477867081386698, 0.0004925653789525368, 0.0005418219168477906, 0.0005960041085325697, 0.0006556045193858267, 0.0007211649713244094, 0.0007932814684568504, 0.0008726096153025355, 0.0009598705768327891, 0.001055857634516068, 0.001161443397967675, 0.0012775877377644426, 0.001405346511540887, 0.0015458811626949758, 0.0017004692789644735, 0.001870516206860921, 0.0020575678275470133, 0.0022633246103017147, 0.0024896570713318863, 0.002738622778465075, 0.0030124850563115826, 0.003313733561942741, 0.0036451069181370156, 0.004009617609950718, 0.00441057937094579, 0.00485163730804037, 0.005336801038844407, 0.005870481142728848, 0.006457529257001733, 0.007103282182701907, 0.007813610400972098, 0.008594971441069308, 0.00945446858517624, 0.010399915443693864, 0.01143990698806325, 0.012583897686869577, 0.013842287455556535, 0.01522651620111219, 0.01674916782122341, 0.018424084603345752, 0.02026649306368033, 0.022293142370048362, 0.0245224566070532, 0.026974702267758523, 0.02967217249453438, 0.03263938974398782, 0.035903328718386605, 0.03949366159022527, 0.043443027749247805, 0.04778733052417259, 0.052566063576589855, 0.057822669934248845, 0.06360493692767373, 0.06996543062044111, 0.07696197368248522, 0.08465817105073375, 0.09312398815580714, 0.10243638697138786, 0.11268002566852665, 0.12394802823537933, 0.13634283105891729, 0.14997711416480902, 0.16497482558128992, 0.18147230813941892, 0.19961953895336082, 0.2195814928486969, 0.24153964213356663, 0.2656936063469233, 0.29226296698161564, 0.3214892636797772, 0.35363819004775493, 0.38900200905253046, 0.42790220995778355, 0.47069243095356195, 0.5177616740489182, 0.56953784145381, 0.6264916255991911, 0.6891407881591103, 0.7580548669750213, 0.8338603536725235, 0.917246389039776, 1.0089710279437536, 1.109868130738129, 1.220854943811942, 1.3429404381931362, 1.47723448201245, 1.624957930213695, 1.7874537232350647, 1.9661990955585713, 2.1628190051144287, 2.379100905625872, 2.6170109961884593, 2.8787120958073054, 3.1665833053880363, 3.48324163592684, 3.8315657995195243, 4.214722379471477, 4.636194617418625, 5.099814079160488, 5.609795487076537, 6.1707750357841915, 6.7878525393626115, 7.466637793298873, 8.213301572628762, 9.034631729891638, 9.938094902880803, 10.931904393168884, 12.025094832485772, 13.22760431573435, 14.550364747307786, 16.005401222038564, 17.60594134424242, 19.366535478666666, 21.303189026533335, 23.43350792918667, 25.77685872210534, 28.35454459431588, 31.18999905374747, 34.30899895912222, 37.73989885503445, 41.513888740537894, 45.66527761459169, 50.23180537605086, 55.25498591365595, 60.78048450502155, 66.85853295552371, 73.54438625107609, 80.89882487618371, 88.98870736380209, 97.88757810018231, 107.67633591020055, 118.44396950122061, 130.28836645134268, 143.31720309647696, 157.64892340612468, 173.41381574673716, 190.7551973214109, 209.830717053552, 230.81378875890724, 253.89516763479799, 279.2846843982778, 307.2131528381056, 337.9344681219162, 371.72791493410784, 408.9007064275187, 449.79077707027056, 494.76985477729767, 544.2468402550275, 598.6715242805302, 658.5386767085832, 724.3925443794416, 796.8317988173858, 876.5149786991244, 964.166476569037, 1060.5831242259408, 1166.6414366485349, 1283.3055803133884, 1411.6361383447274, 1552.7997521792004, 1708.0797273971205, 1878.8877001368326, 2066.776470150516, 2273.454117165568, 2500.799528882125, 2750.8794817703374, 3025.9674299473713, 3328.5641729421086, 3661.4205902363196, 4027.5626492599517, 4430.3189141859475, 4873.350805604543, 5360.685886164998, 5896.754474781498, 6486.429922259648, 7135.072914485614, 7848.580205934176, 8633.438226527594, 9496.782049180354, 10446.46025409839, 11491.10627950823, 12640.216907459055, 13904.238598204962, 15294.66245802546, 16824.128703828006, 18506.54157421081, 20357.19573163189, 22392.915304795082, 24632.206835274592, 27095.427518802055, 29804.97027068226, 32785.46729775049, 36064.01402752554, 39670.415430278095, 43637.45697330591, 48001.20267063651, 52801.32293770016, 58081.45523147019, 63889.60075461721, 70278.56083007893, 77306.41691308682, 85037.05860439551, 93540.76446483507, 102894.84091131858, 113184.32500245044, 124502.75750269549, 136953.03325296505, 150648.33657826157, 165713.17023608775, 182284.48725969656, 200512.93598566623, 220564.22958423287, 242620.65254265617, 266882.7177969218, 293570.989576614, 322928.0885342754, 355220.897387703, 390742.98712647334, 429817.2858391207, 472799.0144230328, 520078.91586533614, 572086.8074518698, 629295.4881970568, 692225.0370167625, 761447.5407184388, 837592.2947902827, 921351.5242693111, 1013486.6766962423, 1114835.3443658666, 1226318.8788024534, 1348950.7666826989, 1483845.8433509688, 1632230.427686066, 1795453.4704546726, 1974998.81750014, 2172498.699250154, 2389748.56917517, 2628723.426092687, 2891595.768701956, 3180755.345572152, 3498830.8801293676, 3848713.9681423046, 4233585.364956535, 4656943.901452189, 5122638.291597408, 5634902.1207571495, 6198392.332832865, 6818231.566116152, 7500054.722727768, 8250060.195000546, 9075066.2145006, 9982572.835950661, 10980830.119545728, 12078913.131500302, 13286804.444650333, 14615484.889115367, 16077033.378026905, 17684736.715829596, 19453210.387412556, 21398531.426153813, 23538384.568769194, 25892223.025646117, 28481445.32821073, 31329589.861031804, 34462548.847134985, 37908803.731848486, 41699684.10503334, 45869652.51553667, 50456617.76709034, 55502279.543799385, 61052507.49817933, 67157758.24799727, 73873534.072797, 81260887.4800767, 89386976.22808437, 98325673.85089281, 108158241.2359821, 118974065.35958032, 130871471.89553836, 143958619.08509222, 158354480.99360144, 174189929.0929616, 191608922.0022578, 210769814.2024836, 231846795.62273198, 255031475.1850052, 280534622.70350575, 308588084.97385633, 339446893.471242, 373391582.8183662, 410730741.10020286, 451803815.2102232, 496984196.7312456, 546682616.4043702, 601350878.0448073, 661485965.8492881, 727634562.434217, 800398018.6776388, 880437820.5454028, 968481602.5999432, 1065329762.8599375, 1171862739.1459315, 1289049013.0605247, 1417953914.3665774, 1559749305.8032353, 1715724236.383559, 1887296660.021915, 2076026326.0241067, 2283628958.626518, 2511991854.4891696, 2763191039.938087, 3039510143.9318957, 3343461158.3250856, 3677807274.1575947, 4045588001.5733542, 4450146801.73069, 4895161481.903759, 5384677630.094135, 5923145393.103549, 6515459932.413904, 7167005925.655295, 7883706518.220825, 8672077170.042908, 9539284887.0472, 10493213375.75192, 11542534713.327114, 12696788184.659826, 13966467003.12581, 15363113703.438393, 16899425073.782234, 18589367581.160458, 20448304339.276505, 22493134773.204155, 24742448250.524574, 27216693075.577034, 29938362383.13474, 32932198621.448215, 36225418483.59304, 39847960331.95235, 43832756365.14758, 48216032001.662346, 53037635201.82858, 58341398722.011444, 64175538594.21259, 70593092453.63387, 77652401698.99725, 85417641868.89699, 93959406055.7867, 103355346661.36537, 113690881327.50192, 125059969460.25212, 137565966406.27734, 151322563046.9051, 166454819351.5956, 183100301286.7552, 201410331415.43073, 221551364556.97382, 243706501012.6712, 268077151113.93835, 294884866225.3322, 324373352847.8655, 356810688132.65204, 392491756945.9173, 431740932640.50903, 474915025904.56, 522406528495.01605, 574647181344.5177, 632111899478.9695, 695323089426.8665, 764855398369.5532, 841340938206.5087, 925475032027.1597, 1018022535229.8757, 1119824788752.8633, 1231807267628.1497, 1354987994390.9648, 1490486793830.0615, 1639535473213.0679, 1803489020534.3748, 1983837922587.8125, 2182221714846.594, 2400443886331.2534, 2640488274964.379, 2904537102460.817, 3194990812706.899, 3514489893977.589, 3865938883375.348, 4252532771712.8833, 4677786048884.172, 5145564653772.59, 5660121119149.85, 6226133231064.835, 6848746554171.319, 7533621209588.452, 8286983330547.298, 9115681663602.03, 10027249829962.232, 11029974812958.457, 12132972294254.305, 13346269523679.736, 14680896476047.71, 16148986123652.482, 17763884736017.73, 19540273209619.504, 21494300530581.457, 23643730583639.605, 26008103642003.566, 28608914006203.926, 31469805406824.32, 34616785947506.754, 38078464542257.43, 41886310996483.18, 46074942096131.5, 50682436305744.66, 55750679936319.125, 61325747929951.04, 67458322722946.15, 74204154995240.77, 81624570494764.84, 89787027544241.33, 98765730298665.47, 108642303328532.03, 119506533661385.25, 131457187027523.78, 144602905730276.16, 159063196303303.78, 174969515933634.2, 192466467526997.62, 211713114279697.4, 232884425707667.16, 256172868278433.9, 281790155106277.3, 309969170616905.06, 340966087678595.6, 375062696446455.2, 412568966091100.75, 453825862700210.9, 499208448970232.0, 549129293867255.25, 604042223253980.9, 664446445579379.0, 730891090137317.0, 803980199151048.8, 884378219066153.8, 972816040972769.2, 1070097645070046.2, 1177107409577051.0, 1294818150534756.2, 1424299965588232.0, 1566729962147055.2, 1723402958361761.0, 1895743254197937.2, 2085317579617731.2, 2293849337579504.5, 2523234271337455.0, 2775557698471200.5, 3053113468318321.0, 3358424815150153.5, 3694267296665169.0, 4063694026331686.0, 4470063428964855.0, 4917069771861341.0, 5408776749047476.0, 5949654423952224.0, 6544619866347447.0, 7199081852982192.0, 7918990038280412.0, 8710889042108454.0, 9581977946319300.0, 1.054017574095123e+16, 1.1594193315046354e+16, 1.275361264655099e+16, 1.402897391120609e+16, 1.54318713023267e+16, 1.6975058432559372e+16, 1.867256427581531e+16, 2.0539820703396844e+16, 2.2593802773736532e+16, 2.4853183051110188e+16, 2.733850135622121e+16, 3.0072351491843332e+16, 3.3079586641027668e+16, 3.638754530513044e+16, 4.002629983564349e+16, 4.402892981920784e+16, 4.843182280112862e+16, 5.327500508124149e+16, 5.860250558936564e+16, 6.446275614830221e+16, 7.090903176313243e+16, 7.799993493944568e+16, 8.579992843339026e+16, 9.43799212767293e+16, 1.0381791340440224e+17, 1.1419970474484248e+17, 1.2561967521932674e+17, 1.3818164274125942e+17, 1.5199980701538538e+17, 1.6719978771692394e+17, 1.8391976648861635e+17, 2.02311743137478e+17, 2.2254291745122582e+17, 2.447972091963484e+17, 2.6927693011598326e+17, 2.9620462312758163e+17, 3.2582508544033984e+17, 3.584075939843738e+17, 3.9424835338281126e+17, 4.336731887210924e+17, 4.770405075932017e+17, 5.247445583525219e+17, 5.772190141877742e+17, 6.349409156065517e+17, 6.984350071672069e+17, 7.682785078839277e+17, 8.451063586723205e+17, 9.296169945395526e+17, 1.022578693993508e+18, 1.1248365633928589e+18, 1.237320219732145e+18, 1.3610522417053596e+18, 1.4971574658758958e+18, 1.6468732124634854e+18, 1.8115605337098342e+18, 1.992716587080818e+18, 2.1919882457888998e+18, 2.41118707036779e+18, 2.652305777404569e+18, 2.917536355145026e+18, 3.2092899906595287e+18, 3.530218989725482e+18, 3.8832408886980306e+18, 4.271564977567834e+18, 4.698721475324618e+18, 5.16859362285708e+18, 5.685452985142788e+18, 6.253998283657068e+18, 6.879398112022775e+18, 7.567337923225053e+18, 8.324071715547559e+18, 9.156478887102316e+18, 1.0072126775812549e+19, 1.1079339453393805e+19, 1.2187273398733187e+19, 1.3406000738606506e+19, 1.4746600812467157e+19, 1.6221260893713875e+19, 1.7843386983085265e+19, 1.962772568139379e+19, 2.1590498249533174e+19, 2.3749548074486493e+19, 2.6124502881935143e+19, 2.873695317012866e+19, 3.1610648487141528e+19, 3.477171333585568e+19, 3.824888466944125e+19, 4.2073773136385384e+19, 4.628115045002392e+19, 5.090926549502632e+19, 5.600019204452896e+19, 6.160021124898186e+19, 6.776023237388005e+19, 7.453625561126807e+19, 8.198988117239489e+19, 9.018886928963438e+19, 9.920775621859783e+19],
          file_writer: instance(FileWriter):
            event_writer: instance(EventFileWriter),
          filename_suffix: '',
          flush_secs: 15,
          log_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                    10)_20240424-143838',
          max_queue: 10,
          purge_step: None,
      buffer_synchronizer: {'type': 'BufferSynchronizer', 'target_buffer': <reinforcement_learning.base.utility.deque_buffer_wrapper.DequeBufferWrapper object at 0x000001C9EAC66B20>},
      output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                   10)_20240424-143838',
      own_sync_manager: False,
      sync_manager: instance(SyncManager):
        address: '\\\\.\\pipe\\pyc-18060-0-va5x8lx2',
        shutdown: <Finalize object, callback=_finalize_manager, args=(<SpawnProcess name='SyncManager-1' pid=18060 parent=31004 started>, '\\\\.\\pipe\\pyc-18060-0-va5x8lx2', b'd\xec;\x89ZJ!q\xa3\xa5H\xbb\x81q\xfe~\x02\xe3(N)\x05\xf8>!ad\xd5\xccZ/9', <multiprocessing.managers.State object at 0x000001C9EACB0610>, <function Client at 0x000001C9EA3625E0>), exitpriority=0>,
      writing_buffer: deque([], maxlen=5000)
    'text': instance(TextLogger):
      file_name: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                  10)_20240424-143838\\log.txt',
      logger: <Logger multiprocessing (INFO)>,
      output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                   10)_20240424-143838'
  },
  loss_fn: MCTSLossFunction(
  (approximator): MCTSApproximator(
    (model): Sequential(
      (0): Linear(in_features=46, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=88, bias=True)
    )
  )
),
  lower_priority: True,
  lr_scheduler: instance(StepLR):
    base_lrs: [0.0002],
    gamma: 0.1,
    last_epoch: 0,
    optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0002
    lr: 0.0002
    weight_decay: 0
),
    step_size: 1000,
    verbose: False,
  num_of_epochs: 5001,
  number_of_evaluation_agents: 2,
  number_of_training_agents: 5,
  optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0002
    lr: 0.0002
    weight_decay: 0
),
  original_affinity: None,
  output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
               10)_20240424-143838',
  output_profile: False,
  output_root: 'logs/',
  processes: [],
  random_seed: 0,
  replay_buffer: {'type': 'ShuffleReplayBuffer', 'batch_size': 100, 'buffer_size': 0},
  replay_buffer_agent_queue: {'type': 'SequentialReplayBuffer', 'batch_size': 100, 'buffer_size': 100},
  replay_buffer_queue: None,
  replay_buffer_size: 1000,
  replay_buffer_synchronizer: {'type': 'BufferSynchronizer', 'target_buffer': {'type': 'ShuffleReplayBuffer', 'batch_size': 100, 'buffer_size': 0}},
  sync_dict: <DictProxy object, typeid 'dict' at 0x1c9eacb0700>,
  sync_manager: instance(SyncManager):
    address: '\\\\.\\pipe\\pyc-18060-0-va5x8lx2',
    shutdown: <Finalize object, callback=_finalize_manager, args=(<SpawnProcess name='SyncManager-1' pid=18060 parent=31004 started>, '\\\\.\\pipe\\pyc-18060-0-va5x8lx2', b'd\xec;\x89ZJ!q\xa3\xa5H\xbb\x81q\xfe~\x02\xe3(N)\x05\xf8>!ad\xd5\xccZ/9', <multiprocessing.managers.State object at 0x000001C9EACB0610>, <function Client at 0x000001C9EA3625E0>), exitpriority=0>,
  train_episode_length: 100,
  weight_decay: 0

2024-04-24 14:39:25,006 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #0: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 6, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 6, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.05128205128205128, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.31, '(rev, 2)': 0.01}}
2024-04-24 14:39:25,006 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:39:25,019 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #0: {'transition': '(exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, rel, 1, 6, 10, 1, 1),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, nob, not, irr, 1, 0, 9, 0, 1)', 'reward_ratio': '0/1', 'revenue': 0.11627906976744186, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 10)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.44, '(rev, 1)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:39:25,020 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:39:25,036 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #0: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.025, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.26, '(rev, 1)': 0.01}}
1)': 0.42, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:39:25,036 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #0: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.029411764705882353, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(min, 0)': 0.42, '(min, 1)': 0.24, '(rev, 1)': 0.01}}
2024-04-24 14:39:25,036 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:39:25,038 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:39:25,042 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-24 14:39:25,042 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-24 14:39:25,042 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-24 14:39:25,061 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #0: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, rel, 1, 2, 10, 0, 1),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, nob, not, irr, 1, 0, 9, 0, 1)', 'reward_ratio': '0/1', 'revenue': 0.11764705882352941, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.32, '(min, 1)': 0.34, '(rev, 1)': 0.04}}
2024-04-24 14:39:25,062 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:39:25,064 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-24 14:39:27,078 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #0: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.02631578947368421, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.36, '(rev, 1)': 0.01}}
2024-04-24 14:39:27,078 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:39:27,079 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-24 14:40:06,225 - MainProcess - INFO - text_logger.py - 51 - Train epoch #0
2024-04-24 14:40:06,285 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.0509,  0.0000,  0.0000,  0.0000,  0.1385,  0.0000,  0.1335,  0.0083,
         0.1518,  0.0000,  0.1096,  0.0032,  0.0000,  0.0000,  0.0756,  0.0021,
         0.0000,  0.0000,  0.0836,  0.0000,  0.0000,  0.0000,  0.0665,  0.0003,
         0.0000,  0.0000,  0.0628,  0.0000,  0.0000,  0.0000,  0.0472,  0.0000,
         0.0000,  0.0000,  0.0551,  0.0000,  0.0000,  0.0000,  0.0454,  0.0000,
         0.0000,  0.0000,  0.0165,  0.0000,  0.0000])  tensor([0.6359, 0.0000, 0.0000, 0.0000, 0.1162, 0.0000, 0.0713, 0.0498, 0.1125,
        0.0000, 0.0601, 0.0275, 0.0000, 0.0000, 0.0446, 0.0208, 0.0000, 0.0000,
        0.0502, 0.0000, 0.0000, 0.0000, 0.0443, 0.0072, 0.0000, 0.0000, 0.0450,
        0.0000, 0.0000, 0.0000, 0.0380, 0.0000, 0.0000, 0.0000, 0.0471, 0.0000,
        0.0000, 0.0000, 0.0498, 0.0000, 0.0000, 0.0000, 0.0397, 0.0000, 0.0000]) (500)
2024-04-24 14:40:06,518 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4703219336656964
2024-04-24 14:40:06,568 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.073530.04412
2024-04-24 14:40:06,569 - MainProcess - INFO - text_logger.py - 51 - Simulated Policy Revenue 0.017740.01269
2024-04-24 14:40:06,623 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #1: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.32, '(min, 1)': 0.29}}
2024-04-24 14:40:06,624 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:06,625 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-24 14:40:07,817 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #1: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.32, '(min, 1)': 0.32}}
2024-04-24 14:40:07,817 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:07,818 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-24 14:40:08,045 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #1: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.14893617021276595, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.34, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:40:08,046 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:08,050 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-24 14:40:08,947 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #1: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 4, 0, 0),(ado, 4)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/4', 'revenue': 0.05263157894736842, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.01, '(ado, 4)': 0.03, '(ado, 7)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.36, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-04-24 14:40:08,947 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:08,948 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-24 14:40:09,213 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #1: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 5, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.21}}
2024-04-24 14:40:09,214 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:09,214 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-24 14:40:10,459 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #1: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, nob, not, irr, 1, 0, 9, 0, 1),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, rel, 1, 0, 10, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.022222222222222223, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 10)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.31, '(rev, 1)': 0.01}}
2024-04-24 14:40:10,460 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:10,462 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-24 14:40:10,860 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #1: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.02, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.33}}
2024-04-24 14:40:10,860 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:10,861 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-24 14:40:11,063 - MainProcess - INFO - text_logger.py - 51 - Train epoch #1
2024-04-24 14:40:11,068 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.2491,  0.0000,  0.0000,  0.0000,  0.1124,  0.0000,  0.1309,  0.0014,
         0.1275,  0.0000,  0.1132,  0.0005,  0.0000,  0.0000,  0.0836,  0.0008,
         0.0000,  0.0000,  0.0929,  0.0004,  0.0000,  0.0000,  0.0774,  0.0000,
         0.0000,  0.0000,  0.0719,  0.0000,  0.0000,  0.0000,  0.0549,  0.0000,
         0.0000,  0.0000,  0.0623,  0.0000,  0.0000,  0.0000,  0.0508,  0.0000,
         0.0000,  0.0000,  0.0191,  0.0000,  0.0000])  tensor([0.6798, 0.0000, 0.0000, 0.0000, 0.0901, 0.0000, 0.0566, 0.0215, 0.0906,
        0.0000, 0.0469, 0.0118, 0.0000, 0.0000, 0.0367, 0.0122, 0.0000, 0.0000,
        0.0422, 0.0084, 0.0000, 0.0000, 0.0388, 0.0000, 0.0000, 0.0000, 0.0406,
        0.0000, 0.0000, 0.0000, 0.0358, 0.0000, 0.0000, 0.0000, 0.0455, 0.0000,
        0.0000, 0.0000, 0.0499, 0.0000, 0.0000, 0.0000, 0.0421, 0.0000, 0.0000]) (500)
2024-04-24 14:40:11,122 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46937969944757585
2024-04-24 14:40:11,125 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:40:11,577 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #2: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.41, '(min, 1)': 0.2}}
2024-04-24 14:40:11,578 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:11,579 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-04-24 14:40:12,661 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #2: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.57, '(min, 1)': 0.03}}
2024-04-24 14:40:12,661 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:12,664 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-04-24 14:40:13,109 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #2: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.41, '(min, 1)': 0.27}}
2024-04-24 14:40:13,111 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:13,112 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-04-24 14:40:13,646 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #2: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 5, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 4)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.21, '(rev, 1)': 0.04, '(rev, 2)': 0.02}}
2024-04-24 14:40:13,647 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:13,648 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-04-24 14:40:14,006 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #2: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 3)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.22}}
2024-04-24 14:40:14,007 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:14,007 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-04-24 14:40:19,729 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #2: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.29}}
2024-04-24 14:40:19,730 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:19,731 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-04-24 14:40:20,085 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #2: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.36585365853658536, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.45, '(rev, 1)': 0.01, '(rev, 2)': 0.02}}
2024-04-24 14:40:20,085 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:20,086 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-04-24 14:40:20,283 - MainProcess - INFO - text_logger.py - 51 - Train epoch #2
2024-04-24 14:40:20,287 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.2749,  0.0000,  0.0000,  0.0000,  0.1084,  0.0000,  0.1138,  0.0048,
         0.1192,  0.0000,  0.1043,  0.0024,  0.0000,  0.0000,  0.0860,  0.0000,
         0.0000,  0.0000,  0.0872,  0.0000,  0.0000,  0.0000,  0.0770,  0.0000,
         0.0000,  0.0000,  0.0825,  0.0000,  0.0000,  0.0000,  0.0593,  0.0000,
         0.0000,  0.0000,  0.0723,  0.0000,  0.0000,  0.0000,  0.0616,  0.0000,
         0.0000,  0.0000,  0.0212,  0.0000,  0.0000])  tensor([0.7598, 0.0000, 0.0000, 0.0000, 0.1003, 0.0000, 0.0513, 0.0379, 0.0988,
        0.0000, 0.0411, 0.0236, 0.0000, 0.0000, 0.0345, 0.0000, 0.0000, 0.0000,
        0.0360, 0.0000, 0.0000, 0.0000, 0.0336, 0.0000, 0.0000, 0.0000, 0.0381,
        0.0000, 0.0000, 0.0000, 0.0305, 0.0000, 0.0000, 0.0000, 0.0403, 0.0000,
        0.0000, 0.0000, 0.0503, 0.0000, 0.0000, 0.0000, 0.0408, 0.0000, 0.0000]) (500)
2024-04-24 14:40:20,313 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46843746522945523
2024-04-24 14:40:20,318 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:40:20,330 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #3: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.32, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(ado, 8)': 0.02, '(min, 0)': 0.47, '(min, 1)': 0.25, '(rev, 1)': 0.02, '(rev, 2)': 0.02}}
2024-04-24 14:40:20,331 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:20,332 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-04-24 14:40:20,348 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #3: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.29}}
2024-04-24 14:40:20,350 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:20,351 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-04-24 14:40:20,377 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #3: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.51, '(min, 1)': 0.11}}
2024-04-24 14:40:20,378 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:20,379 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-04-24 14:40:20,508 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #3: {'transition': '(exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 2, 9, 1, 1),(min, 0)->(exi, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 3, 9, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.29, '(min, 1)': 0.3}}
2024-04-24 14:40:20,510 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:20,511 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-04-24 14:40:22,090 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #3: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 0, 8, 0, 1),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 1, 8, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.02, '(min, 0)': 0.45, '(min, 1)': 0.26}}
2024-04-24 14:40:22,090 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:22,097 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-04-24 14:40:24,165 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #3: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.43, '(min, 1)': 0.21}}
2024-04-24 14:40:24,166 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:24,167 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-04-24 14:40:24,521 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #3: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 7)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.29}}
2024-04-24 14:40:24,521 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:24,522 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-04-24 14:40:24,732 - MainProcess - INFO - text_logger.py - 51 - Train epoch #3
2024-04-24 14:40:24,737 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.4370,  0.0000,  0.0000,  0.0000,  0.0995,  0.0000,  0.1134,  0.0012,
         0.1097,  0.0000,  0.1071,  0.0009,  0.0000,  0.0000,  0.0948,  0.0006,
         0.0000,  0.0000,  0.0875,  0.0000,  0.0000,  0.0000,  0.0875,  0.0000,
         0.0000,  0.0000,  0.0897,  0.0000,  0.0000,  0.0000,  0.0554,  0.0000,
         0.0000,  0.0000,  0.0753,  0.0000,  0.0000,  0.0000,  0.0595,  0.0000,
         0.0000,  0.0000,  0.0181,  0.0000,  0.0000])  tensor([0.7811, 0.0000, 0.0000, 0.0000, 0.0834, 0.0000, 0.0437, 0.0196, 0.0840,
        0.0000, 0.0341, 0.0141, 0.0000, 0.0000, 0.0304, 0.0089, 0.0000, 0.0000,
        0.0297, 0.0000, 0.0000, 0.0000, 0.0321, 0.0000, 0.0000, 0.0000, 0.0368,
        0.0000, 0.0000, 0.0000, 0.0260, 0.0000, 0.0000, 0.0000, 0.0410, 0.0000,
        0.0000, 0.0000, 0.0460, 0.0000, 0.0000, 0.0000, 0.0339, 0.0000, 0.0000]) (500)
2024-04-24 14:40:24,768 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46749523101133467
2024-04-24 14:40:24,771 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:40:24,827 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #4: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.21, '(min, 1)': 0.39}}
2024-04-24 14:40:24,827 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:24,828 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-04-24 14:40:25,496 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #4: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 4, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.44, '(min, 1)': 0.19}}
2024-04-24 14:40:25,497 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:25,497 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-04-24 14:40:26,784 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #4: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 4)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.32}}
2024-04-24 14:40:26,784 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:26,785 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-04-24 14:40:28,647 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #4: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 1, 1, 10, 1, 1),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 0, 9, 0, 1)', 'reward_ratio': '0/1', 'revenue': 0.20454545454545456, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 10)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.27, '(rev, 1)': 0.01, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:40:28,647 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:28,649 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-04-24 14:40:28,715 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #4: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.23}}
2024-04-24 14:40:28,715 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:28,716 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-04-24 14:40:29,375 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #4: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.29, '(min, 1)': 0.33}}
2024-04-24 14:40:29,376 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:29,376 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-04-24 14:40:29,490 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #4: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 6, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.020833333333333332, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.27, '(rev, 1)': 0.01}}
2024-04-24 14:40:29,490 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:29,491 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-04-24 14:40:29,693 - MainProcess - INFO - text_logger.py - 51 - Train epoch #4
2024-04-24 14:40:29,697 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.7685e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1046e-01,
         0.0000e+00,  1.2044e-01,  1.1654e-03,  1.1943e-01,  0.0000e+00,
         1.1254e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.5067e-02,
         2.4242e-04,  0.0000e+00,  0.0000e+00,  8.1553e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  8.9473e-02,  1.4815e-04,  0.0000e+00,
         0.0000e+00,  8.9990e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         4.7644e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  7.4368e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.8004e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  9.4771e-03,  0.0000e+00,  0.0000e+00])  tensor([0.6829, 0.0000, 0.0000, 0.0000, 0.0853, 0.0000, 0.0451, 0.0184, 0.0836,
        0.0000, 0.0378, 0.0000, 0.0000, 0.0000, 0.0326, 0.0054, 0.0000, 0.0000,
        0.0307, 0.0000, 0.0000, 0.0000, 0.0358, 0.0033, 0.0000, 0.0000, 0.0405,
        0.0000, 0.0000, 0.0000, 0.0244, 0.0000, 0.0000, 0.0000, 0.0409, 0.0000,
        0.0000, 0.0000, 0.0403, 0.0000, 0.0000, 0.0000, 0.0219, 0.0000, 0.0000]) (500)
2024-04-24 14:40:29,716 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4665529967932141
2024-04-24 14:40:29,720 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:40:29,726 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #5: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.24390243902439024, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.46, '(min, 1)': 0.22, '(rev, 10)': 0.01}}
2024-04-24 14:40:29,727 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:29,729 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-04-24 14:40:29,977 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #5: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.34, '(min, 1)': 0.29}}
2024-04-24 14:40:29,980 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:29,981 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-04-24 14:40:32,959 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #5: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, nob, not, nob, not, rel, 1, 1, 8, 0, 1),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, nob, not, nob, not, irr, 1, 2, 8, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.22641509433962265, 'length': 100, 'actions': {'(ado, 1)': 0.06, '(ado, 2)': 0.03, '(ado, 4)': 0.02, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.42, '(rev, 1)': 0.04, '(rev, 4)': 0.02}}
2024-04-24 14:40:32,960 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:32,961 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-04-24 14:40:34,122 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #5: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 4, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 10)': 0.01, '(ado, 3)': 0.02, '(ado, 9)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.25}}
2024-04-24 14:40:34,122 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:34,123 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-04-24 14:40:36,871 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #5: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.03508771929824561, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 7)': 0.01, '(ado, 9)': 0.02, '(min, 0)': 0.32, '(min, 1)': 0.38, '(rev, 1)': 0.02}}
2024-04-24 14:40:36,872 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:36,872 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-04-24 14:40:38,434 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #5: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, rel, 1, 0, 10, 0, 1),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, nob, not, irr, 1, 0, 9, 0, 1)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.35, '(min, 1)': 0.29}}
2024-04-24 14:40:38,435 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:38,436 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-04-24 14:40:38,600 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #5: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.31}}
2024-04-24 14:40:38,601 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:38,602 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-04-24 14:40:38,799 - MainProcess - INFO - text_logger.py - 51 - Train epoch #5
2024-04-24 14:40:38,802 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.3213e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2581e-01,
         0.0000e+00,  1.3036e-01,  3.2301e-03,  1.2873e-01,  0.0000e+00,
         1.1640e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.9801e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  7.7022e-02,  2.5714e-04,
         0.0000e+00,  0.0000e+00,  8.6918e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  9.1935e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.5495e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.1368e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.6515e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.1547e-03,  0.0000e+00,  0.0000e+00])  tensor([0.7028, 0.0000, 0.0000, 0.0000, 0.1011, 0.0000, 0.0541, 0.0293, 0.0961,
        0.0000, 0.0464, 0.0000, 0.0000, 0.0000, 0.0419, 0.0000, 0.0000, 0.0000,
        0.0373, 0.0041, 0.0000, 0.0000, 0.0441, 0.0000, 0.0000, 0.0000, 0.0523,
        0.0000, 0.0000, 0.0000, 0.0254, 0.0000, 0.0000, 0.0000, 0.0467, 0.0000,
        0.0000, 0.0000, 0.0384, 0.0000, 0.0000, 0.0000, 0.0140, 0.0000, 0.0000]) (500)
2024-04-24 14:40:38,820 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46585466501411793
2024-04-24 14:40:38,824 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.121950.12195
2024-04-24 14:40:38,832 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.44, '(min, 1)': 0.16}}
2024-04-24 14:40:38,833 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:38,835 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-04-24 14:40:38,878 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.26, '(rev, 1)': 0.01}}
2024-04-24 14:40:38,878 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 4, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.038461538461538464, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.27, '(rev, 2)': 0.01}}
2024-04-24 14:40:38,878 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:38,878 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:38,879 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-04-24 14:40:38,879 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-04-24 14:40:41,019 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #6: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 4)': 0.01, '(ado, 6)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.37}}
2024-04-24 14:40:41,020 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:41,021 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-04-24 14:40:41,760 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.38, '(rev, 6)': 0.01}}
2024-04-24 14:40:41,761 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:41,762 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-04-24 14:40:44,090 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 2, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.29}}
2024-04-24 14:40:44,090 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:44,091 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-04-24 14:40:46,502 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2653061224489796, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.37, '(rev, 1)': 0.03}}
2024-04-24 14:40:46,503 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:46,503 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-04-24 14:40:46,692 - MainProcess - INFO - text_logger.py - 51 - Train epoch #6
2024-04-24 14:40:46,696 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.1305e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2509e-01,
         0.0000e+00,  1.3462e-01,  1.4188e-03,  1.2737e-01,  0.0000e+00,
         1.1998e-01,  2.6667e-04,  0.0000e+00,  0.0000e+00,  1.0545e-01,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  7.6159e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  9.0372e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  9.2950e-02,  7.4074e-05,  0.0000e+00,  0.0000e+00,
         3.2772e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.2706e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8623e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  2.1467e-03,  0.0000e+00,  0.0000e+00])  tensor([0.8490, 0.0000, 0.0000, 0.0000, 0.0861, 0.0000, 0.0498, 0.0183, 0.0814,
        0.0000, 0.0433, 0.0060, 0.0000, 0.0000, 0.0401, 0.0000, 0.0000, 0.0000,
        0.0340, 0.0000, 0.0000, 0.0000, 0.0427, 0.0000, 0.0000, 0.0000, 0.0522,
        0.0017, 0.0000, 0.0000, 0.0216, 0.0000, 0.0000, 0.0000, 0.0457, 0.0000,
        0.0000, 0.0000, 0.0330, 0.0000, 0.0000, 0.0000, 0.0074, 0.0000, 0.0000]) (500)
2024-04-24 14:40:46,716 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46515687524044175
2024-04-24 14:40:46,720 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.122220.12222
2024-04-24 14:40:46,738 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #7: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5116279069767442, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 7)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.37, '(rev, 1)': 0.03, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:40:46,738 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:46,740 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-04-24 14:40:46,769 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #7: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 5, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.21}}
2024-04-24 14:40:46,770 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:46,771 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-04-24 14:40:47,971 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #7: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.28, '(min, 1)': 0.33}}
2024-04-24 14:40:47,971 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:47,972 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-04-24 14:40:49,431 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #7: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 5, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.36}}
2024-04-24 14:40:49,431 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:49,432 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-04-24 14:40:50,616 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #7: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.020833333333333332, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 4)': 0.02, '(ado, 5)': 0.01, '(ado, 7)': 0.02, '(min, 0)': 0.3, '(min, 1)': 0.45, '(rev, 1)': 0.01}}
2024-04-24 14:40:50,617 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:50,617 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-04-24 14:40:50,652 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #7: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.09302325581395349, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.42, '(rev, 2)': 0.02}}
2024-04-24 14:40:50,655 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:50,657 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-04-24 14:40:51,548 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #7: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(ado, 4)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.16}}
2024-04-24 14:40:51,550 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:51,550 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-04-24 14:40:51,756 - MainProcess - INFO - text_logger.py - 51 - Train epoch #7
2024-04-24 14:40:51,761 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.2760,  0.0000,  0.0000,  0.0000,  0.1087,  0.0000,  0.1350,  0.0004,
         0.1081,  0.0000,  0.1192,  0.0005,  0.0000,  0.0000,  0.1132,  0.0000,
         0.0000,  0.0000,  0.0839,  0.0000,  0.0000,  0.0000,  0.0997,  0.0000,
         0.0000,  0.0000,  0.1038,  0.0000,  0.0000,  0.0000,  0.0356,  0.0000,
         0.0000,  0.0000,  0.0653,  0.0000,  0.0000,  0.0000,  0.0253,  0.0000,
         0.0000,  0.0000,  0.0012,  0.0000,  0.0000])  tensor([0.7433, 0.0000, 0.0000, 0.0000, 0.0722, 0.0000, 0.0370, 0.0097, 0.0669,
        0.0000, 0.0313, 0.0067, 0.0000, 0.0000, 0.0301, 0.0000, 0.0000, 0.0000,
        0.0256, 0.0000, 0.0000, 0.0000, 0.0320, 0.0000, 0.0000, 0.0000, 0.0400,
        0.0000, 0.0000, 0.0000, 0.0171, 0.0000, 0.0000, 0.0000, 0.0390, 0.0000,
        0.0000, 0.0000, 0.0277, 0.0000, 0.0000, 0.0000, 0.0047, 0.0000, 0.0000]) (500)
2024-04-24 14:40:51,830 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4647262689292979
2024-04-24 14:40:51,835 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.255810.25581
2024-04-24 14:40:51,882 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #8: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.44, '(min, 0)': 0.41, '(min, 1)': 0.15}}
2024-04-24 14:40:51,882 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #8: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 3, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.02, '(min, 0)': 0.42, '(min, 1)': 0.31}}
2024-04-24 14:40:51,882 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:51,882 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:51,883 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-04-24 14:40:51,883 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-04-24 14:40:52,653 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #8: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.46, '(min, 1)': 0.16}}
2024-04-24 14:40:52,654 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:52,655 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-04-24 14:40:55,657 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #8: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.31}}
2024-04-24 14:40:55,657 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:55,659 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-04-24 14:40:55,844 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #8: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.38636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.43, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:40:55,844 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:55,845 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-04-24 14:40:55,850 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #8: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.34, '(rev, 1)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:40:55,851 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:55,851 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-04-24 14:40:56,379 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #8: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(ado, 9)': 0.02, '(min, 0)': 0.25, '(min, 1)': 0.44}}
2024-04-24 14:40:56,380 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:56,382 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-04-24 14:40:56,572 - MainProcess - INFO - text_logger.py - 51 - Train epoch #8
2024-04-24 14:40:56,575 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.2338e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4610e-01,
         0.0000e+00,  1.4827e-01,  2.2367e-03,  1.4067e-01,  0.0000e+00,
         1.2631e-01,  1.6514e-04,  0.0000e+00,  0.0000e+00,  1.1219e-01,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  7.5760e-02,  1.3118e-04,
         0.0000e+00,  0.0000e+00,  8.3356e-02,  7.1429e-05,  0.0000e+00,
         0.0000e+00,  8.3329e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.6762e-02,  6.6667e-05,  0.0000e+00,  0.0000e+00,  4.2627e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1608e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.4037e-04,  0.0000e+00,  0.0000e+00])  tensor([0.9523, 0.0000, 0.0000, 0.0000, 0.1022, 0.0000, 0.0551, 0.0203, 0.0916,
        0.0000, 0.0482, 0.0037, 0.0000, 0.0000, 0.0473, 0.0000, 0.0000, 0.0000,
        0.0381, 0.0021, 0.0000, 0.0000, 0.0474, 0.0016, 0.0000, 0.0000, 0.0520,
        0.0000, 0.0000, 0.0000, 0.0198, 0.0015, 0.0000, 0.0000, 0.0387, 0.0000,
        0.0000, 0.0000, 0.0183, 0.0000, 0.0000, 0.0000, 0.0024, 0.0000, 0.0000]) (500)
2024-04-24 14:40:56,593 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46378403471117735
2024-04-24 14:40:56,599 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:40:56,619 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #9: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 4)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.28}}
2024-04-24 14:40:56,620 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:56,623 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-04-24 14:40:56,653 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #9: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.47, '(min, 0)': 0.44, '(min, 1)': 0.09}}
2024-04-24 14:40:56,654 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:56,656 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-04-24 14:40:57,347 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #9: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.26, '(min, 1)': 0.31}}
2024-04-24 14:40:57,347 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:40:57,348 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-04-24 14:41:00,719 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #9: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.19047619047619047, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.31, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:41:00,719 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:00,720 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-04-24 14:41:00,868 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #9: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.04081632653061224, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.28, '(rev, 1)': 0.02}}
2024-04-24 14:41:00,869 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:00,870 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-04-24 14:41:03,564 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #9: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 2, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 5)': 0.02, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.3}}
2024-04-24 14:41:03,565 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:03,567 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-04-24 14:41:04,047 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #9: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.38, '(min, 1)': 0.36, '(rev, 1)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:41:04,047 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:04,048 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-04-24 14:41:04,263 - MainProcess - INFO - text_logger.py - 51 - Train epoch #9
2024-04-24 14:41:04,267 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.0845e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3351e-01, 0.0000e+00,
        1.5016e-01, 1.7154e-03, 1.2747e-01, 0.0000e+00, 1.2825e-01, 1.2903e-04,
        0.0000e+00, 0.0000e+00, 1.1680e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.0408e-02, 1.1765e-04, 0.0000e+00, 0.0000e+00, 9.0740e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.8899e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9282e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2512e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.5814e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.1614e-04, 0.0000e+00, 0.0000e+00])  tensor([0.7108, 0.0000, 0.0000, 0.0000, 0.0945, 0.0000, 0.0492, 0.0171, 0.0830,
        0.0000, 0.0425, 0.0029, 0.0000, 0.0000, 0.0429, 0.0000, 0.0000, 0.0000,
        0.0355, 0.0019, 0.0000, 0.0000, 0.0438, 0.0000, 0.0000, 0.0000, 0.0495,
        0.0000, 0.0000, 0.0000, 0.0190, 0.0000, 0.0000, 0.0000, 0.0377, 0.0000,
        0.0000, 0.0000, 0.0156, 0.0000, 0.0000, 0.0000, 0.0025, 0.0000, 0.0000]) (500)
2024-04-24 14:41:04,286 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4628418004930568
2024-04-24 14:41:04,288 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:41:04,295 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.52, '(min, 1)': 0.17}}
2024-04-24 14:41:04,296 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:04,297 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-04-24 14:41:04,325 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #10: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 5, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.08695652173913043, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.54, '(min, 1)': 0.23, '(rev, 4)': 0.01}}
2024-04-24 14:41:04,325 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:04,326 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-04-24 14:41:04,340 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.027777777777777776, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.41, '(min, 1)': 0.23, '(rev, 1)': 0.01}}
2024-04-24 14:41:04,341 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:04,342 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-04-24 14:41:06,275 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3684210526315789, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.42, '(rev, 1)': 0.01, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:41:06,276 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:06,277 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-04-24 14:41:08,363 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.48, '(min, 1)': 0.15}}
2024-04-24 14:41:08,363 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:08,364 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-04-24 14:41:08,939 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.15789473684210525, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(ado, 5)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.35, '(rev, 2)': 0.03}}
2024-04-24 14:41:08,940 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:08,945 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-04-24 14:41:11,214 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.11627906976744186, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.33, '(rev, 5)': 0.01}}
2024-04-24 14:41:11,214 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:11,215 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-04-24 14:41:11,411 - MainProcess - INFO - text_logger.py - 51 - Train epoch #10
2024-04-24 14:41:11,415 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.6141e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4978e-01,
         0.0000e+00,  1.6110e-01,  8.4094e-04,  1.3691e-01,  0.0000e+00,
         1.2972e-01,  7.2803e-04,  0.0000e+00,  0.0000e+00,  1.1509e-01,
         2.5941e-04,  0.0000e+00,  0.0000e+00,  7.5663e-02,  6.6667e-05,
         0.0000e+00,  0.0000e+00,  7.9413e-02,  6.6667e-05,  0.0000e+00,
         0.0000e+00,  7.7207e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.6002e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.7472e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  9.0707e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.2120e-04,  0.0000e+00,  0.0000e+00])  tensor([1.0480, 0.0000, 0.0000, 0.0000, 0.1091, 0.0000, 0.0564, 0.0095, 0.0934,
        0.0000, 0.0495, 0.0065, 0.0000, 0.0000, 0.0509, 0.0031, 0.0000, 0.0000,
        0.0395, 0.0015, 0.0000, 0.0000, 0.0457, 0.0015, 0.0000, 0.0000, 0.0489,
        0.0000, 0.0000, 0.0000, 0.0187, 0.0000, 0.0000, 0.0000, 0.0314, 0.0000,
        0.0000, 0.0000, 0.0139, 0.0000, 0.0000, 0.0000, 0.0031, 0.0000, 0.0000]) (500)
2024-04-24 14:41:11,436 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4619273440527139
2024-04-24 14:41:11,439 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.013890.01389
2024-04-24 14:41:11,489 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #11: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 4, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.39, '(min, 1)': 0.26}}
2024-04-24 14:41:11,490 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:11,491 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-04-24 14:41:11,506 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #11: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 5, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8043478260869565, 'length': 100, 'actions': {'(ado, 1)': 0.05, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.48, '(rev, 1)': 0.04, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.03}}
2024-04-24 14:41:11,506 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #11: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.49, '(min, 1)': 0.11}}
2024-04-24 14:41:11,507 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:11,507 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:11,507 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-04-24 14:41:11,507 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-04-24 14:41:12,899 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #11: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 4, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 9)': 0.02, '(min, 0)': 0.37, '(min, 1)': 0.3}}
2024-04-24 14:41:12,900 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:12,900 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-04-24 14:41:16,077 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #11: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 6, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 5, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0425531914893617, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 3)': 0.01, '(ado, 5)': 0.02, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.27, '(rev, 2)': 0.01}}
2024-04-24 14:41:16,078 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:16,079 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-04-24 14:41:16,653 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #11: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.18181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.42, '(min, 1)': 0.28, '(rev, 8)': 0.01}}
2024-04-24 14:41:16,654 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:16,655 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-04-24 14:41:16,726 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #11: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.37}}
2024-04-24 14:41:16,726 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:16,727 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-04-24 14:41:16,950 - MainProcess - INFO - text_logger.py - 51 - Train epoch #11
2024-04-24 14:41:16,953 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.2525e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7271e-01, 0.0000e+00,
        1.6679e-01, 3.3844e-03, 1.4920e-01, 0.0000e+00, 1.2736e-01, 1.9751e-03,
        0.0000e+00, 0.0000e+00, 1.1377e-01, 1.6745e-03, 0.0000e+00, 0.0000e+00,
        7.0703e-02, 9.9183e-04, 0.0000e+00, 0.0000e+00, 7.5141e-02, 5.7477e-04,
        0.0000e+00, 0.0000e+00, 6.5990e-02, 8.3464e-05, 0.0000e+00, 0.0000e+00,
        2.1871e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3034e-02, 6.2500e-05,
        0.0000e+00, 0.0000e+00, 4.3102e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.6525e-04, 0.0000e+00, 0.0000e+00])  tensor([1.4961e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2454e-01, 0.0000e+00,
        5.9621e-02, 1.6888e-02, 9.3327e-02, 0.0000e+00, 5.2142e-02, 8.7547e-03,
        0.0000e+00, 0.0000e+00, 5.3971e-02, 7.0405e-03, 0.0000e+00, 0.0000e+00,
        3.9460e-02, 4.5704e-03, 0.0000e+00, 0.0000e+00, 4.7493e-02, 3.5879e-03,
        0.0000e+00, 0.0000e+00, 4.8140e-02, 1.0814e-03, 0.0000e+00, 0.0000e+00,
        1.8439e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4696e-02, 1.3975e-03,
        0.0000e+00, 0.0000e+00, 9.5567e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3669e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:41:17,024 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46098510983459334
2024-04-24 14:41:17,027 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:41:17,077 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #12: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.39, '(min, 1)': 0.18}}
2024-04-24 14:41:17,077 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:17,079 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-04-24 14:41:18,886 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #12: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.46, '(min, 1)': 0.16}}
2024-04-24 14:41:18,887 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:18,887 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-04-24 14:41:19,657 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #12: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.23}}
2024-04-24 14:41:19,658 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:19,659 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-04-24 14:41:19,737 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #12: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17391304347826086, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.28, '(rev, 1)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:41:19,737 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:19,738 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-04-24 14:41:21,268 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #12: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 6)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.2}}
2024-04-24 14:41:21,269 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:21,272 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-04-24 14:41:21,408 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #12: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.55, '(min, 1)': 0.14}}
2024-04-24 14:41:21,408 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:21,409 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-04-24 14:41:21,531 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #12: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.04878048780487805, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 8)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.17, '(rev, 2)': 0.01}}
2024-04-24 14:41:21,532 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:21,532 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-04-24 14:41:21,739 - MainProcess - INFO - text_logger.py - 51 - Train epoch #12
2024-04-24 14:41:21,743 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-4.5656e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1426e-01,
         0.0000e+00,  1.5901e-01,  2.1495e-04,  1.0502e-01,  0.0000e+00,
         1.3796e-01,  7.1429e-05,  0.0000e+00,  0.0000e+00,  1.3043e-01,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  8.9096e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  9.1562e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  9.2157e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.0433e-02,  6.6667e-05,  0.0000e+00,  0.0000e+00,  4.0114e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  8.2744e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  1.3347e-03,  0.0000e+00,  0.0000e+00])  tensor([0.7962, 0.0000, 0.0000, 0.0000, 0.0875, 0.0000, 0.0399, 0.0048, 0.0737,
        0.0000, 0.0332, 0.0016, 0.0000, 0.0000, 0.0359, 0.0000, 0.0000, 0.0000,
        0.0312, 0.0000, 0.0000, 0.0000, 0.0367, 0.0000, 0.0000, 0.0000, 0.0414,
        0.0000, 0.0000, 0.0000, 0.0162, 0.0015, 0.0000, 0.0000, 0.0262, 0.0000,
        0.0000, 0.0000, 0.0113, 0.0000, 0.0000, 0.0000, 0.0044, 0.0000, 0.0000]) (500)
2024-04-24 14:41:21,770 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4600428756164728
2024-04-24 14:41:21,774 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:41:22,644 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #13: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 0, 8, 0, 0),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 1, 8, 1, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.45, '(min, 1)': 0.16}}
2024-04-24 14:41:22,645 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:22,646 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-04-24 14:41:25,084 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #13: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.18}}
2024-04-24 14:41:25,084 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:25,085 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-04-24 14:41:25,613 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #13: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 3, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36585365853658536, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 7)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.24, '(rev, 5)': 0.01}}
2024-04-24 14:41:25,614 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:25,615 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-04-24 14:41:26,643 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #13: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 3, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.29}}
2024-04-24 14:41:26,644 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:26,645 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-04-24 14:41:28,160 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #13: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.28}}
2024-04-24 14:41:28,161 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:28,162 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-04-24 14:41:28,262 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #13: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2982456140350877, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 4)': 0.02, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.38, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:41:28,263 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:28,264 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-04-24 14:41:30,054 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #13: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 1, 1, 9, 1, 1),(min, 0)->(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 2, 9, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.36}}
2024-04-24 14:41:30,055 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:30,056 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-04-24 14:41:30,247 - MainProcess - INFO - text_logger.py - 51 - Train epoch #13
2024-04-24 14:41:30,251 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([9.0063e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5436e-01, 0.0000e+00,
        1.8150e-01, 6.1104e-04, 1.4030e-01, 0.0000e+00, 1.3727e-01, 6.0606e-05,
        0.0000e+00, 0.0000e+00, 1.1722e-01, 4.3478e-05, 0.0000e+00, 0.0000e+00,
        7.4198e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7105e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.3506e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5802e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4387e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2449e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.9423e-04, 0.0000e+00, 0.0000e+00])  tensor([1.1919e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0242e-01, 0.0000e+00,
        4.7654e-02, 6.4607e-03, 7.9749e-02, 0.0000e+00, 3.9105e-02, 1.3552e-03,
        0.0000e+00, 0.0000e+00, 4.2390e-02, 9.7220e-04, 0.0000e+00, 0.0000e+00,
        3.2807e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9199e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.6444e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7838e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2314e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.5063e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3684e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:41:30,276 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4594664950568888
2024-04-24 14:41:30,279 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.182930.18293
2024-04-24 14:41:30,326 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #14: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.61, '(min, 1)': 0.02}}
2024-04-24 14:41:30,327 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:30,328 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-04-24 14:41:30,967 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #14: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 4)': 0.01, '(ado, 5)': 0.03, '(min, 0)': 0.53, '(min, 1)': 0.13}}
2024-04-24 14:41:30,967 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:30,967 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-04-24 14:41:31,098 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #14: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 5, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 8)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.34, '(rev, 3)': 0.01}}
2024-04-24 14:41:31,099 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:31,100 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-04-24 14:41:31,682 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #14: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2127659574468085, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.19, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:41:31,683 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:31,684 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-04-24 14:41:32,962 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #14: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 6)': 0.02, '(min, 0)': 0.53, '(min, 1)': 0.16}}
2024-04-24 14:41:32,962 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:32,964 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-04-24 14:41:34,918 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #14: {'transition': '(exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 1, 3, 8, 1, 1),(min, 0)->(exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 1, 3, 9, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.38636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.08, '(ado, 3)': 0.02, '(ado, 4)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.32, '(rev, 1)': 0.03, '(rev, 10)': 0.01, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:41:34,919 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:34,919 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-04-24 14:41:37,667 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #14: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 0, 9, 0, 1),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 1, 9, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.31}}
2024-04-24 14:41:37,667 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:37,669 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-04-24 14:41:37,877 - MainProcess - INFO - text_logger.py - 51 - Train epoch #14
2024-04-24 14:41:37,880 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-4.8173e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2343e-01,
         0.0000e+00,  1.5561e-01,  1.0693e-03,  1.0808e-01,  0.0000e+00,
         1.3823e-01,  6.1929e-04,  0.0000e+00,  0.0000e+00,  1.3190e-01,
         2.6391e-04,  0.0000e+00,  0.0000e+00,  9.1785e-02,  1.0833e-04,
         0.0000e+00,  0.0000e+00,  9.0953e-02,  7.6923e-05,  0.0000e+00,
         0.0000e+00,  8.7833e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.8796e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.3285e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  6.7302e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  1.1562e-03,  6.4516e-05,  0.0000e+00])  tensor([1.1898, 0.0000, 0.0000, 0.0000, 0.1192, 0.0000, 0.0486, 0.0080, 0.0882,
        0.0000, 0.0428, 0.0040, 0.0000, 0.0000, 0.0467, 0.0025, 0.0000, 0.0000,
        0.0406, 0.0018, 0.0000, 0.0000, 0.0470, 0.0017, 0.0000, 0.0000, 0.0534,
        0.0000, 0.0000, 0.0000, 0.0200, 0.0000, 0.0000, 0.0000, 0.0256, 0.0000,
        0.0000, 0.0000, 0.0104, 0.0000, 0.0000, 0.0000, 0.0042, 0.0014, 0.0000]) (500)
2024-04-24 14:41:37,906 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.45880686953442046
2024-04-24 14:41:37,910 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.141300.14130
2024-04-24 14:41:37,924 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #15: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 6, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.44, '(min, 1)': 0.15}}
o, 3)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.23, '(rev, 10)': 0.01}}
2024-04-24 14:41:37,925 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty

2024-04-24 14:41:37,926 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-04-24 14:41:37,926 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-04-24 14:41:37,972 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #15: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 6, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.34, '(min, 1)': 0.24}}
2024-04-24 14:41:37,973 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:37,983 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-04-24 14:41:38,002 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #15: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 1, 7, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 2, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.27}}
2024-04-24 14:41:38,003 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:38,004 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-04-24 14:41:39,896 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #15: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 2, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.038461538461538464, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.34, '(rev, 2)': 0.01}}
2024-04-24 14:41:39,897 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:39,898 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-04-24 14:41:42,860 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #15: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 3, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.06382978723404255, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 8)': 0.02, '(min, 0)': 0.4, '(min, 1)': 0.33, '(rev, 3)': 0.01}}
2024-04-24 14:41:42,860 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:42,861 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-04-24 14:41:43,264 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #15: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.17}}
2024-04-24 14:41:43,265 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:43,266 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-04-24 14:41:43,454 - MainProcess - INFO - text_logger.py - 51 - Train epoch #15
2024-04-24 14:41:43,458 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.1737e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5253e-01, 0.0000e+00,
        1.9077e-01, 0.0000e+00, 1.3914e-01, 0.0000e+00, 1.4270e-01, 4.4444e-05,
        0.0000e+00, 0.0000e+00, 1.1073e-01, 6.0606e-05, 0.0000e+00, 0.0000e+00,
        7.7842e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0702e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.4214e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8052e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0754e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.2048e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8350e-04, 6.6667e-05, 0.0000e+00])  tensor([0.9119, 0.0000, 0.0000, 0.0000, 0.0906, 0.0000, 0.0489, 0.0000, 0.0682,
        0.0000, 0.0330, 0.0010, 0.0000, 0.0000, 0.0336, 0.0014, 0.0000, 0.0000,
        0.0304, 0.0000, 0.0000, 0.0000, 0.0315, 0.0000, 0.0000, 0.0000, 0.0325,
        0.0000, 0.0000, 0.0000, 0.0194, 0.0000, 0.0000, 0.0000, 0.0219, 0.0000,
        0.0000, 0.0000, 0.0063, 0.0000, 0.0000, 0.0000, 0.0017, 0.0015, 0.0000]) (500)
2024-04-24 14:41:43,482 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4578646353162999
2024-04-24 14:41:43,488 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:41:43,547 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #16: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.12195121951219512, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.28, '(rev, 5)': 0.01}}
2024-04-24 14:41:43,547 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #16: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.37, '(min, 1)': 0.25}}
2024-04-24 14:41:43,548 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:43,548 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:43,548 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-04-24 14:41:43,549 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-04-24 14:41:43,991 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #16: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.21, '(rev, 1)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:41:43,992 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:43,993 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-04-24 14:41:45,147 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #16: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 5, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.25, '(rev, 1)': 0.01, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-04-24 14:41:45,148 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:45,149 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-04-24 14:41:45,309 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #16: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.11904761904761904, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.54, '(min, 1)': 0.22, '(rev, 5)': 0.01}}
2024-04-24 14:41:45,310 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:45,311 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-04-24 14:41:47,326 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #16: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.15}}
2024-04-24 14:41:47,326 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:47,328 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-04-24 14:41:50,415 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #16: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 2, 7, 0, 0),(ado, 5)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 2, 0, 0)', 'reward_ratio': '0/5', 'revenue': 0.17777777777777778, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 5)': 0.02, '(min, 0)': 0.35, '(min, 1)': 0.31, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-04-24 14:41:50,416 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:50,417 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-04-24 14:41:50,620 - MainProcess - INFO - text_logger.py - 51 - Train epoch #16
2024-04-24 14:41:50,624 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.7100e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.3308e-01,
         0.0000e+00,  1.6258e-01,  8.4530e-04,  1.1135e-01,  0.0000e+00,
         1.3481e-01,  5.3282e-04,  0.0000e+00,  0.0000e+00,  1.4233e-01,
         3.1351e-04,  0.0000e+00,  0.0000e+00,  8.8484e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  8.8593e-02,  1.4039e-04,  0.0000e+00,
         0.0000e+00,  7.4482e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.0433e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7011e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.4145e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.0313e-04,  0.0000e+00,  0.0000e+00])  tensor([1.2383, 0.0000, 0.0000, 0.0000, 0.1239, 0.0000, 0.0480, 0.0062, 0.0889,
        0.0000, 0.0424, 0.0038, 0.0000, 0.0000, 0.0532, 0.0029, 0.0000, 0.0000,
        0.0396, 0.0000, 0.0000, 0.0000, 0.0466, 0.0022, 0.0000, 0.0000, 0.0448,
        0.0000, 0.0000, 0.0000, 0.0205, 0.0000, 0.0000, 0.0000, 0.0238, 0.0000,
        0.0000, 0.0000, 0.0086, 0.0000, 0.0000, 0.0000, 0.0031, 0.0000, 0.0000]) (500)
2024-04-24 14:41:50,649 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4572335122092904
2024-04-24 14:41:50,653 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.155560.15556
2024-04-24 14:41:50,687 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #17: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.2}}
2024-04-24 14:41:50,687 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #17: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.2}}
2024-04-24 14:41:50,688 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:50,688 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:50,689 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-04-24 14:41:50,703 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #17: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.36, '(min, 1)': 0.26}}
2024-04-24 14:41:50,703 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:50,709 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-04-24 14:41:51,679 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #17: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 1, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4634146341463415, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.34, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:41:51,679 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:51,680 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-04-24 14:41:52,223 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #17: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 5, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.29, '(rev, 1)': 0.02, '(rev, 3)': 0.02}}
2024-04-24 14:41:52,223 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:52,224 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-04-24 14:41:52,276 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #17: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 2)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.33}}
2024-04-24 14:41:52,277 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:52,280 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-04-24 14:41:57,482 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #17: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.34, '(rev, 2)': 0.03}}
2024-04-24 14:41:57,483 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:57,484 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-04-24 14:41:57,677 - MainProcess - INFO - text_logger.py - 51 - Train epoch #17
2024-04-24 14:41:57,680 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.7991e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.5350e-01,
         0.0000e+00,  1.7855e-01,  1.2574e-03,  1.3368e-01,  0.0000e+00,
         1.3968e-01,  5.6514e-04,  0.0000e+00,  0.0000e+00,  9.8124e-02,
         2.2545e-04,  0.0000e+00,  0.0000e+00,  8.3203e-02,  6.2500e-05,
         0.0000e+00,  0.0000e+00,  7.6752e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  7.0627e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.0236e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.6986e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  5.6122e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  9.3345e-04,  0.0000e+00,  0.0000e+00])  tensor([1.4616e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3930e-01, 0.0000e+00,
        4.9965e-02, 7.0712e-03, 9.6386e-02, 0.0000e+00, 5.0532e-02, 3.7166e-03,
        0.0000e+00, 0.0000e+00, 4.1614e-02, 2.5866e-03, 0.0000e+00, 0.0000e+00,
        4.0820e-02, 1.3975e-03, 0.0000e+00, 0.0000e+00, 4.1001e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.0731e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9307e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1327e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.0653e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.7552e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:41:57,699 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.45629127799116986
2024-04-24 14:41:57,704 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:41:57,757 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #18: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.03, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.02, '(min, 0)': 0.44, '(min, 1)': 0.28, '(rev, 1)': 0.04, '(rev, 2)': 0.02}}
2024-04-24 14:41:57,757 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:57,757 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:57,759 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-04-24 14:41:57,759 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-04-24 14:41:57,772 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #18: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 3, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.15}}
2024-04-24 14:41:57,772 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #18: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.46, '(min, 1)': 0.11}}
2024-04-24 14:41:57,772 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #18: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 2, 7, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.06521739130434782, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.24, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:41:57,772 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:57,773 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:57,776 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-04-24 14:41:57,777 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-04-24 14:41:57,777 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-04-24 14:41:57,951 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #18: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41509433962264153, 'length': 100, 'actions': {'(ado, 1)': 0.09, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.02, '(min, 0)': 0.48, '(min, 1)': 0.3, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:41:57,952 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:41:57,953 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-04-24 14:42:04,725 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #18: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.26, '(rev, 1)': 0.03, '(rev, 2)': 0.01}}
2024-04-24 14:42:04,725 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:04,727 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-04-24 14:42:04,935 - MainProcess - INFO - text_logger.py - 51 - Train epoch #18
2024-04-24 14:42:04,939 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.9235e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7915e-01, 0.0000e+00,
        1.7294e-01, 1.2256e-03, 1.4055e-01, 0.0000e+00, 1.1973e-01, 5.8509e-04,
        0.0000e+00, 0.0000e+00, 1.2395e-01, 2.0944e-04, 0.0000e+00, 0.0000e+00,
        7.6187e-02, 1.0283e-04, 0.0000e+00, 0.0000e+00, 6.8480e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.2147e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7703e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1067e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.8828e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0870e-03, 0.0000e+00, 0.0000e+00])  tensor([1.9406e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6032e-01, 0.0000e+00,
        5.5797e-02, 6.5797e-03, 1.0801e-01, 0.0000e+00, 4.9980e-02, 3.4701e-03,
        0.0000e+00, 0.0000e+00, 6.4711e-02, 2.4346e-03, 0.0000e+00, 0.0000e+00,
        4.6433e-02, 1.6265e-03, 0.0000e+00, 0.0000e+00, 4.6390e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.4709e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.2355e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0970e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.6863e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.2116e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:42:04,962 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4553490437730493
2024-04-24 14:42:04,973 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:42:04,983 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #19: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 8)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.13}}
2024-04-24 14:42:04,983 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:04,984 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-04-24 14:42:05,015 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #19: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3023255813953488, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 8)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.32, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-04-24 14:42:05,016 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:05,017 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-04-24 14:42:05,030 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #19: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 8)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/8', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 3)': 0.02, '(ado, 5)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.22}}
2024-04-24 14:42:05,030 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #19: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.56, '(min, 1)': 0.14, '(rev, 1)': 0.01}}
2024-04-24 14:42:05,030 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #19: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 3)': 0.01, '(ado, 6)': 0.03, '(min, 0)': 0.4, '(min, 1)': 0.28}}
2024-04-24 14:42:05,031 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:05,031 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:05,033 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-04-24 14:42:05,033 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-04-24 14:42:05,033 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-04-24 14:42:05,903 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #19: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.27, '(min, 1)': 0.3}}
2024-04-24 14:42:05,903 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:05,904 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-04-24 14:42:12,105 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #19: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 5)': 0.01, '(ado, 7)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.29, '(rev, 5)': 0.01}}
2024-04-24 14:42:12,105 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:12,106 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-04-24 14:42:12,307 - MainProcess - INFO - text_logger.py - 51 - Train epoch #19
2024-04-24 14:42:12,309 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-4.6106e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1721e-01,
         0.0000e+00,  1.7649e-01,  1.2163e-04,  9.9133e-02,  0.0000e+00,
         1.5055e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2480e-01,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  9.3461e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  8.7925e-02,  1.0760e-04,  0.0000e+00,
         0.0000e+00,  7.7047e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.6330e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.9080e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  6.4165e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  1.3210e-03,  0.0000e+00,  0.0000e+00])  tensor([1.1902, 0.0000, 0.0000, 0.0000, 0.1058, 0.0000, 0.0392, 0.0020, 0.0738,
        0.0000, 0.0307, 0.0000, 0.0000, 0.0000, 0.0320, 0.0000, 0.0000, 0.0000,
        0.0346, 0.0000, 0.0000, 0.0000, 0.0382, 0.0017, 0.0000, 0.0000, 0.0371,
        0.0000, 0.0000, 0.0000, 0.0207, 0.0000, 0.0000, 0.0000, 0.0207, 0.0000,
        0.0000, 0.0000, 0.0094, 0.0000, 0.0000, 0.0000, 0.0044, 0.0000, 0.0000]) (500)
2024-04-24 14:42:12,331 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.454709135136324
2024-04-24 14:42:12,334 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.151160.15116
2024-04-24 14:42:12,355 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #20: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 1, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.24324324324324326, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.51, '(min, 1)': 0.16, '(rev, 1)': 0.02, '(rev, 2)': 0.02, '(rev, 5)': 0.01}}
'(rev, 4)': 0.01}}
2024-04-24 14:42:12,355 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:12,356 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:12,357 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-04-24 14:42:12,358 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-04-24 14:42:12,386 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #20: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.31, '(min, 1)': 0.34}}
2024-04-24 14:42:12,387 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:12,388 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-04-24 14:42:12,504 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #20: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3191489361702128, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.02, '(min, 0)': 0.39, '(min, 1)': 0.34, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:42:12,506 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:12,507 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-04-24 14:42:13,340 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #20: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.22}}
2024-04-24 14:42:13,341 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:13,342 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-04-24 14:42:13,934 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #20: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.27, '(rev, 1)': 0.01}}
2024-04-24 14:42:13,934 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:13,935 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-04-24 14:42:17,352 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #20: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.08888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.22, '(rev, 4)': 0.01}}
2024-04-24 14:42:17,352 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:17,353 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-04-24 14:42:17,564 - MainProcess - INFO - text_logger.py - 51 - Train epoch #20
2024-04-24 14:42:17,568 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.0282,  0.0000,  0.0000,  0.0000,  0.1648,  0.0000,  0.1780,  0.0009,
         0.1290,  0.0000,  0.1231,  0.0005,  0.0000,  0.0000,  0.1083,  0.0003,
         0.0000,  0.0000,  0.0846,  0.0002,  0.0000,  0.0000,  0.0763,  0.0000,
         0.0000,  0.0000,  0.0675,  0.0000,  0.0000,  0.0000,  0.0325,  0.0000,
         0.0000,  0.0000,  0.0277,  0.0000,  0.0000,  0.0000,  0.0053,  0.0000,
         0.0000,  0.0000,  0.0009,  0.0000,  0.0000])  tensor([1.6133, 0.0000, 0.0000, 0.0000, 0.1692, 0.0000, 0.0548, 0.0050, 0.1076,
        0.0000, 0.0492, 0.0030, 0.0000, 0.0000, 0.0514, 0.0025, 0.0000, 0.0000,
        0.0462, 0.0021, 0.0000, 0.0000, 0.0442, 0.0000, 0.0000, 0.0000, 0.0424,
        0.0000, 0.0000, 0.0000, 0.0226, 0.0000, 0.0000, 0.0000, 0.0209, 0.0000,
        0.0000, 0.0000, 0.0089, 0.0000, 0.0000, 0.0000, 0.0037, 0.0000, 0.0000]) (500)
2024-04-24 14:42:17,599 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.45401014416144664
2024-04-24 14:42:17,602 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.121620.12162
2024-04-24 14:42:17,613 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #21: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.54, '(min, 1)': 0.06}}
2024-04-24 14:42:17,614 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:17,617 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-04-24 14:42:18,037 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #21: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5217391304347826, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(min, 0)': 0.4, '(min, 1)': 0.23, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 5)': 0.03}}
2024-04-24 14:42:18,038 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:18,039 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-04-24 14:42:18,459 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #21: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2682926829268293, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 8)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.15, '(rev, 1)': 0.01}}
2024-04-24 14:42:18,460 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:18,461 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-04-24 14:42:19,075 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #21: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1891891891891892, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.41, '(min, 1)': 0.23, '(rev, 1)': 0.05, '(rev, 4)': 0.01}}
2024-04-24 14:42:19,075 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:19,076 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-04-24 14:42:19,512 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #21: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 3, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.20408163265306123, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.35, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:42:19,513 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:19,515 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-04-24 14:42:20,118 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #21: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.42857142857142855, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.24, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:42:20,120 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:20,121 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-04-24 14:42:25,917 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #21: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 1, 1, 9, 1, 1),(min, 0)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 1, 1, 10, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.43902439024390244, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.41, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:42:25,917 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:25,919 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-04-24 14:42:26,129 - MainProcess - INFO - text_logger.py - 51 - Train epoch #21
2024-04-24 14:42:26,131 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.8018e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4530e-01, 0.0000e+00,
        1.4065e-01, 2.7679e-03, 2.1790e-01, 0.0000e+00, 7.2675e-02, 2.0853e-03,
        0.0000e+00, 0.0000e+00, 6.1899e-02, 1.4161e-03, 0.0000e+00, 0.0000e+00,
        4.3624e-02, 4.3635e-04, 0.0000e+00, 0.0000e+00, 3.8836e-02, 3.1539e-04,
        0.0000e+00, 0.0000e+00, 3.5302e-02, 1.7770e-04, 0.0000e+00, 0.0000e+00,
        1.8082e-02, 3.1000e-04, 0.0000e+00, 0.0000e+00, 1.4688e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.0309e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.0104e-04, 0.0000e+00, 0.0000e+00])  tensor([2.7306e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2768e-01, 0.0000e+00,
        7.4961e-02, 7.9999e-03, 1.3474e-01, 0.0000e+00, 7.4017e-02, 6.0368e-03,
        0.0000e+00, 0.0000e+00, 6.9627e-02, 5.2797e-03, 0.0000e+00, 0.0000e+00,
        5.3412e-02, 2.8535e-03, 0.0000e+00, 0.0000e+00, 4.9822e-02, 2.5392e-03,
        0.0000e+00, 0.0000e+00, 4.6564e-02, 1.7829e-03, 0.0000e+00, 0.0000e+00,
        2.5110e-02, 2.9522e-03, 0.0000e+00, 0.0000e+00, 2.1445e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.3779e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8020e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:42:26,152 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.45333620262625296
2024-04-24 14:42:26,159 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.134150.13415
2024-04-24 14:42:26,192 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #22: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.54, '(min, 1)': 0.1}}
2024-04-24 14:42:26,192 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #22: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.45, '(min, 1)': 0.16}}
2024-04-24 14:42:26,193 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:26,193 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:26,194 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-04-24 14:42:26,194 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-04-24 14:42:26,208 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #22: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17777777777777778, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.38, '(rev, 1)': 0.05, '(rev, 5)': 0.01}}
2024-04-24 14:42:26,208 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #22: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.4782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(min, 0)': 0.21, '(min, 1)': 0.39, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 5)': 0.01}}
2024-04-24 14:42:26,208 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:26,208 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:26,209 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-04-24 14:42:26,209 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-04-24 14:42:26,225 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #22: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.09523809523809523, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.27, '(rev, 1)': 0.02, '(rev, 2)': 0.02, '(rev, 4)': 0.01}}

2024-04-24 14:42:26,225 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:26,225 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:26,226 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-04-24 14:42:26,226 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-04-24 14:42:31,245 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #22: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.04081632653061224, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.26, '(rev, 1)': 0.03}}
2024-04-24 14:42:31,246 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:31,247 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-04-24 14:42:31,451 - MainProcess - INFO - text_logger.py - 51 - Train epoch #22
2024-04-24 14:42:31,456 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.4632e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1447e-01, 0.0000e+00,
        1.5425e-01, 2.1787e-03, 2.0707e-01, 0.0000e+00, 7.6371e-02, 1.3469e-03,
        0.0000e+00, 0.0000e+00, 6.3872e-02, 4.8771e-04, 0.0000e+00, 0.0000e+00,
        5.0829e-02, 2.3888e-04, 0.0000e+00, 0.0000e+00, 4.6539e-02, 1.6226e-04,
        0.0000e+00, 0.0000e+00, 3.9333e-02, 9.9755e-05, 0.0000e+00, 0.0000e+00,
        2.1156e-02, 9.9755e-05, 0.0000e+00, 0.0000e+00, 1.7088e-02, 9.9755e-05,
        0.0000e+00, 0.0000e+00, 3.6039e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.0032e-04, 0.0000e+00, 0.0000e+00])  tensor([2.3033e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3506e-01, 0.0000e+00,
        8.4181e-02, 6.8400e-03, 1.4124e-01, 0.0000e+00, 7.0722e-02, 4.6505e-03,
        0.0000e+00, 0.0000e+00, 6.2738e-02, 2.7259e-03, 0.0000e+00, 0.0000e+00,
        5.3606e-02, 2.0898e-03, 0.0000e+00, 0.0000e+00, 5.1064e-02, 1.8994e-03,
        0.0000e+00, 0.0000e+00, 4.4847e-02, 1.2911e-03, 0.0000e+00, 0.0000e+00,
        2.5339e-02, 1.2911e-03, 0.0000e+00, 0.0000e+00, 2.2429e-02, 1.2911e-03,
        0.0000e+00, 0.0000e+00, 7.8437e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2382e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:42:31,487 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4523939684081324
2024-04-24 14:42:31,490 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:42:31,496 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #23: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 5, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24489795918367346, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.4, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:42:31,497 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:31,497 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-04-24 14:42:31,516 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #23: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.54, '(min, 1)': 0.08}}
2024-04-24 14:42:31,517 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:31,520 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-04-24 14:42:31,662 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #23: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 1, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13043478260869565, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.25, '(rev, 1)': 0.05, '(rev, 4)': 0.01}}
2024-04-24 14:42:31,663 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:31,665 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-04-24 14:42:31,830 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #23: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.475, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.18, '(min, 1)': 0.46, '(rev, 1)': 0.12, '(rev, 2)': 0.06, '(rev, 3)': 0.03}}
2024-04-24 14:42:31,830 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:31,831 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-04-24 14:42:32,984 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #23: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 3, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6764705882352942, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.31, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.03}}
2024-04-24 14:42:32,985 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:32,986 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-04-24 14:42:33,872 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #23: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32558139534883723, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.18, '(rev, 4)': 0.01}}
2024-04-24 14:42:33,873 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:33,875 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-04-24 14:42:36,022 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #23: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.06666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.27, '(rev, 1)': 0.03}}
2024-04-24 14:42:36,023 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:36,024 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-04-24 14:42:36,245 - MainProcess - INFO - text_logger.py - 51 - Train epoch #23
2024-04-24 14:42:36,248 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.8448e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5889e-01, 0.0000e+00,
        1.3408e-01, 2.8890e-03, 2.3884e-01, 0.0000e+00, 5.6281e-02, 2.0893e-03,
        0.0000e+00, 0.0000e+00, 5.2573e-02, 1.4899e-03, 0.0000e+00, 0.0000e+00,
        4.2420e-02, 2.8371e-04, 0.0000e+00, 0.0000e+00, 3.8530e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.3171e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9449e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5104e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2930e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.1231e-04, 0.0000e+00, 0.0000e+00])  tensor([2.1605, 0.0000, 0.0000, 0.0000, 0.2294, 0.0000, 0.0795, 0.0076, 0.1406,
        0.0000, 0.0610, 0.0056, 0.0000, 0.0000, 0.0641, 0.0049, 0.0000, 0.0000,
        0.0564, 0.0025, 0.0000, 0.0000, 0.0531, 0.0000, 0.0000, 0.0000, 0.0468,
        0.0000, 0.0000, 0.0000, 0.0286, 0.0000, 0.0000, 0.0000, 0.0237, 0.0000,
        0.0000, 0.0000, 0.0079, 0.0000, 0.0000, 0.0000, 0.0031, 0.0000, 0.0000]) (500)
2024-04-24 14:42:36,286 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4517773155853606
2024-04-24 14:42:36,295 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.162790.16279
2024-04-24 14:42:37,139 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #24: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2549019607843137, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.15, '(rev, 1)': 0.02, '(rev, 2)': 0.01}}
2024-04-24 14:42:37,139 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:37,141 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-04-24 14:42:37,196 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #24: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.31, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:42:37,196 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:37,202 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-04-24 14:42:37,273 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #24: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.23076923076923078, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.26, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-24 14:42:37,274 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:37,275 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-04-24 14:42:38,009 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #24: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 3, 0, 0),(rev, 3)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5853658536585366, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.09, '(min, 1)': 0.55, '(rev, 1)': 0.08, '(rev, 3)': 0.05, '(rev, 4)': 0.01}}
2024-04-24 14:42:38,009 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:38,010 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-04-24 14:42:38,349 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #24: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.58, '(min, 1)': 0.04}}
2024-04-24 14:42:38,350 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:38,351 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-04-24 14:42:41,046 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #24: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5576923076923077, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.37, '(rev, 1)': 0.04, '(rev, 10)': 0.01, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-04-24 14:42:41,046 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:41,047 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-04-24 14:42:42,593 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #24: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.33, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-04-24 14:42:42,593 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:42,595 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-04-24 14:42:42,794 - MainProcess - INFO - text_logger.py - 51 - Train epoch #24
2024-04-24 14:42:42,798 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.5762e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8608e-01, 0.0000e+00,
        1.3146e-01, 3.3479e-03, 2.5035e-01, 0.0000e+00, 5.1753e-02, 2.2375e-03,
        0.0000e+00, 0.0000e+00, 4.8291e-02, 1.2717e-03, 0.0000e+00, 0.0000e+00,
        3.4475e-02, 6.0214e-04, 0.0000e+00, 0.0000e+00, 2.9547e-02, 2.6845e-04,
        0.0000e+00, 0.0000e+00, 2.8603e-02, 6.6120e-05, 0.0000e+00, 0.0000e+00,
        1.5746e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2549e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.7353e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.4919e-04, 6.0606e-05, 0.0000e+00])  tensor([2.1048e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2140e-01, 0.0000e+00,
        9.3938e-02, 8.0175e-03, 1.4063e-01, 0.0000e+00, 6.0955e-02, 5.8768e-03,
        0.0000e+00, 0.0000e+00, 6.4502e-02, 5.1054e-03, 0.0000e+00, 0.0000e+00,
        5.1423e-02, 3.5376e-03, 0.0000e+00, 0.0000e+00, 4.5621e-02, 2.1282e-03,
        0.0000e+00, 0.0000e+00, 4.5297e-02, 1.0444e-03, 0.0000e+00, 0.0000e+00,
        2.7113e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3462e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.6663e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9597e-03, 1.3552e-03, 0.0000e+00]) (500)
2024-04-24 14:42:42,823 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.45108998332802436
2024-04-24 14:42:42,826 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.127450.12745
2024-04-24 14:42:42,844 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #25: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.11428571428571428, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.49, '(min, 1)': 0.14, '(rev, 1)': 0.04, '(rev, 2)': 0.02}}
2024-04-24 14:42:42,844 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:42,845 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-04-24 14:42:42,860 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #25: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(min, 0)': 0.08, '(min, 1)': 0.5, '(rev, 1)': 0.08, '(rev, 2)': 0.02}}
2024-04-24 14:42:42,861 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:42,862 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-04-24 14:42:42,975 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #25: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 5, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.44, '(min, 1)': 0.18}}
2024-04-24 14:42:42,975 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:42,977 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-04-24 14:42:43,098 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #25: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.2653061224489796, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.29, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:42:43,099 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:43,100 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-04-24 14:42:43,928 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #25: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.2}}
2024-04-24 14:42:43,932 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:43,933 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-04-24 14:42:47,473 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #25: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.08823529411764706, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.2, '(rev, 1)': 0.04, '(rev, 2)': 0.01}}
2024-04-24 14:42:47,474 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:47,475 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-04-24 14:42:49,805 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #25: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.04, '(ado, 6)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.24, '(rev, 1)': 0.1, '(rev, 2)': 0.04}}
2024-04-24 14:42:49,806 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:49,807 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-04-24 14:42:49,997 - MainProcess - INFO - text_logger.py - 51 - Train epoch #25
2024-04-24 14:42:50,000 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.2163e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7688e-01, 0.0000e+00,
        1.2395e-01, 2.9064e-03, 2.5882e-01, 0.0000e+00, 4.9168e-02, 1.4598e-03,
        0.0000e+00, 0.0000e+00, 4.5478e-02, 4.9162e-04, 0.0000e+00, 0.0000e+00,
        3.7302e-02, 2.8999e-04, 0.0000e+00, 0.0000e+00, 3.3436e-02, 6.4516e-05,
        0.0000e+00, 0.0000e+00, 3.0910e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8125e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6236e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.9369e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.4076e-04, 0.0000e+00, 0.0000e+00])  tensor([1.7014e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2795e-01, 0.0000e+00,
        8.1275e-02, 7.5326e-03, 1.4822e-01, 0.0000e+00, 6.3215e-02, 4.7677e-03,
        0.0000e+00, 0.0000e+00, 6.2690e-02, 2.8286e-03, 0.0000e+00, 0.0000e+00,
        5.2487e-02, 2.3002e-03, 0.0000e+00, 0.0000e+00, 4.7823e-02, 1.4426e-03,
        0.0000e+00, 0.0000e+00, 4.4558e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7178e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4837e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.8680e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8344e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:42:50,031 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4502620348241895
2024-04-24 14:42:50,034 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.057140.05714
2024-04-24 14:42:50,090 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #26: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 3, 0, 1),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 4, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(ado, 7)': 0.01, '(min, 0)': 0.52, '(min, 1)': 0.1}}
2024-04-24 14:42:50,091 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:50,090 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #26: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 6)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.09, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-04-24 14:42:50,091 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #26: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46511627906976744, 'length': 100, 'actions': {'(ado, 1)': 0.09, '(ado, 2)': 0.01, '(ado, 3)': 0.04, '(min, 0)': 0.44, '(min, 1)': 0.24, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 6)': 0.01}}
2024-04-24 14:42:50,091 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:50,091 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:50,092 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-04-24 14:42:50,092 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-04-24 14:42:50,092 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-04-24 14:42:50,103 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #26: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3953488372093023, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 9)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.2, '(rev, 1)': 0.07, '(rev, 3)': 0.01}}
2024-04-24 14:42:50,104 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:50,109 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-04-24 14:42:51,283 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #26: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.55, '(min, 1)': 0.07}}
2024-04-24 14:42:51,284 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:51,285 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-04-24 14:42:52,385 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #26: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.30612244897959184, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.21, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-04-24 14:42:52,385 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:52,386 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-04-24 14:42:57,946 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #26: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7659574468085106, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.46, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 7)': 0.01}}
2024-04-24 14:42:57,946 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:57,947 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-04-24 14:42:58,143 - MainProcess - INFO - text_logger.py - 51 - Train epoch #26
2024-04-24 14:42:58,147 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.4639e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8509e-01, 0.0000e+00,
        1.0326e-01, 4.2181e-03, 3.2732e-01, 0.0000e+00, 2.4460e-02, 2.5664e-03,
        0.0000e+00, 0.0000e+00, 1.5954e-02, 1.9792e-03, 0.0000e+00, 0.0000e+00,
        1.0588e-02, 6.1553e-04, 0.0000e+00, 0.0000e+00, 9.1967e-03, 4.0794e-04,
        0.0000e+00, 0.0000e+00, 6.7605e-03, 1.0387e-04, 0.0000e+00, 0.0000e+00,
        3.8038e-03, 1.2239e-04, 0.0000e+00, 0.0000e+00, 3.1235e-03, 6.6834e-05,
        0.0000e+00, 0.0000e+00, 3.2429e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.7736e-05, 0.0000e+00, 0.0000e+00])  tensor([1.8234e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4765e-01, 0.0000e+00,
        8.3586e-02, 8.8118e-03, 9.4388e-02, 0.0000e+00, 4.6317e-02, 6.2231e-03,
        0.0000e+00, 0.0000e+00, 3.9640e-02, 6.1664e-03, 0.0000e+00, 0.0000e+00,
        3.1976e-02, 3.3545e-03, 0.0000e+00, 0.0000e+00, 2.9514e-02, 2.7471e-03,
        0.0000e+00, 0.0000e+00, 2.4082e-02, 1.3410e-03, 0.0000e+00, 0.0000e+00,
        1.4588e-02, 1.6288e-03, 0.0000e+00, 0.0000e+00, 1.2543e-02, 1.0570e-03,
        0.0000e+00, 0.0000e+00, 2.6220e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.4380e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:42:58,176 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.44931980060606896
2024-04-24 14:42:58,180 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:42:58,191 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #27: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.44, '(min, 1)': 0.16}}
2024-04-24 14:42:58,192 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:58,195 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-04-24 14:42:58,207 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #27: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.07894736842105263, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 4)': 0.01, '(min, 0)': 0.58, '(min, 1)': 0.08, '(rev, 1)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:42:58,207 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #27: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24489795918367346, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.21, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:42:58,209 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:58,209 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:58,209 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-04-24 14:42:58,209 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-04-24 14:42:58,223 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #27: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.28, '(min, 1)': 0.38, '(rev, 1)': 0.05, '(rev, 2)': 0.09, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:42:58,224 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:58,226 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-04-24 14:42:58,238 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #27: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.25}}
2024-04-24 14:42:58,238 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:42:58,240 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-04-24 14:43:00,245 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #27: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 1.1111111111111112, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.02, '(min, 0)': 0.11, '(min, 1)': 0.53, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.05, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:43:00,246 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:00,247 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-04-24 14:43:03,091 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #27: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5581395348837209, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.47, '(rev, 1)': 0.11, '(rev, 2)': 0.05, '(rev, 3)': 0.04, '(rev, 5)': 0.01}}
2024-04-24 14:43:03,091 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:03,092 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-04-24 14:43:03,294 - MainProcess - INFO - text_logger.py - 51 - Train epoch #27
2024-04-24 14:43:03,299 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.1840e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3622e-01, 0.0000e+00,
        1.0180e-01, 5.1427e-03, 2.8042e-01, 0.0000e+00, 3.8356e-02, 3.4036e-03,
        0.0000e+00, 0.0000e+00, 3.3745e-02, 1.6356e-03, 0.0000e+00, 0.0000e+00,
        2.7329e-02, 9.1489e-04, 0.0000e+00, 0.0000e+00, 2.3399e-02, 7.2711e-04,
        0.0000e+00, 0.0000e+00, 2.0532e-02, 3.0629e-04, 0.0000e+00, 0.0000e+00,
        1.2660e-02, 3.2787e-05, 0.0000e+00, 0.0000e+00, 1.0266e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.5739e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.4658e-04, 0.0000e+00, 0.0000e+00])  tensor([2.8414e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1567e-01, 0.0000e+00,
        9.0628e-02, 9.4945e-03, 1.3073e-01, 0.0000e+00, 5.6505e-02, 7.4274e-03,
        0.0000e+00, 0.0000e+00, 5.5996e-02, 5.7543e-03, 0.0000e+00, 0.0000e+00,
        4.7566e-02, 4.5518e-03, 0.0000e+00, 0.0000e+00, 4.2814e-02, 4.0686e-03,
        0.0000e+00, 0.0000e+00, 3.8844e-02, 2.7552e-03, 0.0000e+00, 0.0000e+00,
        2.5235e-02, 7.3314e-04, 0.0000e+00, 0.0000e+00, 2.1797e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.6515e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9495e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:43:03,335 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4483775663879484
2024-04-24 14:43:03,339 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:43:03,373 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #28: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 3, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.53, '(min, 1)': 0.06}}
2024-04-24 14:43:03,374 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:03,375 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-04-24 14:43:03,387 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #28: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.47, '(min, 1)': 0.11}}
2024-04-24 14:43:03,389 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:03,391 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-04-24 14:43:05,116 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #28: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.15789473684210525, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 6)': 0.01, '(min, 0)': 0.56, '(min, 1)': 0.13, '(rev, 1)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:43:05,116 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:05,117 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-04-24 14:43:05,316 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #28: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3137254901960784, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.2, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:43:05,316 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:05,317 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-04-24 14:43:05,700 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #28: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3023255813953488, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 8)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.29, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 4)': 0.01}}
2024-04-24 14:43:05,700 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:05,702 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-04-24 14:43:05,733 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #28: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46938775510204084, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.33, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:43:05,734 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:05,735 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-04-24 14:43:08,362 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #28: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.11904761904761904, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.27, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:43:08,363 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:08,365 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-04-24 14:43:08,573 - MainProcess - INFO - text_logger.py - 51 - Train epoch #28
2024-04-24 14:43:08,576 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.2922e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.0455e-01,
         0.0000e+00,  1.4960e-01,  2.4424e-03,  2.1049e-01,  0.0000e+00,
         7.3082e-02,  1.5450e-03,  0.0000e+00,  0.0000e+00,  6.6095e-02,
         5.5574e-04,  0.0000e+00,  0.0000e+00,  5.1940e-02,  4.3512e-04,
         0.0000e+00,  0.0000e+00,  4.5993e-02,  9.1847e-05,  0.0000e+00,
         0.0000e+00,  4.2696e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.5036e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.0903e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.0616e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  4.8304e-04,  0.0000e+00,  0.0000e+00])  tensor([1.8604e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2621e-01, 0.0000e+00,
        8.7464e-02, 6.8842e-03, 1.3470e-01, 0.0000e+00, 5.7375e-02, 5.2099e-03,
        0.0000e+00, 0.0000e+00, 5.6781e-02, 2.9388e-03, 0.0000e+00, 0.0000e+00,
        4.8320e-02, 3.0446e-03, 0.0000e+00, 0.0000e+00, 4.4906e-02, 1.4662e-03,
        0.0000e+00, 0.0000e+00, 4.3466e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7660e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5715e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.7403e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7830e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:43:08,596 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4474353321698278
2024-04-24 14:43:08,599 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:43:08,607 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #29: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.53, '(min, 1)': 0.08}}
2024-04-24 14:43:08,609 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:08,612 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-04-24 14:43:08,636 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #29: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 4, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.55, '(min, 1)': 0.08}}
2024-04-24 14:43:08,636 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:08,637 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-04-24 14:43:10,700 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #29: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 5, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17391304347826086, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.15, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-04-24 14:43:10,700 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:10,701 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-04-24 14:43:10,709 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #29: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1276595744680851, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 5)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.14, '(rev, 1)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:43:10,709 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:10,712 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-04-24 14:43:12,389 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #29: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 6, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 5, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.9024390243902439, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 3)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.46, '(rev, 1)': 0.12, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:43:12,389 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:12,390 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-04-24 14:43:13,374 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #29: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 4, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10256410256410256, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(ado, 5)': 0.02, '(min, 0)': 0.62, '(min, 1)': 0.13, '(rev, 1)': 0.02, '(rev, 2)': 0.02}}
2024-04-24 14:43:13,374 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:13,375 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-04-24 14:43:17,415 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #29: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2894736842105263, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.34, '(rev, 1)': 0.04, '(rev, 9)': 0.01}}
2024-04-24 14:43:17,415 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:17,417 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-04-24 14:43:17,618 - MainProcess - INFO - text_logger.py - 51 - Train epoch #29
2024-04-24 14:43:17,622 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.0570e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6026e-01, 0.0000e+00,
        1.3872e-01, 2.5162e-03, 2.5938e-01, 0.0000e+00, 5.5983e-02, 1.3172e-03,
        0.0000e+00, 0.0000e+00, 4.8970e-02, 8.0481e-04, 0.0000e+00, 0.0000e+00,
        3.6416e-02, 3.7067e-04, 0.0000e+00, 0.0000e+00, 3.1473e-02, 2.2070e-04,
        0.0000e+00, 0.0000e+00, 2.8553e-02, 6.8765e-05, 0.0000e+00, 0.0000e+00,
        1.7496e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4620e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.4258e-03, 5.2632e-05, 0.0000e+00, 0.0000e+00,
        3.5388e-04, 0.0000e+00, 0.0000e+00])  tensor([1.8385e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1610e-01, 0.0000e+00,
        9.3295e-02, 6.9465e-03, 1.3719e-01, 0.0000e+00, 5.8372e-02, 4.6119e-03,
        0.0000e+00, 0.0000e+00, 5.6103e-02, 3.7532e-03, 0.0000e+00, 0.0000e+00,
        4.5034e-02, 2.7978e-03, 0.0000e+00, 0.0000e+00, 4.1332e-02, 2.0358e-03,
        0.0000e+00, 0.0000e+00, 3.8711e-02, 1.0938e-03, 0.0000e+00, 0.0000e+00,
        2.5472e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2121e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.0205e-03, 1.1769e-03, 0.0000e+00, 0.0000e+00,
        2.3896e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:43:17,660 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4464930979517072
2024-04-24 14:43:17,664 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:43:17,686 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #30: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.6, '(min, 1)': 0.03, '(rev, 1)': 0.01}}
2024-04-24 14:43:17,686 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #30: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 1, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.21621621621621623, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.35, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:43:17,687 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:17,687 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:17,689 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-04-24 14:43:17,689 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-04-24 14:43:17,713 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #30: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.3157894736842105, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 2)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.09, '(rev, 1)': 0.03}}
2024-04-24 14:43:17,713 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #30: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40540540540540543, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(min, 0)': 0.37, '(min, 1)': 0.28, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.03}}
2024-04-24 14:43:17,714 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:17,714 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:17,715 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-04-24 14:43:17,715 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-04-24 14:43:18,661 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #30: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.4, '(rev, 1)': 0.04, '(rev, 2)': 0.06, '(rev, 3)': 0.03}}
2024-04-24 14:43:18,662 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:18,662 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-04-24 14:43:19,694 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #30: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.41, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 5)': 0.01}}
2024-04-24 14:43:19,695 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:19,696 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-04-24 14:43:24,816 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #30: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.07692307692307693, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.05, '(ado, 3)': 0.02, '(ado, 4)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.29, '(rev, 1)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:43:24,816 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:24,817 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-04-24 14:43:25,022 - MainProcess - INFO - text_logger.py - 51 - Train epoch #30
2024-04-24 14:43:25,027 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.7532e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6311e-01, 0.0000e+00,
        1.2593e-01, 2.5290e-03, 2.6211e-01, 0.0000e+00, 5.5797e-02, 1.3070e-03,
        0.0000e+00, 0.0000e+00, 4.6264e-02, 5.6427e-04, 0.0000e+00, 0.0000e+00,
        3.9344e-02, 1.8476e-04, 0.0000e+00, 0.0000e+00, 3.5042e-02, 3.0303e-05,
        0.0000e+00, 0.0000e+00, 3.1175e-02, 3.0303e-05, 0.0000e+00, 0.0000e+00,
        1.9243e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4506e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.4759e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5609e-04, 0.0000e+00, 0.0000e+00])  tensor([1.9831e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2236e-01, 0.0000e+00,
        8.9290e-02, 7.0529e-03, 1.4228e-01, 0.0000e+00, 6.2259e-02, 4.8008e-03,
        0.0000e+00, 0.0000e+00, 5.4958e-02, 3.3656e-03, 0.0000e+00, 0.0000e+00,
        5.0090e-02, 1.8508e-03, 0.0000e+00, 0.0000e+00, 4.6462e-02, 6.7760e-04,
        0.0000e+00, 0.0000e+00, 4.2285e-02, 6.7760e-04, 0.0000e+00, 0.0000e+00,
        2.7780e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3807e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.1104e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.4065e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:43:25,054 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.44595626913899206
2024-04-24 14:43:25,058 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.202700.20270
2024-04-24 14:43:25,070 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #31: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 5, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 6, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.35, '(min, 1)': 0.25}}
2024-04-24 14:43:25,071 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:25,071 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-04-24 14:43:25,100 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #31: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.2, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:43:25,101 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:25,101 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:25,102 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-04-24 14:43:25,102 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-04-24 14:43:25,116 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #31: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.047619047619047616, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 4)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.17, '(rev, 1)': 0.04}}
2024-04-24 14:43:25,116 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:25,117 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-04-24 14:43:25,618 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #31: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.22, '(rev, 1)': 0.03, '(rev, 3)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:43:25,618 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:25,619 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-04-24 14:43:25,827 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #31: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0425531914893617, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.18, '(rev, 1)': 0.03}}
2024-04-24 14:43:25,827 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:25,828 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-04-24 14:43:31,117 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #31: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.075, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.22, '(rev, 1)': 0.04}}
2024-04-24 14:43:31,117 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:31,120 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-04-24 14:43:31,315 - MainProcess - INFO - text_logger.py - 51 - Train epoch #31
2024-04-24 14:43:31,318 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-2.7033e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.3465e-01,
         0.0000e+00,  1.4433e-01,  1.7652e-03,  2.4880e-01,  0.0000e+00,
         6.2395e-02,  4.8541e-04,  0.0000e+00,  0.0000e+00,  5.2590e-02,
         2.1400e-04,  0.0000e+00,  0.0000e+00,  4.3628e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.8027e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  3.4583e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.0476e-02,  5.4054e-05,  0.0000e+00,  0.0000e+00,  1.5401e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.2866e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.2234e-04,  0.0000e+00,  0.0000e+00])  tensor([1.6936e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1740e-01, 0.0000e+00,
        8.8082e-02, 6.0241e-03, 1.4142e-01, 0.0000e+00, 5.9984e-02, 2.9068e-03,
        0.0000e+00, 0.0000e+00, 5.4355e-02, 2.3392e-03, 0.0000e+00, 0.0000e+00,
        4.9184e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5958e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.3724e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7722e-02, 1.2087e-03, 0.0000e+00, 0.0000e+00, 2.4159e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.9994e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.6278e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:43:31,335 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4450140349208715
2024-04-24 14:43:31,338 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:43:31,351 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #32: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1590909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.31, '(min, 1)': 0.26, '(rev, 1)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
'(rev, 1)': 0.07, '(rev, 2)': 0.01}}
2024-04-24 14:43:31,352 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:31,352 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:31,353 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-04-24 14:43:31,353 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-04-24 14:43:31,380 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #32: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.021739130434782608, 'length': 100, 'actions': {'(ado, 1)': 0.45, '(min, 0)': 0.41, '(min, 1)': 0.13, '(rev, 1)': 0.01}}
2024-04-24 14:43:31,380 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #32: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.06666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.29, '(rev, 1)': 0.04, '(rev, 2)': 0.02}}
2024-04-24 14:43:31,381 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:31,381 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:31,381 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #32: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.18604651162790697, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 8)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.3, '(rev, 1)': 0.1}}
2024-04-24 14:43:31,381 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:31,382 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-04-24 14:43:31,382 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-04-24 14:43:31,382 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-04-24 14:43:31,482 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #32: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 4)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.33, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 4)': 0.01}}
2024-04-24 14:43:31,482 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:31,483 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-04-24 14:43:37,239 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #32: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.673469387755102, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.5, '(rev, 1)': 0.13, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:43:37,239 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:37,240 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-04-24 14:43:37,442 - MainProcess - INFO - text_logger.py - 51 - Train epoch #32
2024-04-24 14:43:37,445 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.7473e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2942e-01, 0.0000e+00,
        1.0267e-01, 3.3771e-03, 2.8620e-01, 0.0000e+00, 3.8527e-02, 2.6509e-03,
        0.0000e+00, 0.0000e+00, 3.4417e-02, 1.0354e-03, 0.0000e+00, 0.0000e+00,
        2.7638e-02, 4.6464e-04, 0.0000e+00, 0.0000e+00, 2.4567e-02, 1.5421e-04,
        0.0000e+00, 0.0000e+00, 2.1907e-02, 5.4143e-05, 0.0000e+00, 0.0000e+00,
        1.4664e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0558e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.5290e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6321e-04, 0.0000e+00, 0.0000e+00])  tensor([2.0453e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1956e-01, 0.0000e+00,
        8.7934e-02, 7.6739e-03, 1.3261e-01, 0.0000e+00, 5.7518e-02, 6.3132e-03,
        0.0000e+00, 0.0000e+00, 5.4034e-02, 4.0784e-03, 0.0000e+00, 0.0000e+00,
        4.5335e-02, 2.6953e-03, 0.0000e+00, 0.0000e+00, 4.0995e-02, 1.5475e-03,
        0.0000e+00, 0.0000e+00, 3.6991e-02, 8.5592e-04, 0.0000e+00, 0.0000e+00,
        2.5300e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9965e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.5251e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6437e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:43:37,472 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.44425263074227656
2024-04-24 14:43:37,475 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.090420.06868
2024-04-24 14:43:37,491 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #33: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 7)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.37, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:43:37,493 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:37,495 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-04-24 14:43:37,521 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #33: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.45, '(rev, 1)': 0.13, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:43:37,521 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:37,522 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-04-24 14:43:38,108 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #33: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.65, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.47, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:43:38,109 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:38,110 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-04-24 14:43:38,137 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #33: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 8, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3611111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.42, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.02}}
2024-04-24 14:43:38,138 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:38,139 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-04-24 14:43:38,402 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #33: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.9333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 3)': 0.03, '(min, 0)': 0.21, '(min, 1)': 0.46, '(rev, 1)': 0.11, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.03}}
2024-04-24 14:43:38,403 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:38,404 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-04-24 14:43:38,463 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #33: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 8)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.41, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-24 14:43:38,464 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:38,465 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-04-24 14:43:43,023 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #33: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46153846153846156, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.16, '(min, 1)': 0.49, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:43:43,024 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:43,025 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-04-24 14:43:43,232 - MainProcess - INFO - text_logger.py - 51 - Train epoch #33
2024-04-24 14:43:43,240 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.7745e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5310e-01, 0.0000e+00,
        5.4962e-02, 4.5035e-03, 3.5012e-01, 0.0000e+00, 9.8829e-03, 3.7582e-03,
        0.0000e+00, 0.0000e+00, 6.5385e-03, 2.2386e-03, 0.0000e+00, 0.0000e+00,
        4.1994e-03, 1.2557e-03, 0.0000e+00, 0.0000e+00, 3.5443e-03, 4.9375e-05,
        0.0000e+00, 0.0000e+00, 2.7762e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8191e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1763e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.9482e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.9291e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1101e-01, 0.0000e+00,
        5.9400e-02, 8.4329e-03, 6.8257e-02, 0.0000e+00, 2.8972e-02, 7.2873e-03,
        0.0000e+00, 0.0000e+00, 2.4829e-02, 5.7743e-03, 0.0000e+00, 0.0000e+00,
        2.0111e-02, 4.8777e-03, 0.0000e+00, 0.0000e+00, 1.8135e-02, 7.8461e-04,
        0.0000e+00, 0.0000e+00, 1.4630e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0142e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0861e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1016e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:43:43,279 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4438671598091802
2024-04-24 14:43:43,282 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.278380.08273
2024-04-24 14:43:43,314 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #34: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 2, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 1, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.14583333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.14, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:43:43,315 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:43,316 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-04-24 14:43:43,325 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #34: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.4, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:43:43,325 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:43,326 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-04-24 14:43:43,340 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #34: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.02, '(min, 0)': 0.02, '(min, 1)': 0.59, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:43:43,340 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:43,341 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-04-24 14:43:44,196 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #34: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.41, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-04-24 14:43:44,196 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:44,197 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-04-24 14:43:45,337 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #34: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8536585365853658, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 3)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.38, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.05, '(rev, 4)': 0.01}}
2024-04-24 14:43:45,338 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:45,341 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-04-24 14:43:46,756 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #34: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.39, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:43:46,756 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:46,757 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-04-24 14:43:48,397 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #34: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.42, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-24 14:43:48,397 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:48,398 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-04-24 14:43:48,615 - MainProcess - INFO - text_logger.py - 51 - Train epoch #34
2024-04-24 14:43:48,619 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.6787e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3925e-01, 0.0000e+00,
        5.7046e-02, 3.5841e-03, 3.5119e-01, 0.0000e+00, 1.1492e-02, 2.5135e-03,
        0.0000e+00, 0.0000e+00, 8.6446e-03, 1.7342e-03, 0.0000e+00, 0.0000e+00,
        6.5222e-03, 7.7687e-04, 0.0000e+00, 0.0000e+00, 5.6638e-03, 2.8676e-04,
        0.0000e+00, 0.0000e+00, 5.0297e-03, 2.0236e-04, 0.0000e+00, 0.0000e+00,
        3.2860e-03, 8.5497e-05, 0.0000e+00, 0.0000e+00, 2.3248e-03, 2.9412e-05,
        0.0000e+00, 0.0000e+00, 3.4415e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.0733e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3376e-01, 0.0000e+00,
        7.7735e-02, 7.7528e-03, 8.3435e-02, 0.0000e+00, 3.1336e-02, 6.2321e-03,
        0.0000e+00, 0.0000e+00, 2.8509e-02, 5.6695e-03, 0.0000e+00, 0.0000e+00,
        2.4309e-02, 3.7455e-03, 0.0000e+00, 0.0000e+00, 2.2033e-02, 2.0189e-03,
        0.0000e+00, 0.0000e+00, 2.0216e-02, 1.7100e-03, 0.0000e+00, 0.0000e+00,
        1.3457e-02, 1.1052e-03, 0.0000e+00, 0.0000e+00, 1.0048e-02, 6.5767e-04,
        0.0000e+00, 0.0000e+00, 2.5658e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:43:48,654 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4433968458809146
2024-04-24 14:43:48,660 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.235960.09013
2024-04-24 14:43:48,693 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #35: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36363636363636365, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.21, '(min, 1)': 0.38, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-24 14:43:48,693 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:48,695 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-04-24 14:43:49,468 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #35: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5853658536585366, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.5, '(min, 1)': 0.15, '(rev, 1)': 0.13, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 7)': 0.01}}
2024-04-24 14:43:49,469 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:49,470 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-04-24 14:43:49,522 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #35: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.875, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.13, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:43:49,522 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:49,523 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-04-24 14:43:50,930 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #35: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.022222222222222223, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.16, '(rev, 1)': 0.02}}
2024-04-24 14:43:50,931 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:50,931 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-04-24 14:43:51,744 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #35: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3611111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.43, '(min, 1)': 0.24, '(rev, 1)': 0.03, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:43:51,744 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:51,745 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-04-24 14:43:52,115 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #35: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(ado, 3)': 0.02, '(min, 0)': 0.16, '(min, 1)': 0.43, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:43:52,115 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:52,116 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-04-24 14:43:53,294 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #35: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0),(ado, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/3', 'revenue': 0.22727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.32, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:43:53,294 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:53,295 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-04-24 14:43:53,496 - MainProcess - INFO - text_logger.py - 51 - Train epoch #35
2024-04-24 14:43:53,501 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.5027e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6094e-01, 0.0000e+00,
        9.1682e-02, 3.1678e-03, 3.2056e-01, 0.0000e+00, 2.8251e-02, 1.7722e-03,
        0.0000e+00, 0.0000e+00, 2.3475e-02, 8.5122e-04, 0.0000e+00, 0.0000e+00,
        1.9432e-02, 4.5675e-04, 0.0000e+00, 0.0000e+00, 1.6489e-02, 2.1472e-04,
        0.0000e+00, 0.0000e+00, 1.4705e-02, 5.5787e-05, 0.0000e+00, 0.0000e+00,
        9.9476e-03, 3.2258e-05, 0.0000e+00, 0.0000e+00, 6.5854e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2015e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7739e-04, 0.0000e+00, 0.0000e+00])  tensor([1.9334e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9373e-01, 0.0000e+00,
        9.0088e-02, 7.5665e-03, 1.2169e-01, 0.0000e+00, 4.9270e-02, 5.4956e-03,
        0.0000e+00, 0.0000e+00, 4.5964e-02, 4.2107e-03, 0.0000e+00, 0.0000e+00,
        4.0440e-02, 3.1279e-03, 0.0000e+00, 0.0000e+00, 3.5775e-02, 2.2166e-03,
        0.0000e+00, 0.0000e+00, 3.2249e-02, 8.9196e-04, 0.0000e+00, 0.0000e+00,
        2.2950e-02, 7.2131e-04, 0.0000e+00, 0.0000e+00, 1.5986e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.6793e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6406e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:43:53,527 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.443403613880089
2024-04-24 14:43:53,529 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.474500.11086
2024-04-24 14:43:53,601 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #36: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3404255319148936, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.42, '(min, 1)': 0.13, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 4)': 0.01}}
2024-04-24 14:43:53,601 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:53,602 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-04-24 14:43:54,940 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #36: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.5, '(min, 1)': 0.12, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:43:54,940 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:54,941 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-04-24 14:43:55,690 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #36: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(min, 0)': 0.37, '(min, 1)': 0.19, '(rev, 1)': 0.12, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:43:55,690 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:55,691 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-04-24 14:43:56,482 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #36: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0975609756097561, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.5, '(min, 1)': 0.1, '(rev, 1)': 0.01, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:43:56,482 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:56,483 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-04-24 14:43:57,055 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #36: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.42, '(min, 1)': 0.17, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 6)': 0.01}}
2024-04-24 14:43:57,056 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:57,059 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-04-24 14:43:57,097 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #36: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3958333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 5)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.19, '(rev, 1)': 0.1, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-04-24 14:43:57,097 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:57,099 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-04-24 14:43:58,973 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #36: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 7, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.675, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.38, '(min, 1)': 0.25, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-04-24 14:43:58,973 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:58,974 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-04-24 14:43:59,167 - MainProcess - INFO - text_logger.py - 51 - Train epoch #36
2024-04-24 14:43:59,171 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.6275e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4567e-01, 0.0000e+00,
        5.9283e-02, 5.7920e-03, 3.7365e-01, 0.0000e+00, 5.6156e-03, 2.9363e-03,
        0.0000e+00, 0.0000e+00, 2.5923e-03, 8.3475e-04, 0.0000e+00, 0.0000e+00,
        1.0488e-03, 4.4797e-04, 0.0000e+00, 0.0000e+00, 6.9893e-04, 2.1204e-04,
        0.0000e+00, 0.0000e+00, 4.7149e-04, 5.5556e-05, 0.0000e+00, 0.0000e+00,
        4.3759e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5269e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.1984, 0.0000, 0.0000, 0.0000, 0.0729, 0.0000, 0.0638, 0.0097, 0.0418,
        0.0000, 0.0198, 0.0071, 0.0000, 0.0000, 0.0141, 0.0038, 0.0000, 0.0000,
        0.0097, 0.0029, 0.0000, 0.0000, 0.0085, 0.0023, 0.0000, 0.0000, 0.0061,
        0.0012, 0.0000, 0.0000, 0.0056, 0.0000, 0.0000, 0.0000, 0.0033, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-04-24 14:43:59,190 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4428993661694931
2024-04-24 14:43:59,193 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.218990.12143
2024-04-24 14:43:59,740 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #37: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 2, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.47, '(min, 1)': 0.07, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:43:59,741 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:43:59,741 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-04-24 14:44:00,046 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #37: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.05, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.44, '(min, 1)': 0.16, '(rev, 1)': 0.02}}
2024-04-24 14:44:00,047 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:00,048 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-04-24 14:44:00,708 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #37: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.30434782608695654, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.23, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:44:00,709 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:00,709 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-04-24 14:44:00,922 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #37: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.53, '(min, 1)': 0.08}}
2024-04-24 14:44:00,923 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:00,925 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-04-24 14:44:02,557 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #37: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7045454545454546, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.27, '(rev, 1)': 0.09, '(rev, 2)': 0.08, '(rev, 3)': 0.02}}
2024-04-24 14:44:02,557 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:02,558 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-04-24 14:44:02,637 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #37: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5909090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(min, 0)': 0.39, '(min, 1)': 0.23, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:44:02,637 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:02,638 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-04-24 14:44:04,843 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #37: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.46808510638297873, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.4, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:44:04,843 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:04,844 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-04-24 14:44:05,034 - MainProcess - INFO - text_logger.py - 51 - Train epoch #37
2024-04-24 14:44:05,042 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.0497e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5267e-01, 0.0000e+00,
        5.7198e-02, 5.0781e-03, 3.7242e-01, 0.0000e+00, 4.8975e-03, 2.8911e-03,
        0.0000e+00, 0.0000e+00, 1.6209e-03, 1.1614e-03, 0.0000e+00, 0.0000e+00,
        2.1440e-04, 7.0649e-04, 0.0000e+00, 0.0000e+00, 5.4444e-05, 3.3365e-04,
        0.0000e+00, 0.0000e+00, 2.7778e-05, 2.9238e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.1545e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2525e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0159e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5787e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.1285e-02, 0.0000e+00,
        7.2278e-02, 9.3626e-03, 4.3856e-02, 0.0000e+00, 1.7571e-02, 7.2379e-03,
        0.0000e+00, 0.0000e+00, 1.0143e-02, 4.5829e-03, 0.0000e+00, 0.0000e+00,
        2.4562e-03, 4.0358e-03, 0.0000e+00, 0.0000e+00, 8.6016e-04, 2.6658e-03,
        0.0000e+00, 0.0000e+00, 6.2113e-04, 2.5146e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.8434e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4082e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1721e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:44:05,080 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4420071319513725
2024-04-24 14:44:05,083 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.025000.02500
2024-04-24 14:44:05,097 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #38: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 3, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.56, '(min, 1)': 0.02}}
2024-04-24 14:44:05,099 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:05,100 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-04-24 14:44:05,130 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #38: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 6)': 0.01, '(min, 0)': 0.52, '(min, 1)': 0.06, '(rev, 1)': 0.09, '(rev, 2)': 0.05}}
2024-04-24 14:44:05,130 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:05,131 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-04-24 14:44:05,562 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #38: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35714285714285715, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(min, 0)': 0.45, '(min, 1)': 0.1, '(rev, 1)': 0.13, '(rev, 2)': 0.05}}
2024-04-24 14:44:05,565 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:05,566 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-04-24 14:44:05,572 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #38: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.52, '(min, 1)': 0.07}}
2024-04-24 14:44:05,573 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:05,574 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-04-24 14:44:07,836 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #38: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10869565217391304, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.16, '(rev, 1)': 0.04, '(rev, 2)': 0.01}}
2024-04-24 14:44:07,836 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:07,837 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-04-24 14:44:09,606 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #38: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.23, '(rev, 1)': 0.07, '(rev, 2)': 0.03}}
2024-04-24 14:44:09,607 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:09,607 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-04-24 14:44:09,776 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #38: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.2, '(rev, 1)': 0.08, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:44:09,777 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:09,779 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-04-24 14:44:09,982 - MainProcess - INFO - text_logger.py - 51 - Train epoch #38
2024-04-24 14:44:09,986 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.3554e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1297e-01, 0.0000e+00,
        7.1020e-02, 4.5371e-03, 3.5940e-01, 0.0000e+00, 1.3672e-02, 2.0646e-03,
        0.0000e+00, 0.0000e+00, 1.0424e-02, 5.5125e-04, 0.0000e+00, 0.0000e+00,
        7.5413e-03, 4.2356e-04, 0.0000e+00, 0.0000e+00, 6.1637e-03, 1.6311e-04,
        0.0000e+00, 0.0000e+00, 5.0178e-03, 1.0477e-04, 0.0000e+00, 0.0000e+00,
        3.2647e-03, 7.6197e-05, 0.0000e+00, 0.0000e+00, 2.2205e-03, 3.7736e-05,
        0.0000e+00, 0.0000e+00, 3.1624e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9412e-05, 0.0000e+00, 0.0000e+00])  tensor([1.2837e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3079e-01, 0.0000e+00,
        7.6764e-02, 8.9754e-03, 7.9060e-02, 0.0000e+00, 3.3122e-02, 6.0420e-03,
        0.0000e+00, 0.0000e+00, 3.0915e-02, 3.2128e-03, 0.0000e+00, 0.0000e+00,
        2.5148e-02, 3.0364e-03, 0.0000e+00, 0.0000e+00, 2.1439e-02, 1.6557e-03,
        0.0000e+00, 0.0000e+00, 1.8482e-02, 1.3611e-03, 0.0000e+00, 0.0000e+00,
        1.3349e-02, 1.2036e-03, 0.0000e+00, 0.0000e+00, 9.2802e-03, 8.4380e-04,
        0.0000e+00, 0.0000e+00, 2.3659e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.5767e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:44:10,138 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.44106489773325186
2024-04-24 14:44:10,141 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:44:10,188 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #39: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.44, '(min, 1)': 0.14, '(rev, 1)': 0.12, '(rev, 2)': 0.05}}
2024-04-24 14:44:10,190 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:10,191 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-04-24 14:44:10,635 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #39: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4318181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.49, '(min, 1)': 0.1, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 4)': 0.02}}
2024-04-24 14:44:10,635 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:10,636 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-04-24 14:44:10,880 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #39: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 4, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.58, '(min, 1)': 0.04}}
2024-04-24 14:44:10,881 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:10,882 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-04-24 14:44:13,672 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #39: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3023255813953488, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.42, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-24 14:44:13,673 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:13,674 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-04-24 14:44:14,132 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #39: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.51, '(min, 1)': 0.06}}
2024-04-24 14:44:14,133 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:14,134 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-04-24 14:44:14,736 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #39: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.1, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-24 14:44:14,736 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:14,737 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-04-24 14:44:14,952 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #39: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 4, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4883720930232558, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(min, 0)': 0.48, '(min, 1)': 0.11, '(rev, 1)': 0.12, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:44:14,953 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:14,954 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-04-24 14:44:15,190 - MainProcess - INFO - text_logger.py - 51 - Train epoch #39
2024-04-24 14:44:15,194 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.1386e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5382e-01, 0.0000e+00,
        4.7238e-02, 5.6896e-03, 3.8523e-01, 0.0000e+00, 3.1374e-03, 2.5391e-03,
        0.0000e+00, 0.0000e+00, 1.1484e-03, 6.3202e-04, 0.0000e+00, 0.0000e+00,
        1.9520e-04, 2.2575e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2219e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4483e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.4483e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([9.6098e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0373e-02, 0.0000e+00,
        5.2764e-02, 9.6935e-03, 2.7179e-02, 0.0000e+00, 1.2418e-02, 6.6354e-03,
        0.0000e+00, 0.0000e+00, 7.7827e-03, 3.3695e-03, 0.0000e+00, 0.0000e+00,
        3.1085e-03, 1.9123e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1419e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7106e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.7106e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:44:15,219 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4401226635151313
2024-04-24 14:44:15,222 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:44:15,549 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #40: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1282051282051282, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(min, 0)': 0.48, '(min, 1)': 0.11, '(rev, 1)': 0.04, '(rev, 2)': 0.03}}
2024-04-24 14:44:15,551 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:15,553 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-04-24 14:44:16,213 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #40: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.375, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 5)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.22, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:44:16,213 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:16,214 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-04-24 14:44:18,541 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #40: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.8541666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 7)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-04-24 14:44:18,541 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:18,542 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-04-24 14:44:19,126 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #40: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-04-24 14:44:19,126 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:19,128 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-04-24 14:44:20,281 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #40: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.41, '(min, 1)': 0.21, '(rev, 1)': 0.06, '(rev, 2)': 0.07, '(rev, 3)': 0.02}}
2024-04-24 14:44:20,282 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:20,282 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-04-24 14:44:20,605 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #40: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46808510638297873, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.28, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:44:20,605 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:20,606 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-04-24 14:44:21,713 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #40: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5434782608695652, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 7)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.19, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-04-24 14:44:21,715 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:21,716 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-04-24 14:44:21,804 - MainProcess - INFO - text_logger.py - 51 - Train epoch #40
2024-04-24 14:44:21,807 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-6.5838e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  5.0324e-01,
         0.0000e+00,  7.4070e-02,  4.4900e-03,  3.5479e-01,  0.0000e+00,
         1.5824e-02,  2.0706e-03,  0.0000e+00,  0.0000e+00,  1.3075e-02,
         8.2001e-04,  0.0000e+00,  0.0000e+00,  8.9763e-03,  3.6859e-04,
         0.0000e+00,  0.0000e+00,  7.8520e-03,  1.2269e-04,  0.0000e+00,
         0.0000e+00,  6.6181e-03,  7.9216e-05,  0.0000e+00,  0.0000e+00,
         4.2282e-03,  4.0000e-05,  0.0000e+00,  0.0000e+00,  2.8986e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.8957e-04,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  5.2303e-05,  0.0000e+00,  0.0000e+00])  tensor([1.6946e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4118e-01, 0.0000e+00,
        8.6325e-02, 8.8986e-03, 8.2653e-02, 0.0000e+00, 3.2707e-02, 6.0398e-03,
        0.0000e+00, 0.0000e+00, 3.1210e-02, 4.0749e-03, 0.0000e+00, 0.0000e+00,
        2.3238e-02, 2.7199e-03, 0.0000e+00, 0.0000e+00, 2.1577e-02, 1.5824e-03,
        0.0000e+00, 0.0000e+00, 1.9371e-02, 1.2513e-03, 0.0000e+00, 0.0000e+00,
        1.3257e-02, 8.9443e-04, 0.0000e+00, 0.0000e+00, 9.9011e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.6633e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.4177e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:44:21,843 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.440578074224547
2024-04-24 14:44:21,846 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.698820.15534
2024-04-24 14:44:21,883 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #41: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.023255813953488372, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 6)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.1, '(rev, 1)': 0.02}}
2024-04-24 14:44:21,883 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:21,884 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-04-24 14:44:21,979 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #41: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 6)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.16, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:44:21,980 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:21,981 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-04-24 14:44:23,911 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #41: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.52, '(min, 1)': 0.08, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:44:23,911 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:23,912 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-04-24 14:44:25,057 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #41: {'transition': '(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 2, 5, 1, 1),(min, 0)->(exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 3, 5, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.41, '(min, 1)': 0.19, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:44:25,057 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:25,059 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-04-24 14:44:25,751 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #41: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5869565217391305, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(min, 0)': 0.29, '(min, 1)': 0.26, '(rev, 1)': 0.11, '(rev, 2)': 0.05}}
2024-04-24 14:44:25,752 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:25,753 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-04-24 14:44:26,307 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #41: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 6, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40476190476190477, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.43, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:44:26,308 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:26,309 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-04-24 14:44:27,249 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #41: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6428571428571429, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(min, 0)': 0.27, '(min, 1)': 0.36, '(rev, 1)': 0.11, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-24 14:44:27,250 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:27,251 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-04-24 14:44:27,340 - MainProcess - INFO - text_logger.py - 51 - Train epoch #41
2024-04-24 14:44:27,344 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-2.4780e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.8062e-01,
         0.0000e+00,  8.2155e-02,  4.1523e-03,  3.3818e-01,  0.0000e+00,
         2.0960e-02,  1.6970e-03,  0.0000e+00,  0.0000e+00,  1.7971e-02,
         6.1111e-04,  0.0000e+00,  0.0000e+00,  1.3415e-02,  5.1597e-04,
         0.0000e+00,  0.0000e+00,  1.2301e-02,  3.4116e-04,  0.0000e+00,
         0.0000e+00,  1.0902e-02,  3.7958e-04,  0.0000e+00,  0.0000e+00,
         7.9294e-03,  1.3486e-04,  0.0000e+00,  0.0000e+00,  6.2985e-03,
         3.5714e-05,  0.0000e+00,  0.0000e+00,  1.2318e-03,  3.5714e-05,
         0.0000e+00,  0.0000e+00,  1.3438e-04,  0.0000e+00,  0.0000e+00])  tensor([1.8187e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7119e-01, 0.0000e+00,
        1.0330e-01, 8.6674e-03, 1.0216e-01, 0.0000e+00, 3.8422e-02, 5.4138e-03,
        0.0000e+00, 0.0000e+00, 3.5712e-02, 3.4326e-03, 0.0000e+00, 0.0000e+00,
        2.7495e-02, 3.1188e-03, 0.0000e+00, 0.0000e+00, 2.5936e-02, 2.4066e-03,
        0.0000e+00, 0.0000e+00, 2.3552e-02, 2.9703e-03, 0.0000e+00, 0.0000e+00,
        1.7384e-02, 1.5086e-03, 0.0000e+00, 0.0000e+00, 1.4009e-02, 7.9860e-04,
        0.0000e+00, 0.0000e+00, 4.6836e-03, 7.9860e-04, 0.0000e+00, 0.0000e+00,
        1.5078e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:44:27,370 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4405786971492836
2024-04-24 14:44:27,377 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.471430.17143
2024-04-24 14:44:27,419 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2692307692307692, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 7)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.18, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:44:27,419 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:27,420 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-04-24 14:44:28,764 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5294117647058824, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.17, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:44:28,764 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:28,765 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-04-24 14:44:28,846 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.48, '(min, 1)': 0.11}}
2024-04-24 14:44:28,846 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:28,846 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-04-24 14:44:31,239 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.045454545454545456, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.23, '(rev, 1)': 0.04}}
2024-04-24 14:44:31,240 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:31,240 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-04-24 14:44:31,885 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 8)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.31, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-04-24 14:44:31,886 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:31,887 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-04-24 14:44:32,245 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.36, '(min, 1)': 0.2, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:44:32,246 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:32,246 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-04-24 14:44:32,664 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7555555555555555, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(min, 0)': 0.37, '(min, 1)': 0.28, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.07, '(rev, 4)': 0.04}}
2024-04-24 14:44:32,665 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:32,665 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-04-24 14:44:32,870 - MainProcess - INFO - text_logger.py - 51 - Train epoch #42
2024-04-24 14:44:32,874 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.1348e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0159e-01, 0.0000e+00,
        6.9313e-02, 4.0843e-03, 3.4256e-01, 0.0000e+00, 1.8941e-02, 2.8893e-03,
        0.0000e+00, 0.0000e+00, 1.4575e-02, 2.1868e-03, 0.0000e+00, 0.0000e+00,
        1.0242e-02, 1.5799e-03, 0.0000e+00, 0.0000e+00, 9.8714e-03, 4.8663e-04,
        0.0000e+00, 0.0000e+00, 8.6144e-03, 3.6796e-04, 0.0000e+00, 0.0000e+00,
        6.2385e-03, 3.0907e-04, 0.0000e+00, 0.0000e+00, 4.9592e-03, 3.6364e-05,
        0.0000e+00, 0.0000e+00, 1.0056e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4532e-04, 0.0000e+00, 0.0000e+00])  tensor([2.0738e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6112e-01, 0.0000e+00,
        9.5430e-02, 8.2663e-03, 9.4860e-02, 0.0000e+00, 3.6711e-02, 6.6710e-03,
        0.0000e+00, 0.0000e+00, 3.2343e-02, 6.0066e-03, 0.0000e+00, 0.0000e+00,
        2.4618e-02, 5.4076e-03, 0.0000e+00, 0.0000e+00, 2.4410e-02, 2.8956e-03,
        0.0000e+00, 0.0000e+00, 2.1474e-02, 2.4863e-03, 0.0000e+00, 0.0000e+00,
        1.5873e-02, 2.2999e-03, 0.0000e+00, 0.0000e+00, 1.2975e-02, 8.1312e-04,
        0.0000e+00, 0.0000e+00, 4.2118e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4692e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:44:32,902 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43994757404227414
2024-04-24 14:44:32,910 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.155560.15556
2024-04-24 14:44:33,145 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #43: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 4, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 7)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.16, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:44:33,145 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:33,146 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-04-24 14:44:34,929 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #43: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 9, 3, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 9, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4594594594594595, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.21, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.04, '(rev, 5)': 0.01}}
2024-04-24 14:44:34,929 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:34,930 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-04-24 14:44:37,206 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #43: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 4, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 6)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.3}}
2024-04-24 14:44:37,207 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:37,208 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-04-24 14:44:37,637 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #43: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.23404255319148937, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.4, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:44:37,638 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:37,639 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-04-24 14:44:38,999 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #43: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 10)': 0.01, '(ado, 2)': 0.02, '(min, 0)': 0.45, '(min, 1)': 0.2, '(rev, 1)': 0.08, '(rev, 2)': 0.03}}
2024-04-24 14:44:39,000 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:39,001 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-04-24 14:44:39,279 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #43: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 1),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 2, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.375, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.3, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:44:39,280 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:39,286 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-04-24 14:44:39,326 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #43: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.08108108108108109, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(min, 0)': 0.43, '(min, 1)': 0.21, '(rev, 1)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:44:39,327 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:39,330 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-04-24 14:44:39,491 - MainProcess - INFO - text_logger.py - 51 - Train epoch #43
2024-04-24 14:44:39,498 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.5734e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0649e-01, 0.0000e+00,
        7.2479e-02, 3.5302e-03, 3.4712e-01, 0.0000e+00, 1.7472e-02, 2.4893e-03,
        0.0000e+00, 0.0000e+00, 1.3313e-02, 1.6546e-03, 0.0000e+00, 0.0000e+00,
        8.9788e-03, 1.1303e-03, 0.0000e+00, 0.0000e+00, 8.2597e-03, 7.3222e-04,
        0.0000e+00, 0.0000e+00, 6.8963e-03, 5.7088e-04, 0.0000e+00, 0.0000e+00,
        4.1819e-03, 5.1313e-04, 0.0000e+00, 0.0000e+00, 3.2299e-03, 2.3399e-04,
        0.0000e+00, 0.0000e+00, 6.0997e-04, 3.6364e-05, 0.0000e+00, 0.0000e+00,
        8.2695e-05, 0.0000e+00, 0.0000e+00])  tensor([2.2182e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5520e-01, 0.0000e+00,
        9.5556e-02, 7.6240e-03, 9.0552e-02, 0.0000e+00, 3.5798e-02, 5.9175e-03,
        0.0000e+00, 0.0000e+00, 3.0487e-02, 5.0662e-03, 0.0000e+00, 0.0000e+00,
        2.1931e-02, 4.0308e-03, 0.0000e+00, 0.0000e+00, 2.2472e-02, 3.2606e-03,
        0.0000e+00, 0.0000e+00, 1.9894e-02, 2.8554e-03, 0.0000e+00, 0.0000e+00,
        1.3785e-02, 2.7135e-03, 0.0000e+00, 0.0000e+00, 1.1265e-02, 1.8800e-03,
        0.0000e+00, 0.0000e+00, 3.4288e-03, 8.1312e-04, 0.0000e+00, 0.0000e+00,
        1.0798e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:44:39,523 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4390864209052346
2024-04-24 14:44:39,526 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.040540.04054
2024-04-24 14:44:41,396 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 4)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.23, '(rev, 1)': 0.02, '(rev, 2)': 0.02, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:44:41,397 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:41,397 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-04-24 14:44:41,986 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.36, '(min, 1)': 0.27}}
2024-04-24 14:44:41,986 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:41,987 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-04-24 14:44:42,304 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.36, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 3)': 0.03, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.4, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:44:42,304 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:42,307 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-04-24 14:44:43,305 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #44: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.07692307692307693, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.31, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:44:43,305 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:43,307 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-04-24 14:44:44,087 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.38, '(min, 1)': 0.2}}
2024-04-24 14:44:44,088 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:44,092 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-04-24 14:44:44,781 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.29, '(rev, 1)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:44:44,782 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:44,782 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-04-24 14:44:45,737 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 5)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.22}}
2024-04-24 14:44:45,739 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:45,741 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-04-24 14:44:45,930 - MainProcess - INFO - text_logger.py - 51 - Train epoch #44
2024-04-24 14:44:45,934 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-7.1114e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.1395e-01,
         0.0000e+00,  1.7042e-01,  2.1033e-03,  2.4171e-01,  0.0000e+00,
         6.2073e-02,  1.4011e-03,  0.0000e+00,  0.0000e+00,  4.9834e-02,
         5.9143e-04,  0.0000e+00,  0.0000e+00,  3.8661e-02,  2.3694e-04,
         0.0000e+00,  0.0000e+00,  3.7497e-02,  5.2094e-04,  0.0000e+00,
         0.0000e+00,  3.4201e-02,  3.2258e-05,  0.0000e+00,  0.0000e+00,
         2.4427e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.8936e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.0899e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.0639e-04,  0.0000e+00,  0.0000e+00])  tensor([1.9727e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2199e-01, 0.0000e+00,
        1.2899e-01, 6.2317e-03, 1.3389e-01, 0.0000e+00, 5.1817e-02, 4.7689e-03,
        0.0000e+00, 0.0000e+00, 4.3491e-02, 3.4349e-03, 0.0000e+00, 0.0000e+00,
        3.5122e-02, 2.0167e-03, 0.0000e+00, 0.0000e+00, 3.5539e-02, 3.9136e-03,
        0.0000e+00, 0.0000e+00, 3.3385e-02, 7.2131e-04, 0.0000e+00, 0.0000e+00,
        2.5788e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1859e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.2711e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.1669e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:44:45,963 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.438144186687114
2024-04-24 14:44:45,968 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:44:48,040 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #45: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43137254901960786, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.32, '(rev, 1)': 0.03, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-24 14:44:48,041 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:48,041 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-04-24 14:44:49,050 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #45: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.3, '(min, 1)': 0.33}}
2024-04-24 14:44:49,052 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:49,058 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-04-24 14:44:49,255 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #45: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7435897435897436, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.33, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 5)': 0.02}}
2024-04-24 14:44:49,256 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:49,257 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-04-24 14:44:49,330 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #45: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 7)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.1}}
2024-04-24 14:44:49,332 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:49,332 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-04-24 14:44:50,921 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #45: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.52, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 6)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.3, '(rev, 1)': 0.05, '(rev, 5)': 0.01, '(rev, 6)': 0.02}}
2024-04-24 14:44:50,921 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:50,922 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-04-24 14:44:51,003 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #45: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3673469387755102, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 9)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.42, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 5)': 0.02}}
2024-04-24 14:44:51,003 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:51,004 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-04-24 14:44:51,415 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #45: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.16326530612244897, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.14, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:44:51,416 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:51,421 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-04-24 14:44:51,632 - MainProcess - INFO - text_logger.py - 51 - Train epoch #45
2024-04-24 14:44:51,636 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.3675e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3078e-01, 0.0000e+00,
        1.1235e-01, 3.0676e-03, 3.0306e-01, 0.0000e+00, 3.4429e-02, 2.0275e-03,
        0.0000e+00, 0.0000e+00, 2.8253e-02, 1.2080e-03, 0.0000e+00, 0.0000e+00,
        2.1168e-02, 6.7340e-04, 0.0000e+00, 0.0000e+00, 1.9589e-02, 6.9373e-04,
        0.0000e+00, 0.0000e+00, 1.7652e-02, 3.6722e-04, 0.0000e+00, 0.0000e+00,
        1.2531e-02, 1.0588e-04, 0.0000e+00, 0.0000e+00, 9.8324e-03, 3.6364e-05,
        0.0000e+00, 0.0000e+00, 1.8835e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.0031e-04, 0.0000e+00, 0.0000e+00])  tensor([2.4719e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1266e-01, 0.0000e+00,
        1.2858e-01, 7.3583e-03, 1.3013e-01, 0.0000e+00, 4.8757e-02, 5.7518e-03,
        0.0000e+00, 0.0000e+00, 4.3061e-02, 4.6920e-03, 0.0000e+00, 0.0000e+00,
        3.3662e-02, 3.3071e-03, 0.0000e+00, 0.0000e+00, 3.2548e-02, 3.5140e-03,
        0.0000e+00, 0.0000e+00, 2.9749e-02, 2.8631e-03, 0.0000e+00, 0.0000e+00,
        2.2139e-02, 1.3718e-03, 0.0000e+00, 0.0000e+00, 1.8016e-02, 8.1312e-04,
        0.0000e+00, 0.0000e+00, 5.8310e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.1417e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:44:51,665 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43720195246899346
2024-04-24 14:44:51,669 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:44:53,802 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #46: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.22, '(min, 1)': 0.37}}
2024-04-24 14:44:53,802 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:53,803 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-04-24 14:44:53,872 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #46: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3125, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 8)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.25, '(rev, 1)': 0.08, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:44:53,872 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:53,873 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-04-24 14:44:54,389 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #46: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.22, '(min, 1)': 0.38}}
2024-04-24 14:44:54,390 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:54,391 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-04-24 14:44:55,403 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #46: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 3, 1, 1),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 4, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.46, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.26, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.04, '(rev, 4)': 0.01}}
2024-04-24 14:44:55,404 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:55,405 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-04-24 14:44:57,666 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #46: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.48, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-04-24 14:44:57,668 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:57,669 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-04-24 14:44:59,670 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #46: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.09803921568627451, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.19, '(rev, 1)': 0.01, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:44:59,670 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:59,671 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-04-24 14:44:59,935 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #46: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.44680851063829785, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.34, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-04-24 14:44:59,936 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:44:59,947 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-04-24 14:45:00,155 - MainProcess - INFO - text_logger.py - 51 - Train epoch #46
2024-04-24 14:45:00,159 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.0413e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4966e-01, 0.0000e+00,
        9.3711e-02, 3.7625e-03, 3.2611e-01, 0.0000e+00, 3.0168e-02, 1.8121e-03,
        0.0000e+00, 0.0000e+00, 2.3568e-02, 1.3860e-03, 0.0000e+00, 0.0000e+00,
        1.6806e-02, 7.8657e-04, 0.0000e+00, 0.0000e+00, 1.6378e-02, 5.8606e-04,
        0.0000e+00, 0.0000e+00, 1.4641e-02, 3.4387e-04, 0.0000e+00, 0.0000e+00,
        1.0562e-02, 3.0613e-04, 0.0000e+00, 0.0000e+00, 7.7868e-03, 3.6364e-05,
        0.0000e+00, 0.0000e+00, 1.3372e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5569e-04, 0.0000e+00, 0.0000e+00])  tensor([2.2195e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9413e-01, 0.0000e+00,
        1.1056e-01, 8.3025e-03, 1.2154e-01, 0.0000e+00, 4.8304e-02, 5.4450e-03,
        0.0000e+00, 0.0000e+00, 4.0956e-02, 4.6998e-03, 0.0000e+00, 0.0000e+00,
        3.0773e-02, 3.6647e-03, 0.0000e+00, 0.0000e+00, 3.1686e-02, 3.1721e-03,
        0.0000e+00, 0.0000e+00, 2.8886e-02, 2.4388e-03, 0.0000e+00, 0.0000e+00,
        2.2189e-02, 2.2932e-03, 0.0000e+00, 0.0000e+00, 1.7071e-02, 8.1312e-04,
        0.0000e+00, 0.0000e+00, 4.9609e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.0261e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:45:00,181 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4362597182508729
2024-04-24 14:45:00,184 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:45:00,203 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #47: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2708333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.19, '(min, 1)': 0.42, '(rev, 1)': 0.03, '(rev, 10)': 0.01}}
2024-04-24 14:45:00,204 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:00,205 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-04-24 14:45:00,515 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #47: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.33, '(min, 1)': 0.29, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-04-24 14:45:00,520 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:00,521 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-04-24 14:45:00,805 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #47: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(ado, 8)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.19}}
2024-04-24 14:45:00,806 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:00,808 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-04-24 14:45:03,948 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #47: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 3, 0, 0),(rev, 3)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.27, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-24 14:45:03,948 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:03,950 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-04-24 14:45:04,708 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #47: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 3, 9, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.2}}
2024-04-24 14:45:04,709 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:04,709 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-04-24 14:45:05,480 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #47: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1875, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 3)': 0.03, '(ado, 8)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.24, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:45:05,480 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:05,481 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-04-24 14:45:08,629 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #47: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 2, 1, 1),(min, 0)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 3, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.19047619047619047, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.39, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:45:08,629 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:08,629 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-04-24 14:45:08,829 - MainProcess - INFO - text_logger.py - 51 - Train epoch #47
2024-04-24 14:45:08,833 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.3567e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.5587e-01,
         0.0000e+00,  1.5011e-01,  1.9760e-03,  2.6737e-01,  0.0000e+00,
         5.0904e-02,  1.4587e-03,  0.0000e+00,  0.0000e+00,  4.1269e-02,
         8.2454e-04,  0.0000e+00,  0.0000e+00,  3.1219e-02,  5.9187e-04,
         0.0000e+00,  0.0000e+00,  3.0360e-02,  2.3752e-04,  0.0000e+00,
         0.0000e+00,  2.8039e-02,  4.0816e-05,  0.0000e+00,  0.0000e+00,
         2.0783e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.5226e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.1162e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.0773e-04,  0.0000e+00,  0.0000e+00])  tensor([2.2636e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2690e-01, 0.0000e+00,
        1.3079e-01, 6.2641e-03, 1.4596e-01, 0.0000e+00, 5.4243e-02, 4.8474e-03,
        0.0000e+00, 0.0000e+00, 4.6247e-02, 3.7843e-03, 0.0000e+00, 0.0000e+00,
        3.7190e-02, 3.3883e-03, 0.0000e+00, 0.0000e+00, 3.7975e-02, 2.0146e-03,
        0.0000e+00, 0.0000e+00, 3.5814e-02, 9.1268e-04, 0.0000e+00, 0.0000e+00,
        2.8133e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2301e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.5571e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.0905e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:45:08,867 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43558831736608566
2024-04-24 14:45:08,870 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.135420.13542
2024-04-24 14:45:08,893 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #48: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.24, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:45:08,893 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #48: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 6, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.26, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:45:08,895 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty

2024-04-24 14:45:08,898 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729

2024-04-24 14:45:08,922 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #48: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.05263157894736842, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.37, '(min, 1)': 0.24, '(rev, 1)': 0.02, '(rev, 2)': 0.01}}
2024-04-24 14:45:08,922 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:08,923 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729
2024-04-24 14:45:09,806 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #48: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5714285714285714, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(min, 0)': 0.3, '(min, 1)': 0.29, '(rev, 1)': 0.12, '(rev, 2)': 0.07, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-04-24 14:45:09,807 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:09,807 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729
2024-04-24 14:45:12,263 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #48: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.4074074074074074, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.15, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:45:12,263 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:12,264 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729
2024-04-24 14:45:13,228 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #48: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 2, 0, 1),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 1, 0, 1)', 'reward_ratio': '0/1', 'revenue': 0.23404255319148937, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.03, '(ado, 5)': 0.02, '(min, 0)': 0.39, '(min, 1)': 0.29, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:45:13,228 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:13,229 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729
2024-04-24 14:45:16,161 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #48: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 8)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.35, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:45:16,163 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:16,164 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729
2024-04-24 14:45:16,354 - MainProcess - INFO - text_logger.py - 51 - Train epoch #48
2024-04-24 14:45:16,358 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.8644e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8341e-01, 0.0000e+00,
        8.0020e-02, 3.8365e-03, 3.5160e-01, 0.0000e+00, 1.9837e-02, 2.8473e-03,
        0.0000e+00, 0.0000e+00, 1.4915e-02, 1.9913e-03, 0.0000e+00, 0.0000e+00,
        1.0716e-02, 9.7278e-04, 0.0000e+00, 0.0000e+00, 9.4654e-03, 5.9830e-04,
        0.0000e+00, 0.0000e+00, 8.0379e-03, 2.0826e-04, 0.0000e+00, 0.0000e+00,
        6.4292e-03, 7.4773e-05, 0.0000e+00, 0.0000e+00, 4.4028e-03, 7.4773e-05,
        0.0000e+00, 0.0000e+00, 5.6576e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.0909e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5989e-01, 0.0000e+00,
        1.0039e-01, 8.4677e-03, 1.0190e-01, 0.0000e+00, 3.8609e-02, 6.9654e-03,
        0.0000e+00, 0.0000e+00, 3.3519e-02, 5.7357e-03, 0.0000e+00, 0.0000e+00,
        2.6686e-02, 4.0771e-03, 0.0000e+00, 0.0000e+00, 2.5305e-02, 3.3263e-03,
        0.0000e+00, 0.0000e+00, 2.2419e-02, 2.2779e-03, 0.0000e+00, 0.0000e+00,
        1.8722e-02, 1.1811e-03, 0.0000e+00, 0.0000e+00, 1.3333e-02, 1.1811e-03,
        0.0000e+00, 0.0000e+00, 3.5065e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:45:16,386 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4350987147269124
2024-04-24 14:45:16,389 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.226320.17368
2024-04-24 14:45:16,402 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #49: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.02, '(min, 0)': 0.14, '(min, 1)': 0.43, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:45:16,403 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:16,404 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43558831736608566
2024-04-24 14:45:16,417 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #49: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4523809523809524, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.02, '(min, 0)': 0.31, '(min, 1)': 0.32, '(rev, 1)': 0.04, '(rev, 3)': 0.02}}
2024-04-24 14:45:16,418 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:16,420 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43558831736608566
2024-04-24 14:45:16,436 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #49: {'transition': '(exi, wit, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 4, 9, 1, 1),(min, 0)->(exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 5, 9, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.2}}
2024-04-24 14:45:16,436 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:16,437 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43558831736608566
2024-04-24 14:45:16,451 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #49: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.48, '(min, 1)': 0.12}}
2024-04-24 14:45:16,452 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:16,453 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43558831736608566
2024-04-24 14:45:17,850 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #49: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.28, '(min, 1)': 0.33, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:45:17,850 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:17,851 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43558831736608566
2024-04-24 14:45:19,370 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #49: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.34, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:45:19,370 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:19,372 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43558831736608566
2024-04-24 14:45:21,305 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #49: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.275, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.04, '(min, 0)': 0.26, '(min, 1)': 0.35, '(rev, 1)': 0.1, '(rev, 2)': 0.04}}
2024-04-24 14:45:21,306 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:21,307 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43558831736608566
2024-04-24 14:45:21,507 - MainProcess - INFO - text_logger.py - 51 - Train epoch #49
2024-04-24 14:45:21,511 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.7844e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2157e-01, 0.0000e+00,
        5.4320e-02, 4.9637e-03, 3.7244e-01, 0.0000e+00, 1.1496e-02, 3.3140e-03,
        0.0000e+00, 0.0000e+00, 7.9989e-03, 1.8463e-03, 0.0000e+00, 0.0000e+00,
        5.7487e-03, 4.6123e-04, 0.0000e+00, 0.0000e+00, 4.7484e-03, 1.0131e-04,
        0.0000e+00, 0.0000e+00, 4.6222e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4616e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4700e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.0578e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.1250e-05, 0.0000e+00, 0.0000e+00])  tensor([1.5525e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2212e-01, 0.0000e+00,
        7.0607e-02, 9.3715e-03, 7.6340e-02, 0.0000e+00, 3.1169e-02, 7.2097e-03,
        0.0000e+00, 0.0000e+00, 2.5902e-02, 5.9269e-03, 0.0000e+00, 0.0000e+00,
        2.1061e-02, 2.7484e-03, 0.0000e+00, 0.0000e+00, 1.8780e-02, 1.3064e-03,
        0.0000e+00, 0.0000e+00, 1.8274e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4250e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0725e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.9071e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.9877e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:45:21,528 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43415648050879185
2024-04-24 14:45:21,530 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:45:21,540 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #50: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32558139534883723, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.33, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-24 14:45:21,540 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:21,541 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4350987147269124
2024-04-24 14:45:22,078 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #50: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0967741935483871, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.56, '(min, 1)': 0.11, '(rev, 1)': 0.03, '(rev, 2)': 0.02}}
2024-04-24 14:45:22,079 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:22,082 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4350987147269124
2024-04-24 14:45:23,595 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #50: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.13157894736842105, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.19, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:45:23,595 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:23,596 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4350987147269124
2024-04-24 14:45:23,657 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #50: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.06521739130434782, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.28, '(rev, 1)': 0.03, '(rev, 2)': 0.03}}
2024-04-24 14:45:23,658 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:23,659 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4350987147269124
2024-04-24 14:45:24,864 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #50: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.03, '(min, 0)': 0.24, '(min, 1)': 0.41, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-04-24 14:45:24,864 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:24,871 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4350987147269124
2024-04-24 14:45:25,248 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #50: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43243243243243246, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.2, '(min, 1)': 0.41, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-04-24 14:45:25,249 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:25,249 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4350987147269124
2024-04-24 14:45:27,106 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #50: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.23684210526315788, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.42, '(min, 1)': 0.28, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:45:27,106 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:27,107 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4350987147269124
2024-04-24 14:45:27,309 - MainProcess - INFO - text_logger.py - 51 - Train epoch #50
2024-04-24 14:45:27,312 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.7318e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7669e-01, 0.0000e+00,
        8.8320e-02, 3.9829e-03, 3.5464e-01, 0.0000e+00, 2.0432e-02, 2.9770e-03,
        0.0000e+00, 0.0000e+00, 1.4041e-02, 2.1318e-03, 0.0000e+00, 0.0000e+00,
        9.8043e-03, 6.4910e-04, 0.0000e+00, 0.0000e+00, 8.2357e-03, 2.2072e-04,
        0.0000e+00, 0.0000e+00, 8.2472e-03, 2.7397e-05, 0.0000e+00, 0.0000e+00,
        5.6174e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6024e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.8572e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.8686e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6113e-01, 0.0000e+00,
        1.1699e-01, 8.5795e-03, 1.0229e-01, 0.0000e+00, 4.0138e-02, 6.7260e-03,
        0.0000e+00, 0.0000e+00, 3.1683e-02, 6.2419e-03, 0.0000e+00, 0.0000e+00,
        2.4432e-02, 3.1691e-03, 0.0000e+00, 0.0000e+00, 2.1624e-02, 1.7611e-03,
        0.0000e+00, 0.0000e+00, 2.2469e-02, 6.1262e-04, 0.0000e+00, 0.0000e+00,
        1.6901e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1979e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.8873e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:45:27,339 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4334425994315881
2024-04-24 14:45:27,342 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.114180.01740
2024-04-24 14:45:27,373 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #51: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.09090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.28, '(rev, 1)': 0.05, '(rev, 2)': 0.02}}
2024-04-24 14:45:27,373 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:27,376 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43415648050879185
2024-04-24 14:45:29,139 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #51: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5098039215686274, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 8)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.3, '(rev, 1)': 0.05, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-04-24 14:45:29,139 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:29,141 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43415648050879185
2024-04-24 14:45:29,530 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #51: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7021276595744681, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(min, 0)': 0.34, '(min, 1)': 0.36, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 6)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:45:29,531 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:29,531 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43415648050879185
2024-04-24 14:45:29,903 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #51: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(min, 0)': 0.12, '(min, 1)': 0.44, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:45:29,903 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:29,904 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43415648050879185
2024-04-24 14:45:31,552 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #51: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.57, '(min, 1)': 0.1}}
2024-04-24 14:45:31,552 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:31,554 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43415648050879185
2024-04-24 14:45:32,789 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #51: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.42, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 5)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.25, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:45:32,790 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:32,791 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43415648050879185
2024-04-24 14:45:33,491 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #51: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.39215686274509803, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.02, '(min, 0)': 0.2, '(min, 1)': 0.41, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:45:33,492 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:33,492 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43415648050879185
2024-04-24 14:45:33,690 - MainProcess - INFO - text_logger.py - 51 - Train epoch #51
2024-04-24 14:45:33,694 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.0092e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4926e-01, 0.0000e+00,
        9.5926e-02, 4.5311e-03, 3.2863e-01, 0.0000e+00, 2.7861e-02, 2.2772e-03,
        0.0000e+00, 0.0000e+00, 2.2054e-02, 1.1543e-03, 0.0000e+00, 0.0000e+00,
        1.7267e-02, 8.6356e-04, 0.0000e+00, 0.0000e+00, 1.5041e-02, 3.5569e-04,
        0.0000e+00, 0.0000e+00, 1.3989e-02, 6.0400e-04, 0.0000e+00, 0.0000e+00,
        1.1777e-02, 3.8462e-05, 0.0000e+00, 0.0000e+00, 7.0973e-03, 6.0606e-05,
        0.0000e+00, 0.0000e+00, 9.9993e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.0914e-04, 0.0000e+00, 0.0000e+00])  tensor([2.7567e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9100e-01, 0.0000e+00,
        1.0712e-01, 9.3869e-03, 1.2441e-01, 0.0000e+00, 4.7908e-02, 6.2216e-03,
        0.0000e+00, 0.0000e+00, 4.1487e-02, 4.5771e-03, 0.0000e+00, 0.0000e+00,
        3.4284e-02, 4.0533e-03, 0.0000e+00, 0.0000e+00, 3.1003e-02, 2.4089e-03,
        0.0000e+00, 0.0000e+00, 2.9316e-02, 4.1196e-03, 0.0000e+00, 0.0000e+00,
        2.5103e-02, 8.6003e-04, 0.0000e+00, 0.0000e+00, 1.7098e-02, 1.3552e-03,
        0.0000e+00, 0.0000e+00, 4.3303e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7938e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:45:33,716 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4330101691350361
2024-04-24 14:45:33,724 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.254900.25490
2024-04-24 14:45:33,771 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #52: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3617021276595745, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.25, '(min, 1)': 0.3, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 4)': 0.01}}
2024-04-24 14:45:33,772 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:33,773 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4334425994315881
2024-04-24 14:45:35,242 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #52: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2608695652173913, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.15, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:45:35,242 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:35,243 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4334425994315881
2024-04-24 14:45:35,596 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #52: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5217391304347826, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.51, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 7)': 0.01}}
2024-04-24 14:45:35,596 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:35,598 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4334425994315881
2024-04-24 14:45:36,015 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #52: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8095238095238095, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(min, 0)': 0.42, '(min, 1)': 0.19, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-24 14:45:36,015 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:36,017 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4334425994315881
2024-04-24 14:45:37,183 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #52: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5416666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(min, 0)': 0.34, '(min, 1)': 0.21, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:45:37,184 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:37,185 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4334425994315881
2024-04-24 14:45:38,383 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #52: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.27, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:45:38,383 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:38,384 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4334425994315881
2024-04-24 14:45:39,271 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #52: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6585365853658537, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(min, 0)': 0.27, '(min, 1)': 0.4, '(rev, 1)': 0.11, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:45:39,272 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:39,273 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4334425994315881
2024-04-24 14:45:39,484 - MainProcess - INFO - text_logger.py - 51 - Train epoch #52
2024-04-24 14:45:39,488 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.9688e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1647e-01, 0.0000e+00,
        6.1197e-02, 5.3188e-03, 3.7817e-01, 0.0000e+00, 1.1213e-02, 3.0371e-03,
        0.0000e+00, 0.0000e+00, 6.8769e-03, 1.7143e-03, 0.0000e+00, 0.0000e+00,
        4.2821e-03, 9.0427e-04, 0.0000e+00, 0.0000e+00, 3.3658e-03, 3.1769e-04,
        0.0000e+00, 0.0000e+00, 3.1542e-03, 2.5696e-04, 0.0000e+00, 0.0000e+00,
        2.2226e-03, 1.5060e-04, 0.0000e+00, 0.0000e+00, 1.1751e-03, 2.7778e-05,
        0.0000e+00, 0.0000e+00, 1.1316e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4483e-05, 0.0000e+00, 0.0000e+00])  tensor([1.6400e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1254e-01, 0.0000e+00,
        7.9106e-02, 9.7767e-03, 6.7764e-02, 0.0000e+00, 2.9021e-02, 7.0918e-03,
        0.0000e+00, 0.0000e+00, 2.2897e-02, 5.3889e-03, 0.0000e+00, 0.0000e+00,
        1.7412e-02, 3.8467e-03, 0.0000e+00, 0.0000e+00, 1.4939e-02, 2.1409e-03,
        0.0000e+00, 0.0000e+00, 1.4528e-02, 1.9138e-03, 0.0000e+00, 0.0000e+00,
        1.0967e-02, 1.7986e-03, 0.0000e+00, 0.0000e+00, 7.1421e-03, 6.2113e-04,
        0.0000e+00, 0.0000e+00, 1.5088e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.7106e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:45:39,514 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.433419125393106
2024-04-24 14:45:39,517 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.675600.13393
2024-04-24 14:45:40,803 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #53: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.43902439024390244, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.49, '(rev, 1)': 0.12, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-04-24 14:45:40,803 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:40,804 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4330101691350361
2024-04-24 14:45:41,573 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #53: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 7, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 7, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.9285714285714286, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.02, '(min, 0)': 0.21, '(min, 1)': 0.45, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 6)': 0.01}}
2024-04-24 14:45:41,574 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:41,574 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4330101691350361
2024-04-24 14:45:45,577 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #53: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.25, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:45:45,578 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:45,578 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4330101691350361
2024-04-24 14:45:45,991 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #53: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.4444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.34, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:45:45,991 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:45,992 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4330101691350361
2024-04-24 14:45:46,201 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #53: {'transition': '(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 2, 4, 1, 1),(min, 0)->(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 2, 5, 1, 1)', 'reward_ratio': '0/0', 'revenue': 1.3095238095238095, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.51, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 4)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:45:46,202 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:46,203 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4330101691350361
2024-04-24 14:45:47,683 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #53: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2708333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.38, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:45:47,684 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:47,689 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4330101691350361
2024-04-24 14:45:49,922 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #53: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6585365853658537, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.42, '(rev, 1)': 0.06, '(rev, 3)': 0.04, '(rev, 4)': 0.02}}
2024-04-24 14:45:49,923 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:49,924 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4330101691350361
2024-04-24 14:45:50,036 - MainProcess - INFO - text_logger.py - 51 - Train epoch #53
2024-04-24 14:45:50,039 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.7046e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2815e-01, 0.0000e+00,
        5.5707e-02, 4.8250e-03, 3.6947e-01, 0.0000e+00, 9.7838e-03, 3.8373e-03,
        0.0000e+00, 0.0000e+00, 6.6349e-03, 2.0325e-03, 0.0000e+00, 0.0000e+00,
        4.7114e-03, 1.2539e-03, 0.0000e+00, 0.0000e+00, 3.6491e-03, 7.4801e-04,
        0.0000e+00, 0.0000e+00, 3.6980e-03, 4.4119e-04, 0.0000e+00, 0.0000e+00,
        2.6908e-03, 1.0643e-04, 0.0000e+00, 0.0000e+00, 1.7137e-03, 2.2841e-04,
        0.0000e+00, 0.0000e+00, 2.7813e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2787e-05, 0.0000e+00, 0.0000e+00])  tensor([3.0576e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2294e-01, 0.0000e+00,
        9.3034e-02, 9.3650e-03, 7.5776e-02, 0.0000e+00, 2.8158e-02, 7.9409e-03,
        0.0000e+00, 0.0000e+00, 2.2937e-02, 5.9631e-03, 0.0000e+00, 0.0000e+00,
        1.8234e-02, 4.4760e-03, 0.0000e+00, 0.0000e+00, 1.5299e-02, 3.4627e-03,
        0.0000e+00, 0.0000e+00, 1.5729e-02, 2.6425e-03, 0.0000e+00, 0.0000e+00,
        1.2306e-02, 1.3748e-03, 0.0000e+00, 0.0000e+00, 8.1597e-03, 2.5782e-03,
        0.0000e+00, 0.0000e+00, 2.2356e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.3314e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:45:50,064 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4335798722047957
2024-04-24 14:45:50,067 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.551490.10705
2024-04-24 14:45:50,115 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #54: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6363636363636364, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 5)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.36, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.03, '(rev, 4)': 0.02, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:45:50,116 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:50,117 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.433419125393106
2024-04-24 14:45:50,131 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #54: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4523809523809524, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.18, '(min, 1)': 0.49, '(rev, 1)': 0.03, '(rev, 2)': 0.03, '(rev, 4)': 0.02, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:45:50,131 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:50,131 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.433419125393106
2024-04-24 14:45:51,774 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #54: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 9, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 8, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.47368421052631576, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(min, 0)': 0.21, '(min, 1)': 0.43, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:45:51,775 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:51,776 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.433419125393106
2024-04-24 14:45:51,966 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #54: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.15555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 7)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.39, '(rev, 1)': 0.06, '(rev, 3)': 0.01}}
2024-04-24 14:45:51,967 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:51,968 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.433419125393106
2024-04-24 14:45:52,050 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #54: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 4)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.29, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-24 14:45:52,050 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:52,051 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.433419125393106
2024-04-24 14:45:52,945 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #54: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.38636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(min, 0)': 0.48, '(min, 1)': 0.13, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.05}}
2024-04-24 14:45:52,946 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:52,946 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.433419125393106
2024-04-24 14:45:55,478 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #54: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.15384615384615385, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.05, '(ado, 5)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.42, '(rev, 1)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:45:55,479 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:55,480 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.433419125393106
2024-04-24 14:45:55,568 - MainProcess - INFO - text_logger.py - 51 - Train epoch #54
2024-04-24 14:45:55,572 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.3155e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0670e-01, 0.0000e+00,
        6.4310e-02, 5.0441e-03, 3.8153e-01, 0.0000e+00, 1.1692e-02, 3.5197e-03,
        0.0000e+00, 0.0000e+00, 7.0833e-03, 2.1090e-03, 0.0000e+00, 0.0000e+00,
        4.6380e-03, 1.3144e-03, 0.0000e+00, 0.0000e+00, 3.4514e-03, 6.2476e-04,
        0.0000e+00, 0.0000e+00, 3.1840e-03, 4.6936e-04, 0.0000e+00, 0.0000e+00,
        2.2642e-03, 2.5836e-04, 0.0000e+00, 0.0000e+00, 1.5286e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.2337e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.7310e-05, 0.0000e+00, 0.0000e+00])  tensor([1.9280e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1308e-01, 0.0000e+00,
        8.2645e-02, 9.5476e-03, 7.1158e-02, 0.0000e+00, 2.8564e-02, 7.5056e-03,
        0.0000e+00, 0.0000e+00, 2.2691e-02, 5.7452e-03, 0.0000e+00, 0.0000e+00,
        1.8018e-02, 4.8627e-03, 0.0000e+00, 0.0000e+00, 1.5290e-02, 3.0530e-03,
        0.0000e+00, 0.0000e+00, 1.4599e-02, 2.9039e-03, 0.0000e+00, 0.0000e+00,
        1.0953e-02, 2.3999e-03, 0.0000e+00, 0.0000e+00, 7.8551e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.0605e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.2786e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:45:55,592 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43326516835104767
2024-04-24 14:45:55,596 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.313770.15992
2024-04-24 14:45:57,138 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #55: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.26666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.02, '(min, 0)': 0.15, '(min, 1)': 0.41, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-24 14:45:57,138 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:57,139 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4335798722047957
2024-04-24 14:45:57,538 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #55: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 4)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.26, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 6)': 0.01}}
2024-04-24 14:45:57,538 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:57,540 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4335798722047957
2024-04-24 14:45:57,932 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #55: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 3, 0, 0),(rev, 4)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '4/4', 'revenue': 0.723404255319149, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(min, 0)': 0.36, '(min, 1)': 0.29, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.07, '(rev, 4)': 0.05}}
2024-04-24 14:45:57,933 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:57,934 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4335798722047957
2024-04-24 14:45:57,973 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #55: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.2, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 6)': 0.01}}
2024-04-24 14:45:57,973 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:57,974 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4335798722047957
2024-04-24 14:45:58,738 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #55: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 5, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 4, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.37209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(min, 0)': 0.38, '(min, 1)': 0.29, '(rev, 1)': 0.02, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:45:58,738 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:58,739 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4335798722047957
2024-04-24 14:45:59,929 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #55: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 1),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 2, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.7111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.06, '(min, 1)': 0.57, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:45:59,929 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:45:59,930 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4335798722047957
2024-04-24 14:46:01,915 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #55: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24390243902439024, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 7)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.38, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:46:01,916 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:01,917 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4335798722047957
2024-04-24 14:46:02,019 - MainProcess - INFO - text_logger.py - 51 - Train epoch #55
2024-04-24 14:46:02,022 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.1923e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9486e-01, 0.0000e+00,
        7.6800e-02, 4.1114e-03, 3.6307e-01, 0.0000e+00, 1.6038e-02, 2.4869e-03,
        0.0000e+00, 0.0000e+00, 1.1245e-02, 1.3042e-03, 0.0000e+00, 0.0000e+00,
        8.1422e-03, 9.8946e-04, 0.0000e+00, 0.0000e+00, 6.3933e-03, 5.7649e-04,
        0.0000e+00, 0.0000e+00, 5.5593e-03, 2.0258e-04, 0.0000e+00, 0.0000e+00,
        4.7936e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5853e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.5348e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8769e-04, 0.0000e+00, 0.0000e+00])  tensor([2.0153e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4004e-01, 0.0000e+00,
        9.0705e-02, 9.0911e-03, 9.0018e-02, 0.0000e+00, 3.5382e-02, 6.4220e-03,
        0.0000e+00, 0.0000e+00, 2.9216e-02, 4.6350e-03, 0.0000e+00, 0.0000e+00,
        2.4816e-02, 4.1828e-03, 0.0000e+00, 0.0000e+00, 2.0835e-02, 3.3317e-03,
        0.0000e+00, 0.0000e+00, 1.8836e-02, 1.8521e-03, 0.0000e+00, 0.0000e+00,
        1.6716e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.7176e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.5301e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7275e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:46:02,056 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43329024082727063
2024-04-24 14:46:02,062 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.483650.23975
2024-04-24 14:46:02,861 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #56: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.41, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.03}}
2024-04-24 14:46:02,862 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:02,863 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43326516835104767
2024-04-24 14:46:03,209 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #56: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4523809523809524, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.2, '(rev, 1)': 0.14, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:46:03,210 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:03,211 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43326516835104767
2024-04-24 14:46:03,254 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #56: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.29545454545454547, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.28, '(rev, 1)': 0.11, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:46:03,255 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:03,256 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43326516835104767
2024-04-24 14:46:04,536 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #56: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36363636363636365, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.42, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:46:04,536 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:04,537 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43326516835104767
2024-04-24 14:46:06,145 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #56: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 5)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.28, '(rev, 1)': 0.08, '(rev, 4)': 0.01}}
2024-04-24 14:46:06,145 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:06,146 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43326516835104767
2024-04-24 14:46:06,643 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #56: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3902439024390244, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.43, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:46:06,643 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:06,644 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43326516835104767
2024-04-24 14:46:07,965 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #56: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(min, 0)': 0.4, '(min, 1)': 0.22, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 4)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:46:07,966 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:07,970 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43326516835104767
2024-04-24 14:46:08,074 - MainProcess - INFO - text_logger.py - 51 - Train epoch #56
2024-04-24 14:46:08,079 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-8.4694e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  5.0568e-01,
         0.0000e+00,  7.1448e-02,  4.5858e-03,  3.8496e-01,  0.0000e+00,
         1.0374e-02,  3.0817e-03,  0.0000e+00,  0.0000e+00,  6.1425e-03,
         1.5045e-03,  0.0000e+00,  0.0000e+00,  3.9272e-03,  5.1647e-04,
         0.0000e+00,  0.0000e+00,  2.6775e-03,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  2.1462e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         1.6636e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1145e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4439e-04,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.0769e-05,  0.0000e+00,  0.0000e+00])  tensor([1.4802e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0299e-01, 0.0000e+00,
        7.5939e-02, 9.5103e-03, 6.2443e-02, 0.0000e+00, 2.6818e-02, 7.5404e-03,
        0.0000e+00, 0.0000e+00, 2.0626e-02, 5.1342e-03, 0.0000e+00, 0.0000e+00,
        1.6469e-02, 3.4787e-03, 0.0000e+00, 0.0000e+00, 1.2604e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1259e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.1846e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2273e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.6556e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.8802e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:46:08,104 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43304346115460457
2024-04-24 14:46:08,107 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.347730.05227
2024-04-24 14:46:08,392 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #57: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40476190476190477, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.26, '(min, 1)': 0.34, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:46:08,392 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:08,393 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43329024082727063
2024-04-24 14:46:08,538 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #57: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36363636363636365, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.14, '(min, 1)': 0.47, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 7)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:46:08,538 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:08,539 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43329024082727063
2024-04-24 14:46:09,789 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #57: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7027027027027027, 'length': 100, 'actions': {'(ado, 1)': 0.09, '(ado, 2)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.31, '(rev, 1)': 0.12, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-04-24 14:46:09,789 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:09,790 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43329024082727063
2024-04-24 14:46:11,912 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #57: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3617021276595745, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.28, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:46:11,913 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:11,913 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43329024082727063
2024-04-24 14:46:12,523 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #57: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.22, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 5)': 0.02}}
2024-04-24 14:46:12,524 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:12,526 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43329024082727063
2024-04-24 14:46:12,596 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #57: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3617021276595745, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.47, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 7)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:46:12,597 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:12,597 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43329024082727063
2024-04-24 14:46:12,741 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #57: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2653061224489796, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.03, '(min, 0)': 0.46, '(min, 1)': 0.11, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:46:12,741 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:12,742 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43329024082727063
2024-04-24 14:46:12,845 - MainProcess - INFO - text_logger.py - 51 - Train epoch #57
2024-04-24 14:46:12,853 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0844e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4038e-01, 0.0000e+00,
        5.2713e-02, 5.0531e-03, 3.8055e-01, 0.0000e+00, 5.4900e-03, 3.7189e-03,
        0.0000e+00, 0.0000e+00, 2.5312e-03, 2.2204e-03, 0.0000e+00, 0.0000e+00,
        1.0874e-03, 1.8590e-03, 0.0000e+00, 0.0000e+00, 4.3162e-04, 1.5009e-03,
        0.0000e+00, 0.0000e+00, 1.4820e-04, 9.3969e-04, 0.0000e+00, 0.0000e+00,
        7.0523e-05, 7.4857e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5111e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.6849e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.4061e-02, 0.0000e+00,
        8.3042e-02, 9.7892e-03, 3.8066e-02, 0.0000e+00, 1.5235e-02, 7.8811e-03,
        0.0000e+00, 0.0000e+00, 1.0235e-02, 5.8614e-03, 0.0000e+00, 0.0000e+00,
        6.2598e-03, 5.3358e-03, 0.0000e+00, 0.0000e+00, 3.6088e-03, 4.8574e-03,
        0.0000e+00, 0.0000e+00, 1.6558e-03, 3.7375e-03, 0.0000e+00, 0.0000e+00,
        1.1167e-03, 3.4112e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5325e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:46:12,876 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43277129496369493
2024-04-24 14:46:12,880 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.335030.06973
2024-04-24 14:46:13,758 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #58: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1590909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.03, '(ado, 3)': 0.02, '(min, 0)': 0.37, '(min, 1)': 0.23, '(rev, 1)': 0.09, '(rev, 2)': 0.01}}
2024-04-24 14:46:13,758 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:13,759 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43304346115460457
2024-04-24 14:46:15,744 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #58: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6363636363636364, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 3)': 0.01, '(min, 0)': 0.12, '(min, 1)': 0.47, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:46:15,744 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:15,745 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43304346115460457
2024-04-24 14:46:17,595 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #58: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5306122448979592, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.03, '(ado, 4)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.41, '(rev, 1)': 0.06, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:46:17,596 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:17,596 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43304346115460457
2024-04-24 14:46:18,866 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #58: {'transition': '(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 2, 6, 1, 1),(min, 0)->(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 1, 2, 7, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.3170731707317073, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.17, '(min, 1)': 0.49, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:46:18,867 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:18,868 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43304346115460457
2024-04-24 14:46:18,944 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #58: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6428571428571429, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.26, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:46:18,944 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:18,946 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43304346115460457
2024-04-24 14:46:18,984 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #58: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.425, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 4)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.27, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:46:18,984 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:18,985 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43304346115460457
2024-04-24 14:46:19,647 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #58: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.42, '(min, 1)': 0.23, '(rev, 1)': 0.03, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-04-24 14:46:19,647 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:19,649 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43304346115460457
2024-04-24 14:46:19,855 - MainProcess - INFO - text_logger.py - 51 - Train epoch #58
2024-04-24 14:46:19,861 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.5619e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9517e-01, 0.0000e+00,
        7.2724e-02, 5.0066e-03, 3.7806e-01, 0.0000e+00, 1.4500e-02, 3.9404e-03,
        0.0000e+00, 0.0000e+00, 8.8893e-03, 1.8587e-03, 0.0000e+00, 0.0000e+00,
        5.7673e-03, 9.6552e-04, 0.0000e+00, 0.0000e+00, 4.4258e-03, 5.8635e-04,
        0.0000e+00, 0.0000e+00, 3.6978e-03, 2.5196e-04, 0.0000e+00, 0.0000e+00,
        2.4382e-03, 3.4483e-05, 0.0000e+00, 0.0000e+00, 1.4715e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.7171e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.1746e-05, 0.0000e+00, 0.0000e+00])  tensor([1.9504e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2343e-01, 0.0000e+00,
        8.6693e-02, 9.9874e-03, 7.5393e-02, 0.0000e+00, 3.3923e-02, 8.5943e-03,
        0.0000e+00, 0.0000e+00, 2.5429e-02, 5.4450e-03, 0.0000e+00, 0.0000e+00,
        1.9350e-02, 4.0087e-03, 0.0000e+00, 0.0000e+00, 1.7197e-02, 2.9857e-03,
        0.0000e+00, 0.0000e+00, 1.5656e-02, 2.3442e-03, 0.0000e+00, 0.0000e+00,
        1.1920e-02, 7.7106e-04, 0.0000e+00, 0.0000e+00, 7.4987e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.7502e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.0986e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:46:19,903 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4331082815247951
2024-04-24 14:46:19,906 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.639610.00325
2024-04-24 14:46:19,920 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #59: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.4791666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.44, '(rev, 1)': 0.05, '(rev, 2)': 0.08, '(rev, 3)': 0.04}}
2024-04-24 14:46:19,922 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:19,925 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43277129496369493
2024-04-24 14:46:21,681 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #59: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6511627906976745, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(min, 0)': 0.31, '(min, 1)': 0.34, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.03, '(rev, 7)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:46:21,682 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:21,683 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43277129496369493
2024-04-24 14:46:22,158 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #59: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.18, '(min, 1)': 0.41, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:46:22,158 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:22,160 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43277129496369493
2024-04-24 14:46:23,693 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #59: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5348837209302325, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(min, 0)': 0.22, '(min, 1)': 0.4, '(rev, 1)': 0.13, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:46:23,693 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:23,694 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43277129496369493
2024-04-24 14:46:24,103 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #59: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.27450980392156865, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.31, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-04-24 14:46:24,104 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:24,105 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43277129496369493
2024-04-24 14:46:24,710 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #59: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.39215686274509803, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.21, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 5)': 0.01}}
2024-04-24 14:46:24,711 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:24,712 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43277129496369493
2024-04-24 14:46:27,515 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #59: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.08695652173913043, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 2)': 0.02, '(min, 0)': 0.22, '(min, 1)': 0.33, '(rev, 1)': 0.05}}
2024-04-24 14:46:27,515 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:27,516 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43277129496369493
2024-04-24 14:46:27,712 - MainProcess - INFO - text_logger.py - 51 - Train epoch #59
2024-04-24 14:46:27,715 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.6486e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.9808e-01,
         0.0000e+00,  7.5711e-02,  5.4752e-03,  3.5751e-01,  0.0000e+00,
         1.6264e-02,  2.9164e-03,  0.0000e+00,  0.0000e+00,  1.1456e-02,
         9.4398e-04,  0.0000e+00,  0.0000e+00,  8.6552e-03,  2.9231e-04,
         0.0000e+00,  0.0000e+00,  7.3292e-03,  4.8529e-05,  0.0000e+00,
         0.0000e+00,  6.1485e-03,  2.3529e-05,  0.0000e+00,  0.0000e+00,
         5.3694e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.2389e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.7568e-04,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.8966e-05,  0.0000e+00,  0.0000e+00])  tensor([1.6221e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5121e-01, 0.0000e+00,
        9.5577e-02, 1.0378e-02, 9.8408e-02, 0.0000e+00, 4.0650e-02, 7.9513e-03,
        0.0000e+00, 0.0000e+00, 3.1706e-02, 4.4535e-03, 0.0000e+00, 0.0000e+00,
        2.4913e-02, 2.5209e-03, 0.0000e+00, 0.0000e+00, 2.1744e-02, 7.6690e-04,
        0.0000e+00, 0.0000e+00, 1.9012e-02, 5.2613e-04, 0.0000e+00, 0.0000e+00,
        1.7314e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0698e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.9692e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0893e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:46:27,737 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4333520938183025
2024-04-24 14:46:27,745 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.593020.05814
2024-04-24 14:46:27,759 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #60: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.34, '(min, 1)': 0.21, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-04-24 14:46:27,760 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:27,761 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331082815247951
2024-04-24 14:46:27,775 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #60: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32558139534883723, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.25, '(rev, 1)': 0.08, '(rev, 2)': 0.07}}
2024-04-24 14:46:27,776 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:27,778 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331082815247951
2024-04-24 14:46:27,790 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #60: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(min, 0)': 0.22, '(min, 1)': 0.43, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:46:27,790 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:27,791 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331082815247951
2024-04-24 14:46:28,997 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #60: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.42857142857142855, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(min, 0)': 0.47, '(min, 1)': 0.13, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-24 14:46:28,997 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:28,998 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331082815247951
2024-04-24 14:46:29,063 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #60: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.41, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03}}
2024-04-24 14:46:29,063 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:29,066 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331082815247951
2024-04-24 14:46:31,069 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #60: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.39, '(min, 1)': 0.24, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:46:31,070 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:31,070 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331082815247951
2024-04-24 14:46:33,744 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #60: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.18421052631578946, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(min, 0)': 0.37, '(min, 1)': 0.25, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:46:33,745 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:33,746 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331082815247951
2024-04-24 14:46:33,978 - MainProcess - INFO - text_logger.py - 51 - Train epoch #60
2024-04-24 14:46:33,982 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.2521e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0984e-01, 0.0000e+00,
        6.0588e-02, 5.9973e-03, 3.9417e-01, 0.0000e+00, 9.2310e-03, 4.0167e-03,
        0.0000e+00, 0.0000e+00, 4.5869e-03, 1.7681e-03, 0.0000e+00, 0.0000e+00,
        2.5643e-03, 8.5119e-04, 0.0000e+00, 0.0000e+00, 1.8348e-03, 4.9869e-04,
        0.0000e+00, 0.0000e+00, 1.5833e-03, 3.5480e-04, 0.0000e+00, 0.0000e+00,
        1.2319e-03, 1.5487e-04, 0.0000e+00, 0.0000e+00, 5.9611e-04, 2.6316e-05,
        0.0000e+00, 0.0000e+00, 6.3492e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5714e-05, 0.0000e+00, 0.0000e+00])  tensor([1.6832e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.4960e-02, 0.0000e+00,
        7.2058e-02, 1.0735e-02, 5.6777e-02, 0.0000e+00, 2.7297e-02, 9.1146e-03,
        0.0000e+00, 0.0000e+00, 1.9800e-02, 5.7591e-03, 0.0000e+00, 0.0000e+00,
        1.4333e-02, 3.8367e-03, 0.0000e+00, 0.0000e+00, 1.0950e-02, 2.7191e-03,
        0.0000e+00, 0.0000e+00, 9.8622e-03, 2.6243e-03, 0.0000e+00, 0.0000e+00,
        8.4485e-03, 1.5674e-03, 0.0000e+00, 0.0000e+00, 4.4561e-03, 5.8844e-04,
        0.0000e+00, 0.0000e+00, 1.0107e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.9860e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:46:34,010 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43316401242410213
2024-04-24 14:46:34,013 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.377080.05150
2024-04-24 14:46:34,017 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #61: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.19, '(rev, 1)': 0.05, '(rev, 2)': 0.04}}
2024-04-24 14:46:34,017 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #61: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 3)': 0.02, '(min, 0)': 0.47, '(min, 1)': 0.15, '(rev, 1)': 0.02, '(rev, 2)': 0.01}}
2024-04-24 14:46:34,017 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:34,018 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4333520938183025
2024-04-24 14:46:34,018 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4333520938183025
2024-04-24 14:46:34,033 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #61: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.9230769230769231, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(min, 0)': 0.35, '(min, 1)': 0.3, '(rev, 1)': 0.15, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:46:34,034 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:34,036 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4333520938183025
2024-04-24 14:46:34,037 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #61: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.43, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-04-24 14:46:34,037 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:34,039 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4333520938183025
2024-04-24 14:46:34,055 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #61: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(min, 0)': 0.32, '(min, 1)': 0.28, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.03}}
2024-04-24 14:46:34,057 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:34,062 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4333520938183025
2024-04-24 14:46:35,123 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #61: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3191489361702128, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(min, 0)': 0.2, '(min, 1)': 0.4, '(rev, 1)': 0.05, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:46:35,123 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:35,125 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4333520938183025
2024-04-24 14:46:37,924 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #61: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.24, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(ado, 3)': 0.03, '(ado, 5)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.21, '(rev, 1)': 0.05, '(rev, 2)': 0.01}}
2024-04-24 14:46:37,925 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:37,926 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4333520938183025
2024-04-24 14:46:38,098 - MainProcess - INFO - text_logger.py - 51 - Train epoch #61
2024-04-24 14:46:38,101 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-5.4623e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.5976e-01,
         0.0000e+00,  9.7643e-02,  4.9134e-03,  3.3965e-01,  0.0000e+00,
         2.8841e-02,  3.2865e-03,  0.0000e+00,  0.0000e+00,  1.8407e-02,
         1.0259e-03,  0.0000e+00,  0.0000e+00,  1.2855e-02,  1.9904e-04,
         0.0000e+00,  0.0000e+00,  1.0970e-02,  1.4304e-04,  0.0000e+00,
         0.0000e+00,  9.5333e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         7.5044e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.7146e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.8013e-04,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.8622e-05,  0.0000e+00,  0.0000e+00])  tensor([1.5781e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7973e-01, 0.0000e+00,
        1.1772e-01, 1.0322e-02, 1.1733e-01, 0.0000e+00, 5.5604e-02, 9.2139e-03,
        0.0000e+00, 0.0000e+00, 3.8275e-02, 4.7951e-03, 0.0000e+00, 0.0000e+00,
        2.8720e-02, 2.0159e-03, 0.0000e+00, 0.0000e+00, 2.6522e-02, 2.0098e-03,
        0.0000e+00, 0.0000e+00, 2.3822e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.0100e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2938e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.9799e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0859e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:46:38,131 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4331448551290584
2024-04-24 14:46:38,133 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.461540.46154
2024-04-24 14:46:38,192 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #62: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.08333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.01, '(min, 0)': 0.58, '(min, 1)': 0.07, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:46:38,192 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
nsition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3023255813953488, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(min, 0)': 0.14, '(min, 1)': 0.48, '(rev, 1)': 0.11, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:46:38,192 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:38,192 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #62: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.4, '(min, 1)': 0.17}}
(ado, 3)': 0.03, '(min, 0)': 0.27, '(min, 1)': 0.35, '(rev, 1)': 0.15, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:46:38,193 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:38,193 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:38,193 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43316401242410213
2024-04-24 14:46:38,193 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43316401242410213
2024-04-24 14:46:38,193 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43316401242410213
2024-04-24 14:46:38,194 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43316401242410213
2024-04-24 14:46:38,276 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #62: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.26, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.35, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:46:38,276 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:38,278 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43316401242410213
2024-04-24 14:46:38,953 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #62: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 8)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.29, '(rev, 1)': 0.11, '(rev, 3)': 0.02}}
2024-04-24 14:46:38,954 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:38,955 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43316401242410213
2024-04-24 14:46:40,842 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #62: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.31, '(min, 1)': 0.29, '(rev, 1)': 0.16, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:46:40,843 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:40,845 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43316401242410213
2024-04-24 14:46:41,020 - MainProcess - INFO - text_logger.py - 51 - Train epoch #62
2024-04-24 14:46:41,023 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.5594e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8152e-01, 0.0000e+00,
        7.7883e-02, 6.6277e-03, 3.7524e-01, 0.0000e+00, 1.5282e-02, 5.5533e-03,
        0.0000e+00, 0.0000e+00, 9.6708e-03, 1.6858e-03, 0.0000e+00, 0.0000e+00,
        6.6060e-03, 3.6947e-04, 0.0000e+00, 0.0000e+00, 6.0992e-03, 1.6840e-04,
        0.0000e+00, 0.0000e+00, 5.3566e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.4257e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0082e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.7358e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2258e-05, 0.0000e+00, 0.0000e+00])  tensor([1.5064e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3636e-01, 0.0000e+00,
        9.5828e-02, 1.1598e-02, 9.2634e-02, 0.0000e+00, 3.8923e-02, 1.1292e-02,
        0.0000e+00, 0.0000e+00, 2.9359e-02, 6.1333e-03, 0.0000e+00, 0.0000e+00,
        2.2207e-02, 2.4944e-03, 0.0000e+00, 0.0000e+00, 2.0934e-02, 2.0867e-03,
        0.0000e+00, 0.0000e+00, 1.8526e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6100e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1119e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.9609e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.2131e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:46:41,044 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43228595424427124
2024-04-24 14:46:41,049 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.041670.04167
2024-04-24 14:46:41,100 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #63: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0),(ado, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/3', 'revenue': 0.26666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.18, '(rev, 1)': 0.11, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-04-24 14:46:41,101 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:41,102 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331448551290584
2024-04-24 14:46:41,745 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #63: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40425531914893614, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.47, '(min, 1)': 0.15, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:46:41,745 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:41,746 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331448551290584
2024-04-24 14:46:41,753 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #63: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4489795918367347, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 4)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.15, '(rev, 1)': 0.06, '(rev, 2)': 0.04}}
2024-04-24 14:46:41,753 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:41,754 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331448551290584
2024-04-24 14:46:41,968 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #63: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22916666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.05, '(min, 0)': 0.46, '(min, 1)': 0.11, '(rev, 1)': 0.07, '(rev, 2)': 0.04}}
2024-04-24 14:46:41,968 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:41,969 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331448551290584
2024-04-24 14:46:42,220 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #63: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 1, 0, 1),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 2, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.46938775510204084, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.21, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:46:42,220 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:42,221 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331448551290584
2024-04-24 14:46:42,501 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #63: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6136363636363636, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.37, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:46:42,501 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:42,502 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331448551290584
2024-04-24 14:46:43,731 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #63: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3125, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(min, 0)': 0.35, '(min, 1)': 0.22, '(rev, 1)': 0.03, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-04-24 14:46:43,732 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:43,734 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331448551290584
2024-04-24 14:46:43,911 - MainProcess - INFO - text_logger.py - 51 - Train epoch #63
2024-04-24 14:46:43,914 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.4918e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3037e-01, 0.0000e+00,
        5.1452e-02, 6.4486e-03, 3.9650e-01, 0.0000e+00, 5.2904e-03, 4.5945e-03,
        0.0000e+00, 0.0000e+00, 2.0778e-03, 1.5239e-03, 0.0000e+00, 0.0000e+00,
        7.8588e-04, 2.7694e-04, 0.0000e+00, 0.0000e+00, 3.7702e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.4144e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.6667e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.1477, 0.0000, 0.0000, 0.0000, 0.0673, 0.0000, 0.0612, 0.0117, 0.0303,
        0.0000, 0.0176, 0.0108, 0.0000, 0.0000, 0.0106, 0.0059, 0.0000, 0.0000,
        0.0061, 0.0025, 0.0000, 0.0000, 0.0045, 0.0000, 0.0000, 0.0000, 0.0038,
        0.0000, 0.0000, 0.0000, 0.0015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-04-24 14:46:43,933 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43226208737308947
2024-04-24 14:46:43,936 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.459180.01020
2024-04-24 14:46:43,974 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #64: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.15555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.1, '(min, 1)': 0.48, '(rev, 1)': 0.09, '(rev, 2)': 0.02}}
2024-04-24 14:46:43,974 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:43,975 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43228595424427124
2024-04-24 14:46:45,363 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #64: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3611111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(min, 0)': 0.39, '(min, 1)': 0.26, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:46:45,364 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:45,365 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43228595424427124
2024-04-24 14:46:45,498 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #64: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8157894736842105, 'length': 100, 'actions': {'(ado, 1)': 0.09, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.15, '(min, 1)': 0.49, '(rev, 1)': 0.17, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-04-24 14:46:45,499 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:45,502 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43228595424427124
2024-04-24 14:46:45,675 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #64: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.02, '(min, 0)': 0.03, '(min, 1)': 0.53, '(rev, 1)': 0.08, '(rev, 2)': 0.03}}
2024-04-24 14:46:45,676 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:45,676 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43228595424427124
2024-04-24 14:46:45,717 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #64: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(min, 0)': 0.18, '(min, 1)': 0.41, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.06}}
2024-04-24 14:46:45,717 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:45,723 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43228595424427124
2024-04-24 14:46:46,391 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #64: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4878048780487805, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.14, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 7)': 0.01}}
2024-04-24 14:46:46,391 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:46,392 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43228595424427124
2024-04-24 14:46:48,969 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #64: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4146341463414634, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.28, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:46:48,970 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:48,971 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43228595424427124
2024-04-24 14:46:49,149 - MainProcess - INFO - text_logger.py - 51 - Train epoch #64
2024-04-24 14:46:49,155 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.4939e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9517e-01, 0.0000e+00,
        7.1044e-02, 5.3553e-03, 3.8347e-01, 0.0000e+00, 1.2661e-02, 5.4033e-03,
        0.0000e+00, 0.0000e+00, 7.1581e-03, 1.7150e-03, 0.0000e+00, 0.0000e+00,
        4.4814e-03, 6.2033e-04, 0.0000e+00, 0.0000e+00, 3.9262e-03, 2.7066e-04,
        0.0000e+00, 0.0000e+00, 3.5127e-03, 1.1174e-04, 0.0000e+00, 0.0000e+00,
        2.9530e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8993e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.5342e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.1150e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2350e-01, 0.0000e+00,
        9.6430e-02, 1.0935e-02, 8.2323e-02, 0.0000e+00, 3.7387e-02, 1.1890e-02,
        0.0000e+00, 0.0000e+00, 2.4543e-02, 6.0097e-03, 0.0000e+00, 0.0000e+00,
        1.8012e-02, 3.5734e-03, 0.0000e+00, 0.0000e+00, 1.6431e-02, 2.3057e-03,
        0.0000e+00, 0.0000e+00, 1.5180e-02, 1.2769e-03, 0.0000e+00, 0.0000e+00,
        1.3162e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.7691e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.1843e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:46:49,179 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43249654692190653
2024-04-24 14:46:49,184 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.588350.10054
2024-04-24 14:46:49,227 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #65: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 5, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 5, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5517241379310345, 'length': 100, 'actions': {'(ado, 1)': 0.07, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.47, '(rev, 1)': 0.12, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 6)': 0.01}}
2024-04-24 14:46:49,227 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:49,228 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43226208737308947
2024-04-24 14:46:49,243 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #65: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 2, 0, 1),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 3, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.19230769230769232, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.04, '(ado, 8)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.46, '(rev, 1)': 0.06, '(rev, 2)': 0.04}}
2024-04-24 14:46:49,243 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #65: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.17391304347826086, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.4, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:46:49,243 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:49,243 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:49,244 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43226208737308947
2024-04-24 14:46:49,486 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #65: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.18181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.03, '(ado, 4)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.22, '(min, 1)': 0.41, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:46:49,486 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:49,487 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43226208737308947
2024-04-24 14:46:49,499 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #65: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 7)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.28, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:46:49,500 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:49,505 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43226208737308947
2024-04-24 14:46:50,682 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #65: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10526315789473684, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.35, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:46:50,682 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:50,683 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43226208737308947
2024-04-24 14:46:52,460 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #65: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5945945945945946, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.02, '(min, 0)': 0.44, '(min, 1)': 0.19, '(rev, 1)': 0.14, '(rev, 2)': 0.05, '(rev, 3)': 0.04, '(rev, 6)': 0.01}}
2024-04-24 14:46:52,460 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:52,461 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43226208737308947
2024-04-24 14:46:52,655 - MainProcess - INFO - text_logger.py - 51 - Train epoch #65
2024-04-24 14:46:52,658 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.5621e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7693e-01, 0.0000e+00,
        8.5262e-02, 5.4491e-03, 3.7158e-01, 0.0000e+00, 1.6683e-02, 6.6789e-03,
        0.0000e+00, 0.0000e+00, 9.8635e-03, 2.6669e-03, 0.0000e+00, 0.0000e+00,
        6.6180e-03, 8.7762e-04, 0.0000e+00, 0.0000e+00, 5.7335e-03, 4.9350e-04,
        0.0000e+00, 0.0000e+00, 4.8993e-03, 3.3674e-04, 0.0000e+00, 0.0000e+00,
        3.3800e-03, 2.1674e-04, 0.0000e+00, 0.0000e+00, 2.0927e-03, 4.2553e-05,
        0.0000e+00, 0.0000e+00, 1.9242e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.9437e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3930e-01, 0.0000e+00,
        1.0697e-01, 1.0892e-02, 9.3586e-02, 0.0000e+00, 4.2538e-02, 1.2931e-02,
        0.0000e+00, 0.0000e+00, 2.8320e-02, 7.3146e-03, 0.0000e+00, 0.0000e+00,
        2.0220e-02, 3.8689e-03, 0.0000e+00, 0.0000e+00, 1.9097e-02, 2.9193e-03,
        0.0000e+00, 0.0000e+00, 1.7409e-02, 2.5205e-03, 0.0000e+00, 0.0000e+00,
        1.3279e-02, 2.3301e-03, 0.0000e+00, 0.0000e+00, 8.9086e-03, 9.5152e-04,
        0.0000e+00, 0.0000e+00, 1.9578e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:46:52,681 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4319040203061252
2024-04-24 14:46:52,684 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.174850.06959
2024-04-24 14:46:52,718 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #66: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.03, '(min, 0)': 0.22, '(min, 1)': 0.38, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.05}}
2024-04-24 14:46:52,718 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:52,720 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43249654692190653
2024-04-24 14:46:52,751 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #66: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 3)': 0.01, '(min, 0)': 0.1, '(min, 1)': 0.46, '(rev, 1)': 0.09, '(rev, 2)': 0.05}}
2024-04-24 14:46:52,751 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:52,752 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43249654692190653
2024-04-24 14:46:52,775 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #66: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5609756097560976, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.03, '(min, 0)': 0.4, '(min, 1)': 0.24, '(rev, 1)': 0.13, '(rev, 2)': 0.02, '(rev, 3)': 0.06}}
2024-04-24 14:46:52,775 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:52,776 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43249654692190653
2024-04-24 14:46:53,011 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #66: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.27, '(rev, 1)': 0.11, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:46:53,011 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:53,012 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43249654692190653
2024-04-24 14:46:53,479 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #66: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.14893617021276595, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.47, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:46:53,480 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:53,481 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43249654692190653
2024-04-24 14:46:53,813 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #66: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3584905660377358, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.56, '(min, 1)': 0.02, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:46:53,814 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:53,815 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43249654692190653
2024-04-24 14:46:57,310 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #66: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 6, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.725, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.18, '(min, 1)': 0.47, '(rev, 1)': 0.14, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-04-24 14:46:57,312 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:57,313 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43249654692190653
2024-04-24 14:46:57,497 - MainProcess - INFO - text_logger.py - 51 - Train epoch #66
2024-04-24 14:46:57,500 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([9.0636e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1289e-01, 0.0000e+00,
        5.7769e-02, 6.1697e-03, 3.9390e-01, 0.0000e+00, 8.0397e-03, 6.1704e-03,
        0.0000e+00, 0.0000e+00, 3.9249e-03, 2.2736e-03, 0.0000e+00, 0.0000e+00,
        2.3498e-03, 7.9026e-04, 0.0000e+00, 0.0000e+00, 1.5911e-03, 3.3914e-04,
        0.0000e+00, 0.0000e+00, 1.4686e-03, 1.8765e-04, 0.0000e+00, 0.0000e+00,
        1.1227e-03, 6.0181e-05, 0.0000e+00, 0.0000e+00, 7.8604e-04, 3.0769e-05,
        0.0000e+00, 0.0000e+00, 1.1217e-04, 3.0769e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.9742e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.3073e-02, 0.0000e+00,
        7.0567e-02, 1.1112e-02, 5.7506e-02, 0.0000e+00, 2.8101e-02, 1.2143e-02,
        0.0000e+00, 0.0000e+00, 1.7499e-02, 6.8300e-03, 0.0000e+00, 0.0000e+00,
        1.3187e-02, 3.8153e-03, 0.0000e+00, 0.0000e+00, 1.0268e-02, 2.3186e-03,
        0.0000e+00, 0.0000e+00, 9.6187e-03, 1.7279e-03, 0.0000e+00, 0.0000e+00,
        8.0800e-03, 9.5083e-04, 0.0000e+00, 0.0000e+00, 5.5454e-03, 6.8802e-04,
        0.0000e+00, 0.0000e+00, 1.4859e-03, 6.8802e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:46:57,521 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43172936756313324
2024-04-24 14:46:57,524 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.383790.02530
2024-04-24 14:46:57,562 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #67: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4883720930232558, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.03, '(min, 0)': 0.22, '(min, 1)': 0.39, '(rev, 1)': 0.11, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-04-24 14:46:57,562 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:57,563 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319040203061252
2024-04-24 14:46:57,578 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #67: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.41, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:46:57,578 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:57,578 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:57,579 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319040203061252
2024-04-24 14:46:57,580 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319040203061252
2024-04-24 14:46:57,862 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #67: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.30434782608695654, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.15, '(rev, 1)': 0.09, '(rev, 2)': 0.06}}
2024-04-24 14:46:57,862 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:57,863 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319040203061252
2024-04-24 14:46:58,136 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #67: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.8222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.1, '(min, 1)': 0.49, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:46:58,136 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:58,137 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319040203061252
2024-04-24 14:46:58,348 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #67: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.8809523809523809, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(min, 0)': 0.31, '(min, 1)': 0.34, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-24 14:46:58,349 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:46:58,350 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319040203061252
2024-04-24 14:47:02,563 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #67: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.47058823529411764, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.03, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.12, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:47:02,563 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:02,564 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319040203061252
2024-04-24 14:47:02,784 - MainProcess - INFO - text_logger.py - 51 - Train epoch #67
2024-04-24 14:47:02,788 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0560e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3522e-01, 0.0000e+00,
        4.0954e-02, 5.8785e-03, 4.0462e-01, 0.0000e+00, 2.2134e-03, 5.0837e-03,
        0.0000e+00, 0.0000e+00, 8.5810e-04, 1.8770e-03, 0.0000e+00, 0.0000e+00,
        2.7785e-04, 1.3600e-03, 0.0000e+00, 0.0000e+00, 1.8071e-04, 5.5199e-04,
        0.0000e+00, 0.0000e+00, 1.4897e-04, 4.6099e-04, 0.0000e+00, 0.0000e+00,
        6.8966e-05, 2.1333e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2258e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.4701e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3840e-02, 0.0000e+00,
        5.0122e-02, 1.0648e-02, 2.4064e-02, 0.0000e+00, 1.1470e-02, 1.1231e-02,
        0.0000e+00, 0.0000e+00, 6.2351e-03, 6.1312e-03, 0.0000e+00, 0.0000e+00,
        3.6828e-03, 5.1645e-03, 0.0000e+00, 0.0000e+00, 2.4620e-03, 2.9947e-03,
        0.0000e+00, 0.0000e+00, 2.3595e-03, 2.6805e-03, 0.0000e+00, 0.0000e+00,
        1.5421e-03, 1.8322e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2131e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:47:02,818 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4322191116647958
2024-04-24 14:47:02,821 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.715990.10623
2024-04-24 14:47:02,833 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #68: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(min, 0)': 0.51, '(min, 1)': 0.09, '(rev, 1)': 0.06, '(rev, 2)': 0.06, '(rev, 3)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:47:02,834 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:02,836 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43172936756313324
2024-04-24 14:47:02,849 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #68: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.574468085106383, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.23, '(min, 1)': 0.33, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 4)': 0.01}}
2024-04-24 14:47:02,850 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:02,851 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43172936756313324
2024-04-24 14:47:02,865 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #68: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.07, '(min, 1)': 0.54, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:47:02,866 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:02,866 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:02,868 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43172936756313324
2024-04-24 14:47:02,882 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #68: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 2, 0, 0),(rev, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.5625, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 3)': 0.02, '(min, 0)': 0.14, '(min, 1)': 0.48, '(rev, 1)': 0.1, '(rev, 2)': 0.08, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:47:02,882 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
tion': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.17, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:47:02,882 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:02,883 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43172936756313324
2024-04-24 14:47:02,884 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43172936756313324
2024-04-24 14:47:07,698 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #68: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.7142857142857143, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.4, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:47:07,699 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:07,700 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43172936756313324
2024-04-24 14:47:07,915 - MainProcess - INFO - text_logger.py - 51 - Train epoch #68
2024-04-24 14:47:07,923 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.8827e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2709e-01, 0.0000e+00,
        5.1183e-02, 6.2517e-03, 4.0236e-01, 0.0000e+00, 3.2930e-03, 4.5905e-03,
        0.0000e+00, 0.0000e+00, 1.1483e-03, 1.6880e-03, 0.0000e+00, 0.0000e+00,
        2.3332e-04, 1.0456e-03, 0.0000e+00, 0.0000e+00, 8.8440e-05, 4.2456e-04,
        0.0000e+00, 0.0000e+00, 3.3898e-05, 2.7008e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.9254e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7408e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2908e-02, 0.0000e+00,
        7.0644e-02, 1.0794e-02, 2.5846e-02, 0.0000e+00, 1.0973e-02, 1.0902e-02,
        0.0000e+00, 0.0000e+00, 6.3269e-03, 6.0251e-03, 0.0000e+00, 0.0000e+00,
        2.2974e-03, 4.6528e-03, 0.0000e+00, 0.0000e+00, 1.1488e-03, 2.7476e-03,
        0.0000e+00, 0.0000e+00, 7.5799e-04, 2.1364e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.3712e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:47:07,941 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4321774324883033
2024-04-24 14:47:07,944 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.450280.12419
2024-04-24 14:47:07,961 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #69: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(min, 0)': 0.16, '(min, 1)': 0.43, '(rev, 1)': 0.13, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 5)': 0.02}}
2024-04-24 14:47:07,962 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:07,963 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4322191116647958
2024-04-24 14:47:07,994 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #69: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(min, 0)': 0.39, '(min, 1)': 0.16, '(rev, 1)': 0.09, '(rev, 2)': 0.02}}
'(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:47:07,994 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #69: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.41, '(min, 1)': 0.22, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-04-24 14:47:07,994 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #69: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.717391304347826, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.17, '(min, 1)': 0.43, '(rev, 1)': 0.08, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-04-24 14:47:07,995 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:07,996 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:07,995 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:07,996 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:07,999 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4322191116647958
2024-04-24 14:47:07,999 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4322191116647958
2024-04-24 14:47:08,000 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4322191116647958
2024-04-24 14:47:08,006 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #69: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.14583333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.27, '(min, 1)': 0.31, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-04-24 14:47:08,007 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:08,013 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4322191116647958
2024-04-24 14:47:11,129 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #69: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.07, '(min, 0)': 0.24, '(min, 1)': 0.33, '(rev, 1)': 0.09, '(rev, 2)': 0.01}}
2024-04-24 14:47:11,131 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:11,133 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4322191116647958
2024-04-24 14:47:11,359 - MainProcess - INFO - text_logger.py - 51 - Train epoch #69
2024-04-24 14:47:11,362 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.4583e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3718e-01, 0.0000e+00,
        4.1492e-02, 6.0478e-03, 4.0824e-01, 0.0000e+00, 2.2865e-03, 2.8400e-03,
        0.0000e+00, 0.0000e+00, 4.5949e-04, 8.3019e-04, 0.0000e+00, 0.0000e+00,
        1.3350e-04, 1.7108e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0128e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3114e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.3114e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3114e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5049e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9417e-02, 0.0000e+00,
        4.6503e-02, 1.0797e-02, 1.3820e-02, 0.0000e+00, 9.2200e-03, 8.6238e-03,
        0.0000e+00, 0.0000e+00, 4.2385e-03, 4.3473e-03, 0.0000e+00, 0.0000e+00,
        1.8739e-03, 1.7234e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3166e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1579e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.1579e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1579e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:47:11,378 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4319735821085666
2024-04-24 14:47:11,382 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.369190.14192
2024-04-24 14:47:11,421 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #70: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.4888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(min, 0)': 0.3, '(min, 1)': 0.29, '(rev, 1)': 0.11, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-04-24 14:47:11,421 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:11,422 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321774324883033
2024-04-24 14:47:11,443 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #70: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.06, '(min, 0)': 0.33, '(min, 1)': 0.26, '(rev, 1)': 0.11, '(rev, 2)': 0.06}}
2024-04-24 14:47:11,444 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:11,445 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321774324883033
2024-04-24 14:47:11,452 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #70: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.26666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(min, 0)': 0.32, '(min, 1)': 0.23, '(rev, 1)': 0.07, '(rev, 2)': 0.05}}
2024-04-24 14:47:11,454 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:11,456 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321774324883033
2024-04-24 14:47:11,498 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #70: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.29, '(min, 1)': 0.32, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:47:11,498 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:11,499 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321774324883033
2024-04-24 14:47:12,153 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #70: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5813953488372093, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.27, '(min, 1)': 0.32, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:47:12,153 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:12,154 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321774324883033
2024-04-24 14:47:12,673 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #70: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 3, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:47:12,673 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:12,674 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321774324883033
2024-04-24 14:47:14,178 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #70: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.03, '(min, 0)': 0.24, '(min, 1)': 0.38, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 6)': 0.01}}
2024-04-24 14:47:14,178 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:14,179 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321774324883033
2024-04-24 14:47:14,375 - MainProcess - INFO - text_logger.py - 51 - Train epoch #70
2024-04-24 14:47:14,378 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.2711e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  5.1596e-01,
         0.0000e+00,  6.5149e-02,  5.5637e-03,  3.9351e-01,  0.0000e+00,
         7.0318e-03,  3.0848e-03,  0.0000e+00,  0.0000e+00,  3.0964e-03,
         9.7623e-04,  0.0000e+00,  0.0000e+00,  1.7377e-03,  3.9413e-04,
         0.0000e+00,  0.0000e+00,  1.0720e-03,  1.9025e-04,  0.0000e+00,
         0.0000e+00,  1.0464e-03,  4.0000e-05,  0.0000e+00,  0.0000e+00,
         5.3636e-04,  4.0000e-05,  0.0000e+00,  0.0000e+00,  4.7389e-04,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0021e-04,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00])  tensor([1.4442e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.6017e-02, 0.0000e+00,
        9.6620e-02, 1.0307e-02, 5.6611e-02, 0.0000e+00, 2.3570e-02, 8.7641e-03,
        0.0000e+00, 0.0000e+00, 1.4525e-02, 4.5599e-03, 0.0000e+00, 0.0000e+00,
        1.0047e-02, 2.9542e-03, 0.0000e+00, 0.0000e+00, 7.4624e-03, 1.7851e-03,
        0.0000e+00, 0.0000e+00, 7.2308e-03, 8.9443e-04, 0.0000e+00, 0.0000e+00,
        4.5200e-03, 8.9443e-04, 0.0000e+00, 0.0000e+00, 4.0395e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.3259e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:47:14,394 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4318384185975168
2024-04-24 14:47:14,397 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.403540.08535
2024-04-24 14:47:14,439 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #71: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2553191489361702, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.02, '(min, 0)': 0.09, '(min, 1)': 0.48, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:47:14,439 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:14,440 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319735821085666
2024-04-24 14:47:14,619 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #71: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:47:14,619 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:14,621 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319735821085666
2024-04-24 14:47:14,695 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #71: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5434782608695652, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.04, '(min, 0)': 0.23, '(min, 1)': 0.38, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:47:14,696 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:14,697 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319735821085666
2024-04-24 14:47:14,748 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #71: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43478260869565216, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-04-24 14:47:14,749 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:14,750 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319735821085666
2024-04-24 14:47:15,003 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #71: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3023255813953488, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.34, '(min, 1)': 0.25, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:47:15,003 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:15,004 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319735821085666
2024-04-24 14:47:16,089 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #71: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46296296296296297, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.13, '(rev, 1)': 0.04, '(rev, 2)': 0.07}}
2024-04-24 14:47:16,089 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:16,089 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319735821085666
2024-04-24 14:47:17,892 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #71: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.2, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:47:17,892 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:17,894 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319735821085666
2024-04-24 14:47:18,091 - MainProcess - INFO - text_logger.py - 51 - Train epoch #71
2024-04-24 14:47:18,095 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.3312e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2493e-01, 0.0000e+00,
        4.7920e-02, 5.8275e-03, 4.0741e-01, 0.0000e+00, 3.5264e-03, 4.4477e-03,
        0.0000e+00, 0.0000e+00, 1.3589e-03, 1.9544e-03, 0.0000e+00, 0.0000e+00,
        7.7924e-04, 5.3234e-04, 0.0000e+00, 0.0000e+00, 3.0187e-04, 1.6261e-04,
        0.0000e+00, 0.0000e+00, 2.2550e-04, 5.7700e-05, 0.0000e+00, 0.0000e+00,
        2.2550e-04, 5.7700e-05, 0.0000e+00, 0.0000e+00, 1.4550e-04, 5.7700e-05,
        0.0000e+00, 0.0000e+00, 8.0000e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.6320e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6109e-02, 0.0000e+00,
        5.9366e-02, 1.1019e-02, 2.8960e-02, 0.0000e+00, 1.3942e-02, 1.1044e-02,
        0.0000e+00, 0.0000e+00, 7.7537e-03, 6.5602e-03, 0.0000e+00, 0.0000e+00,
        6.4892e-03, 3.2114e-03, 0.0000e+00, 0.0000e+00, 3.1439e-03, 1.6559e-03,
        0.0000e+00, 0.0000e+00, 2.9087e-03, 9.1257e-04, 0.0000e+00, 0.0000e+00,
        2.9087e-03, 9.1257e-04, 0.0000e+00, 0.0000e+00, 2.2987e-03, 9.1257e-04,
        0.0000e+00, 0.0000e+00, 1.7889e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:47:18,110 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43193966264026573
2024-04-24 14:47:18,116 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.521740.02174
2024-04-24 14:47:18,157 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #72: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5918367346938775, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.2, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:47:18,157 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #72: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.08, '(rev, 1)': 0.11, '(rev, 2)': 0.07}}
2024-04-24 14:47:18,158 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:18,158 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:18,160 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318384185975168
2024-04-24 14:47:18,160 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318384185975168
2024-04-24 14:47:18,172 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #72: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.48, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.04, '(rev, 4)': 0.01}}
2024-04-24 14:47:18,172 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #72: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.27, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-04-24 14:47:18,173 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:18,173 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:18,174 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318384185975168
2024-04-24 14:47:18,174 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318384185975168
2024-04-24 14:47:18,187 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #72: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.7045454545454546, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.28, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.03, '(rev, 5)': 0.01}}
2024-04-24 14:47:18,188 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:18,190 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318384185975168
2024-04-24 14:47:19,372 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #72: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(min, 0)': 0.33, '(min, 1)': 0.26, '(rev, 1)': 0.08, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-04-24 14:47:19,373 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:19,374 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318384185975168
2024-04-24 14:47:20,306 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #72: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.18, '(rev, 1)': 0.06, '(rev, 2)': 0.09, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:47:20,306 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:20,307 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318384185975168
2024-04-24 14:47:20,509 - MainProcess - INFO - text_logger.py - 51 - Train epoch #72
2024-04-24 14:47:20,512 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.6049e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3233e-01, 0.0000e+00,
        4.7311e-02, 7.6463e-03, 4.0276e-01, 0.0000e+00, 2.3659e-03, 4.6951e-03,
        0.0000e+00, 0.0000e+00, 7.4133e-04, 1.5187e-03, 0.0000e+00, 0.0000e+00,
        2.4170e-04, 2.7119e-04, 0.0000e+00, 0.0000e+00, 3.9216e-05, 7.9278e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.3138e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8011e-02, 0.0000e+00,
        5.8219e-02, 1.3136e-02, 1.9054e-02, 0.0000e+00, 9.1446e-03, 1.1828e-02,
        0.0000e+00, 0.0000e+00, 4.8661e-03, 6.1003e-03, 0.0000e+00, 0.0000e+00,
        2.5156e-03, 2.6081e-03, 0.0000e+00, 0.0000e+00, 8.7689e-04, 1.2528e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:47:20,531 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43210197387669064
2024-04-24 14:47:20,533 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.552270.15227
2024-04-24 14:47:20,772 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #73: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.5333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.39, '(min, 1)': 0.25, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:47:20,772 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:20,772 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #73: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.35, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:47:20,773 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:20,773 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43193966264026573
2024-04-24 14:47:20,775 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43193966264026573
2024-04-24 14:47:20,830 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #73: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.27906976744186046, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 4)': 0.01, '(min, 0)': 0.15, '(min, 1)': 0.45, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:47:20,830 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:20,832 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43193966264026573
2024-04-24 14:47:21,010 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #73: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6744186046511628, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.02, '(min, 0)': 0.25, '(min, 1)': 0.42, '(rev, 1)': 0.1, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:47:21,011 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:21,013 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43193966264026573
2024-04-24 14:47:21,407 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #73: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7346938775510204, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(ado, 9)': 0.01, '(min, 0)': 0.12, '(min, 1)': 0.53, '(rev, 1)': 0.05, '(rev, 2)': 0.06, '(rev, 4)': 0.01}}
2024-04-24 14:47:21,408 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:21,409 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43193966264026573
2024-04-24 14:47:21,903 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #73: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 1, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6585365853658537, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.47, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-24 14:47:21,904 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:21,907 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43193966264026573
2024-04-24 14:47:22,875 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #73: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.48, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:47:22,876 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:22,878 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43193966264026573
2024-04-24 14:47:23,115 - MainProcess - INFO - text_logger.py - 51 - Train epoch #73
2024-04-24 14:47:23,120 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.7098e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0185e-01, 0.0000e+00,
        6.7076e-02, 8.2400e-03, 4.0219e-01, 0.0000e+00, 4.4519e-03, 7.8142e-03,
        0.0000e+00, 0.0000e+00, 1.6032e-03, 3.4520e-03, 0.0000e+00, 0.0000e+00,
        6.8056e-04, 1.2108e-03, 0.0000e+00, 0.0000e+00, 2.8567e-04, 4.9294e-04,
        0.0000e+00, 0.0000e+00, 2.1292e-04, 1.2603e-04, 0.0000e+00, 0.0000e+00,
        7.6923e-05, 3.7037e-05, 0.0000e+00, 0.0000e+00, 7.6923e-05, 8.7037e-05,
        0.0000e+00, 0.0000e+00, 3.8462e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.0125e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.7161e-02, 0.0000e+00,
        1.0425e-01, 1.3766e-02, 4.5395e-02, 0.0000e+00, 1.3889e-02, 1.6117e-02,
        0.0000e+00, 0.0000e+00, 7.6909e-03, 9.5549e-03, 0.0000e+00, 0.0000e+00,
        5.0662e-03, 4.7954e-03, 0.0000e+00, 0.0000e+00, 3.2133e-03, 2.8638e-03,
        0.0000e+00, 0.0000e+00, 3.0059e-03, 1.4138e-03, 0.0000e+00, 0.0000e+00,
        1.7201e-03, 8.2817e-04, 0.0000e+00, 0.0000e+00, 1.7201e-03, 1.3900e-03,
        0.0000e+00, 0.0000e+00, 8.6003e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:47:23,149 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43197214275934526
2024-04-24 14:47:23,154 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.406200.12713
2024-04-24 14:47:23,559 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #74: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.45652173913043476, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(min, 0)': 0.04, '(min, 1)': 0.55, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-04-24 14:47:23,560 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:23,562 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210197387669064
2024-04-24 14:47:23,643 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #74: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.13, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:47:23,643 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:23,644 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210197387669064
2024-04-24 14:47:24,124 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #74: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8478260869565217, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.06, '(min, 0)': 0.19, '(min, 1)': 0.42, '(rev, 1)': 0.1, '(rev, 2)': 0.08}}
2024-04-24 14:47:24,126 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:24,128 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210197387669064
2024-04-24 14:47:24,304 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #74: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4883720930232558, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.15, '(min, 1)': 0.49, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-24 14:47:24,305 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:24,305 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210197387669064
2024-04-24 14:47:25,704 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #74: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.28, '(rev, 1)': 0.04, '(rev, 2)': 0.02}}
2024-04-24 14:47:25,704 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:25,705 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210197387669064
2024-04-24 14:47:25,761 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #74: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7555555555555555, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.29, '(min, 1)': 0.35, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-04-24 14:47:25,761 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:25,762 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210197387669064
2024-04-24 14:47:25,973 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #74: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17073170731707318, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.49, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-04-24 14:47:25,973 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:25,974 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210197387669064
2024-04-24 14:47:26,066 - MainProcess - INFO - text_logger.py - 51 - Train epoch #74
2024-04-24 14:47:26,072 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.1799e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0907e-01, 0.0000e+00,
        7.1241e-02, 8.2611e-03, 3.9056e-01, 0.0000e+00, 5.8473e-03, 5.4103e-03,
        0.0000e+00, 0.0000e+00, 2.5680e-03, 2.1349e-03, 0.0000e+00, 0.0000e+00,
        1.6287e-03, 5.2272e-04, 0.0000e+00, 0.0000e+00, 1.0689e-03, 7.0846e-05,
        0.0000e+00, 0.0000e+00, 8.1960e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.4111e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8455e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.8986e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7026e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0226e-01, 0.0000e+00,
        1.2582e-01, 1.3770e-02, 6.1084e-02, 0.0000e+00, 1.8554e-02, 1.2957e-02,
        0.0000e+00, 0.0000e+00, 1.1174e-02, 7.4809e-03, 0.0000e+00, 0.0000e+00,
        8.3295e-03, 3.0012e-03, 0.0000e+00, 0.0000e+00, 6.5926e-03, 1.1195e-03,
        0.0000e+00, 0.0000e+00, 5.7203e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.9429e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1743e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0898e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:47:26,092 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43155480691520837
2024-04-24 14:47:26,095 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.262450.09172
2024-04-24 14:47:26,519 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #75: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.15, '(min, 1)': 0.45, '(rev, 1)': 0.09, '(rev, 2)': 0.06}}
2024-04-24 14:47:26,519 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:26,520 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43197214275934526
2024-04-24 14:47:26,692 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #75: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.36, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:47:26,693 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:26,693 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43197214275934526
2024-04-24 14:47:26,737 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #75: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7391304347826086, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.53, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-04-24 14:47:26,737 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:26,738 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43197214275934526
2024-04-24 14:47:27,608 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #75: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.68, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(min, 0)': 0.18, '(min, 1)': 0.42, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-04-24 14:47:27,608 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:27,609 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43197214275934526
2024-04-24 14:47:28,001 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #75: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2978723404255319, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(min, 0)': 0.26, '(min, 1)': 0.32, '(rev, 1)': 0.04, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:47:28,001 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:28,002 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43197214275934526
2024-04-24 14:47:28,168 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #75: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.32, '(rev, 1)': 0.02, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-24 14:47:28,168 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:28,169 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43197214275934526
2024-04-24 14:47:28,239 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #75: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.24561403508771928, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.03, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.08, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:47:28,240 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:28,241 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43197214275934526
2024-04-24 14:47:28,370 - MainProcess - INFO - text_logger.py - 51 - Train epoch #75
2024-04-24 14:47:28,373 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.2526e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1725e-01, 0.0000e+00,
        4.8838e-02, 6.5418e-03, 4.1385e-01, 0.0000e+00, 3.1914e-03, 4.7114e-03,
        0.0000e+00, 0.0000e+00, 1.5224e-03, 2.1542e-03, 0.0000e+00, 0.0000e+00,
        7.5135e-04, 4.9101e-04, 0.0000e+00, 0.0000e+00, 3.9993e-04, 4.0816e-05,
        0.0000e+00, 0.0000e+00, 2.1302e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.2553e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.6439e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5298e-02, 0.0000e+00,
        6.3091e-02, 1.2653e-02, 2.4353e-02, 0.0000e+00, 1.0429e-02, 1.2741e-02,
        0.0000e+00, 0.0000e+00, 6.8038e-03, 7.9512e-03, 0.0000e+00, 0.0000e+00,
        4.3630e-03, 3.1002e-03, 0.0000e+00, 0.0000e+00, 3.1069e-03, 9.1268e-04,
        0.0000e+00, 0.0000e+00, 2.1491e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.5152e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:47:28,393 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4315973171669582
2024-04-24 14:47:28,396 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.492370.24676
2024-04-24 14:47:28,997 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #76: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(min, 0)': 0.18, '(min, 1)': 0.41, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 5)': 0.01}}
2024-04-24 14:47:28,997 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:28,998 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43155480691520837
2024-04-24 14:47:29,308 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #76: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.14583333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.05, '(min, 0)': 0.13, '(min, 1)': 0.42, '(rev, 1)': 0.06, '(rev, 2)': 0.03}}
2024-04-24 14:47:29,309 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:29,311 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43155480691520837
2024-04-24 14:47:29,316 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #76: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6444444444444445, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(min, 0)': 0.26, '(min, 1)': 0.36, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:47:29,317 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:29,318 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43155480691520837
2024-04-24 14:47:29,922 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #76: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(min, 0)': 0.13, '(min, 1)': 0.46, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-04-24 14:47:29,923 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:29,923 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43155480691520837
2024-04-24 14:47:30,215 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #76: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 3, 0, 0),(rev, 4)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '4/4', 'revenue': 0.4772727272727273, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.28, '(min, 1)': 0.33, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:47:30,215 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:30,217 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43155480691520837
2024-04-24 14:47:30,332 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #76: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(min, 0)': 0.46, '(min, 1)': 0.11, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:47:30,332 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:30,333 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43155480691520837
2024-04-24 14:47:31,498 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #76: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.09, '(min, 1)': 0.49, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:47:31,498 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:31,498 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43155480691520837
2024-04-24 14:47:31,709 - MainProcess - INFO - text_logger.py - 51 - Train epoch #76
2024-04-24 14:47:31,712 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.6600e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2699e-01, 0.0000e+00,
        5.0214e-02, 6.5798e-03, 4.0120e-01, 0.0000e+00, 2.3768e-03, 6.5598e-03,
        0.0000e+00, 0.0000e+00, 5.7227e-04, 2.9863e-03, 0.0000e+00, 0.0000e+00,
        2.8318e-04, 1.1428e-03, 0.0000e+00, 0.0000e+00, 3.7736e-05, 6.2918e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4586e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.1808e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7614e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7365e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.0620e-02, 0.0000e+00,
        6.3120e-02, 1.2451e-02, 2.3568e-02, 0.0000e+00, 8.0800e-03, 1.6006e-02,
        0.0000e+00, 0.0000e+00, 3.5804e-03, 8.8042e-03, 0.0000e+00, 0.0000e+00,
        2.4214e-03, 4.7382e-03, 0.0000e+00, 0.0000e+00, 8.4380e-04, 3.3711e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9770e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.3406e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0711e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:47:31,736 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.431299527393282
2024-04-24 14:47:31,739 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.322220.03333
2024-04-24 14:47:31,765 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #77: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 7, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 7, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(min, 0)': 0.34, '(min, 1)': 0.27, '(rev, 1)': 0.12, '(rev, 2)': 0.02}}
2024-04-24 14:47:31,765 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:31,766 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315973171669582
2024-04-24 14:47:31,931 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #77: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40816326530612246, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.01, '(min, 0)': 0.18, '(min, 1)': 0.43, '(rev, 1)': 0.04, '(rev, 2)': 0.08}}
2024-04-24 14:47:31,932 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:31,934 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315973171669582
2024-04-24 14:47:32,373 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #77: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8372093023255814, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.34, '(min, 1)': 0.29, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 3)': 0.03}}
2024-04-24 14:47:32,373 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:32,374 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315973171669582
2024-04-24 14:47:32,587 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #77: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 1, 1, 1),(min, 0)->(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 2, 1, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.17777777777777778, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.03, '(min, 0)': 0.04, '(min, 1)': 0.52, '(rev, 1)': 0.08, '(rev, 2)': 0.02}}
2024-04-24 14:47:32,588 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:32,589 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315973171669582
2024-04-24 14:47:32,665 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #77: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.16, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-04-24 14:47:32,666 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:32,668 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315973171669582
2024-04-24 14:47:32,981 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #77: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6444444444444445, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 3)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.41, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.02, '(rev, 5)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:47:32,982 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:32,983 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315973171669582
2024-04-24 14:47:34,203 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #77: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3953488372093023, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.04, '(min, 0)': 0.3, '(min, 1)': 0.32, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:47:34,203 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:34,204 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315973171669582
2024-04-24 14:47:34,424 - MainProcess - INFO - text_logger.py - 51 - Train epoch #77
2024-04-24 14:47:34,427 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.9062e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1326e-01, 0.0000e+00,
        4.4297e-02, 8.0292e-03, 4.1886e-01, 0.0000e+00, 1.8459e-03, 7.6687e-03,
        0.0000e+00, 0.0000e+00, 1.7739e-04, 4.1579e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 9.8894e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1623e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7415e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.9827e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0303e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.0482e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6354e-02, 0.0000e+00,
        4.8532e-02, 1.3875e-02, 1.7972e-02, 0.0000e+00, 7.0985e-03, 1.9734e-02,
        0.0000e+00, 0.0000e+00, 2.0983e-03, 1.0608e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.0168e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4834e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5910e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.1591e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7760e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:47:34,449 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4314099008849121
2024-04-24 14:47:34,453 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.526300.11814
2024-04-24 14:47:34,502 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #78: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5625, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.32, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:47:34,502 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:34,502 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431299527393282
2024-04-24 14:47:34,693 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #78: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.16, '(min, 1)': 0.41, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 4)': 0.01}}
2024-04-24 14:47:34,693 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:34,694 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431299527393282
2024-04-24 14:47:35,065 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #78: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.05, '(min, 0)': 0.1, '(min, 1)': 0.46, '(rev, 1)': 0.09, '(rev, 2)': 0.02}}
2024-04-24 14:47:35,066 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:35,066 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431299527393282
2024-04-24 14:47:35,348 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #78: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7674418604651163, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.41, '(rev, 1)': 0.11, '(rev, 2)': 0.07, '(rev, 4)': 0.01}}
2024-04-24 14:47:35,349 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:35,350 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431299527393282
2024-04-24 14:47:35,653 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #78: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46938775510204084, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.03, '(min, 0)': 0.18, '(min, 1)': 0.41, '(rev, 1)': 0.02, '(rev, 2)': 0.06}}
2024-04-24 14:47:35,653 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:35,654 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431299527393282
2024-04-24 14:47:35,979 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #78: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(min, 0)': 0.48, '(min, 1)': 0.18, '(rev, 1)': 0.08, '(rev, 2)': 0.08, '(rev, 3)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:47:35,980 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:35,981 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431299527393282
2024-04-24 14:47:36,688 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #78: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5217391304347826, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.08, '(min, 1)': 0.53, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:47:36,688 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:36,690 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431299527393282
2024-04-24 14:47:36,919 - MainProcess - INFO - text_logger.py - 51 - Train epoch #78
2024-04-24 14:47:36,926 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.1697e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2973e-01, 0.0000e+00,
        5.0194e-02, 6.9670e-03, 4.0072e-01, 0.0000e+00, 2.2460e-03, 5.4403e-03,
        0.0000e+00, 0.0000e+00, 7.2327e-04, 2.2451e-03, 0.0000e+00, 0.0000e+00,
        3.6806e-04, 6.9591e-04, 0.0000e+00, 0.0000e+00, 1.6476e-04, 2.4191e-04,
        0.0000e+00, 0.0000e+00, 8.7996e-05, 9.5868e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.0000e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.6056e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5706e-02, 0.0000e+00,
        7.4104e-02, 1.2512e-02, 3.0796e-02, 0.0000e+00, 9.0852e-03, 1.5274e-02,
        0.0000e+00, 0.0000e+00, 4.6151e-03, 8.2853e-03, 0.0000e+00, 0.0000e+00,
        3.3525e-03, 3.7614e-03, 0.0000e+00, 0.0000e+00, 1.8730e-03, 2.1042e-03,
        0.0000e+00, 0.0000e+00, 1.3982e-03, 1.2395e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.7889e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:47:36,946 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43210177519392323
2024-04-24 14:47:36,950 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.817050.04961
2024-04-24 14:47:36,965 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #79: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7291666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.09, '(min, 1)': 0.5, '(rev, 1)': 0.08, '(rev, 2)': 0.09, '(rev, 3)': 0.01}}
2024-04-24 14:47:36,966 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:36,967 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4314099008849121
2024-04-24 14:47:37,012 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #79: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(min, 0)': 0.18, '(min, 1)': 0.41, '(rev, 1)': 0.08, '(rev, 2)': 0.05}}
2024-04-24 14:47:37,012 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:37,013 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4314099008849121
2024-04-24 14:47:37,357 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #79: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(min, 0)': 0.04, '(min, 1)': 0.51, '(rev, 1)': 0.1, '(rev, 2)': 0.04}}
2024-04-24 14:47:37,357 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:37,358 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4314099008849121
2024-04-24 14:47:37,652 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #79: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.5333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.22, '(rev, 1)': 0.11, '(rev, 2)': 0.09}}
2024-04-24 14:47:37,652 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:37,653 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4314099008849121
2024-04-24 14:47:38,331 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #79: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 2, 1, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.425, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(min, 0)': 0.25, '(min, 1)': 0.36, '(rev, 1)': 0.13, '(rev, 2)': 0.05}}
2024-04-24 14:47:38,331 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:38,332 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4314099008849121
2024-04-24 14:47:39,612 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #79: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.48936170212765956, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.46, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:47:39,612 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:39,614 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4314099008849121
2024-04-24 14:47:39,659 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #79: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5957446808510638, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.04, '(ado, 4)': 0.01, '(min, 0)': 0.18, '(min, 1)': 0.43, '(rev, 1)': 0.1, '(rev, 2)': 0.07}}
2024-04-24 14:47:39,659 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:39,659 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4314099008849121
2024-04-24 14:47:39,866 - MainProcess - INFO - text_logger.py - 51 - Train epoch #79
2024-04-24 14:47:39,869 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.4353e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1683e-01, 0.0000e+00,
        4.2944e-02, 7.1793e-03, 4.2783e-01, 0.0000e+00, 1.1143e-03, 3.1274e-03,
        0.0000e+00, 0.0000e+00, 1.5710e-04, 6.9480e-04, 0.0000e+00, 0.0000e+00,
        4.0816e-05, 8.3370e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.2742e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8011e-02, 0.0000e+00,
        4.6847e-02, 1.1908e-02, 1.1392e-02, 0.0000e+00, 5.9475e-03, 9.2649e-03,
        0.0000e+00, 0.0000e+00, 2.1209e-03, 4.7944e-03, 0.0000e+00, 0.0000e+00,
        9.1268e-04, 1.3172e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:47:39,887 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4321822360112636
2024-04-24 14:47:39,890 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.511350.02199
2024-04-24 14:47:39,945 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #80: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 9, 5, 0, 0),(rev, 6)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '6/6', 'revenue': 0.5813953488372093, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.03, '(min, 0)': 0.15, '(min, 1)': 0.51, '(rev, 1)': 0.1, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:47:39,946 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:39,947 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210177519392323
2024-04-24 14:47:40,126 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #80: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8043478260869565, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(min, 0)': 0.38, '(min, 1)': 0.22, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:47:40,126 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:40,127 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210177519392323
2024-04-24 14:47:40,203 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #80: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4318181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.21, '(min, 1)': 0.41, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.02}}
2024-04-24 14:47:40,204 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:40,204 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210177519392323
2024-04-24 14:47:40,762 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #80: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.42, '(min, 1)': 0.16, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:47:40,763 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:40,766 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210177519392323
2024-04-24 14:47:40,947 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #80: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.43, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:47:40,948 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:40,949 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210177519392323
2024-04-24 14:47:42,001 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #80: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3404255319148936, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.06, '(min, 0)': 0.08, '(min, 1)': 0.51, '(rev, 1)': 0.09, '(rev, 2)': 0.07}}
2024-04-24 14:47:42,001 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:42,002 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210177519392323
2024-04-24 14:47:42,481 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #80: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(min, 0)': 0.45, '(min, 1)': 0.13, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:47:42,481 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:42,482 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210177519392323
2024-04-24 14:47:42,560 - MainProcess - INFO - text_logger.py - 51 - Train epoch #80
2024-04-24 14:47:42,565 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.2698e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2971e-01, 0.0000e+00,
        5.0744e-02, 6.8435e-03, 3.9641e-01, 0.0000e+00, 2.4503e-03, 6.1745e-03,
        0.0000e+00, 0.0000e+00, 4.7945e-04, 4.0000e-03, 0.0000e+00, 0.0000e+00,
        1.6053e-04, 1.1412e-03, 0.0000e+00, 0.0000e+00, 7.5565e-05, 7.6743e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.1656e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.6444e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6993e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.2982e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5352e-02, 0.0000e+00,
        7.0629e-02, 1.2045e-02, 2.6752e-02, 0.0000e+00, 7.6390e-03, 1.5282e-02,
        0.0000e+00, 0.0000e+00, 2.8879e-03, 1.1403e-02, 0.0000e+00, 0.0000e+00,
        1.6301e-03, 4.4150e-03, 0.0000e+00, 0.0000e+00, 1.1999e-03, 3.5105e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7779e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.1020e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0736e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:47:42,586 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4321719462375876
2024-04-24 14:47:42,589 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.465970.11181
2024-04-24 14:47:42,652 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #81: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.48936170212765956, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(min, 0)': 0.12, '(min, 1)': 0.51, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:47:42,652 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:42,653 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321822360112636
2024-04-24 14:47:42,922 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #81: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(min, 0)': 0.13, '(min, 1)': 0.46, '(rev, 1)': 0.09, '(rev, 2)': 0.08, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:47:42,922 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:42,923 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321822360112636
2024-04-24 14:47:43,200 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #81: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.3191489361702128, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.03, '(min, 0)': 0.13, '(min, 1)': 0.46, '(rev, 1)': 0.05, '(rev, 2)': 0.07}}
2024-04-24 14:47:43,201 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:43,201 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321822360112636
2024-04-24 14:47:43,444 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #81: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(min, 0)': 0.52, '(min, 1)': 0.07, '(rev, 1)': 0.09, '(rev, 2)': 0.06}}
2024-04-24 14:47:43,445 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:43,446 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321822360112636
2024-04-24 14:47:43,811 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #81: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.52, '(min, 1)': 0.07, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-04-24 14:47:43,812 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:43,815 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321822360112636
2024-04-24 14:47:44,852 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #81: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.21, '(rev, 1)': 0.06, '(rev, 2)': 0.05}}
2024-04-24 14:47:44,852 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:44,853 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321822360112636
2024-04-24 14:47:45,384 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #81: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(min, 0)': 0.36, '(min, 1)': 0.25, '(rev, 1)': 0.08, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-04-24 14:47:45,385 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:45,386 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321822360112636
2024-04-24 14:47:45,611 - MainProcess - INFO - text_logger.py - 51 - Train epoch #81
2024-04-24 14:47:45,614 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.8111e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0588e-01, 0.0000e+00,
        4.6375e-02, 7.6501e-03, 4.2980e-01, 0.0000e+00, 2.4208e-03, 4.5294e-03,
        0.0000e+00, 0.0000e+00, 9.1783e-04, 1.3893e-03, 0.0000e+00, 0.0000e+00,
        5.1472e-04, 2.2558e-04, 0.0000e+00, 0.0000e+00, 1.8986e-04, 7.0667e-05,
        0.0000e+00, 0.0000e+00, 4.0816e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.6993e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6959e-02, 0.0000e+00,
        5.7200e-02, 1.2982e-02, 2.0109e-02, 0.0000e+00, 8.6151e-03, 1.2487e-02,
        0.0000e+00, 0.0000e+00, 4.9533e-03, 6.6518e-03, 0.0000e+00, 0.0000e+00,
        3.6517e-03, 2.0597e-03, 0.0000e+00, 0.0000e+00, 2.2805e-03, 1.1296e-03,
        0.0000e+00, 0.0000e+00, 9.1268e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:47:45,643 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43209927723685826
2024-04-24 14:47:45,647 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.434780.04348
2024-04-24 14:47:45,659 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #82: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.03, '(min, 0)': 0.04, '(min, 1)': 0.53, '(rev, 1)': 0.09, '(rev, 2)': 0.06}}
2024-04-24 14:47:45,659 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:45,660 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321719462375876
2024-04-24 14:47:45,675 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #82: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.02, '(min, 0)': 0.08, '(min, 1)': 0.5, '(rev, 1)': 0.05, '(rev, 2)': 0.06}}
'(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:47:45,676 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:45,676 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:45,677 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #82: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(min, 0)': 0.24, '(min, 1)': 0.38, '(rev, 1)': 0.12, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-04-24 14:47:45,677 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321719462375876
2024-04-24 14:47:45,677 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:45,677 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321719462375876
2024-04-24 14:47:45,678 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321719462375876
2024-04-24 14:47:46,238 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #82: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.21, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:47:46,239 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:46,240 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321719462375876
2024-04-24 14:47:47,422 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #82: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5531914893617021, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.05, '(min, 1)': 0.56, '(rev, 1)': 0.07, '(rev, 2)': 0.11}}
2024-04-24 14:47:47,422 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:47,423 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321719462375876
2024-04-24 14:47:47,914 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #82: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7045454545454546, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.45, '(min, 1)': 0.14, '(rev, 1)': 0.12, '(rev, 2)': 0.03, '(rev, 3)': 0.03}}
2024-04-24 14:47:47,915 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:47,919 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321719462375876
2024-04-24 14:47:48,000 - MainProcess - INFO - text_logger.py - 51 - Train epoch #82
2024-04-24 14:47:48,003 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.6678e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3643e-01, 0.0000e+00,
        4.9837e-02, 8.0855e-03, 3.9309e-01, 0.0000e+00, 1.7817e-03, 5.7171e-03,
        0.0000e+00, 0.0000e+00, 5.6448e-04, 3.2547e-03, 0.0000e+00, 0.0000e+00,
        2.1278e-04, 5.5775e-04, 0.0000e+00, 0.0000e+00, 6.9151e-05, 1.7603e-04,
        0.0000e+00, 0.0000e+00, 3.6364e-05, 1.2633e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.3333e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3333e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5134e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6575e-02, 0.0000e+00,
        6.1671e-02, 1.3420e-02, 2.8095e-02, 0.0000e+00, 7.3558e-03, 1.3511e-02,
        0.0000e+00, 0.0000e+00, 4.1012e-03, 1.0553e-02, 0.0000e+00, 0.0000e+00,
        2.2306e-03, 3.3600e-03, 0.0000e+00, 0.0000e+00, 1.0937e-03, 1.6141e-03,
        0.0000e+00, 0.0000e+00, 8.1312e-04, 1.4149e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.4536e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.4536e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:47:48,035 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4323398493428483
2024-04-24 14:47:48,037 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.591400.11314
2024-04-24 14:47:48,063 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #83: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22916666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.05, '(min, 0)': 0.04, '(min, 1)': 0.53, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:47:48,064 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:48,065 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43209927723685826
2024-04-24 14:47:48,079 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #83: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.09, '(min, 1)': 0.46, '(rev, 1)': 0.1, '(rev, 2)': 0.05}}
2024-04-24 14:47:48,079 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:48,080 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43209927723685826
2024-04-24 14:47:48,095 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #83: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.22727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.06, '(min, 0)': 0.2, '(min, 1)': 0.38, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:47:48,095 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:48,096 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43209927723685826
2024-04-24 14:47:48,463 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #83: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.625, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.23, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:47:48,463 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:48,464 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43209927723685826
2024-04-24 14:47:49,037 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #83: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.16666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.39, '(rev, 1)': 0.05, '(rev, 2)': 0.03}}
2024-04-24 14:47:49,038 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:49,039 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43209927723685826
2024-04-24 14:47:50,317 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #83: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(min, 0)': 0.14, '(min, 1)': 0.47, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-24 14:47:50,317 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:50,318 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43209927723685826
2024-04-24 14:47:50,592 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #83: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 1.2708333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(min, 0)': 0.13, '(min, 1)': 0.46, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 4)': 0.01}}
2024-04-24 14:47:50,598 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:50,599 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43209927723685826
2024-04-24 14:47:50,807 - MainProcess - INFO - text_logger.py - 51 - Train epoch #83
2024-04-24 14:47:50,810 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.4308e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9760e-01, 0.0000e+00,
        4.7119e-02, 5.6586e-03, 4.4373e-01, 0.0000e+00, 1.5622e-03, 2.7793e-03,
        0.0000e+00, 0.0000e+00, 1.5951e-04, 9.7299e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.1381e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.0418, 0.0000, 0.0000, 0.0000, 0.0536, 0.0000, 0.0590, 0.0110, 0.0198,
        0.0000, 0.0067, 0.0085, 0.0000, 0.0000, 0.0022, 0.0053, 0.0000, 0.0000,
        0.0000, 0.0029, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-04-24 14:47:50,824 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43195558613922047
2024-04-24 14:47:50,829 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.278990.11232
2024-04-24 14:47:50,841 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #84: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6170212765957447, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.44, '(rev, 1)': 0.08, '(rev, 2)': 0.08}}
2024-04-24 14:47:50,841 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #84: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.03, '(min, 0)': 0.18, '(min, 1)': 0.4, '(rev, 1)': 0.07, '(rev, 2)': 0.07}}
2024-04-24 14:47:50,841 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:50,841 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:50,842 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323398493428483
2024-04-24 14:47:50,842 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323398493428483
2024-04-24 14:47:50,857 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #84: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(min, 1)': 0.57, '(rev, 1)': 0.09, '(rev, 2)': 0.05}}
2024-04-24 14:47:50,857 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:50,858 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323398493428483
2024-04-24 14:47:51,034 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #84: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5116279069767442, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.45, '(min, 1)': 0.16, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:47:51,035 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:51,036 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323398493428483
2024-04-24 14:47:51,685 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #84: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6818181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(min, 0)': 0.23, '(min, 1)': 0.35, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:47:51,685 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:51,686 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323398493428483
2024-04-24 14:47:52,383 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #84: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.16, '(min, 1)': 0.46, '(rev, 1)': 0.09, '(rev, 2)': 0.09, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:47:52,383 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:52,384 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323398493428483
2024-04-24 14:47:52,906 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #84: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.06, '(min, 0)': 0.15, '(min, 1)': 0.41, '(rev, 1)': 0.14, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:47:52,906 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:52,907 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323398493428483
2024-04-24 14:47:53,105 - MainProcess - INFO - text_logger.py - 51 - Train epoch #84
2024-04-24 14:47:53,108 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.8999e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4546e-01, 0.0000e+00,
        5.0490e-02, 7.2953e-03, 3.8893e-01, 0.0000e+00, 1.2570e-03, 3.9870e-03,
        0.0000e+00, 0.0000e+00, 1.2489e-04, 1.8685e-03, 0.0000e+00, 0.0000e+00,
        4.0816e-05, 2.8420e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4607e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2787e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.0000e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.2632e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6476e-02, 0.0000e+00,
        7.2800e-02, 1.2740e-02, 3.1949e-02, 0.0000e+00, 5.9603e-03, 1.1274e-02,
        0.0000e+00, 0.0000e+00, 1.6356e-03, 8.2457e-03, 0.0000e+00, 0.0000e+00,
        9.1268e-04, 2.2844e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6492e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3314e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.7889e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:47:53,129 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43231739232514044
2024-04-24 14:47:53,133 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.652020.02980
2024-04-24 14:47:53,168 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #85: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10638297872340426, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.06, '(min, 0)': 0.03, '(min, 1)': 0.53, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-04-24 14:47:53,168 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:53,169 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195558613922047
2024-04-24 14:47:53,189 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #85: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.20930232558139536, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(min, 0)': 0.44, '(min, 1)': 0.12, '(rev, 1)': 0.09, '(rev, 2)': 0.03}}
2024-04-24 14:47:53,190 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:53,193 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195558613922047
2024-04-24 14:47:53,261 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #85: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.574468085106383, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(min, 0)': 0.38, '(min, 1)': 0.2, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:47:53,262 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:53,263 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195558613922047
2024-04-24 14:47:53,728 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #85: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3617021276595745, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.03, '(min, 1)': 0.58, '(rev, 1)': 0.04, '(rev, 2)': 0.08}}
2024-04-24 14:47:53,728 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:53,729 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195558613922047
2024-04-24 14:47:53,842 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #85: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1702127659574468, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.04, '(min, 0)': 0.48, '(min, 1)': 0.07, '(rev, 1)': 0.06, '(rev, 2)': 0.04}}
2024-04-24 14:47:53,842 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:53,845 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195558613922047
2024-04-24 14:47:55,045 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #85: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.03, '(min, 0)': 0.18, '(min, 1)': 0.39, '(rev, 1)': 0.12, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-04-24 14:47:55,046 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:55,047 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195558613922047
2024-04-24 14:47:55,111 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #85: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4883720930232558, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.15, '(min, 1)': 0.46, '(rev, 1)': 0.12, '(rev, 2)': 0.08}}
2024-04-24 14:47:55,112 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:55,113 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195558613922047
2024-04-24 14:47:55,336 - MainProcess - INFO - text_logger.py - 51 - Train epoch #85
2024-04-24 14:47:55,339 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.2710e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9280e-01, 0.0000e+00,
        4.6705e-02, 7.3843e-03, 4.4701e-01, 0.0000e+00, 1.4496e-03, 3.1359e-03,
        0.0000e+00, 0.0000e+00, 2.5874e-04, 8.7702e-04, 0.0000e+00, 0.0000e+00,
        1.1489e-04, 2.3190e-04, 0.0000e+00, 0.0000e+00, 3.2787e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.0472e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1576e-02, 0.0000e+00,
        5.7067e-02, 1.3315e-02, 1.9874e-02, 0.0000e+00, 6.3801e-03, 9.8495e-03,
        0.0000e+00, 0.0000e+00, 2.4346e-03, 5.4536e-03, 0.0000e+00, 0.0000e+00,
        1.5024e-03, 2.4424e-03, 0.0000e+00, 0.0000e+00, 7.3314e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:47:55,375 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43195446178206814
2024-04-24 14:47:55,377 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.289650.11944
2024-04-24 14:47:55,849 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #86: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3829787234042553, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.05, '(min, 0)': 0.24, '(min, 1)': 0.36, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 8)': 0.01}}
2024-04-24 14:47:55,849 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:55,849 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43231739232514044
2024-04-24 14:47:56,109 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #86: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.21739130434782608, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.06, '(ado, 3)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.5, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:47:56,110 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:56,111 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43231739232514044
2024-04-24 14:47:56,160 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #86: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6818181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.18, '(rev, 1)': 0.11, '(rev, 2)': 0.05, '(rev, 3)': 0.03}}
2024-04-24 14:47:56,160 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:56,161 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43231739232514044
2024-04-24 14:47:56,246 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #86: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5454545454545454, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(min, 0)': 0.17, '(min, 1)': 0.44, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 4)': 0.03}}
2024-04-24 14:47:56,246 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:56,247 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43231739232514044
2024-04-24 14:47:56,691 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #86: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(min, 0)': 0.43, '(min, 1)': 0.14, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:47:56,694 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:56,697 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43231739232514044
2024-04-24 14:47:58,106 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #86: {'transition': '(exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 1, 5, 7, 1, 1),(min, 1)->(exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 1, 5, 8, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.38, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:47:58,106 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:58,107 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43231739232514044
2024-04-24 14:47:58,504 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #86: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.26, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:47:58,505 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:58,506 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43231739232514044
2024-04-24 14:47:58,732 - MainProcess - INFO - text_logger.py - 51 - Train epoch #86
2024-04-24 14:47:58,735 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.3707e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2186e-01, 0.0000e+00,
        6.5090e-02, 7.0690e-03, 3.8736e-01, 0.0000e+00, 3.2494e-03, 7.5197e-03,
        0.0000e+00, 0.0000e+00, 1.1676e-03, 4.8299e-03, 0.0000e+00, 0.0000e+00,
        5.4724e-04, 8.4363e-04, 0.0000e+00, 0.0000e+00, 2.2377e-04, 2.0774e-04,
        0.0000e+00, 0.0000e+00, 3.9216e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.8513e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8407e-02, 0.0000e+00,
        8.0764e-02, 1.3712e-02, 4.0253e-02, 0.0000e+00, 1.0590e-02, 2.0367e-02,
        0.0000e+00, 0.0000e+00, 5.6348e-03, 1.4540e-02, 0.0000e+00, 0.0000e+00,
        3.9306e-03, 4.1079e-03, 0.0000e+00, 0.0000e+00, 2.2525e-03, 1.7610e-03,
        0.0000e+00, 0.0000e+00, 8.7689e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:47:58,760 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43189101544273545
2024-04-24 14:47:58,762 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.439390.10606
2024-04-24 14:47:58,766 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #87: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4878048780487805, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.04, '(min, 0)': 0.18, '(min, 1)': 0.42, '(rev, 1)': 0.15, '(rev, 2)': 0.05, '(rev, 3)': 0.03}}
2024-04-24 14:47:58,766 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:58,767 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195446178206814
2024-04-24 14:47:58,813 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #87: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5681818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(min, 0)': 0.05, '(min, 1)': 0.54, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}

2024-04-24 14:47:58,813 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:58,813 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:58,814 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195446178206814
2024-04-24 14:47:58,814 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195446178206814
2024-04-24 14:47:58,828 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #87: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.03, '(min, 0)': 0.45, '(min, 1)': 0.11, '(rev, 1)': 0.1, '(rev, 2)': 0.05}}
2024-04-24 14:47:58,828 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:58,829 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195446178206814
2024-04-24 14:47:58,949 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #87: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.575, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.09, '(min, 1)': 0.52, '(rev, 1)': 0.13, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-04-24 14:47:58,949 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:47:58,950 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195446178206814
2024-04-24 14:48:00,310 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #87: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.08, '(min, 1)': 0.49, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-04-24 14:48:00,311 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:00,312 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195446178206814
2024-04-24 14:48:01,043 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #87: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(min, 0)': 0.06, '(min, 1)': 0.51, '(rev, 1)': 0.1, '(rev, 2)': 0.07}}
2024-04-24 14:48:01,044 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:01,044 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195446178206814
2024-04-24 14:48:01,264 - MainProcess - INFO - text_logger.py - 51 - Train epoch #87
2024-04-24 14:48:01,267 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.2795e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8964e-01, 0.0000e+00,
        5.6258e-02, 1.0032e-02, 4.2756e-01, 0.0000e+00, 1.6630e-03, 8.6526e-03,
        0.0000e+00, 0.0000e+00, 3.2772e-04, 4.7710e-03, 0.0000e+00, 0.0000e+00,
        9.4246e-05, 7.9547e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0172e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5016, 0.0000, 0.0000, 0.0000, 0.0604, 0.0000, 0.0679, 0.0164, 0.0330,
        0.0000, 0.0068, 0.0203, 0.0000, 0.0000, 0.0032, 0.0138, 0.0000, 0.0000,
        0.0016, 0.0040, 0.0000, 0.0000, 0.0000, 0.0017, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-04-24 14:48:01,289 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4315710034468371
2024-04-24 14:48:01,292 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.311110.02222
2024-04-24 14:48:01,296 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #88: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.11, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 4)': 0.01}}
2024-04-24 14:48:01,297 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:01,297 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #88: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4166666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(min, 0)': 0.09, '(min, 1)': 0.5, '(rev, 1)': 0.06, '(rev, 2)': 0.09}}
2024-04-24 14:48:01,297 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:01,297 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43189101544273545
2024-04-24 14:48:01,298 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43189101544273545
2024-04-24 14:48:01,315 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #88: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.06, '(min, 1)': 0.53, '(rev, 1)': 0.1, '(rev, 2)': 0.09}}
2024-04-24 14:48:01,315 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:01,317 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43189101544273545
2024-04-24 14:48:01,481 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #88: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.03, '(ado, 5)': 0.01, '(min, 0)': 0.06, '(min, 1)': 0.55, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-04-24 14:48:01,482 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:01,483 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43189101544273545
2024-04-24 14:48:02,011 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #88: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 2, 1, 0, 1, 0)', 'reward_ratio': '0/0', 'revenue': 0.6875, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.26, '(min, 1)': 0.34, '(rev, 1)': 0.05, '(rev, 2)': 0.09, '(rev, 3)': 0.01}}
2024-04-24 14:48:02,012 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:02,012 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43189101544273545
2024-04-24 14:48:02,473 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #88: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(min, 1)': 0.57, '(rev, 1)': 0.11, '(rev, 2)': 0.07}}
2024-04-24 14:48:02,473 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:02,474 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43189101544273545
2024-04-24 14:48:03,396 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #88: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3695652173913043, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.04, '(min, 0)': 0.23, '(min, 1)': 0.38, '(rev, 1)': 0.04, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:48:03,397 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:03,399 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43189101544273545
2024-04-24 14:48:03,654 - MainProcess - INFO - text_logger.py - 51 - Train epoch #88
2024-04-24 14:48:03,657 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.6435e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3186e-01, 0.0000e+00,
        4.6263e-02, 8.3972e-03, 4.0595e-01, 0.0000e+00, 1.0414e-03, 4.6626e-03,
        0.0000e+00, 0.0000e+00, 1.3783e-04, 1.3975e-03, 0.0000e+00, 0.0000e+00,
        6.5045e-05, 2.0074e-04, 0.0000e+00, 0.0000e+00, 3.2258e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.1857e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9963e-02, 0.0000e+00,
        6.2525e-02, 1.4038e-02, 2.9993e-02, 0.0000e+00, 5.2306e-03, 1.1483e-02,
        0.0000e+00, 0.0000e+00, 1.5431e-03, 6.8082e-03, 0.0000e+00, 0.0000e+00,
        1.0275e-03, 2.2054e-03, 0.0000e+00, 0.0000e+00, 7.2131e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:48:03,672 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43149543589538314
2024-04-24 14:48:03,676 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.433330.05556
2024-04-24 14:48:03,690 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #89: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.3673469387755102, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(min, 0)': 0.22, '(min, 1)': 0.35, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-04-24 14:48:03,691 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:03,692 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315710034468371
2024-04-24 14:48:03,703 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #89: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3488372093023256, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.09, '(min, 1)': 0.49, '(rev, 1)': 0.1, '(rev, 2)': 0.05}}
2024-04-24 14:48:03,703 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:03,705 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315710034468371
2024-04-24 14:48:03,900 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #89: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(min, 0)': 0.26, '(min, 1)': 0.34, '(rev, 1)': 0.07, '(rev, 2)': 0.09, '(rev, 3)': 0.01}}
2024-04-24 14:48:03,901 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:03,901 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315710034468371
2024-04-24 14:48:04,235 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #89: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46511627906976744, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.12, '(min, 1)': 0.48, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:48:04,236 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:04,236 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315710034468371
2024-04-24 14:48:05,108 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #89: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.44680851063829785, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(min, 0)': 0.06, '(min, 1)': 0.53, '(rev, 1)': 0.07, '(rev, 2)': 0.09, '(rev, 3)': 0.01}}
2024-04-24 14:48:05,109 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:05,109 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315710034468371
2024-04-24 14:48:05,375 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #89: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.18, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:48:05,375 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:05,376 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315710034468371
2024-04-24 14:48:05,929 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #89: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(min, 0)': 0.32, '(min, 1)': 0.24, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:48:05,930 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:05,930 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315710034468371
2024-04-24 14:48:06,153 - MainProcess - INFO - text_logger.py - 51 - Train epoch #89
2024-04-24 14:48:06,156 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.8506e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0324e-01, 0.0000e+00,
        5.3437e-02, 8.0002e-03, 4.2776e-01, 0.0000e+00, 1.3432e-03, 4.1991e-03,
        0.0000e+00, 0.0000e+00, 1.3880e-04, 1.6251e-03, 0.0000e+00, 0.0000e+00,
        3.3898e-05, 2.2959e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5816e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5490e-02, 0.0000e+00,
        6.8451e-02, 1.3173e-02, 2.9987e-02, 0.0000e+00, 6.1484e-03, 1.0961e-02,
        0.0000e+00, 0.0000e+00, 1.8788e-03, 7.2889e-03, 0.0000e+00, 0.0000e+00,
        7.5799e-04, 2.4190e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:48:06,186 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43146512646697066
2024-04-24 14:48:06,189 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.455960.00915
2024-04-24 14:48:06,200 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #90: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(min, 0)': 0.09, '(min, 1)': 0.5, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:48:06,201 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:06,202 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43149543589538314
2024-04-24 14:48:06,247 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #90: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.41, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:48:06,248 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:06,250 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43149543589538314
2024-04-24 14:48:06,376 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #90: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.12, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:48:06,376 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:06,378 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43149543589538314
2024-04-24 14:48:07,114 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #90: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 9)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.32, '(rev, 1)': 0.06, '(rev, 2)': 0.06, '(rev, 4)': 0.01}}
2024-04-24 14:48:07,114 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:07,115 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43149543589538314
2024-04-24 14:48:07,515 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #90: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.18181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.05, '(min, 0)': 0.17, '(min, 1)': 0.39, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:48:07,516 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:07,519 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43149543589538314
2024-04-24 14:48:07,801 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #90: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.06, '(min, 0)': 0.26, '(min, 1)': 0.37, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-04-24 14:48:07,801 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:07,802 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43149543589538314
2024-04-24 14:48:08,281 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #90: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.18, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:48:08,281 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:08,282 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43149543589538314
2024-04-24 14:48:08,496 - MainProcess - INFO - text_logger.py - 51 - Train epoch #90
2024-04-24 14:48:08,499 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.6964e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0844e-01, 0.0000e+00,
        6.3233e-02, 8.1384e-03, 4.1096e-01, 0.0000e+00, 1.7504e-03, 4.6571e-03,
        0.0000e+00, 0.0000e+00, 2.8962e-04, 1.8241e-03, 0.0000e+00, 0.0000e+00,
        1.1890e-04, 4.0713e-04, 0.0000e+00, 0.0000e+00, 3.5714e-05, 1.5037e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.2038e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.6004e-02, 0.0000e+00,
        1.1055e-01, 1.3674e-02, 4.8604e-02, 0.0000e+00, 7.8226e-03, 1.2268e-02,
        0.0000e+00, 0.0000e+00, 2.7441e-03, 8.1944e-03, 0.0000e+00, 0.0000e+00,
        1.5406e-03, 3.1336e-03, 0.0000e+00, 0.0000e+00, 7.9860e-04, 2.0723e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:48:08,521 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4310525365176248
2024-04-24 14:48:08,524 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.264820.08300
2024-04-24 14:48:09,063 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #91: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36363636363636365, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.35, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-04-24 14:48:09,064 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:09,065 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43146512646697066
2024-04-24 14:48:09,307 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #91: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2978723404255319, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.18, '(min, 1)': 0.42, '(rev, 1)': 0.07, '(rev, 2)': 0.05}}
2024-04-24 14:48:09,307 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:09,308 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43146512646697066
2024-04-24 14:48:09,465 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #91: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.01, '(min, 0)': 0.04, '(min, 1)': 0.5, '(rev, 1)': 0.07, '(rev, 2)': 0.03}}
2024-04-24 14:48:09,465 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:09,467 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43146512646697066
2024-04-24 14:48:09,577 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #91: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(rev, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5531914893617021, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.38, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:48:09,577 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:09,578 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43146512646697066
2024-04-24 14:48:09,838 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #91: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4318181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(min, 0)': 0.4, '(min, 1)': 0.22, '(rev, 1)': 0.06, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-04-24 14:48:09,838 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:09,839 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43146512646697066
2024-04-24 14:48:10,211 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #91: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.48, '(min, 1)': 0.13, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:48:10,211 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:10,212 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43146512646697066
2024-04-24 14:48:10,950 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #91: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.03, '(ado, 6)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.26, '(rev, 1)': 0.13, '(rev, 2)': 0.08}}
2024-04-24 14:48:10,951 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:10,951 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43146512646697066
2024-04-24 14:48:11,181 - MainProcess - INFO - text_logger.py - 51 - Train epoch #91
2024-04-24 14:48:11,184 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.0725e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0039e-01, 0.0000e+00,
        6.0106e-02, 8.6110e-03, 4.1489e-01, 0.0000e+00, 1.7821e-03, 7.6861e-03,
        0.0000e+00, 0.0000e+00, 5.3915e-04, 4.7007e-03, 0.0000e+00, 0.0000e+00,
        2.8594e-04, 6.1234e-04, 0.0000e+00, 0.0000e+00, 1.1250e-04, 6.6667e-05,
        0.0000e+00, 0.0000e+00, 1.5505e-04, 3.3333e-05, 0.0000e+00, 0.0000e+00,
        3.1250e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5489e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8002e-02, 0.0000e+00,
        8.4864e-02, 1.5191e-02, 4.3121e-02, 0.0000e+00, 7.5230e-03, 2.2263e-02,
        0.0000e+00, 0.0000e+00, 3.9116e-03, 1.6298e-02, 0.0000e+00, 0.0000e+00,
        2.6844e-03, 3.6206e-03, 0.0000e+00, 0.0000e+00, 1.7880e-03, 1.0530e-03,
        0.0000e+00, 0.0000e+00, 2.0230e-03, 7.4536e-04, 0.0000e+00, 0.0000e+00,
        6.9877e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:48:11,199 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43083999282174795
2024-04-24 14:48:11,205 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.364850.06697
2024-04-24 14:48:11,331 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #92: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2765957446808511, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(min, 0)': 0.07, '(min, 1)': 0.5, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:48:11,331 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:11,332 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310525365176248
2024-04-24 14:48:11,869 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #92: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5813953488372093, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(min, 0)': 0.45, '(min, 1)': 0.16, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-04-24 14:48:11,869 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:11,870 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310525365176248
2024-04-24 14:48:12,156 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #92: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7674418604651163, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(min, 0)': 0.09, '(min, 1)': 0.49, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-04-24 14:48:12,156 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:12,157 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310525365176248
2024-04-24 14:48:12,167 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #92: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3877551020408163, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.07, '(min, 1)': 0.49, '(rev, 1)': 0.06, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-04-24 14:48:12,167 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:12,169 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310525365176248
2024-04-24 14:48:12,342 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #92: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(min, 0)': 0.01, '(min, 1)': 0.58, '(rev, 1)': 0.16}}
2024-04-24 14:48:12,343 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:12,343 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310525365176248
2024-04-24 14:48:12,834 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #92: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4878048780487805, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.04, '(ado, 8)': 0.01, '(min, 0)': 0.15, '(min, 1)': 0.49, '(rev, 1)': 0.14, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:48:12,834 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:12,835 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310525365176248
2024-04-24 14:48:14,300 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #92: {'transition': '(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 2, 5, 1, 1),(min, 0)->(exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 3, 5, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.3902439024390244, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.24, '(min, 1)': 0.36, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:48:14,301 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:14,301 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310525365176248
2024-04-24 14:48:14,525 - MainProcess - INFO - text_logger.py - 51 - Train epoch #92
2024-04-24 14:48:14,528 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.5768e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9458e-01, 0.0000e+00,
        6.6621e-02, 8.1883e-03, 4.1780e-01, 0.0000e+00, 1.7978e-03, 6.9124e-03,
        0.0000e+00, 0.0000e+00, 3.5618e-04, 2.9933e-03, 0.0000e+00, 0.0000e+00,
        1.4390e-04, 3.1235e-04, 0.0000e+00, 0.0000e+00, 7.3698e-05, 1.2040e-04,
        0.0000e+00, 0.0000e+00, 3.9216e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8966e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.1442e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9025e-02, 0.0000e+00,
        9.3173e-02, 1.5084e-02, 4.2557e-02, 0.0000e+00, 6.7184e-03, 1.8222e-02,
        0.0000e+00, 0.0000e+00, 2.6924e-03, 1.1229e-02, 0.0000e+00, 0.0000e+00,
        1.6063e-03, 2.6441e-03, 0.0000e+00, 0.0000e+00, 1.1665e-03, 1.9741e-03,
        0.0000e+00, 0.0000e+00, 8.7689e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5421e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:48:14,551 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.430562109450349
2024-04-24 14:48:14,558 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.332180.05558
2024-04-24 14:48:14,605 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #93: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 6, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5238095238095238, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(min, 0)': 0.36, '(min, 1)': 0.22, '(rev, 1)': 0.11, '(rev, 2)': 0.04}}
(rev, 3)': 0.02}}
2024-04-24 14:48:14,605 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:14,605 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:14,606 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43083999282174795
2024-04-24 14:48:14,606 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43083999282174795
2024-04-24 14:48:14,743 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #93: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(min, 0)': 0.41, '(min, 1)': 0.19, '(rev, 1)': 0.15, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:48:14,743 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:14,744 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43083999282174795
2024-04-24 14:48:15,176 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #93: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(min, 0)': 0.11, '(min, 1)': 0.47, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-04-24 14:48:15,177 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:15,178 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43083999282174795
2024-04-24 14:48:15,467 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #93: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4791666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.4, '(min, 1)': 0.2, '(rev, 1)': 0.05, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-04-24 14:48:15,468 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:15,468 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43083999282174795
2024-04-24 14:48:15,945 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #93: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5714285714285714, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.04, '(min, 0)': 0.1, '(min, 1)': 0.51, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-04-24 14:48:15,945 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:15,946 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43083999282174795
2024-04-24 14:48:17,538 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #93: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6170212765957447, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.09, '(min, 1)': 0.48, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-24 14:48:17,538 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:17,538 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43083999282174795
2024-04-24 14:48:17,769 - MainProcess - INFO - text_logger.py - 51 - Train epoch #93
2024-04-24 14:48:17,773 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.6723e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0143e-01, 0.0000e+00,
        6.3560e-02, 8.8409e-03, 4.1081e-01, 0.0000e+00, 2.7047e-03, 6.6874e-03,
        0.0000e+00, 0.0000e+00, 5.3325e-04, 4.6408e-03, 0.0000e+00, 0.0000e+00,
        1.1152e-04, 5.8987e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.4295e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.9167e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5516e-02, 0.0000e+00,
        8.2949e-02, 1.5640e-02, 3.7776e-02, 0.0000e+00, 8.3454e-03, 1.7394e-02,
        0.0000e+00, 0.0000e+00, 3.6486e-03, 1.3876e-02, 0.0000e+00, 0.0000e+00,
        1.4519e-03, 3.3950e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3321e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:48:17,793 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43074368475603797
2024-04-24 14:48:17,796 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.561900.03810
2024-04-24 14:48:17,800 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #94: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.2, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.03}}
2024-04-24 14:48:17,800 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:17,801 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430562109450349
2024-04-24 14:48:17,816 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #94: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 6, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 7, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34146341463414637, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.04, '(min, 0)': 0.09, '(min, 1)': 0.53, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 5)': 0.01}}
2024-04-24 14:48:17,817 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:17,818 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430562109450349
2024-04-24 14:48:17,831 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #94: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.425531914893617, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(min, 0)': 0.02, '(min, 1)': 0.57, '(rev, 1)': 0.05, '(rev, 2)': 0.08, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:48:17,831 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:17,831 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #94: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(min, 0)': 0.32, '(min, 1)': 0.27, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:48:17,831 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:17,832 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430562109450349
2024-04-24 14:48:17,832 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430562109450349
2024-04-24 14:48:17,846 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #94: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3170731707317073, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.27, '(min, 1)': 0.31, '(rev, 1)': 0.08, '(rev, 2)': 0.06}}
2024-04-24 14:48:17,846 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:17,847 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430562109450349
2024-04-24 14:48:18,447 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #94: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(min, 0)': 0.2, '(min, 1)': 0.41, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-04-24 14:48:18,447 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:18,447 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430562109450349
2024-04-24 14:48:20,135 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #94: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.04, '(min, 0)': 0.18, '(min, 1)': 0.43, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:48:20,135 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:20,136 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430562109450349
2024-04-24 14:48:20,363 - MainProcess - INFO - text_logger.py - 51 - Train epoch #94
2024-04-24 14:48:20,367 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.1817e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9437e-01, 0.0000e+00,
        5.9901e-02, 8.7470e-03, 4.2445e-01, 0.0000e+00, 1.5826e-03, 5.9650e-03,
        0.0000e+00, 0.0000e+00, 8.1818e-05, 4.1409e-03, 0.0000e+00, 0.0000e+00,
        4.5455e-05, 5.4718e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6893e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.1254e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2248e-02, 0.0000e+00,
        7.8079e-02, 1.4720e-02, 3.5672e-02, 0.0000e+00, 6.3680e-03, 1.6340e-02,
        0.0000e+00, 0.0000e+00, 1.3003e-03, 1.4161e-02, 0.0000e+00, 0.0000e+00,
        1.0164e-03, 3.2458e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9112e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:48:20,392 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4305869824528111
2024-04-24 14:48:20,396 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.392770.03277
2024-04-24 14:48:20,408 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #95: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.03, '(min, 0)': 0.52, '(min, 1)': 0.05, '(rev, 1)': 0.09, '(rev, 2)': 0.04}}
2024-04-24 14:48:20,408 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:20,409 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43074368475603797
2024-04-24 14:48:20,423 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #95: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5434782608695652, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.42, '(min, 1)': 0.21, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:48:20,423 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:20,425 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43074368475603797
2024-04-24 14:48:20,591 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #95: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5714285714285714, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.03, '(min, 0)': 0.28, '(min, 1)': 0.33, '(rev, 1)': 0.11, '(rev, 2)': 0.09, '(rev, 3)': 0.01}}
2024-04-24 14:48:20,591 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:20,591 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43074368475603797
2024-04-24 14:48:20,824 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #95: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5208333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.01, '(min, 0)': 0.06, '(min, 1)': 0.5, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:48:20,824 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:20,826 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43074368475603797
2024-04-24 14:48:21,119 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #95: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.05, '(min, 0)': 0.29, '(min, 1)': 0.29, '(rev, 1)': 0.09, '(rev, 2)': 0.05}}
2024-04-24 14:48:21,119 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:21,120 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43074368475603797
2024-04-24 14:48:21,483 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #95: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.625, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(min, 0)': 0.51, '(min, 1)': 0.12, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:48:21,484 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:21,485 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43074368475603797
2024-04-24 14:48:23,047 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #95: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.45454545454545453, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.44, '(min, 1)': 0.2, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-04-24 14:48:23,048 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:23,049 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43074368475603797
2024-04-24 14:48:23,300 - MainProcess - INFO - text_logger.py - 51 - Train epoch #95
2024-04-24 14:48:23,303 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.5919e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0186e-01, 0.0000e+00,
        6.3695e-02, 8.4106e-03, 4.0969e-01, 0.0000e+00, 2.0493e-03, 7.8925e-03,
        0.0000e+00, 0.0000e+00, 3.6669e-04, 5.0016e-03, 0.0000e+00, 0.0000e+00,
        7.4825e-05, 7.4335e-04, 0.0000e+00, 0.0000e+00, 7.7180e-05, 9.4275e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.6983e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5933e-02, 0.0000e+00,
        8.2359e-02, 1.4596e-02, 4.0631e-02, 0.0000e+00, 7.5740e-03, 2.0770e-02,
        0.0000e+00, 0.0000e+00, 2.9551e-03, 1.6222e-02, 0.0000e+00, 0.0000e+00,
        1.1824e-03, 3.8177e-03, 0.0000e+00, 0.0000e+00, 1.2211e-03, 1.2389e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1180e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:48:23,320 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43070905982889335
2024-04-24 14:48:23,323 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.532160.01132
2024-04-24 14:48:23,421 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #96: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(min, 0)': 0.16, '(min, 1)': 0.44, '(rev, 1)': 0.04, '(rev, 2)': 0.07}}
2024-04-24 14:48:23,422 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:23,424 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4305869824528111
2024-04-24 14:48:23,629 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #96: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(min, 0)': 0.22, '(min, 1)': 0.38, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:48:23,630 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:23,632 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4305869824528111
2024-04-24 14:48:24,258 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #96: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.16, '(rev, 1)': 0.09, '(rev, 2)': 0.05}}
2024-04-24 14:48:24,259 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:24,260 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4305869824528111
2024-04-24 14:48:24,517 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #96: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 2, 0, 1),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 1, 0, 1)', 'reward_ratio': '0/1', 'revenue': 0.45652173913043476, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.37, '(rev, 1)': 0.08, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-04-24 14:48:24,519 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:24,520 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4305869824528111
2024-04-24 14:48:24,657 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #96: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7045454545454546, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.35, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 4)': 0.02, '(rev, 5)': 0.02, '(rev, 6)': 0.01}}
2024-04-24 14:48:24,657 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:24,659 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4305869824528111
2024-04-24 14:48:24,752 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #96: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36363636363636365, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(min, 0)': 0.15, '(min, 1)': 0.43, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-04-24 14:48:24,753 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:24,754 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4305869824528111
2024-04-24 14:48:27,667 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #96: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 5)': 0.01, '(min, 0)': 0.05, '(min, 1)': 0.53, '(rev, 1)': 0.07, '(rev, 2)': 0.08}}
2024-04-24 14:48:27,667 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:27,668 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4305869824528111
2024-04-24 14:48:27,940 - MainProcess - INFO - text_logger.py - 51 - Train epoch #96
2024-04-24 14:48:27,944 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.0160e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9249e-01, 0.0000e+00,
        6.0461e-02, 8.9166e-03, 4.2458e-01, 0.0000e+00, 1.8896e-03, 6.4583e-03,
        0.0000e+00, 0.0000e+00, 5.1617e-04, 3.8123e-03, 0.0000e+00, 0.0000e+00,
        1.8052e-04, 6.1557e-04, 0.0000e+00, 0.0000e+00, 3.3333e-05, 4.0816e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.3754e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.0846e-02, 0.0000e+00,
        7.3715e-02, 1.5184e-02, 3.4627e-02, 0.0000e+00, 6.7748e-03, 1.7052e-02,
        0.0000e+00, 0.0000e+00, 3.2729e-03, 1.5187e-02, 0.0000e+00, 0.0000e+00,
        1.8467e-03, 3.4568e-03, 0.0000e+00, 0.0000e+00, 7.4536e-04, 9.1268e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:48:27,962 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43079745802183994
2024-04-24 14:48:27,965 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.515320.18923
2024-04-24 14:48:27,974 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #97: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.05, '(min, 0)': 0.33, '(min, 1)': 0.26, '(rev, 1)': 0.1, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-04-24 14:48:27,974 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:27,975 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43070905982889335
2024-04-24 14:48:28,006 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #97: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.574468085106383, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(min, 0)': 0.24, '(min, 1)': 0.39, '(rev, 1)': 0.09, '(rev, 2)': 0.09, '(rev, 5)': 0.01}}
2024-04-24 14:48:28,006 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:28,008 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43070905982889335
2024-04-24 14:48:28,021 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #97: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.21739130434782608, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.03, '(min, 0)': 0.07, '(min, 1)': 0.49, '(rev, 1)': 0.07, '(rev, 2)': 0.04}}
2024-04-24 14:48:28,022 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:28,022 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43070905982889335
2024-04-24 14:48:28,149 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #97: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43478260869565216, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.12, '(rev, 1)': 0.06, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-04-24 14:48:28,149 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:28,150 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43070905982889335
2024-04-24 14:48:28,160 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #97: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.06, '(ado, 5)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.4, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:48:28,161 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:28,162 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43070905982889335
2024-04-24 14:48:28,725 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #97: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2608695652173913, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.05, '(ado, 4)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.47, '(rev, 1)': 0.11, '(rev, 2)': 0.03}}
2024-04-24 14:48:28,726 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:28,726 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43070905982889335
2024-04-24 14:48:30,250 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #97: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3617021276595745, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.43, '(min, 1)': 0.13, '(rev, 1)': 0.06, '(rev, 2)': 0.08}}
2024-04-24 14:48:30,250 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:30,251 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43070905982889335
2024-04-24 14:48:30,468 - MainProcess - INFO - text_logger.py - 51 - Train epoch #97
2024-04-24 14:48:30,471 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0876e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0504e-01, 0.0000e+00,
        6.3253e-02, 7.7833e-03, 4.1441e-01, 0.0000e+00, 1.8754e-03, 4.5245e-03,
        0.0000e+00, 0.0000e+00, 3.0268e-04, 2.2725e-03, 0.0000e+00, 0.0000e+00,
        1.6291e-04, 3.1113e-04, 0.0000e+00, 0.0000e+00, 6.3556e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.0280e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2007e-02, 0.0000e+00,
        7.9299e-02, 1.3833e-02, 3.4861e-02, 0.0000e+00, 6.8935e-03, 1.3404e-02,
        0.0000e+00, 0.0000e+00, 2.2435e-03, 9.8919e-03, 0.0000e+00, 0.0000e+00,
        1.6282e-03, 2.3361e-03, 0.0000e+00, 0.0000e+00, 1.0044e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:48:30,487 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43080746966660355
2024-04-24 14:48:30,490 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.476120.09835
2024-04-24 14:48:30,812 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #98: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5227272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.03, '(min, 0)': 0.09, '(min, 1)': 0.47, '(rev, 1)': 0.12, '(rev, 2)': 0.04}}
2024-04-24 14:48:30,812 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:30,813 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43079745802183994
2024-04-24 14:48:30,987 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #98: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(min, 0)': 0.45, '(min, 1)': 0.12, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-04-24 14:48:30,987 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:30,988 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43079745802183994
2024-04-24 14:48:31,008 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #98: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.17, '(rev, 1)': 0.13, '(rev, 2)': 0.03, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:48:31,008 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:31,009 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43079745802183994
2024-04-24 14:48:31,042 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #98: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(min, 0)': 0.1, '(min, 1)': 0.46, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:48:31,042 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:31,043 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43079745802183994
2024-04-24 14:48:31,142 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #98: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.2978723404255319, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.03, '(min, 0)': 0.06, '(min, 1)': 0.52, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-04-24 14:48:31,142 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:31,143 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43079745802183994
2024-04-24 14:48:31,709 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #98: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.2391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.38, '(min, 1)': 0.23, '(rev, 1)': 0.05, '(rev, 2)': 0.04}}
2024-04-24 14:48:31,709 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:31,710 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43079745802183994
2024-04-24 14:48:32,439 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #98: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5434782608695652, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.2, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:48:32,439 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:32,440 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43079745802183994
2024-04-24 14:48:32,631 - MainProcess - INFO - text_logger.py - 51 - Train epoch #98
2024-04-24 14:48:32,634 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.5779e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9091e-01, 0.0000e+00,
        6.6051e-02, 7.1962e-03, 4.2462e-01, 0.0000e+00, 2.6606e-03, 4.1746e-03,
        0.0000e+00, 0.0000e+00, 8.5929e-04, 2.3848e-03, 0.0000e+00, 0.0000e+00,
        3.0171e-04, 5.2633e-04, 0.0000e+00, 0.0000e+00, 1.5245e-04, 4.0000e-05,
        0.0000e+00, 0.0000e+00, 4.0000e-05, 4.0000e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.0000e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5492e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.1707e-02, 0.0000e+00,
        9.8163e-02, 1.3816e-02, 4.2846e-02, 0.0000e+00, 8.3118e-03, 1.3267e-02,
        0.0000e+00, 0.0000e+00, 4.4897e-03, 1.1953e-02, 0.0000e+00, 0.0000e+00,
        2.3780e-03, 3.4637e-03, 0.0000e+00, 0.0000e+00, 1.7036e-03, 8.9443e-04,
        0.0000e+00, 0.0000e+00, 8.9443e-04, 8.9443e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.9443e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:48:32,648 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4304075522333529
2024-04-24 14:48:32,650 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.271160.02671
2024-04-24 14:48:32,662 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #99: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(min, 0)': 0.2, '(min, 1)': 0.4, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:48:32,663 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #99: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.375, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(min, 0)': 0.35, '(min, 1)': 0.25, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 8)': 0.01}}
2024-04-24 14:48:32,663 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:32,663 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:32,665 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43080746966660355
2024-04-24 14:48:32,665 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43080746966660355
2024-04-24 14:48:32,692 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #99: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6976744186046512, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.4, '(min, 1)': 0.16, '(rev, 1)': 0.14, '(rev, 2)': 0.07}}
2024-04-24 14:48:32,692 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:32,693 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43080746966660355
2024-04-24 14:48:32,836 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #99: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5319148936170213, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.16, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:48:32,836 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:32,837 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43080746966660355
2024-04-24 14:48:32,893 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #99: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(min, 0)': 0.47, '(min, 1)': 0.14, '(rev, 1)': 0.06, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:48:32,893 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:32,894 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43080746966660355
2024-04-24 14:48:33,964 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #99: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(min, 0)': 0.21, '(min, 1)': 0.39, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-04-24 14:48:33,965 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:33,965 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43080746966660355
2024-04-24 14:48:34,168 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #99: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.54, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.16, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:48:34,168 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:34,168 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43080746966660355
2024-04-24 14:48:34,350 - MainProcess - INFO - text_logger.py - 51 - Train epoch #99
2024-04-24 14:48:34,353 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.7860e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0114e-01, 0.0000e+00,
        6.3560e-02, 8.5994e-03, 4.1652e-01, 0.0000e+00, 2.5673e-03, 4.2637e-03,
        0.0000e+00, 0.0000e+00, 6.5466e-04, 2.0050e-03, 0.0000e+00, 0.0000e+00,
        1.3660e-04, 4.2839e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8780e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.4173e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7555e-02, 0.0000e+00,
        8.7327e-02, 1.4637e-02, 3.9026e-02, 0.0000e+00, 8.8428e-03, 1.3143e-02,
        0.0000e+00, 0.0000e+00, 4.2545e-03, 1.1356e-02, 0.0000e+00, 0.0000e+00,
        1.8205e-03, 3.2656e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4092e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.9443e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:48:34,377 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4307934272164457
2024-04-24 14:48:34,379 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.664050.03362
2024-04-24 14:48:34,405 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #100: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46511627906976744, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.03, '(min, 0)': 0.31, '(min, 1)': 0.29, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:48:34,405 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:34,407 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4304075522333529
2024-04-24 14:48:34,461 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #100: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.29545454545454547, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.03, '(min, 0)': 0.2, '(min, 1)': 0.36, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:48:34,461 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:34,462 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4304075522333529
2024-04-24 14:48:34,523 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #100: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 4, 0, 0),(rev, 4)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8157894736842105, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.46, '(rev, 1)': 0.1, '(rev, 2)': 0.08, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-04-24 14:48:34,523 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:34,524 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4304075522333529
2024-04-24 14:48:34,628 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #100: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 1),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 2, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.4772727272727273, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.21, '(rev, 1)': 0.08, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-04-24 14:48:34,628 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:34,629 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4304075522333529
2024-04-24 14:48:34,640 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #100: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5813953488372093, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.14, '(min, 1)': 0.46, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-24 14:48:34,641 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:34,642 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4304075522333529
2024-04-24 14:48:35,426 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #100: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.30434782608695654, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.03, '(min, 0)': 0.38, '(min, 1)': 0.21, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:48:35,427 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:35,427 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4304075522333529
2024-04-24 14:48:35,653 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #100: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40476190476190477, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.03, '(min, 0)': 0.09, '(min, 1)': 0.49, '(rev, 1)': 0.13, '(rev, 2)': 0.07}}
2024-04-24 14:48:35,653 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:35,653 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4304075522333529
2024-04-24 14:48:47,629 - MainProcess - INFO - text_logger.py - 51 - Train epoch #100
2024-04-24 14:48:47,631 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.5678e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8586e-01, 0.0000e+00,
        6.6204e-02, 1.1069e-02, 4.2210e-01, 0.0000e+00, 1.2714e-03, 8.1227e-03,
        0.0000e+00, 0.0000e+00, 9.9444e-05, 4.2683e-03, 0.0000e+00, 0.0000e+00,
        4.2553e-05, 9.6318e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.2111e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7959e-02, 0.0000e+00,
        8.8380e-02, 1.7369e-02, 4.2458e-02, 0.0000e+00, 5.5941e-03, 1.9434e-02,
        0.0000e+00, 0.0000e+00, 1.3099e-03, 1.4948e-02, 0.0000e+00, 0.0000e+00,
        9.5152e-04, 4.6686e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:48:47,644 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43072804289261696
2024-04-24 14:48:47,665 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.438420.14297
2024-04-24 14:48:47,665 - MainProcess - INFO - text_logger.py - 51 - Simulated Policy Revenue 0.510540.01378
2024-04-24 14:48:47,676 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #101: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(min, 0)': 0.15, '(min, 1)': 0.46, '(rev, 1)': 0.09, '(rev, 2)': 0.09}}
2024-04-24 14:48:47,676 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #101: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.21428571428571427, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.04, '(min, 0)': 0.47, '(min, 1)': 0.12, '(rev, 1)': 0.11, '(rev, 2)': 0.01}}
2024-04-24 14:48:47,676 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:47,676 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:47,677 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307934272164457
2024-04-24 14:48:47,677 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307934272164457
2024-04-24 14:48:47,693 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #101: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2608695652173913, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(min, 0)': 0.26, '(min, 1)': 0.31, '(rev, 1)': 0.07, '(rev, 2)': 0.04}}
2024-04-24 14:48:47,693 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:47,694 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307934272164457
2024-04-24 14:48:47,700 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #101: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43478260869565216, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(min, 0)': 0.16, '(min, 1)': 0.45, '(rev, 1)': 0.06, '(rev, 2)': 0.09}}
2024-04-24 14:48:47,700 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:47,701 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307934272164457
2024-04-24 14:48:47,722 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #101: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.04, '(min, 0)': 0.33, '(min, 1)': 0.26, '(rev, 1)': 0.13, '(rev, 2)': 0.05}}
2024-04-24 14:48:47,722 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:47,722 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307934272164457
2024-04-24 14:48:48,165 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #101: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.41, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:48:48,165 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:48,166 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307934272164457
2024-04-24 14:48:49,374 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #101: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5681818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.39, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-04-24 14:48:49,374 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:49,375 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307934272164457
2024-04-24 14:48:49,543 - MainProcess - INFO - text_logger.py - 51 - Train epoch #101
2024-04-24 14:48:49,545 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.4487e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0329e-01, 0.0000e+00,
        5.9460e-02, 9.4990e-03, 4.2109e-01, 0.0000e+00, 1.1146e-03, 4.2442e-03,
        0.0000e+00, 0.0000e+00, 6.2049e-05, 1.1264e-03, 0.0000e+00, 0.0000e+00,
        3.0303e-05, 8.1769e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.2827e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3328e-02, 0.0000e+00,
        6.9985e-02, 1.5537e-02, 2.7685e-02, 0.0000e+00, 5.4402e-03, 1.1471e-02,
        0.0000e+00, 0.0000e+00, 9.8036e-04, 6.1997e-03, 0.0000e+00, 0.0000e+00,
        6.7760e-04, 1.2927e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:48:49,560 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43060009438878205
2024-04-24 14:48:49,562 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.407140.19286
2024-04-24 14:48:49,575 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #102: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.42, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(min, 0)': 0.14, '(min, 1)': 0.46, '(rev, 1)': 0.02, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:48:49,575 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:49,576 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43072804289261696
2024-04-24 14:48:49,591 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #102: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.03, '(min, 0)': 0.15, '(min, 1)': 0.51, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.02, '(rev, 6)': 0.01}}
2024-04-24 14:48:49,591 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:49,591 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #102: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 6, 3, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5476190476190477, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.22, '(rev, 1)': 0.05, '(rev, 2)': 0.1, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:48:49,592 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:49,592 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43072804289261696
2024-04-24 14:48:49,593 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43072804289261696
2024-04-24 14:48:49,608 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #102: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.5319148936170213, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(min, 0)': 0.14, '(min, 1)': 0.51, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:48:49,608 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:49,608 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43072804289261696
2024-04-24 14:48:49,623 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #102: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.4782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(min, 0)': 0.18, '(min, 1)': 0.45, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:48:49,623 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:49,624 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43072804289261696
2024-04-24 14:48:49,730 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #102: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.03, '(min, 0)': 0.17, '(min, 1)': 0.48, '(rev, 1)': 0.13, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 5)': 0.02}}
2024-04-24 14:48:49,730 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:49,731 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43072804289261696
2024-04-24 14:48:50,937 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #102: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.05, '(min, 1)': 0.56, '(rev, 1)': 0.06, '(rev, 2)': 0.05}}
2024-04-24 14:48:50,937 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:50,938 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43072804289261696
2024-04-24 14:48:51,116 - MainProcess - INFO - text_logger.py - 51 - Train epoch #102
2024-04-24 14:48:51,118 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0910e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7174e-01, 0.0000e+00,
        7.9574e-02, 1.0771e-02, 4.1241e-01, 0.0000e+00, 1.9110e-03, 1.1012e-02,
        0.0000e+00, 0.0000e+00, 5.3005e-04, 8.4145e-03, 0.0000e+00, 0.0000e+00,
        2.2731e-04, 2.2341e-03, 0.0000e+00, 0.0000e+00, 1.1955e-04, 4.3161e-04,
        0.0000e+00, 0.0000e+00, 8.8780e-05, 3.1437e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.4261e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9216e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9216e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.2101e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8925e-02, 0.0000e+00,
        1.2660e-01, 1.9420e-02, 6.0770e-02, 0.0000e+00, 6.6516e-03, 2.4749e-02,
        0.0000e+00, 0.0000e+00, 3.1561e-03, 2.1982e-02, 0.0000e+00, 0.0000e+00,
        2.1003e-03, 6.4646e-03, 0.0000e+00, 0.0000e+00, 1.5664e-03, 3.0506e-03,
        0.0000e+00, 0.0000e+00, 1.4092e-03, 2.8413e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.6008e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.7689e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.7689e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:48:51,130 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4307054792182805
2024-04-24 14:48:51,132 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.523810.02381
2024-04-24 14:48:51,148 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #103: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.1, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:48:51,148 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:51,149 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43060009438878205
2024-04-24 14:48:51,164 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #103: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2682926829268293, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.33, '(rev, 1)': 0.06, '(rev, 2)': 0.04}}
2024-04-24 14:48:51,165 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:51,165 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43060009438878205
2024-04-24 14:48:51,180 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #103: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.46808510638297873, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.4, '(min, 1)': 0.22, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:48:51,180 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:51,180 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43060009438878205
2024-04-24 14:48:51,197 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #103: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.02, '(min, 0)': 0.41, '(min, 1)': 0.16, '(rev, 1)': 0.06, '(rev, 2)': 0.04}}
2024-04-24 14:48:51,197 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:51,198 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43060009438878205
2024-04-24 14:48:51,284 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #103: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.2127659574468085, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.04, '(ado, 4)': 0.01, '(min, 0)': 0.09, '(min, 1)': 0.49, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:48:51,284 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:51,285 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43060009438878205
2024-04-24 14:48:51,307 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #103: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.13, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:48:51,309 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:51,310 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43060009438878205
2024-04-24 14:48:52,295 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #103: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46511627906976744, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(min, 0)': 0.44, '(min, 1)': 0.18, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 4)': 0.01}}
2024-04-24 14:48:52,295 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:52,296 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43060009438878205
2024-04-24 14:48:52,477 - MainProcess - INFO - text_logger.py - 51 - Train epoch #103
2024-04-24 14:48:52,479 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.2581e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9051e-01, 0.0000e+00,
        6.5810e-02, 9.8002e-03, 4.1600e-01, 0.0000e+00, 1.3076e-03, 8.9482e-03,
        0.0000e+00, 0.0000e+00, 2.9839e-04, 6.0915e-03, 0.0000e+00, 0.0000e+00,
        7.0523e-05, 7.5565e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3323e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1772e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.1279e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7700e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3719e-02, 0.0000e+00,
        1.0265e-01, 1.8208e-02, 5.0433e-02, 0.0000e+00, 6.3641e-03, 2.6817e-02,
        0.0000e+00, 0.0000e+00, 2.8328e-03, 2.2102e-02, 0.0000e+00, 0.0000e+00,
        1.1167e-03, 3.8731e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9744e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.7758e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.9319e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:48:52,495 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43047601095760674
2024-04-24 14:48:52,497 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.356380.14362
2024-04-24 14:48:52,662 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #104: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.39, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:48:52,662 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:52,663 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307054792182805
2024-04-24 14:48:52,663 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #104: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.5555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(min, 0)': 0.2, '(min, 1)': 0.41, '(rev, 1)': 0.1, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:48:52,663 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:52,664 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307054792182805
2024-04-24 14:48:52,678 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #104: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5454545454545454, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.29, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:48:52,678 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:52,679 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307054792182805
2024-04-24 14:48:52,834 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #104: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.22, '(rev, 1)': 0.04, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.02, '(rev, 7)': 0.01}}
2024-04-24 14:48:52,834 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:52,835 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307054792182805
2024-04-24 14:48:52,927 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #104: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5681818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(min, 0)': 0.55, '(min, 1)': 0.13, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.02, '(rev, 8)': 0.01}}
2024-04-24 14:48:52,928 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:52,928 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307054792182805
2024-04-24 14:48:52,934 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #104: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.28, '(rev, 1)': 0.09, '(rev, 2)': 0.04}}
2024-04-24 14:48:52,934 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:52,934 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307054792182805
2024-04-24 14:48:54,021 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #104: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.03, '(min, 0)': 0.07, '(min, 1)': 0.48, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:48:54,021 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:54,022 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307054792182805
2024-04-24 14:48:54,190 - MainProcess - INFO - text_logger.py - 51 - Train epoch #104
2024-04-24 14:48:54,193 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.9413e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6750e-01, 0.0000e+00,
        9.2718e-02, 9.7889e-03, 4.1399e-01, 0.0000e+00, 2.8414e-03, 5.5604e-03,
        0.0000e+00, 0.0000e+00, 7.4597e-04, 4.4166e-03, 0.0000e+00, 0.0000e+00,
        1.7597e-04, 1.3561e-03, 0.0000e+00, 0.0000e+00, 3.7736e-05, 5.1292e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4150e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.1636e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7795e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.1264e-02, 0.0000e+00,
        1.3778e-01, 1.6393e-02, 6.0578e-02, 0.0000e+00, 8.2993e-03, 1.4861e-02,
        0.0000e+00, 0.0000e+00, 4.0659e-03, 1.4063e-02, 0.0000e+00, 0.0000e+00,
        1.7631e-03, 5.3138e-03, 0.0000e+00, 0.0000e+00, 8.4380e-04, 3.2868e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3434e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.9635e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:48:54,205 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.430701958557668
2024-04-24 14:48:54,207 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.584090.01591
2024-04-24 14:48:54,237 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #105: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.05, '(min, 0)': 0.11, '(min, 1)': 0.45, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:48:54,237 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:54,237 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43047601095760674
2024-04-24 14:48:54,270 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #105: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(min, 0)': 0.11, '(min, 1)': 0.46, '(rev, 1)': 0.06, '(rev, 2)': 0.05}}
2024-04-24 14:48:54,270 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:54,271 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43047601095760674
2024-04-24 14:48:54,496 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #105: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2553191489361702, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.03, '(min, 0)': 0.16, '(min, 1)': 0.43, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:48:54,496 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:54,496 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43047601095760674
2024-04-24 14:48:54,631 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #105: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5106382978723404, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.02, '(min, 0)': 0.42, '(min, 1)': 0.14, '(rev, 1)': 0.08, '(rev, 2)': 0.05}}
2024-04-24 14:48:54,632 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:54,632 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43047601095760674
2024-04-24 14:48:54,638 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #105: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.43, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:48:54,638 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:54,639 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43047601095760674
2024-04-24 14:48:55,123 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #105: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5416666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.03, '(min, 0)': 0.13, '(min, 1)': 0.47, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:48:55,123 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:55,124 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43047601095760674
2024-04-24 14:48:55,266 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #105: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5116279069767442, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.03, '(min, 0)': 0.17, '(min, 1)': 0.43, '(rev, 1)': 0.13, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-04-24 14:48:55,266 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:55,267 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43047601095760674
2024-04-24 14:48:55,453 - MainProcess - INFO - text_logger.py - 51 - Train epoch #105
2024-04-24 14:48:55,455 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.0698e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8126e-01, 0.0000e+00,
        8.9148e-02, 6.6626e-03, 4.1261e-01, 0.0000e+00, 1.9094e-03, 4.0617e-03,
        0.0000e+00, 0.0000e+00, 3.3793e-04, 3.0045e-03, 0.0000e+00, 0.0000e+00,
        1.1555e-04, 6.1458e-04, 0.0000e+00, 0.0000e+00, 3.1250e-05, 1.0899e-04,
        0.0000e+00, 0.0000e+00, 3.1250e-05, 7.4074e-05, 0.0000e+00, 0.0000e+00,
        3.1250e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5702e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8771e-02, 0.0000e+00,
        1.3474e-01, 1.2903e-02, 5.9089e-02, 0.0000e+00, 7.2373e-03, 1.2478e-02,
        0.0000e+00, 0.0000e+00, 2.7197e-03, 1.2857e-02, 0.0000e+00, 0.0000e+00,
        1.5157e-03, 4.0291e-03, 0.0000e+00, 0.0000e+00, 6.9877e-04, 1.9014e-03,
        0.0000e+00, 0.0000e+00, 6.9877e-04, 1.6563e-03, 0.0000e+00, 0.0000e+00,
        6.9877e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:48:55,471 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4308120293040864
2024-04-24 14:48:55,473 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.526150.01551
2024-04-24 14:48:55,640 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #106: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5106382978723404, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(min, 0)': 0.24, '(min, 1)': 0.4, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:48:55,640 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:55,640 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430701958557668
2024-04-24 14:48:55,786 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #106: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.12, '(min, 1)': 0.44, '(rev, 1)': 0.1, '(rev, 2)': 0.06}}
2024-04-24 14:48:55,786 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:55,787 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430701958557668
2024-04-24 14:48:55,817 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #106: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.44680851063829785, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.03, '(min, 0)': 0.45, '(min, 1)': 0.17, '(rev, 1)': 0.05, '(rev, 2)': 0.08, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:48:55,817 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:55,817 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430701958557668
2024-04-24 14:48:56,206 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #106: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5106382978723404, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.47, '(min, 1)': 0.15, '(rev, 1)': 0.03, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:48:56,206 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:56,206 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430701958557668
2024-04-24 14:48:56,230 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #106: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 4, 0, 0),(rev, 4)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6585365853658537, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(min, 0)': 0.15, '(min, 1)': 0.49, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-04-24 14:48:56,230 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:56,230 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430701958557668
2024-04-24 14:48:56,319 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #106: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(min, 0)': 0.4, '(min, 1)': 0.15, '(rev, 1)': 0.1, '(rev, 2)': 0.09}}
2024-04-24 14:48:56,319 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:56,320 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430701958557668
2024-04-24 14:48:56,844 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #106: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40816326530612246, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.09, '(rev, 1)': 0.03, '(rev, 2)': 0.04, '(rev, 5)': 0.02, '(rev, 6)': 0.01}}
2024-04-24 14:48:56,845 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:56,845 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430701958557668
2024-04-24 14:48:57,012 - MainProcess - INFO - text_logger.py - 51 - Train epoch #106
2024-04-24 14:48:57,015 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.6386e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7312e-01, 0.0000e+00,
        7.8269e-02, 1.0164e-02, 4.1856e-01, 0.0000e+00, 1.5202e-03, 8.1485e-03,
        0.0000e+00, 0.0000e+00, 2.1296e-04, 7.5098e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.0355e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7339e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5236e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.3898e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.8088e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3245e-02, 0.0000e+00,
        1.1550e-01, 1.8409e-02, 5.4295e-02, 0.0000e+00, 6.0539e-03, 2.1500e-02,
        0.0000e+00, 0.0000e+00, 1.9531e-03, 2.5328e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 6.8848e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6241e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1213e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.5799e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:48:57,030 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4309505538935539
2024-04-24 14:48:57,032 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.540380.11816
2024-04-24 14:48:57,074 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #107: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.38636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.41, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.02}}
2024-04-24 14:48:57,074 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:57,075 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4308120293040864
2024-04-24 14:48:57,252 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #107: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5454545454545454, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.39, '(rev, 1)': 0.12, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-04-24 14:48:57,252 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:57,253 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4308120293040864
2024-04-24 14:48:57,358 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #107: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(min, 0)': 0.46, '(min, 1)': 0.11, '(rev, 1)': 0.07, '(rev, 2)': 0.04}}
2024-04-24 14:48:57,358 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:57,359 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4308120293040864
2024-04-24 14:48:57,691 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #107: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.04, '(min, 0)': 0.14, '(min, 1)': 0.43, '(rev, 1)': 0.1, '(rev, 2)': 0.01}}
2024-04-24 14:48:57,691 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:57,692 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4308120293040864
2024-04-24 14:48:57,824 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #107: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2608695652173913, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(min, 0)': 0.05, '(min, 1)': 0.52, '(rev, 1)': 0.08, '(rev, 2)': 0.03}}
2024-04-24 14:48:57,825 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:57,825 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4308120293040864
2024-04-24 14:48:57,861 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #107: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.2653061224489796, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.23, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:48:57,862 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:57,862 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4308120293040864
2024-04-24 14:48:58,012 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #107: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(min, 0)': 0.07, '(min, 1)': 0.5, '(rev, 1)': 0.11, '(rev, 2)': 0.08}}
2024-04-24 14:48:58,012 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:58,013 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4308120293040864
2024-04-24 14:48:58,199 - MainProcess - INFO - text_logger.py - 51 - Train epoch #107
2024-04-24 14:48:58,201 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.3753e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8447e-01, 0.0000e+00,
        7.7617e-02, 8.6471e-03, 4.1669e-01, 0.0000e+00, 1.4259e-03, 5.7020e-03,
        0.0000e+00, 0.0000e+00, 1.7798e-04, 3.4524e-03, 0.0000e+00, 0.0000e+00,
        6.3011e-05, 1.5223e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3601e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5381e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.5296e-02, 0.0000e+00,
        1.0439e-01, 1.5729e-02, 4.7855e-02, 0.0000e+00, 6.4296e-03, 1.6312e-02,
        0.0000e+00, 0.0000e+00, 1.8077e-03, 1.3189e-02, 0.0000e+00, 0.0000e+00,
        1.0106e-03, 6.3375e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3564e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:48:58,216 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43053449536309973
2024-04-24 14:48:58,218 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.263090.00222
2024-04-24 14:48:58,674 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #108: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 4)': 0.01, '(min, 0)': 0.07, '(min, 1)': 0.54, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 3)': 0.04}}
2024-04-24 14:48:58,674 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:58,675 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4309505538935539
2024-04-24 14:48:58,825 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #108: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5319148936170213, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.2, '(rev, 1)': 0.04, '(rev, 2)': 0.09, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:48:58,826 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:58,826 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4309505538935539
2024-04-24 14:48:58,838 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #108: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.29, '(rev, 1)': 0.11, '(rev, 2)': 0.04}}
2024-04-24 14:48:58,838 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:58,839 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4309505538935539
2024-04-24 14:48:59,091 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #108: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2558139534883721, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.4, '(rev, 1)': 0.08, '(rev, 2)': 0.05}}
2024-04-24 14:48:59,092 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:59,093 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4309505538935539
2024-04-24 14:48:59,261 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #108: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.03, '(min, 0)': 0.37, '(min, 1)': 0.24, '(rev, 1)': 0.1, '(rev, 2)': 0.09}}
2024-04-24 14:48:59,262 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:59,262 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4309505538935539
2024-04-24 14:48:59,313 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #108: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.05, '(ado, 3)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.39, '(rev, 1)': 0.13, '(rev, 2)': 0.02, '(rev, 3)': 0.03}}
2024-04-24 14:48:59,313 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:59,314 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4309505538935539
2024-04-24 14:48:59,742 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #108: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6976744186046512, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 4)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.53, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 6)': 0.01}}
2024-04-24 14:48:59,742 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:48:59,743 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4309505538935539
2024-04-24 14:48:59,806 - MainProcess - INFO - text_logger.py - 51 - Train epoch #108
2024-04-24 14:48:59,808 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.2190e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6320e-01, 0.0000e+00,
        1.0129e-01, 8.9943e-03, 4.1408e-01, 0.0000e+00, 3.1978e-03, 5.2325e-03,
        0.0000e+00, 0.0000e+00, 6.4351e-04, 2.3069e-03, 0.0000e+00, 0.0000e+00,
        2.5676e-04, 7.9182e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.1627, 0.0000, 0.0000, 0.0000, 0.0877, 0.0000, 0.1281, 0.0149, 0.0569,
        0.0000, 0.0101, 0.0124, 0.0000, 0.0000, 0.0038, 0.0094, 0.0000, 0.0000,
        0.0024, 0.0047, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-04-24 14:48:59,821 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4306232688969171
2024-04-24 14:48:59,823 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.515500.18217
2024-04-24 14:49:00,175 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #109: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.05, '(min, 0)': 0.03, '(min, 1)': 0.55, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-04-24 14:49:00,175 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:00,176 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43053449536309973
2024-04-24 14:49:00,180 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #109: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.44, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:49:00,180 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:00,181 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43053449536309973
2024-04-24 14:49:00,438 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #109: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5102040816326531, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.39, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:49:00,438 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:00,438 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43053449536309973
2024-04-24 14:49:00,459 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #109: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46511627906976744, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.22, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-04-24 14:49:00,460 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:00,460 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43053449536309973
2024-04-24 14:49:00,809 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #109: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5227272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.04, '(min, 0)': 0.3, '(min, 1)': 0.37, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 6)': 0.01}}
2024-04-24 14:49:00,809 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:00,810 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43053449536309973
2024-04-24 14:49:00,983 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #109: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.8636363636363636, 'length': 100, 'actions': {'(ado, 1)': 0.04, '(ado, 2)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.28, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.05, '(rev, 4)': 0.02, '(rev, 5)': 0.02, '(rev, 6)': 0.01}}
2024-04-24 14:49:00,983 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:00,984 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43053449536309973
2024-04-24 14:49:01,718 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #109: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 4, 0, 0),(rev, 4)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 1.0227272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(min, 0)': 0.16, '(min, 1)': 0.51, '(rev, 1)': 0.02, '(rev, 2)': 0.04, '(rev, 3)': 0.05, '(rev, 4)': 0.03}}
2024-04-24 14:49:01,718 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:01,718 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43053449536309973
2024-04-24 14:49:01,792 - MainProcess - INFO - text_logger.py - 51 - Train epoch #109
2024-04-24 14:49:01,794 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.8996e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7616e-01, 0.0000e+00,
        8.4954e-02, 8.5897e-03, 4.1566e-01, 0.0000e+00, 2.1111e-03, 5.0082e-03,
        0.0000e+00, 0.0000e+00, 3.8363e-04, 4.7280e-03, 0.0000e+00, 0.0000e+00,
        1.0414e-04, 1.5637e-03, 0.0000e+00, 0.0000e+00, 3.5714e-05, 4.2947e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0240e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.5088e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5088e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.6866e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.8675e-02, 0.0000e+00,
        1.0945e-01, 1.5310e-02, 4.8013e-02, 0.0000e+00, 7.3548e-03, 1.4411e-02,
        0.0000e+00, 0.0000e+00, 2.9033e-03, 1.8715e-02, 0.0000e+00, 0.0000e+00,
        1.3423e-03, 6.5659e-03, 0.0000e+00, 0.0000e+00, 7.9860e-04, 3.1925e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0638e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.8459e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.8459e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:01,806 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43156739831516017
2024-04-24 14:49:01,808 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.943180.07955
2024-04-24 14:49:01,823 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #110: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3191489361702128, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(ado, 4)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.44, '(rev, 1)': 0.08, '(rev, 2)': 0.06}}
2024-04-24 14:49:01,823 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:01,824 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4306232688969171
2024-04-24 14:49:01,855 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #110: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.3404255319148936, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.04, '(min, 0)': 0.07, '(min, 1)': 0.53, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:49:01,855 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:01,855 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4306232688969171
2024-04-24 14:49:01,871 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #110: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(min, 0)': 0.09, '(min, 1)': 0.5, '(rev, 1)': 0.09, '(rev, 2)': 0.07}}
2024-04-24 14:49:01,871 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:01,872 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4306232688969171
2024-04-24 14:49:01,965 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #110: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(min, 0)': 0.36, '(min, 1)': 0.24, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:49:01,965 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:01,966 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4306232688969171
2024-04-24 14:49:02,284 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #110: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(min, 0)': 0.48, '(min, 1)': 0.11, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:49:02,284 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:02,285 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4306232688969171
2024-04-24 14:49:02,392 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #110: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5434782608695652, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.03, '(ado, 5)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.26, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:49:02,393 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:02,393 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4306232688969171
2024-04-24 14:49:02,873 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #110: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.01, '(min, 0)': 0.12, '(min, 1)': 0.43, '(rev, 1)': 0.09, '(rev, 2)': 0.04}}
2024-04-24 14:49:02,873 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:02,873 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4306232688969171
2024-04-24 14:49:02,935 - MainProcess - INFO - text_logger.py - 51 - Train epoch #110
2024-04-24 14:49:02,937 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.9206e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7461e-01, 0.0000e+00,
        8.3869e-02, 7.6625e-03, 4.2210e-01, 0.0000e+00, 2.1012e-03, 4.6793e-03,
        0.0000e+00, 0.0000e+00, 2.9152e-04, 3.1737e-03, 0.0000e+00, 0.0000e+00,
        1.4892e-04, 1.1095e-03, 0.0000e+00, 0.0000e+00, 6.6667e-05, 4.2553e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.0000e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 6.6667e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.3367e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3141e-02, 0.0000e+00,
        1.2033e-01, 1.4275e-02, 5.4973e-02, 0.0000e+00, 8.3057e-03, 1.3935e-02,
        0.0000e+00, 0.0000e+00, 2.7274e-03, 1.5429e-02, 0.0000e+00, 0.0000e+00,
        1.9946e-03, 6.1861e-03, 0.0000e+00, 0.0000e+00, 1.4907e-03, 9.5152e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7889e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.4907e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:02,950 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.431208497430373
2024-04-24 14:49:02,952 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.291670.04167
2024-04-24 14:49:03,048 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #111: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.18604651162790697, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.05, '(min, 1)': 0.48, '(rev, 1)': 0.1, '(rev, 2)': 0.02}}
2024-04-24 14:49:03,048 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:03,048 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43156739831516017
2024-04-24 14:49:03,226 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #111: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(min, 0)': 0.26, '(min, 1)': 0.34, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:49:03,227 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:03,227 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43156739831516017
2024-04-24 14:49:03,609 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #111: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.03, '(min, 0)': 0.13, '(min, 1)': 0.47, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-04-24 14:49:03,610 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:03,610 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43156739831516017
2024-04-24 14:49:03,660 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #111: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.44680851063829785, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.2, '(rev, 1)': 0.05, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:49:03,660 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:03,661 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43156739831516017
2024-04-24 14:49:03,670 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #111: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5581395348837209, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.28, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:49:03,670 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:03,671 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43156739831516017
2024-04-24 14:49:04,344 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #111: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.12195121951219512, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.39, '(rev, 1)': 0.07, '(rev, 2)': 0.03}}
2024-04-24 14:49:04,345 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:04,345 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43156739831516017
2024-04-24 14:49:04,816 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #111: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8888888888888888, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.09, '(min, 1)': 0.52, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:49:04,816 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:04,816 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43156739831516017
2024-04-24 14:49:04,891 - MainProcess - INFO - text_logger.py - 51 - Train epoch #111
2024-04-24 14:49:04,893 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.6441e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6949e-01, 0.0000e+00,
        9.6141e-02, 7.7318e-03, 4.1166e-01, 0.0000e+00, 2.9757e-03, 4.6224e-03,
        0.0000e+00, 0.0000e+00, 8.5359e-04, 3.6908e-03, 0.0000e+00, 0.0000e+00,
        4.5156e-04, 1.8996e-03, 0.0000e+00, 0.0000e+00, 1.4879e-04, 1.1855e-04,
        0.0000e+00, 0.0000e+00, 4.0000e-05, 1.7814e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7086e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8831e-02, 0.0000e+00,
        1.3395e-01, 1.4725e-02, 6.0532e-02, 0.0000e+00, 8.9126e-03, 1.3082e-02,
        0.0000e+00, 0.0000e+00, 4.1664e-03, 1.2846e-02, 0.0000e+00, 0.0000e+00,
        2.9334e-03, 7.0187e-03, 0.0000e+00, 0.0000e+00, 1.6621e-03, 1.3518e-03,
        0.0000e+00, 0.0000e+00, 8.9443e-04, 2.1926e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:04,905 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.431713291636025
2024-04-24 14:49:04,906 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.723510.16537
2024-04-24 14:49:04,922 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #112: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36585365853658536, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(min, 0)': 0.19, '(min, 1)': 0.41, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-04-24 14:49:04,922 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:04,922 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431208497430373
2024-04-24 14:49:04,938 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #112: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.03, '(min, 0)': 0.22, '(min, 1)': 0.43, '(rev, 1)': 0.08, '(rev, 2)': 0.07, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:49:04,939 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:04,941 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431208497430373
2024-04-24 14:49:04,969 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #112: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2553191489361702, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.09, '(min, 1)': 0.47, '(rev, 1)': 0.09, '(rev, 2)': 0.04}}
2024-04-24 14:49:04,970 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:04,970 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431208497430373
2024-04-24 14:49:05,165 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #112: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 6, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(min, 0)': 0.12, '(min, 1)': 0.45, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:49:05,165 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:05,165 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431208497430373
2024-04-24 14:49:05,654 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #112: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 3, 1, 1),(min, 0)->(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 2, 3, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.8863636363636364, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.46, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-04-24 14:49:05,654 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:05,654 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431208497430373
2024-04-24 14:49:05,746 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #112: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.05, '(min, 0)': 0.23, '(min, 1)': 0.35, '(rev, 1)': 0.12, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:49:05,746 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:05,746 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431208497430373
2024-04-24 14:49:06,474 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #112: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.25, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:49:06,475 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:06,475 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431208497430373
2024-04-24 14:49:06,546 - MainProcess - INFO - text_logger.py - 51 - Train epoch #112
2024-04-24 14:49:06,548 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.9370e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7206e-01, 0.0000e+00,
        8.3981e-02, 9.2545e-03, 4.1971e-01, 0.0000e+00, 1.9534e-03, 5.9882e-03,
        0.0000e+00, 0.0000e+00, 2.3396e-04, 4.6932e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.5094e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6163e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6164e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 9.7208e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7942e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7547e-02, 0.0000e+00,
        1.1177e-01, 1.5579e-02, 5.1256e-02, 0.0000e+00, 7.0917e-03, 1.3458e-02,
        0.0000e+00, 0.0000e+00, 2.2574e-03, 1.4353e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 6.2901e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7189e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6192e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.2551e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:06,561 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43137105741790444
2024-04-24 14:49:06,563 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.300000.10000
2024-04-24 14:49:06,578 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #113: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.36, '(min, 1)': 0.22, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-04-24 14:49:06,578 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:06,578 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431713291636025
2024-04-24 14:49:06,593 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #113: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.375, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.05, '(min, 0)': 0.21, '(min, 1)': 0.39, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 4)': 0.01}}
2024-04-24 14:49:06,593 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:06,593 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431713291636025
2024-04-24 14:49:06,608 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #113: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3125, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.02, '(min, 0)': 0.06, '(min, 1)': 0.49, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:49:06,609 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:06,610 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431713291636025
2024-04-24 14:49:06,733 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #113: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6363636363636364, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.04, '(min, 0)': 0.16, '(min, 1)': 0.48, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:49:06,733 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:06,733 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431713291636025
2024-04-24 14:49:07,226 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #113: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(min, 0)': 0.16, '(min, 1)': 0.45, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:49:07,226 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:07,227 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431713291636025
2024-04-24 14:49:07,356 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #113: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.29545454545454547, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.05, '(ado, 3)': 0.01, '(min, 0)': 0.02, '(min, 1)': 0.59, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:49:07,356 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:07,357 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431713291636025
2024-04-24 14:49:08,140 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #113: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 3)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.46, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:49:08,141 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:08,141 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431713291636025
2024-04-24 14:49:08,203 - MainProcess - INFO - text_logger.py - 51 - Train epoch #113
2024-04-24 14:49:08,205 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.9488e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6090e-01, 0.0000e+00,
        1.0770e-01, 8.4631e-03, 4.0620e-01, 0.0000e+00, 3.4466e-03, 4.9098e-03,
        0.0000e+00, 0.0000e+00, 9.0763e-04, 4.5316e-03, 0.0000e+00, 0.0000e+00,
        1.7508e-04, 1.8956e-03, 0.0000e+00, 0.0000e+00, 4.0000e-05, 4.1236e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4010e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.0096e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.4074e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.9053e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.7467e-02, 0.0000e+00,
        1.4901e-01, 1.4598e-02, 6.8635e-02, 0.0000e+00, 1.0797e-02, 1.2241e-02,
        0.0000e+00, 0.0000e+00, 4.7219e-03, 1.4429e-02, 0.0000e+00, 0.0000e+00,
        1.9716e-03, 7.2892e-03, 0.0000e+00, 0.0000e+00, 8.9443e-04, 2.8630e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3338e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.6395e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6563e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:08,220 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4311504141088748
2024-04-24 14:49:08,222 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.360800.04830
2024-04-24 14:49:08,235 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #114: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(min, 0)': 0.4, '(min, 1)': 0.14, '(rev, 1)': 0.1, '(rev, 2)': 0.07}}
2024-04-24 14:49:08,235 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:08,235 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #114: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(min, 0)': 0.16, '(min, 1)': 0.42, '(rev, 1)': 0.1, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-04-24 14:49:08,235 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:08,235 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43137105741790444
2024-04-24 14:49:08,236 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43137105741790444
2024-04-24 14:49:08,250 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #114: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43902439024390244, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.37, '(rev, 1)': 0.11, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:49:08,250 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:08,250 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43137105741790444
2024-04-24 14:49:08,282 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #114: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.5869565217391305, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(min, 0)': 0.45, '(min, 1)': 0.11, '(rev, 1)': 0.09, '(rev, 2)': 0.06}}
2024-04-24 14:49:08,282 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:08,283 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43137105741790444
2024-04-24 14:49:08,555 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #114: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4883720930232558, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(min, 0)': 0.31, '(min, 1)': 0.27, '(rev, 1)': 0.12, '(rev, 2)': 0.05, '(rev, 3)': 0.03}}
2024-04-24 14:49:08,556 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:08,556 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43137105741790444
2024-04-24 14:49:08,751 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #114: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7446808510638298, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.07, '(min, 1)': 0.54, '(rev, 1)': 0.08, '(rev, 2)': 0.08, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:49:08,751 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:08,752 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43137105741790444
2024-04-24 14:49:09,613 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #114: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2708333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 3)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.14, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:49:09,613 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:09,613 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43137105741790444
2024-04-24 14:49:09,672 - MainProcess - INFO - text_logger.py - 51 - Train epoch #114
2024-04-24 14:49:09,675 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.1990e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6604e-01, 0.0000e+00,
        9.3853e-02, 8.4425e-03, 4.1979e-01, 0.0000e+00, 2.1390e-03, 5.1872e-03,
        0.0000e+00, 0.0000e+00, 3.5731e-04, 2.9384e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.2167e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5088e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.1677e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7614e-02, 0.0000e+00,
        1.1184e-01, 1.4520e-02, 4.9710e-02, 0.0000e+00, 7.9276e-03, 1.2337e-02,
        0.0000e+00, 0.0000e+00, 2.8817e-03, 1.0509e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 5.9446e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.8459e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:09,686 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4310659697458266
2024-04-24 14:49:09,691 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.428890.15806
2024-04-24 14:49:09,729 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #115: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4186046511627907, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.03, '(min, 0)': 0.21, '(min, 1)': 0.4, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-04-24 14:49:09,730 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:09,730 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4311504141088748
2024-04-24 14:49:09,734 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #115: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.04, '(min, 1)': 0.53, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-24 14:49:09,734 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:09,734 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4311504141088748
2024-04-24 14:49:09,749 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #115: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.03, '(min, 0)': 0.2, '(min, 1)': 0.36, '(rev, 1)': 0.08, '(rev, 2)': 0.05}}
2024-04-24 14:49:09,749 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:09,749 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #115: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3617021276595745, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.44, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:49:09,749 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:09,750 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4311504141088748
2024-04-24 14:49:09,750 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4311504141088748
2024-04-24 14:49:09,906 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #115: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.04, '(min, 0)': 0.01, '(min, 1)': 0.55, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:49:09,906 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:09,907 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4311504141088748
2024-04-24 14:49:10,316 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #115: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34146341463414637, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.05, '(ado, 4)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.35, '(rev, 1)': 0.13, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-04-24 14:49:10,316 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:10,316 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4311504141088748
2024-04-24 14:49:11,227 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #115: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6739130434782609, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.03, '(min, 0)': 0.42, '(min, 1)': 0.15, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:49:11,227 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:11,227 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4311504141088748
2024-04-24 14:49:11,297 - MainProcess - INFO - text_logger.py - 51 - Train epoch #115
2024-04-24 14:49:11,299 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.8834e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7943e-01, 0.0000e+00,
        8.5095e-02, 8.5289e-03, 4.1930e-01, 0.0000e+00, 2.2118e-03, 3.8309e-03,
        0.0000e+00, 0.0000e+00, 3.2431e-04, 1.1685e-03, 0.0000e+00, 0.0000e+00,
        1.1384e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.0712, 0.0000, 0.0000, 0.0000, 0.0738, 0.0000, 0.1063, 0.0143, 0.0441,
        0.0000, 0.0081, 0.0093, 0.0000, 0.0000, 0.0026, 0.0056, 0.0000, 0.0000,
        0.0015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-04-24 14:49:11,312 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43126431523785097
2024-04-24 14:49:11,314 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.570290.10362
2024-04-24 14:49:11,328 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #116: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(min, 0)': 0.11, '(min, 1)': 0.46, '(rev, 1)': 0.08, '(rev, 2)': 0.08}}
2024-04-24 14:49:11,328 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:11,328 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310659697458266
2024-04-24 14:49:11,374 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #116: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(min, 0)': 0.21, '(min, 1)': 0.42, '(rev, 1)': 0.08, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:49:11,374 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #116: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3488372093023256, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.04, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:49:11,374 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:11,374 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:11,375 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310659697458266
2024-04-24 14:49:11,375 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310659697458266
2024-04-24 14:49:11,474 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #116: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7272727272727273, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.04, '(min, 0)': 0.12, '(min, 1)': 0.48, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:49:11,474 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:11,475 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310659697458266
2024-04-24 14:49:11,861 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #116: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5217391304347826, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.04, '(min, 0)': 0.16, '(min, 1)': 0.51, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 4)': 0.04, '(rev, 5)': 0.01}}
2024-04-24 14:49:11,862 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:11,862 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310659697458266
2024-04-24 14:49:11,888 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #116: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 6, 2, 1, 1),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, exi, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 6, 3, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.37209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.44, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:49:11,888 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:11,889 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310659697458266
2024-04-24 14:49:13,037 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #116: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 1, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.6739130434782609, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(min, 0)': 0.27, '(min, 1)': 0.39, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:49:13,037 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:13,037 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310659697458266
2024-04-24 14:49:13,104 - MainProcess - INFO - text_logger.py - 51 - Train epoch #116
2024-04-24 14:49:13,106 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.6556e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4995e-01, 0.0000e+00,
        1.1259e-01, 8.4483e-03, 4.0872e-01, 0.0000e+00, 3.6028e-03, 6.4989e-03,
        0.0000e+00, 0.0000e+00, 8.0545e-04, 5.9469e-03, 0.0000e+00, 0.0000e+00,
        2.2440e-04, 2.7522e-03, 0.0000e+00, 0.0000e+00, 3.1250e-05, 2.6855e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3458e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.5714e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.8337e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.4581e-02, 0.0000e+00,
        1.4155e-01, 1.5189e-02, 6.6392e-02, 0.0000e+00, 1.0880e-02, 1.4018e-02,
        0.0000e+00, 0.0000e+00, 4.3709e-03, 1.6687e-02, 0.0000e+00, 0.0000e+00,
        2.0795e-03, 8.6981e-03, 0.0000e+00, 0.0000e+00, 6.9877e-04, 2.4515e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8001e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.9860e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:13,124 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4317232667904814
2024-04-24 14:49:13,125 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.700590.02668
2024-04-24 14:49:13,135 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #117: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6976744186046512, 'length': 100, 'actions': {'(ado, 1)': 0.09, '(ado, 2)': 0.02, '(min, 0)': 0.21, '(min, 1)': 0.5, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.03, '(rev, 4)': 0.02, '(rev, 6)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:49:13,136 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:13,137 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43126431523785097
2024-04-24 14:49:13,150 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #117: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43478260869565216, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:49:13,150 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #117: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5581395348837209, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.22, '(rev, 1)': 0.12, '(rev, 2)': 0.11, '(rev, 3)': 0.01}}
2024-04-24 14:49:13,150 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:13,150 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:13,150 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #117: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.24444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.03, '(min, 0)': 0.06, '(min, 1)': 0.49, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:49:13,151 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:13,151 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43126431523785097
2024-04-24 14:49:13,151 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43126431523785097
2024-04-24 14:49:13,152 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43126431523785097
2024-04-24 14:49:13,270 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #117: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0),(rev, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.6326530612244898, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.32, '(min, 1)': 0.24, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:49:13,270 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:13,271 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43126431523785097
2024-04-24 14:49:14,038 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #117: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 1.0217391304347827, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.44, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:49:14,038 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:14,039 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43126431523785097
2024-04-24 14:49:14,826 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #117: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6829268292682927, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.49, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:49:14,826 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:14,826 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43126431523785097
2024-04-24 14:49:14,888 - MainProcess - INFO - text_logger.py - 51 - Train epoch #117
2024-04-24 14:49:14,890 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.3169e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7129e-01, 0.0000e+00,
        9.4762e-02, 8.4740e-03, 4.1535e-01, 0.0000e+00, 2.1636e-03, 4.5760e-03,
        0.0000e+00, 0.0000e+00, 2.3989e-04, 1.9014e-03, 0.0000e+00, 0.0000e+00,
        1.5374e-04, 3.7893e-04, 0.0000e+00, 0.0000e+00, 1.2088e-04, 1.1614e-04,
        0.0000e+00, 0.0000e+00, 4.1667e-05, 2.7391e-04, 0.0000e+00, 0.0000e+00,
        1.2167e-04, 3.9216e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.0104e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.5348e-02, 0.0000e+00,
        1.3279e-01, 1.5251e-02, 6.0373e-02, 0.0000e+00, 7.7967e-03, 1.1119e-02,
        0.0000e+00, 0.0000e+00, 2.2117e-03, 8.8644e-03, 0.0000e+00, 0.0000e+00,
        1.7173e-03, 3.5204e-03, 0.0000e+00, 0.0000e+00, 1.5580e-03, 1.9291e-03,
        0.0000e+00, 0.0000e+00, 9.3170e-04, 2.8142e-03, 0.0000e+00, 0.0000e+00,
        2.0153e-03, 8.7689e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:14,902 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43216163382023376
2024-04-24 14:49:14,904 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.690300.00737
2024-04-24 14:49:14,918 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #118: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.02, '(min, 1)': 0.55, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-04-24 14:49:14,918 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:14,918 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4317232667904814
2024-04-24 14:49:14,934 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #118: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.3958333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.03, '(ado, 4)': 0.01, '(min, 0)': 0.14, '(min, 1)': 0.46, '(rev, 1)': 0.07, '(rev, 2)': 0.08, '(rev, 3)': 0.02}}
2024-04-24 14:49:14,934 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:14,935 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4317232667904814
2024-04-24 14:49:14,949 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #118: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6818181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(min, 0)': 0.04, '(min, 1)': 0.57, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-04-24 14:49:14,949 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:14,949 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #118: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.40425531914893614, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(min, 0)': 0.07, '(min, 1)': 0.52, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:49:14,949 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:14,949 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4317232667904814
2024-04-24 14:49:14,950 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4317232667904814
2024-04-24 14:49:14,965 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #118: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.10869565217391304, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.03, '(min, 0)': 0.07, '(min, 1)': 0.47, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-04-24 14:49:14,965 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:14,965 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4317232667904814
2024-04-24 14:49:15,517 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #118: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6818181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(min, 0)': 0.01, '(min, 1)': 0.56, '(rev, 1)': 0.12, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-04-24 14:49:15,517 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:15,517 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4317232667904814
2024-04-24 14:49:16,169 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #118: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.47058823529411764, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(min, 0)': 0.49, '(min, 1)': 0.11, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 5)': 0.02}}
2024-04-24 14:49:16,169 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:16,170 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4317232667904814
2024-04-24 14:49:16,233 - MainProcess - INFO - text_logger.py - 51 - Train epoch #118
2024-04-24 14:49:16,235 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.6178e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7158e-01, 0.0000e+00,
        8.7982e-02, 6.9367e-03, 4.2551e-01, 0.0000e+00, 1.8022e-03, 3.4758e-03,
        0.0000e+00, 0.0000e+00, 2.9261e-04, 1.9667e-03, 0.0000e+00, 0.0000e+00,
        3.3898e-05, 4.1952e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.6771e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.6929e-02, 0.0000e+00,
        1.1524e-01, 1.3454e-02, 5.0476e-02, 0.0000e+00, 7.6145e-03, 1.0315e-02,
        0.0000e+00, 0.0000e+00, 2.6879e-03, 8.7261e-03, 0.0000e+00, 0.0000e+00,
        7.5799e-04, 3.3186e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:16,252 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4320942431565562
2024-04-24 14:49:16,254 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.437420.03317
2024-04-24 14:49:16,296 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #119: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(min, 0)': 0.1, '(min, 1)': 0.49, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-04-24 14:49:16,296 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:16,297 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43216163382023376
2024-04-24 14:49:16,312 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #119: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.1, '(min, 1)': 0.47, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:49:16,312 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:16,312 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:16,313 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43216163382023376
2024-04-24 14:49:16,313 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43216163382023376
2024-04-24 14:49:16,315 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #119: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5714285714285714, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(min, 0)': 0.2, '(min, 1)': 0.48, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:49:16,315 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:16,316 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43216163382023376
2024-04-24 14:49:16,345 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #119: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.46808510638297873, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(min, 0)': 0.34, '(min, 1)': 0.28, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:49:16,346 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:16,346 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43216163382023376
2024-04-24 14:49:17,230 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #119: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1875, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.45, '(rev, 1)': 0.02, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:49:17,230 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:17,231 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43216163382023376
2024-04-24 14:49:17,486 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #119: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0),(rev, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.36363636363636365, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(min, 0)': 0.06, '(min, 1)': 0.53, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:49:17,486 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:17,487 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43216163382023376
2024-04-24 14:49:17,545 - MainProcess - INFO - text_logger.py - 51 - Train epoch #119
2024-04-24 14:49:17,548 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.2246e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7238e-01, 0.0000e+00,
        9.5980e-02, 7.7294e-03, 4.1397e-01, 0.0000e+00, 2.3996e-03, 3.9111e-03,
        0.0000e+00, 0.0000e+00, 3.5399e-04, 2.1393e-03, 0.0000e+00, 0.0000e+00,
        1.1477e-04, 4.8774e-04, 0.0000e+00, 0.0000e+00, 7.4773e-05, 2.0880e-04,
        0.0000e+00, 0.0000e+00, 7.7736e-05, 2.7778e-05, 0.0000e+00, 0.0000e+00,
        3.7736e-05, 2.7778e-05, 0.0000e+00, 0.0000e+00, 3.7736e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.7736e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.4248e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.4463e-02, 0.0000e+00,
        1.5438e-01, 1.4400e-02, 7.1648e-02, 0.0000e+00, 8.4463e-03, 1.0633e-02,
        0.0000e+00, 0.0000e+00, 2.6384e-03, 8.7022e-03, 0.0000e+00, 0.0000e+00,
        1.4796e-03, 3.7414e-03, 0.0000e+00, 0.0000e+00, 1.1811e-03, 2.2672e-03,
        0.0000e+00, 0.0000e+00, 1.2284e-03, 6.2113e-04, 0.0000e+00, 0.0000e+00,
        8.4380e-04, 6.2113e-04, 0.0000e+00, 0.0000e+00, 8.4380e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.4380e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:17,560 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4320870738735006
2024-04-24 14:49:17,563 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.467530.10390
2024-04-24 14:49:17,690 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #120: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5106382978723404, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(min, 0)': 0.38, '(min, 1)': 0.24, '(rev, 1)': 0.06, '(rev, 2)': 0.09, '(rev, 3)': 0.02}}
2024-04-24 14:49:17,691 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:17,691 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320942431565562
2024-04-24 14:49:17,793 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #120: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.4, '(rev, 1)': 0.12, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:49:17,793 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:17,794 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320942431565562
2024-04-24 14:49:17,806 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #120: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 7, 5, 0, 0),(rev, 5)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 7, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4473684210526316, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.46, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 5)': 0.02}}
2024-04-24 14:49:17,807 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:17,807 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320942431565562
2024-04-24 14:49:18,103 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #120: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6744186046511628, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(min, 0)': 0.18, '(min, 1)': 0.43, '(rev, 1)': 0.11, '(rev, 2)': 0.01, '(rev, 3)': 0.04, '(rev, 4)': 0.01}}
2024-04-24 14:49:18,103 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:18,103 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320942431565562
2024-04-24 14:49:18,415 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #120: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 2)': 0.02, '(min, 0)': 0.47, '(min, 1)': 0.17}}
2024-04-24 14:49:18,416 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:18,416 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320942431565562
2024-04-24 14:49:18,813 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #120: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5909090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.35, '(rev, 1)': 0.05, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:49:18,813 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:18,814 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320942431565562
2024-04-24 14:49:19,244 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #120: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.25, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.02, '(rev, 6)': 0.01}}
2024-04-24 14:49:19,244 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:19,245 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320942431565562
2024-04-24 14:49:19,419 - MainProcess - INFO - text_logger.py - 51 - Train epoch #120
2024-04-24 14:49:19,422 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.3399e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7106e-01, 0.0000e+00,
        2.2912e-01, 7.0107e-03, 3.4581e-01, 0.0000e+00, 1.2076e-02, 6.9381e-03,
        0.0000e+00, 0.0000e+00, 3.9447e-03, 5.1774e-03, 0.0000e+00, 0.0000e+00,
        3.2020e-03, 2.9464e-03, 0.0000e+00, 0.0000e+00, 2.7178e-03, 7.8806e-04,
        0.0000e+00, 0.0000e+00, 2.5774e-03, 5.8503e-04, 0.0000e+00, 0.0000e+00,
        2.4347e-03, 3.9930e-04, 0.0000e+00, 0.0000e+00, 1.8843e-03, 1.1901e-04,
        0.0000e+00, 0.0000e+00, 9.6613e-04, 3.8462e-05, 0.0000e+00, 0.0000e+00,
        2.0906e-04, 0.0000e+00, 0.0000e+00])  tensor([2.9601e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7552e-01, 0.0000e+00,
        2.8004e-01, 1.4305e-02, 1.5066e-01, 0.0000e+00, 2.0834e-02, 1.5782e-02,
        0.0000e+00, 0.0000e+00, 8.3194e-03, 1.6707e-02, 0.0000e+00, 0.0000e+00,
        7.2960e-03, 1.7779e-02, 0.0000e+00, 0.0000e+00, 6.4571e-03, 3.6379e-03,
        0.0000e+00, 0.0000e+00, 6.2585e-03, 3.2523e-03, 0.0000e+00, 0.0000e+00,
        6.0169e-03, 2.5733e-03, 0.0000e+00, 0.0000e+00, 5.3233e-03, 1.3503e-03,
        0.0000e+00, 0.0000e+00, 3.8707e-03, 8.6003e-04, 0.0000e+00, 0.0000e+00,
        1.7866e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:19,433 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43241016735094023
2024-04-24 14:49:19,435 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.632660.04175
2024-04-24 14:49:19,449 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #121: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.4375, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(min, 0)': 0.44, '(min, 1)': 0.14, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 4)': 0.01}}
2024-04-24 14:49:19,449 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:19,450 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320870738735006
2024-04-24 14:49:19,465 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #121: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5208333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(min, 0)': 0.05, '(min, 1)': 0.51, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-24 14:49:19,466 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:19,466 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320870738735006
2024-04-24 14:49:19,732 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #121: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25925925925925924, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.12, '(min, 1)': 0.46, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:49:19,732 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:19,733 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320870738735006
2024-04-24 14:49:19,796 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #121: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.62, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.02, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.42, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-04-24 14:49:19,796 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:19,796 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320870738735006
2024-04-24 14:49:19,974 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #121: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5681818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 3)': 0.02, '(min, 0)': 0.16, '(min, 1)': 0.48, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:49:19,975 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:19,976 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320870738735006
2024-04-24 14:49:20,261 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #121: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5227272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.09, '(min, 1)': 0.55, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.02, '(rev, 7)': 0.01}}
2024-04-24 14:49:20,262 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:20,263 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320870738735006
2024-04-24 14:49:20,549 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #121: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.42, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:49:20,549 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:20,549 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320870738735006
2024-04-24 14:49:20,739 - MainProcess - INFO - text_logger.py - 51 - Train epoch #121
2024-04-24 14:49:20,741 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.2795e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5099e-01, 0.0000e+00,
        1.3262e-01, 7.8415e-03, 3.9573e-01, 0.0000e+00, 4.9582e-03, 3.9673e-03,
        0.0000e+00, 0.0000e+00, 7.7075e-04, 1.1592e-03, 0.0000e+00, 0.0000e+00,
        4.3445e-04, 1.7999e-04, 0.0000e+00, 0.0000e+00, 3.7306e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.3765e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5765e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3785e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0474e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.7736e-05, 0.0000e+00, 0.0000e+00])  tensor([1.4721e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2535e-01, 0.0000e+00,
        2.0428e-01, 1.4718e-02, 9.9294e-02, 0.0000e+00, 1.4874e-02, 1.0292e-02,
        0.0000e+00, 0.0000e+00, 4.0486e-03, 5.8248e-03, 0.0000e+00, 0.0000e+00,
        2.9135e-03, 2.0922e-03, 0.0000e+00, 0.0000e+00, 2.8060e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.8120e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.1792e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0419e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2130e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.4380e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:20,758 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4325588422237288
2024-04-24 14:49:20,761 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.545450.02273
2024-04-24 14:49:20,786 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #122: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.11904761904761904, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.04, '(min, 0)': 0.04, '(min, 1)': 0.52, '(rev, 1)': 0.09, '(rev, 2)': 0.02}}
2024-04-24 14:49:20,787 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:20,788 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43241016735094023
2024-04-24 14:49:20,941 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #122: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.23, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-04-24 14:49:20,941 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:20,941 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43241016735094023
2024-04-24 14:49:21,207 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #122: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.07, '(min, 0)': 0.09, '(min, 1)': 0.51, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:49:21,207 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:21,207 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43241016735094023
2024-04-24 14:49:21,350 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #122: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.33, '(min, 1)': 0.28}}
2024-04-24 14:49:21,350 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:21,351 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43241016735094023
2024-04-24 14:49:21,554 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #122: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.45454545454545453, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.25, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:49:21,555 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:21,555 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43241016735094023
2024-04-24 14:49:21,849 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #122: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 8, 4, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 8, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.39, '(rev, 1)': 0.09, '(rev, 2)': 0.07}}
2024-04-24 14:49:21,849 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:21,849 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43241016735094023
2024-04-24 14:49:22,086 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #122: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2978723404255319, 'length': 100, 'actions': {'(ado, 1)': 0.05, '(ado, 2)': 0.01, '(ado, 3)': 0.06, '(ado, 4)': 0.02, '(min, 0)': 0.24, '(min, 1)': 0.45, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.03}}
2024-04-24 14:49:22,086 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:22,086 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43241016735094023
2024-04-24 14:49:22,271 - MainProcess - INFO - text_logger.py - 51 - Train epoch #122
2024-04-24 14:49:22,273 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.8404e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2960e-01, 0.0000e+00,
        1.3707e-01, 8.8902e-03, 4.0396e-01, 0.0000e+00, 8.2698e-03, 5.1861e-03,
        0.0000e+00, 0.0000e+00, 1.9456e-03, 2.6761e-03, 0.0000e+00, 0.0000e+00,
        7.5805e-04, 1.2412e-03, 0.0000e+00, 0.0000e+00, 1.1889e-04, 1.5335e-04,
        0.0000e+00, 0.0000e+00, 3.7736e-05, 3.8462e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 6.0606e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.3680e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1564e-01, 0.0000e+00,
        1.7541e-01, 1.5302e-02, 8.7922e-02, 0.0000e+00, 2.3564e-02, 1.2727e-02,
        0.0000e+00, 0.0000e+00, 7.4347e-03, 9.4182e-03, 0.0000e+00, 0.0000e+00,
        4.6439e-03, 6.7936e-03, 0.0000e+00, 0.0000e+00, 1.5368e-03, 2.0739e-03,
        0.0000e+00, 0.0000e+00, 8.4380e-04, 8.6003e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.3552e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:22,289 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4323166080056083
2024-04-24 14:49:22,291 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.350000.35000
2024-04-24 14:49:22,333 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #123: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.425531914893617, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.24, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-04-24 14:49:22,333 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:22,334 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4325588422237288
2024-04-24 14:49:22,438 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #123: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 7, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 8, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.225, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.35, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:49:22,438 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:22,439 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4325588422237288
2024-04-24 14:49:22,510 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #123: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.42, '(min, 1)': 0.19}}
2024-04-24 14:49:22,510 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:22,511 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4325588422237288
2024-04-24 14:49:22,666 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #123: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.21052631578947367, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 5)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.2, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:49:22,666 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:22,666 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4325588422237288
2024-04-24 14:49:22,992 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #123: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 6, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 4, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8048780487804879, 'length': 100, 'actions': {'(ado, 1)': 0.08, '(min, 0)': 0.37, '(min, 1)': 0.34, '(rev, 1)': 0.06, '(rev, 2)': 0.08, '(rev, 3)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:49:22,992 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:22,993 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4325588422237288
2024-04-24 14:49:23,467 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #123: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.14893617021276595, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(ado, 3)': 0.03, '(ado, 4)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.41, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:49:23,467 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:23,468 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4325588422237288
2024-04-24 14:49:23,982 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #123: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4791666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.43, '(rev, 1)': 0.02, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:49:23,982 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:23,982 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4325588422237288
2024-04-24 14:49:24,051 - MainProcess - INFO - text_logger.py - 51 - Train epoch #123
2024-04-24 14:49:24,054 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.5527e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8008e-01, 0.0000e+00,
        2.2261e-01, 6.2803e-03, 3.3727e-01, 0.0000e+00, 1.9757e-02, 3.9389e-03,
        0.0000e+00, 0.0000e+00, 7.0662e-03, 2.9097e-03, 0.0000e+00, 0.0000e+00,
        5.5444e-03, 3.2817e-03, 0.0000e+00, 0.0000e+00, 2.9639e-03, 2.7974e-04,
        0.0000e+00, 0.0000e+00, 2.7779e-03, 3.0450e-04, 0.0000e+00, 0.0000e+00,
        2.1365e-03, 3.8462e-05, 0.0000e+00, 0.0000e+00, 1.7828e-03, 3.8462e-05,
        0.0000e+00, 0.0000e+00, 8.2494e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2185e-04, 0.0000e+00, 0.0000e+00])  tensor([2.1132e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7829e-01, 0.0000e+00,
        2.4715e-01, 1.2980e-02, 1.4489e-01, 0.0000e+00, 3.7636e-02, 1.1131e-02,
        0.0000e+00, 0.0000e+00, 1.5035e-02, 9.2889e-03, 0.0000e+00, 0.0000e+00,
        1.2976e-02, 1.4571e-02, 0.0000e+00, 0.0000e+00, 9.0503e-03, 2.2291e-03,
        0.0000e+00, 0.0000e+00, 8.5983e-03, 2.7971e-03, 0.0000e+00, 0.0000e+00,
        7.1570e-03, 8.6003e-04, 0.0000e+00, 0.0000e+00, 6.0468e-03, 8.6003e-04,
        0.0000e+00, 0.0000e+00, 3.6620e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3871e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:24,066 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4318535404541543
2024-04-24 14:49:24,068 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.239580.23958
2024-04-24 14:49:24,083 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #124: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43478260869565216, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(ado, 5)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.49, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.04, '(rev, 4)': 0.02, '(rev, 5)': 0.02}}
2024-04-24 14:49:24,083 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:24,084 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323166080056083
2024-04-24 14:49:24,114 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #124: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.32, '(min, 1)': 0.27}}
2024-04-24 14:49:24,114 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:24,115 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323166080056083
2024-04-24 14:49:24,236 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #124: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.52, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.4, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:49:24,236 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:24,237 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323166080056083
2024-04-24 14:49:24,875 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #124: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.11320754716981132, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 4)': 0.03, '(ado, 7)': 0.02, '(min, 0)': 0.38, '(min, 1)': 0.33, '(rev, 1)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:49:24,875 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:24,875 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323166080056083
2024-04-24 14:49:24,918 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #124: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.4423076923076923, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.37, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-24 14:49:24,918 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:24,919 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323166080056083
2024-04-24 14:49:25,429 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #124: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8043478260869565, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(min, 0)': 0.39, '(min, 1)': 0.28, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.02, '(rev, 6)': 0.01}}
2024-04-24 14:49:25,429 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:25,429 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323166080056083
2024-04-24 14:49:26,141 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #124: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 4, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(ado, 5)': 0.02, '(min, 0)': 0.46, '(min, 1)': 0.25}}
2024-04-24 14:49:26,142 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:26,142 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323166080056083
2024-04-24 14:49:26,209 - MainProcess - INFO - text_logger.py - 51 - Train epoch #124
2024-04-24 14:49:26,211 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([9.1564e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5916e-01, 0.0000e+00,
        2.2786e-01, 7.4732e-03, 3.4648e-01, 0.0000e+00, 1.9160e-02, 5.1545e-03,
        0.0000e+00, 0.0000e+00, 7.5725e-03, 3.9169e-03, 0.0000e+00, 0.0000e+00,
        6.0472e-03, 3.8426e-03, 0.0000e+00, 0.0000e+00, 3.3794e-03, 8.1958e-04,
        0.0000e+00, 0.0000e+00, 2.9014e-03, 6.5636e-04, 0.0000e+00, 0.0000e+00,
        2.1613e-03, 2.2711e-04, 0.0000e+00, 0.0000e+00, 1.7303e-03, 6.8622e-05,
        0.0000e+00, 0.0000e+00, 1.0082e-03, 6.8622e-05, 0.0000e+00, 0.0000e+00,
        3.1100e-04, 0.0000e+00, 0.0000e+00])  tensor([3.7421e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8511e-01, 0.0000e+00,
        2.8551e-01, 1.5029e-02, 1.6641e-01, 0.0000e+00, 3.4807e-02, 1.2520e-02,
        0.0000e+00, 0.0000e+00, 1.5012e-02, 1.0738e-02, 0.0000e+00, 0.0000e+00,
        1.3305e-02, 1.1183e-02, 0.0000e+00, 0.0000e+00, 9.3678e-03, 3.8335e-03,
        0.0000e+00, 0.0000e+00, 8.5829e-03, 3.5921e-03, 0.0000e+00, 0.0000e+00,
        7.0835e-03, 1.9345e-03, 0.0000e+00, 0.0000e+00, 5.8621e-03, 1.0859e-03,
        0.0000e+00, 0.0000e+00, 4.0597e-03, 1.0859e-03, 0.0000e+00, 0.0000e+00,
        2.6272e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:26,225 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43091130623603374
2024-04-24 14:49:26,227 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:49:26,240 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #125: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.05, '(min, 0)': 0.42, '(min, 1)': 0.18, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 4)': 0.01}}
2024-04-24 14:49:26,240 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:26,241 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318535404541543
2024-04-24 14:49:26,255 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #125: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.3, '(min, 1)': 0.31}}
2024-04-24 14:49:26,255 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:26,256 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318535404541543
2024-04-24 14:49:26,258 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #125: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2708333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.19, '(rev, 1)': 0.02, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:49:26,258 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:26,259 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318535404541543
2024-04-24 14:49:26,272 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #125: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7659574468085106, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.14, '(min, 1)': 0.49, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:49:26,272 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:26,273 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318535404541543
2024-04-24 14:49:26,287 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #125: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.04, '(min, 0)': 0.05, '(min, 1)': 0.55, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:49:26,287 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:26,288 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318535404541543
2024-04-24 14:49:26,853 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #125: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4166666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.38, '(rev, 1)': 0.04, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:49:26,853 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:26,853 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318535404541543
2024-04-24 14:49:27,293 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #125: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 2, 7, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.37, '(min, 1)': 0.24}}
2024-04-24 14:49:27,293 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:27,294 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318535404541543
2024-04-24 14:49:27,366 - MainProcess - INFO - text_logger.py - 51 - Train epoch #125
2024-04-24 14:49:27,369 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.1748e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4682e-01, 0.0000e+00,
        1.3068e-01, 9.2841e-03, 3.8847e-01, 0.0000e+00, 7.9411e-03, 5.1099e-03,
        0.0000e+00, 0.0000e+00, 2.2738e-03, 2.4805e-03, 0.0000e+00, 0.0000e+00,
        1.6538e-03, 1.7873e-03, 0.0000e+00, 0.0000e+00, 1.0801e-03, 3.7736e-05,
        0.0000e+00, 0.0000e+00, 7.9189e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.4362e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.3415e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.1376e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.0289e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2915e-01, 0.0000e+00,
        1.8738e-01, 1.5786e-02, 1.0242e-01, 0.0000e+00, 2.5086e-02, 1.1689e-02,
        0.0000e+00, 0.0000e+00, 9.4028e-03, 8.5287e-03, 0.0000e+00, 0.0000e+00,
        7.7678e-03, 7.9162e-03, 0.0000e+00, 0.0000e+00, 5.8380e-03, 8.4380e-04,
        0.0000e+00, 0.0000e+00, 4.7318e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.4712e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8004e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.9769e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:27,383 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4299690720179132
2024-04-24 14:49:27,385 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:49:27,472 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #126: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.45, '(min, 1)': 0.2}}
2024-04-24 14:49:27,472 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:27,473 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43091130623603374
2024-04-24 14:49:27,553 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #126: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35714285714285715, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(min, 0)': 0.15, '(min, 1)': 0.46, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:49:27,553 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:27,554 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43091130623603374
2024-04-24 14:49:27,620 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #126: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(min, 0)': 0.21, '(min, 1)': 0.4, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:49:27,620 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:27,620 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43091130623603374
2024-04-24 14:49:27,665 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #126: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0),(ado, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/3', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.3, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:49:27,665 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:27,666 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43091130623603374
2024-04-24 14:49:28,071 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #126: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.42, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:49:28,071 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:28,071 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43091130623603374
2024-04-24 14:49:28,241 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #126: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4375, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.14, '(min, 1)': 0.47, '(rev, 1)': 0.06, '(rev, 2)': 0.06, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:49:28,241 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:28,241 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43091130623603374
2024-04-24 14:49:28,543 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #126: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 3, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.38, '(min, 1)': 0.25}}
2024-04-24 14:49:28,543 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:28,544 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43091130623603374
2024-04-24 14:49:28,614 - MainProcess - INFO - text_logger.py - 51 - Train epoch #126
2024-04-24 14:49:28,616 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.2995e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4427e-01, 0.0000e+00,
        1.1021e-01, 8.1405e-03, 4.2517e-01, 0.0000e+00, 3.2171e-03, 4.1778e-03,
        0.0000e+00, 0.0000e+00, 7.8356e-04, 1.9810e-03, 0.0000e+00, 0.0000e+00,
        5.6338e-05, 1.6390e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3385e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2000e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7125e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.3373e-02, 0.0000e+00,
        1.4455e-01, 1.4191e-02, 6.7112e-02, 0.0000e+00, 1.0428e-02, 9.9807e-03,
        0.0000e+00, 0.0000e+00, 4.7205e-03, 7.3493e-03, 0.0000e+00, 0.0000e+00,
        1.2598e-03, 7.5232e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7345e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9984e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:28,630 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4290268377997926
2024-04-24 14:49:28,632 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:49:28,863 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #127: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.27906976744186046, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.1, '(min, 1)': 0.49, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-04-24 14:49:28,863 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:28,864 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4299690720179132
2024-04-24 14:49:28,898 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #127: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 6, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 4, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(ado, 2)': 0.02, '(min, 0)': 0.52, '(min, 1)': 0.07}}
2024-04-24 14:49:28,898 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:28,898 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4299690720179132
2024-04-24 14:49:29,113 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #127: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4166666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.32, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:49:29,113 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:29,114 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4299690720179132
2024-04-24 14:49:29,467 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #127: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.32, '(min, 1)': 0.28, '(rev, 1)': 0.09, '(rev, 2)': 0.07}}
2024-04-24 14:49:29,468 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:29,468 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4299690720179132
2024-04-24 14:49:29,569 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #127: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 3, 0, 0),(ado, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/3', 'revenue': 0.5416666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.35, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.02, '(rev, 8)': 0.01}}
2024-04-24 14:49:29,569 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:29,569 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4299690720179132
2024-04-24 14:49:29,845 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #127: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4791666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.45, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.02}}
2024-04-24 14:49:29,846 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:29,846 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4299690720179132
2024-04-24 14:49:30,163 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #127: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.2}}
2024-04-24 14:49:30,163 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:30,164 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4299690720179132
2024-04-24 14:49:30,229 - MainProcess - INFO - text_logger.py - 51 - Train epoch #127
2024-04-24 14:49:30,231 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.8715e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4234e-01, 0.0000e+00,
        1.6057e-01, 5.6637e-03, 3.7065e-01, 0.0000e+00, 7.9509e-03, 2.6170e-03,
        0.0000e+00, 0.0000e+00, 3.0132e-03, 1.3489e-03, 0.0000e+00, 0.0000e+00,
        2.0045e-03, 1.0113e-03, 0.0000e+00, 0.0000e+00, 1.0460e-03, 3.5209e-04,
        0.0000e+00, 0.0000e+00, 7.5377e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8445e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6856e-04, 7.6923e-05,
        0.0000e+00, 0.0000e+00, 1.1450e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.6364e-05, 0.0000e+00, 0.0000e+00])  tensor([2.0924e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3936e-01, 0.0000e+00,
        2.0800e-01, 1.1855e-02, 1.0442e-01, 0.0000e+00, 1.9879e-02, 7.5041e-03,
        0.0000e+00, 0.0000e+00, 9.8907e-03, 5.6533e-03, 0.0000e+00, 0.0000e+00,
        8.2859e-03, 5.3299e-03, 0.0000e+00, 0.0000e+00, 5.8687e-03, 3.3701e-03,
        0.0000e+00, 0.0000e+00, 4.7802e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.6563e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9050e-03, 1.7201e-03,
        0.0000e+00, 0.0000e+00, 1.4767e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.1312e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:30,246 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.428084603581672
2024-04-24 14:49:30,249 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:49:30,391 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #128: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.38, '(rev, 1)': 0.15, '(rev, 2)': 0.01}}
2024-04-24 14:49:30,391 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:30,392 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4290268377997926
2024-04-24 14:49:30,453 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #128: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6190476190476191, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.02, '(min, 0)': 0.35, '(min, 1)': 0.35, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:49:30,453 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:30,454 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4290268377997926
2024-04-24 14:49:30,919 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #128: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5128205128205128, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.02, '(min, 0)': 0.06, '(min, 1)': 0.55, '(rev, 1)': 0.17, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:49:30,919 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:30,920 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4290268377997926
2024-04-24 14:49:30,930 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #128: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.375, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(ado, 3)': 0.02, '(min, 0)': 0.27, '(min, 1)': 0.39, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 9)': 0.01}}
2024-04-24 14:49:30,931 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:30,931 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4290268377997926
2024-04-24 14:49:31,222 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #128: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8043478260869565, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.16, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 5)': 0.01}}
2024-04-24 14:49:31,222 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:31,223 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4290268377997926
2024-04-24 14:49:31,482 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #128: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.44, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:49:31,483 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:31,483 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4290268377997926
2024-04-24 14:49:31,786 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #128: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.43, '(min, 1)': 0.21}}
2024-04-24 14:49:31,787 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:31,787 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4290268377997926
2024-04-24 14:49:31,858 - MainProcess - INFO - text_logger.py - 51 - Train epoch #128
2024-04-24 14:49:31,861 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.8620e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8447e-01, 0.0000e+00,
        1.8030e-01, 8.6590e-03, 3.9124e-01, 0.0000e+00, 1.1451e-02, 5.7399e-03,
        0.0000e+00, 0.0000e+00, 4.0492e-03, 3.4836e-03, 0.0000e+00, 0.0000e+00,
        2.8122e-03, 3.6856e-03, 0.0000e+00, 0.0000e+00, 1.6681e-03, 3.1651e-04,
        0.0000e+00, 0.0000e+00, 1.1990e-03, 1.7305e-04, 0.0000e+00, 0.0000e+00,
        4.1241e-04, 8.9127e-05, 0.0000e+00, 0.0000e+00, 1.3779e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.0000e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.0000e-05, 0.0000e+00, 0.0000e+00])  tensor([2.5196e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3891e-01, 0.0000e+00,
        2.1639e-01, 1.6042e-02, 1.2397e-01, 0.0000e+00, 2.7069e-02, 1.1963e-02,
        0.0000e+00, 0.0000e+00, 1.1694e-02, 1.0244e-02, 0.0000e+00, 0.0000e+00,
        9.8904e-03, 1.2370e-02, 0.0000e+00, 0.0000e+00, 7.5107e-03, 2.3730e-03,
        0.0000e+00, 0.0000e+00, 6.1978e-03, 2.1643e-03, 0.0000e+00, 0.0000e+00,
        3.3336e-03, 1.4784e-03, 0.0000e+00, 0.0000e+00, 1.7844e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.9443e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7889e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:31,873 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4276206302331167
2024-04-24 14:49:31,875 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.239130.23913
2024-04-24 14:49:31,905 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #129: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6458333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.38, '(min, 1)': 0.27, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.02, '(rev, 6)': 0.01}}
2024-04-24 14:49:31,905 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:31,905 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #129: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40476190476190477, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.03, '(min, 0)': 0.29, '(min, 1)': 0.33, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:49:31,905 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:31,906 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.428084603581672
2024-04-24 14:49:31,906 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.428084603581672
2024-04-24 14:49:32,620 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #129: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.29545454545454547, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.05, '(ado, 3)': 0.01, '(min, 0)': 0.08, '(min, 1)': 0.53, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:49:32,620 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:32,621 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.428084603581672
2024-04-24 14:49:32,762 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #129: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10869565217391304, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.38, '(rev, 1)': 0.06, '(rev, 2)': 0.03}}
2024-04-24 14:49:32,762 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:32,763 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.428084603581672
2024-04-24 14:49:32,856 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #129: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.09, '(min, 1)': 0.52, '(rev, 1)': 0.1, '(rev, 2)': 0.01}}
2024-04-24 14:49:32,856 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:32,857 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.428084603581672
2024-04-24 14:49:32,950 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #129: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 3, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 3, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.48, '(min, 1)': 0.14}}
2024-04-24 14:49:32,950 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:32,950 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.428084603581672
2024-04-24 14:49:33,246 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #129: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.02, '(min, 0)': 0.43, '(min, 1)': 0.13, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:49:33,246 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:33,246 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.428084603581672
2024-04-24 14:49:33,423 - MainProcess - INFO - text_logger.py - 51 - Train epoch #129
2024-04-24 14:49:33,426 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.6150e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4825e-01, 0.0000e+00,
        1.5127e-01, 6.6155e-03, 3.6276e-01, 0.0000e+00, 8.7379e-03, 3.9967e-03,
        0.0000e+00, 0.0000e+00, 3.7452e-03, 2.6285e-03, 0.0000e+00, 0.0000e+00,
        3.0212e-03, 1.8784e-03, 0.0000e+00, 0.0000e+00, 2.2109e-03, 2.8347e-04,
        0.0000e+00, 0.0000e+00, 1.8601e-03, 1.5418e-04, 0.0000e+00, 0.0000e+00,
        1.4992e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2702e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.1936e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5714e-05, 0.0000e+00, 0.0000e+00])  tensor([2.4142e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4427e-01, 0.0000e+00,
        1.9772e-01, 1.3935e-02, 1.0807e-01, 0.0000e+00, 2.2684e-02, 1.1105e-02,
        0.0000e+00, 0.0000e+00, 1.2628e-02, 9.7335e-03, 0.0000e+00, 0.0000e+00,
        1.1162e-02, 8.3536e-03, 0.0000e+00, 0.0000e+00, 8.4066e-03, 2.6815e-03,
        0.0000e+00, 0.0000e+00, 7.3326e-03, 2.1361e-03, 0.0000e+00, 0.0000e+00,
        6.2409e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3442e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.0118e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.9860e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:33,439 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.427083157919758
2024-04-24 14:49:33,441 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.202380.20238
2024-04-24 14:49:33,486 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #130: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1388888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 3)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.1, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:49:33,486 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:33,487 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4276206302331167
2024-04-24 14:49:33,735 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #130: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.08333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.29, '(rev, 1)': 0.06}}
2024-04-24 14:49:33,735 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:33,736 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4276206302331167
2024-04-24 14:49:33,932 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #130: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3404255319148936, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.06, '(rev, 1)': 0.05, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-04-24 14:49:33,933 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:33,933 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4276206302331167
2024-04-24 14:49:34,407 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #130: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.5333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.03, '(min, 0)': 0.47, '(min, 1)': 0.09, '(rev, 1)': 0.12, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:49:34,407 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:34,408 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4276206302331167
2024-04-24 14:49:34,412 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #130: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5714285714285714, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.04, '(min, 0)': 0.23, '(min, 1)': 0.45, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:49:34,412 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:34,413 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4276206302331167
2024-04-24 14:49:34,496 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #130: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 7, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 8, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.04, '(min, 0)': 0.13, '(min, 1)': 0.5, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:49:34,496 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:34,496 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4276206302331167
2024-04-24 14:49:34,735 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #130: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4418604651162791, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(min, 0)': 0.31, '(min, 1)': 0.31, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:49:34,735 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:34,736 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4276206302331167
2024-04-24 14:49:34,909 - MainProcess - INFO - text_logger.py - 51 - Train epoch #130
2024-04-24 14:49:34,911 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.0499e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7823e-01, 0.0000e+00,
        1.7024e-01, 6.6323e-03, 3.9911e-01, 0.0000e+00, 1.4045e-02, 3.5631e-03,
        0.0000e+00, 0.0000e+00, 6.0884e-03, 2.3923e-03, 0.0000e+00, 0.0000e+00,
        5.2898e-03, 2.0088e-03, 0.0000e+00, 0.0000e+00, 3.6000e-03, 3.2895e-04,
        0.0000e+00, 0.0000e+00, 2.9504e-03, 2.6028e-04, 0.0000e+00, 0.0000e+00,
        2.3940e-03, 7.6923e-05, 0.0000e+00, 0.0000e+00, 1.8204e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.8587e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8865e-04, 0.0000e+00, 0.0000e+00])  tensor([2.3318e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5390e-01, 0.0000e+00,
        2.1764e-01, 1.3369e-02, 1.4520e-01, 0.0000e+00, 3.2716e-02, 1.0845e-02,
        0.0000e+00, 0.0000e+00, 1.6417e-02, 9.3805e-03, 0.0000e+00, 0.0000e+00,
        1.4741e-02, 9.0169e-03, 0.0000e+00, 0.0000e+00, 1.0509e-02, 2.4665e-03,
        0.0000e+00, 0.0000e+00, 9.0832e-03, 2.5697e-03, 0.0000e+00, 0.0000e+00,
        7.7961e-03, 1.7201e-03, 0.0000e+00, 0.0000e+00, 6.3507e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.6351e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7379e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:34,926 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4266798125905263
2024-04-24 14:49:34,928 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.269440.13056
2024-04-24 14:49:34,955 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #131: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.58, '(min, 1)': 0.06}}
2024-04-24 14:49:34,956 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:34,957 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.427083157919758
2024-04-24 14:49:35,237 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #131: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.044444444444444446, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 9)': 0.01, '(min, 0)': 0.52, '(min, 1)': 0.11, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-04-24 14:49:35,237 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:35,238 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.427083157919758
2024-04-24 14:49:35,392 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #131: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1590909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.36, '(min, 1)': 0.3, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-04-24 14:49:35,392 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:35,393 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.427083157919758
2024-04-24 14:49:35,835 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #131: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3125, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.41, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:49:35,835 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:35,836 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.427083157919758
2024-04-24 14:49:36,116 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #131: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.49, '(min, 1)': 0.13, '(rev, 1)': 0.01}}
2024-04-24 14:49:36,116 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:36,116 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.427083157919758
2024-04-24 14:49:36,208 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #131: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22916666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 8)': 0.02, '(min, 0)': 0.39, '(min, 1)': 0.27, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.03}}
2024-04-24 14:49:36,208 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:36,209 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.427083157919758
2024-04-24 14:49:36,376 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #131: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 5, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.9523809523809523, 'length': 100, 'actions': {'(ado, 1)': 0.09, '(ado, 3)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.21, '(rev, 1)': 0.12, '(rev, 2)': 0.03, '(rev, 3)': 0.04, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:49:36,376 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:36,377 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.427083157919758
2024-04-24 14:49:36,444 - MainProcess - INFO - text_logger.py - 51 - Train epoch #131
2024-04-24 14:49:36,447 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.5942e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.2670e-01,
         0.0000e+00,  4.0952e-01,  2.5105e-03,  1.7680e-01,  0.0000e+00,
         6.2959e-02,  1.2357e-03,  0.0000e+00,  0.0000e+00,  3.0890e-02,
         7.7158e-04,  0.0000e+00,  0.0000e+00,  2.7290e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  2.0133e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  1.6927e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         1.1409e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  8.5219e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.7018e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.3077e-04,  0.0000e+00,  0.0000e+00])  tensor([1.3729, 0.0000, 0.0000, 0.0000, 0.2249, 0.0000, 0.2555, 0.0085, 0.1656,
        0.0000, 0.0498, 0.0053, 0.0000, 0.0000, 0.0263, 0.0042, 0.0000, 0.0000,
        0.0240, 0.0000, 0.0000, 0.0000, 0.0186, 0.0000, 0.0000, 0.0000, 0.0167,
        0.0000, 0.0000, 0.0000, 0.0139, 0.0000, 0.0000, 0.0000, 0.0116, 0.0000,
        0.0000, 0.0000, 0.0075, 0.0000, 0.0000, 0.0000, 0.0032, 0.0000, 0.0000]) (500)
2024-04-24 14:49:36,458 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4266899593247867
2024-04-24 14:49:36,461 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.476190.47619
2024-04-24 14:49:36,502 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #132: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.36, '(min, 1)': 0.23}}
2024-04-24 14:49:36,502 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:36,503 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266798125905263
2024-04-24 14:49:36,523 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #132: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.42, '(min, 1)': 0.2}}
2024-04-24 14:49:36,523 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:36,525 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266798125905263
2024-04-24 14:49:37,237 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #132: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(min, 0)': 0.5, '(min, 1)': 0.09, '(rev, 1)': 0.06, '(rev, 2)': 0.07}}
2024-04-24 14:49:37,237 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:37,238 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266798125905263
2024-04-24 14:49:37,388 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #132: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.725, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 3)': 0.02, '(min, 0)': 0.3, '(min, 1)': 0.36, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.04, '(rev, 4)': 0.02}}
2024-04-24 14:49:37,388 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:37,388 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266798125905263
2024-04-24 14:49:37,488 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #132: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.11538461538461539, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.05, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.13, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:49:37,488 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:37,488 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266798125905263
2024-04-24 14:49:37,643 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #132: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.33, '(min, 1)': 0.25}}
2024-04-24 14:49:37,643 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:37,644 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266798125905263
2024-04-24 14:49:37,678 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #132: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17391304347826086, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 3)': 0.05, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.37, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:49:37,678 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:37,679 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266798125905263
2024-04-24 14:49:37,854 - MainProcess - INFO - text_logger.py - 51 - Train epoch #132
2024-04-24 14:49:37,857 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.3048e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.1992e-01,
         0.0000e+00,  2.1459e-01,  6.5803e-03,  3.5190e-01,  0.0000e+00,
         3.4513e-02,  3.2846e-03,  0.0000e+00,  0.0000e+00,  1.6990e-02,
         2.5261e-03,  0.0000e+00,  0.0000e+00,  1.3699e-02,  1.9375e-03,
         0.0000e+00,  0.0000e+00,  1.0716e-02,  1.7470e-04,  0.0000e+00,
         0.0000e+00,  9.4048e-03,  6.2261e-05,  0.0000e+00,  0.0000e+00,
         8.0637e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.1301e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.3384e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  1.7181e-04,  0.0000e+00,  0.0000e+00])  tensor([2.5062e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8023e-01, 0.0000e+00,
        2.1744e-01, 1.4223e-02, 1.8249e-01, 0.0000e+00, 5.4164e-02, 1.0665e-02,
        0.0000e+00, 0.0000e+00, 2.8380e-02, 1.0745e-02, 0.0000e+00, 0.0000e+00,
        2.4315e-02, 9.9166e-03, 0.0000e+00, 0.0000e+00, 1.8899e-02, 2.0692e-03,
        0.0000e+00, 0.0000e+00, 1.6671e-02, 9.8915e-04, 0.0000e+00, 0.0000e+00,
        1.4877e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0167e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.0773e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7300e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:37,873 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.42574772510666603
2024-04-24 14:49:37,875 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:49:37,918 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #133: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.49, '(min, 1)': 0.08}}
2024-04-24 14:49:37,918 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:37,919 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266899593247867
2024-04-24 14:49:37,971 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #133: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 3, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.23, '(rev, 1)': 0.01}}
2024-04-24 14:49:37,972 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:37,972 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266899593247867
2024-04-24 14:49:38,842 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #133: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 0, 1, 0),(rev, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '11/1', 'revenue': 0.6976744186046512, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.39, '(rev, 1)': 0.16, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:49:38,842 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:38,843 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266899593247867
2024-04-24 14:49:39,112 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #133: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.3684210526315789, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(min, 0)': 0.5, '(min, 1)': 0.13, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:49:39,112 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:39,113 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266899593247867
2024-04-24 14:49:39,278 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #133: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.02, '(ado, 3)': 0.04, '(ado, 5)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.47, '(rev, 1)': 0.14, '(rev, 2)': 0.01}}
2024-04-24 14:49:39,278 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:39,279 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266899593247867
2024-04-24 14:49:39,316 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #133: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3023255813953488, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.23, '(min, 1)': 0.38, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:49:39,317 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:39,317 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266899593247867
2024-04-24 14:49:39,478 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #133: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 7)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.15}}
2024-04-24 14:49:39,479 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:39,479 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266899593247867
2024-04-24 14:49:39,540 - MainProcess - INFO - text_logger.py - 51 - Train epoch #133
2024-04-24 14:49:39,542 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.3374e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3973e-01, 0.0000e+00,
        2.1102e-01, 7.7528e-03, 3.5380e-01, 0.0000e+00, 2.1735e-02, 8.2866e-03,
        0.0000e+00, 0.0000e+00, 1.0643e-02, 7.7164e-03, 0.0000e+00, 0.0000e+00,
        8.8872e-03, 5.1656e-03, 0.0000e+00, 0.0000e+00, 7.6764e-03, 2.3801e-04,
        0.0000e+00, 0.0000e+00, 6.9228e-03, 7.2066e-05, 0.0000e+00, 0.0000e+00,
        4.9209e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0699e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2293e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3125e-04, 0.0000e+00, 0.0000e+00])  tensor([2.3357e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6691e-01, 0.0000e+00,
        2.1804e-01, 1.5835e-02, 1.6055e-01, 0.0000e+00, 4.0121e-02, 1.9716e-02,
        0.0000e+00, 0.0000e+00, 2.1407e-02, 2.5038e-02, 0.0000e+00, 0.0000e+00,
        1.9015e-02, 1.9039e-02, 0.0000e+00, 0.0000e+00, 1.7050e-02, 2.0248e-03,
        0.0000e+00, 0.0000e+00, 1.5907e-02, 1.1484e-03, 0.0000e+00, 0.0000e+00,
        1.2248e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0759e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.0353e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4833e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:39,554 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4248054908885455
2024-04-24 14:49:39,556 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:49:39,572 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #134: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.15, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 9)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.24, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-04-24 14:49:39,572 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:39,572 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:39,573 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42574772510666603
2024-04-24 14:49:39,573 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42574772510666603
2024-04-24 14:49:40,285 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #134: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.19444444444444445, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.27, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:49:40,285 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:40,285 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42574772510666603
2024-04-24 14:49:40,710 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #134: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.29, '(min, 1)': 0.28}}
2024-04-24 14:49:40,710 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:40,710 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42574772510666603
2024-04-24 14:49:40,856 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #134: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 3, 7, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 3, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24390243902439024, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.49, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-04-24 14:49:40,856 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:40,856 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42574772510666603
2024-04-24 14:49:41,087 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #134: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 6, 9, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 6, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5263157894736842, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.27, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:49:41,087 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:41,088 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42574772510666603
2024-04-24 14:49:41,089 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #134: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 4, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 6, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.02127659574468085, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.02, '(ado, 9)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.29, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:49:41,089 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:41,089 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42574772510666603
2024-04-24 14:49:41,273 - MainProcess - INFO - text_logger.py - 51 - Train epoch #134
2024-04-24 14:49:41,276 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.8384e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4546e-01, 0.0000e+00,
        3.3795e-01, 4.2050e-03, 2.4580e-01, 0.0000e+00, 5.7459e-02, 4.0435e-03,
        0.0000e+00, 0.0000e+00, 2.4811e-02, 3.3477e-03, 0.0000e+00, 0.0000e+00,
        2.0374e-02, 2.4528e-03, 0.0000e+00, 0.0000e+00, 1.7247e-02, 1.3903e-04,
        0.0000e+00, 0.0000e+00, 1.5198e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1467e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.4610e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.2835e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.0678e-04, 0.0000e+00, 0.0000e+00])  tensor([2.2513e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9801e-01, 0.0000e+00,
        2.5094e-01, 1.2148e-02, 1.9180e-01, 0.0000e+00, 5.9159e-02, 1.2980e-02,
        0.0000e+00, 0.0000e+00, 2.8584e-02, 1.2599e-02, 0.0000e+00, 0.0000e+00,
        2.4843e-02, 1.1392e-02, 0.0000e+00, 0.0000e+00, 2.2180e-02, 1.8099e-03,
        0.0000e+00, 0.0000e+00, 2.0506e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7562e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3946e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.9388e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3043e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:41,289 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4238632566704249
2024-04-24 14:49:41,291 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:49:41,320 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #135: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.48, '(min, 1)': 0.14}}
2024-04-24 14:49:41,321 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:41,321 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4248054908885455
2024-04-24 14:49:41,410 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #135: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6976744186046512, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.35, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-04-24 14:49:41,410 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:41,412 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4248054908885455
2024-04-24 14:49:41,708 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #135: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17777777777777778, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:49:41,708 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:41,709 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4248054908885455
2024-04-24 14:49:41,908 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #135: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.48, '(min, 1)': 0.14}}
2024-04-24 14:49:41,909 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:41,909 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4248054908885455
2024-04-24 14:49:42,455 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #135: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0784313725490196, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.14, '(rev, 1)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:49:42,455 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:42,456 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4248054908885455
2024-04-24 14:49:42,504 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #135: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.14893617021276595, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 7)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.28, '(rev, 1)': 0.02, '(rev, 6)': 0.01}}
2024-04-24 14:49:42,504 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:42,505 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4248054908885455
2024-04-24 14:49:42,903 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #135: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7115384615384616, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.14, '(min, 1)': 0.5, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-04-24 14:49:42,903 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:42,904 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4248054908885455
2024-04-24 14:49:43,084 - MainProcess - INFO - text_logger.py - 51 - Train epoch #135
2024-04-24 14:49:43,086 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.3978e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4828e-01, 0.0000e+00,
        3.0883e-01, 5.2644e-03, 2.6643e-01, 0.0000e+00, 4.4209e-02, 3.9623e-03,
        0.0000e+00, 0.0000e+00, 2.8125e-02, 2.6784e-03, 0.0000e+00, 0.0000e+00,
        2.2716e-02, 1.0164e-03, 0.0000e+00, 0.0000e+00, 1.9744e-02, 1.1333e-04,
        0.0000e+00, 0.0000e+00, 1.7966e-02, 7.1429e-05, 0.0000e+00, 0.0000e+00,
        1.5731e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8865e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.2025e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.7635e-04, 0.0000e+00, 0.0000e+00])  tensor([2.6810e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9311e-01, 0.0000e+00,
        2.4081e-01, 1.3227e-02, 2.0485e-01, 0.0000e+00, 4.7975e-02, 1.1308e-02,
        0.0000e+00, 0.0000e+00, 3.3079e-02, 9.0925e-03, 0.0000e+00, 0.0000e+00,
        2.7781e-02, 6.1008e-03, 0.0000e+00, 0.0000e+00, 2.4731e-02, 1.9365e-03,
        0.0000e+00, 0.0000e+00, 2.2680e-02, 1.5972e-03, 0.0000e+00, 0.0000e+00,
        2.0095e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4605e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.7165e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5885e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:43,101 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.42292102245230434
2024-04-24 14:49:43,103 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:49:43,161 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #136: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.45, '(min, 1)': 0.2}}
2024-04-24 14:49:43,161 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:43,162 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4238632566704249
2024-04-24 14:49:43,218 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #136: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.23333333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(ado, 9)': 0.02, '(min, 0)': 0.41, '(min, 1)': 0.22, '(rev, 1)': 0.02, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-04-24 14:49:43,218 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:43,218 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4238632566704249
2024-04-24 14:49:43,448 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #136: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.44680851063829785, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.15, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:49:43,449 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:43,449 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4238632566704249
2024-04-24 14:49:43,848 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #136: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(ado, 7)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.18}}
2024-04-24 14:49:43,848 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:43,849 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4238632566704249
2024-04-24 14:49:43,888 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #136: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.47619047619047616, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.34, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:49:43,888 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:43,888 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4238632566704249
2024-04-24 14:49:43,911 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #136: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 4)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.11, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:49:43,911 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:43,912 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4238632566704249
2024-04-24 14:49:44,331 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #136: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 6, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6111111111111112, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.35, '(rev, 1)': 0.12, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:49:44,331 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:44,332 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4238632566704249
2024-04-24 14:49:44,508 - MainProcess - INFO - text_logger.py - 51 - Train epoch #136
2024-04-24 14:49:44,510 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.1528e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4231e-01, 0.0000e+00,
        2.0358e-01, 7.2246e-03, 3.4289e-01, 0.0000e+00, 2.6765e-02, 7.5528e-03,
        0.0000e+00, 0.0000e+00, 1.3583e-02, 6.2323e-03, 0.0000e+00, 0.0000e+00,
        1.1580e-02, 4.6583e-03, 0.0000e+00, 0.0000e+00, 9.1712e-03, 4.3432e-04,
        0.0000e+00, 0.0000e+00, 8.7522e-03, 5.4054e-05, 0.0000e+00, 0.0000e+00,
        7.2265e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0496e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.3377e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.9571e-04, 0.0000e+00, 0.0000e+00])  tensor([2.0924e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6680e-01, 0.0000e+00,
        1.9073e-01, 1.4794e-02, 1.6065e-01, 0.0000e+00, 4.9397e-02, 1.5709e-02,
        0.0000e+00, 0.0000e+00, 2.7653e-02, 1.8118e-02, 0.0000e+00, 0.0000e+00,
        2.5301e-02, 1.6459e-02, 0.0000e+00, 0.0000e+00, 2.0344e-02, 3.2828e-03,
        0.0000e+00, 0.0000e+00, 1.9684e-02, 1.2087e-03, 0.0000e+00, 0.0000e+00,
        1.6469e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1930e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.0765e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.1177e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:44,523 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.42197878823418383
2024-04-24 14:49:44,525 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:49:44,569 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #137: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.56, '(min, 1)': 0.06}}
2024-04-24 14:49:44,569 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:44,570 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42292102245230434
2024-04-24 14:49:44,884 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #137: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7948717948717948, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(min, 0)': 0.18, '(min, 1)': 0.45, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.03}}
2024-04-24 14:49:44,885 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:44,885 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42292102245230434
2024-04-24 14:49:45,063 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #137: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.16, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:49:45,063 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:45,064 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42292102245230434
2024-04-24 14:49:45,073 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #137: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.52, '(min, 1)': 0.07}}
2024-04-24 14:49:45,073 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:45,074 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42292102245230434
2024-04-24 14:49:45,310 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #137: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 4, 7, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 5, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3684210526315789, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 5)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.37, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-04-24 14:49:45,311 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:45,311 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42292102245230434
2024-04-24 14:49:45,314 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #137: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.31, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:49:45,314 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:45,315 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42292102245230434
2024-04-24 14:49:45,696 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #137: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 4)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.23, '(rev, 1)': 0.01}}
2024-04-24 14:49:45,697 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:45,697 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42292102245230434
2024-04-24 14:49:45,881 - MainProcess - INFO - text_logger.py - 51 - Train epoch #137
2024-04-24 14:49:45,883 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.8674e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1105e-01, 0.0000e+00,
        2.5110e-01, 5.9614e-03, 3.1957e-01, 0.0000e+00, 2.8922e-02, 4.5877e-03,
        0.0000e+00, 0.0000e+00, 1.7229e-02, 3.7805e-03, 0.0000e+00, 0.0000e+00,
        1.3958e-02, 2.3958e-03, 0.0000e+00, 0.0000e+00, 1.2725e-02, 1.1774e-04,
        0.0000e+00, 0.0000e+00, 1.1176e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.5872e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8826e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.6920e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7440e-04, 0.0000e+00, 0.0000e+00])  tensor([1.9167e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8288e-01, 0.0000e+00,
        2.3351e-01, 1.3550e-02, 1.8426e-01, 0.0000e+00, 4.2745e-02, 1.2814e-02,
        0.0000e+00, 0.0000e+00, 2.7498e-02, 1.3621e-02, 0.0000e+00, 0.0000e+00,
        2.2925e-02, 1.0088e-02, 0.0000e+00, 0.0000e+00, 2.1574e-02, 1.5175e-03,
        0.0000e+00, 0.0000e+00, 1.9582e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7868e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2846e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.7453e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.1718e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:45,898 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.42103655401606316
2024-04-24 14:49:45,900 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:49:46,227 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #138: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(ado, 6)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 3, 0, 0)', 'reward_ratio': '0/6', 'revenue': 0.4318181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 6)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.16, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:49:46,227 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:46,228 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42197878823418383
2024-04-24 14:49:46,307 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #138: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.4, '(min, 1)': 0.21}}
2024-04-24 14:49:46,308 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:46,309 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42197878823418383
2024-04-24 14:49:46,443 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #138: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 9)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.46, '(rev, 1)': 0.06, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:49:46,443 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:46,443 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42197878823418383
2024-04-24 14:49:46,987 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #138: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.2830188679245283, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.24, '(rev, 1)': 0.04, '(rev, 2)': 0.01}}
2024-04-24 14:49:46,987 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:46,987 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42197878823418383
2024-04-24 14:49:47,029 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #138: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.25}}
2024-04-24 14:49:47,029 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:47,030 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42197878823418383
2024-04-24 14:49:47,035 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #138: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.32653061224489793, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.3, '(rev, 1)': 0.01, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:49:47,035 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:47,036 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42197878823418383
2024-04-24 14:49:47,041 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #138: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.58, '(min, 1)': 0.08, '(rev, 1)': 0.01}}
2024-04-24 14:49:47,042 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:47,042 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42197878823418383
2024-04-24 14:49:47,221 - MainProcess - INFO - text_logger.py - 51 - Train epoch #138
2024-04-24 14:49:47,224 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.2208e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.3518e-01,
         0.0000e+00,  2.7444e-01,  3.1202e-03,  2.3519e-01,  0.0000e+00,
         6.3325e-02,  1.6597e-03,  0.0000e+00,  0.0000e+00,  4.1458e-02,
         7.7611e-04,  0.0000e+00,  0.0000e+00,  3.6244e-02,  4.7647e-04,
         0.0000e+00,  0.0000e+00,  3.2952e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  2.7602e-02,  7.1429e-05,  0.0000e+00,  0.0000e+00,
         2.5820e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.6643e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.3335e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  7.1369e-04,  0.0000e+00,  0.0000e+00])  tensor([1.8078e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9683e-01, 0.0000e+00,
        1.8608e-01, 9.5051e-03, 1.9759e-01, 0.0000e+00, 5.6890e-02, 7.2867e-03,
        0.0000e+00, 0.0000e+00, 3.8961e-02, 5.6608e-03, 0.0000e+00, 0.0000e+00,
        3.5396e-02, 4.1608e-03, 0.0000e+00, 0.0000e+00, 3.3341e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.9394e-02, 1.5972e-03, 0.0000e+00, 0.0000e+00,
        2.9014e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0164e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.3067e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.3824e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:47,238 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4200943197979426
2024-04-24 14:49:47,240 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:49:47,457 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #139: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.57, '(min, 1)': 0.03}}
2024-04-24 14:49:47,457 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:47,458 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42103655401606316
2024-04-24 14:49:47,622 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #139: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.2, '(rev, 1)': 0.01}}
2024-04-24 14:49:47,622 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:47,622 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42103655401606316
2024-04-24 14:49:48,016 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #139: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.03}}
2024-04-24 14:49:48,016 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:48,017 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42103655401606316
2024-04-24 14:49:48,292 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #139: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.47, '(min, 1)': 0.14}}
2024-04-24 14:49:48,292 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:48,293 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42103655401606316
2024-04-24 14:49:48,421 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #139: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.18604651162790697, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.15, '(rev, 1)': 0.06, '(rev, 2)': 0.04}}
2024-04-24 14:49:48,421 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:48,422 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42103655401606316
2024-04-24 14:49:48,646 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #139: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.23404255319148937, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 8)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.17, '(rev, 1)': 0.05, '(rev, 2)': 0.04}}
2024-04-24 14:49:48,646 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:48,647 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42103655401606316
2024-04-24 14:49:48,959 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #139: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3076923076923077, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.22, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:49:48,959 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:48,960 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42103655401606316
2024-04-24 14:49:49,145 - MainProcess - INFO - text_logger.py - 51 - Train epoch #139
2024-04-24 14:49:49,148 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.0141e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9014e-01, 0.0000e+00,
        2.6981e-01, 5.2293e-03, 2.9283e-01, 0.0000e+00, 3.8843e-02, 3.4740e-03,
        0.0000e+00, 0.0000e+00, 2.3052e-02, 2.6448e-03, 0.0000e+00, 0.0000e+00,
        1.8557e-02, 1.3080e-03, 0.0000e+00, 0.0000e+00, 1.5940e-02, 2.4143e-04,
        0.0000e+00, 0.0000e+00, 1.4052e-02, 1.3164e-04, 0.0000e+00, 0.0000e+00,
        1.2033e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.2183e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.3338e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6628e-04, 0.0000e+00, 0.0000e+00])  tensor([1.9598e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9505e-01, 0.0000e+00,
        2.4274e-01, 1.2688e-02, 1.9504e-01, 0.0000e+00, 4.8336e-02, 1.0400e-02,
        0.0000e+00, 0.0000e+00, 3.0533e-02, 1.1353e-02, 0.0000e+00, 0.0000e+00,
        2.6291e-02, 7.0550e-03, 0.0000e+00, 0.0000e+00, 2.4008e-02, 2.3485e-03,
        0.0000e+00, 0.0000e+00, 2.2360e-02, 1.4726e-03, 0.0000e+00, 0.0000e+00,
        2.0109e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6435e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.0205e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6758e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:49,162 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.41915208557982203
2024-04-24 14:49:49,164 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:49:49,324 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #140: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.21739130434782608, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(min, 0)': 0.5, '(min, 1)': 0.09, '(rev, 1)': 0.06, '(rev, 2)': 0.05}}
2024-04-24 14:49:49,324 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:49,325 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4200943197979426
2024-04-24 14:49:49,683 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #140: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.44, '(min, 1)': 0.31, '(rev, 1)': 0.01}}
2024-04-24 14:49:49,683 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:49,684 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4200943197979426
2024-04-24 14:49:49,714 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #140: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.33, '(rev, 1)': 0.04, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:49:49,714 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:49,715 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4200943197979426
2024-04-24 14:49:50,007 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #140: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 6, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 7, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2972972972972973, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.37, '(rev, 1)': 0.06, '(rev, 2)': 0.05}}
2024-04-24 14:49:50,007 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:50,008 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4200943197979426
2024-04-24 14:49:50,241 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #140: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.02564102564102564, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.52, '(min, 1)': 0.09, '(rev, 1)': 0.01}}
2024-04-24 14:49:50,241 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:50,242 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4200943197979426
2024-04-24 14:49:50,287 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #140: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.08, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.47, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:49:50,287 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:50,288 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4200943197979426
2024-04-24 14:49:50,593 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #140: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.34, '(rev, 1)': 0.04, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:49:50,594 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:50,594 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4200943197979426
2024-04-24 14:49:50,782 - MainProcess - INFO - text_logger.py - 51 - Train epoch #140
2024-04-24 14:49:50,784 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.6362e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0083e-01, 0.0000e+00,
        2.0344e-01, 6.3883e-03, 3.1002e-01, 0.0000e+00, 4.9185e-02, 3.7111e-03,
        0.0000e+00, 0.0000e+00, 2.7737e-02, 2.8420e-03, 0.0000e+00, 0.0000e+00,
        2.4301e-02, 2.4362e-03, 0.0000e+00, 0.0000e+00, 2.1381e-02, 1.6987e-04,
        0.0000e+00, 0.0000e+00, 1.7757e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6215e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0779e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.5101e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.0517e-04, 0.0000e+00, 0.0000e+00])  tensor([1.6505, 0.0000, 0.0000, 0.0000, 0.1897, 0.0000, 0.1809, 0.0141, 0.1894,
        0.0000, 0.0639, 0.0117, 0.0000, 0.0000, 0.0381, 0.0131, 0.0000, 0.0000,
        0.0356, 0.0114, 0.0000, 0.0000, 0.0334, 0.0020, 0.0000, 0.0000, 0.0293,
        0.0000, 0.0000, 0.0000, 0.0283, 0.0000, 0.0000, 0.0000, 0.0193, 0.0000,
        0.0000, 0.0000, 0.0075, 0.0000, 0.0000, 0.0000, 0.0023, 0.0000, 0.0000]) (500)
2024-04-24 14:49:50,801 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.41848549238734256
2024-04-24 14:49:50,802 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.137820.11218
2024-04-24 14:49:51,148 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #141: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 3, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.44, '(min, 1)': 0.17}}
2024-04-24 14:49:51,148 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:51,149 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41915208557982203
2024-04-24 14:49:51,481 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #141: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 5, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6097560975609756, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(min, 0)': 0.15, '(min, 1)': 0.47, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:49:51,481 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:51,481 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41915208557982203
2024-04-24 14:49:51,705 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #141: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10638297872340426, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 9)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.17, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:49:51,706 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:51,707 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41915208557982203
2024-04-24 14:49:52,196 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #141: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6136363636363636, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(min, 0)': 0.14, '(min, 1)': 0.46, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:49:52,196 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:52,197 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41915208557982203
2024-04-24 14:49:52,245 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #141: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.21818181818181817, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.04, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.42, '(rev, 1)': 0.03, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:49:52,245 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:52,246 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41915208557982203
2024-04-24 14:49:52,395 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #141: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1875, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.16, '(rev, 1)': 0.08, '(rev, 2)': 0.04}}
2024-04-24 14:49:52,395 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:52,395 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41915208557982203
2024-04-24 14:49:53,027 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #141: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.2, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:49:53,027 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:53,028 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41915208557982203
2024-04-24 14:49:53,104 - MainProcess - INFO - text_logger.py - 51 - Train epoch #141
2024-04-24 14:49:53,107 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.9417e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4688e-01, 0.0000e+00,
        2.0225e-01, 6.9166e-03, 3.4418e-01, 0.0000e+00, 2.3317e-02, 3.5633e-03,
        0.0000e+00, 0.0000e+00, 1.5635e-02, 2.1161e-03, 0.0000e+00, 0.0000e+00,
        1.2962e-02, 1.2358e-03, 0.0000e+00, 0.0000e+00, 1.2098e-02, 2.2684e-04,
        0.0000e+00, 0.0000e+00, 9.9228e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.2827e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3079e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.8549e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5212e-04, 0.0000e+00, 0.0000e+00])  tensor([1.8619, 0.0000, 0.0000, 0.0000, 0.1782, 0.0000, 0.2130, 0.0145, 0.1743,
        0.0000, 0.0394, 0.0112, 0.0000, 0.0000, 0.0292, 0.0108, 0.0000, 0.0000,
        0.0257, 0.0074, 0.0000, 0.0000, 0.0245, 0.0026, 0.0000, 0.0000, 0.0208,
        0.0000, 0.0000, 0.0000, 0.0197, 0.0000, 0.0000, 0.0000, 0.0158, 0.0000,
        0.0000, 0.0000, 0.0062, 0.0000, 0.0000, 0.0000, 0.0020, 0.0000, 0.0000]) (500)
2024-04-24 14:49:53,121 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.41805436928033307
2024-04-24 14:49:53,123 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.255560.25556
2024-04-24 14:49:53,166 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #142: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.48, '(min, 1)': 0.15}}
2024-04-24 14:49:53,167 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:53,168 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41848549238734256
2024-04-24 14:49:53,267 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #142: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.07, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-04-24 14:49:53,267 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:53,268 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41848549238734256
2024-04-24 14:49:53,288 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #142: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37037037037037035, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.03, '(ado, 9)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.14, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:49:53,288 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:53,288 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41848549238734256
2024-04-24 14:49:53,903 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #142: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.25, '(rev, 1)': 0.11, '(rev, 2)': 0.01, '(rev, 3)': 0.03}}
2024-04-24 14:49:53,903 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:53,904 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41848549238734256
2024-04-24 14:49:54,283 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #142: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 5, 0, 1),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 5, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.17, '(min, 1)': 0.44, '(rev, 1)': 0.06, '(rev, 2)': 0.06}}
2024-04-24 14:49:54,283 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:54,284 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41848549238734256
2024-04-24 14:49:54,458 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #142: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.56, '(min, 1)': 0.01}}
2024-04-24 14:49:54,458 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:54,459 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41848549238734256
2024-04-24 14:49:54,668 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #142: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 2, 1, 1),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.2608695652173913, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.19, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:49:54,668 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:54,668 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41848549238734256
2024-04-24 14:49:54,851 - MainProcess - INFO - text_logger.py - 51 - Train epoch #142
2024-04-24 14:49:54,853 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([9.2871e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1393e-01, 0.0000e+00,
        1.1417e-01, 7.7451e-03, 4.1860e-01, 0.0000e+00, 1.2916e-02, 3.4339e-03,
        0.0000e+00, 0.0000e+00, 7.0701e-03, 1.2815e-03, 0.0000e+00, 0.0000e+00,
        5.9288e-03, 4.0196e-04, 0.0000e+00, 0.0000e+00, 4.9667e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.7117e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.3057e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0809e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.2635e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4483e-05, 0.0000e+00, 0.0000e+00])  tensor([1.3769e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2447e-01, 0.0000e+00,
        1.4591e-01, 1.4839e-02, 1.2343e-01, 0.0000e+00, 3.5676e-02, 9.8066e-03,
        0.0000e+00, 0.0000e+00, 2.1961e-02, 6.5837e-03, 0.0000e+00, 0.0000e+00,
        2.0244e-02, 3.7448e-03, 0.0000e+00, 0.0000e+00, 1.8226e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.4471e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3790e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.2119e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.1913e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.7106e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:54,867 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.41711213506221245
2024-04-24 14:49:54,870 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:49:54,883 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #143: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 3, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 3, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.49, '(min, 1)': 0.13}}
2024-04-24 14:49:54,884 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:54,885 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41805436928033307
2024-04-24 14:49:55,332 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #143: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.46, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.13, '(rev, 1)': 0.11, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:49:55,332 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:55,332 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41805436928033307
2024-04-24 14:49:55,612 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #143: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 7, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1282051282051282, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.3, '(rev, 5)': 0.01}}
2024-04-24 14:49:55,612 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:55,613 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41805436928033307
2024-04-24 14:49:56,149 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #143: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3404255319148936, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 9)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.39, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-04-24 14:49:56,149 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:56,150 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41805436928033307
2024-04-24 14:49:56,235 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #143: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 5, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2553191489361702, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.35, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 6)': 0.01}}
2024-04-24 14:49:56,235 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:56,236 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41805436928033307
2024-04-24 14:49:56,363 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #143: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.21951219512195122, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.22, '(rev, 1)': 0.07, '(rev, 2)': 0.04}}
2024-04-24 14:49:56,363 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:56,363 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41805436928033307
2024-04-24 14:49:56,703 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #143: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.37, '(rev, 1)': 0.03, '(rev, 2)': 0.03}}
2024-04-24 14:49:56,704 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:56,704 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41805436928033307
2024-04-24 14:49:56,775 - MainProcess - INFO - text_logger.py - 51 - Train epoch #143
2024-04-24 14:49:56,778 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.4367e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3872e-01, 0.0000e+00,
        2.0018e-01, 5.6961e-03, 3.3868e-01, 0.0000e+00, 3.2642e-02, 2.3705e-03,
        0.0000e+00, 0.0000e+00, 2.0182e-02, 1.5493e-03, 0.0000e+00, 0.0000e+00,
        1.6231e-02, 1.0022e-03, 0.0000e+00, 0.0000e+00, 1.4174e-02, 1.2548e-04,
        0.0000e+00, 0.0000e+00, 1.0911e-02, 7.1429e-05, 0.0000e+00, 0.0000e+00,
        9.4563e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2378e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.6080e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6797e-04, 0.0000e+00, 0.0000e+00])  tensor([1.6451e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7809e-01, 0.0000e+00,
        2.0688e-01, 1.3590e-02, 1.7697e-01, 0.0000e+00, 5.0534e-02, 8.6905e-03,
        0.0000e+00, 0.0000e+00, 3.3943e-02, 7.3539e-03, 0.0000e+00, 0.0000e+00,
        2.9788e-02, 6.5778e-03, 0.0000e+00, 0.0000e+00, 2.7713e-02, 2.0011e-03,
        0.0000e+00, 0.0000e+00, 2.3230e-02, 1.5972e-03, 0.0000e+00, 0.0000e+00,
        2.1771e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5428e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.8532e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6973e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:56,790 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.41647899175318287
2024-04-24 14:49:56,792 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.154550.15455
2024-04-24 14:49:56,837 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #144: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.45, '(min, 0)': 0.42, '(min, 1)': 0.13}}
2024-04-24 14:49:56,837 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:56,838 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41711213506221245
2024-04-24 14:49:57,100 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #144: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 5)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.31, '(rev, 1)': 0.01, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:49:57,100 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:57,100 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41711213506221245
2024-04-24 14:49:57,444 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #144: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.65, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(min, 0)': 0.22, '(min, 1)': 0.41, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-24 14:49:57,444 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:57,445 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41711213506221245
2024-04-24 14:49:57,820 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #144: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 6)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.14}}
2024-04-24 14:49:57,820 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:57,820 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41711213506221245
2024-04-24 14:49:58,253 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #144: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(min, 0)': 0.5, '(min, 1)': 0.16}}
2024-04-24 14:49:58,253 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:58,253 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41711213506221245
2024-04-24 14:49:58,304 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #144: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.024390243902439025, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 9)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.2, '(rev, 1)': 0.02}}
2024-04-24 14:49:58,304 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:58,304 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41711213506221245
2024-04-24 14:49:58,505 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #144: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.52, '(min, 1)': 0.19, '(rev, 1)': 0.01}}
2024-04-24 14:49:58,506 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:58,506 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41711213506221245
2024-04-24 14:49:58,694 - MainProcess - INFO - text_logger.py - 51 - Train epoch #144
2024-04-24 14:49:58,696 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.3074e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.7883e-01,
         0.0000e+00,  3.2801e-01,  2.5755e-03,  1.8010e-01,  0.0000e+00,
         6.9948e-02,  1.7457e-03,  0.0000e+00,  0.0000e+00,  5.2827e-02,
         1.2128e-03,  0.0000e+00,  0.0000e+00,  4.5870e-02,  6.0014e-04,
         0.0000e+00,  0.0000e+00,  4.0756e-02,  7.4074e-05,  0.0000e+00,
         0.0000e+00,  3.4107e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.2038e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.4864e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  5.7115e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  7.3494e-04,  0.0000e+00,  0.0000e+00])  tensor([2.0438e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8490e-01, 0.0000e+00,
        1.9680e-01, 1.0139e-02, 1.9102e-01, 0.0000e+00, 4.8756e-02, 7.7043e-03,
        0.0000e+00, 0.0000e+00, 3.9203e-02, 6.6002e-03, 0.0000e+00, 0.0000e+00,
        3.5908e-02, 4.3085e-03, 0.0000e+00, 0.0000e+00, 3.3661e-02, 1.6563e-03,
        0.0000e+00, 0.0000e+00, 2.8872e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7981e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2055e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.6482e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4146e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:49:58,710 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4155367575350623
2024-04-24 14:49:58,712 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:49:58,726 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #145: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.55, '(min, 1)': 0.1}}
2024-04-24 14:49:58,726 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:58,727 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41647899175318287
2024-04-24 14:49:58,753 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #145: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 7, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 7, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.48936170212765956, 'length': 100, 'actions': {'(ado, 1)': 0.04, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.36, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.03, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:49:58,753 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:58,754 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41647899175318287
2024-04-24 14:49:58,776 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #145: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.58, '(min, 1)': 0.08}}
2024-04-24 14:49:58,777 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:58,778 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41647899175318287
2024-04-24 14:49:59,566 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #145: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.32, '(min, 1)': 0.31}}
2024-04-24 14:49:59,566 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:59,566 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41647899175318287
2024-04-24 14:49:59,655 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #145: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 10)': 0.01, '(min, 0)': 0.61, '(min, 1)': 0.07}}
2024-04-24 14:49:59,656 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:59,656 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41647899175318287
2024-04-24 14:49:59,932 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #145: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.18604651162790697, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.33, '(rev, 1)': 0.01, '(rev, 2)': 0.04}}
2024-04-24 14:49:59,932 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:49:59,933 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41647899175318287
2024-04-24 14:50:00,172 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #145: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2682926829268293, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.28, '(rev, 1)': 0.01}}
2024-04-24 14:50:00,172 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:00,172 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41647899175318287
2024-04-24 14:50:00,348 - MainProcess - INFO - text_logger.py - 51 - Train epoch #145
2024-04-24 14:50:00,351 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-7.1296e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2924e-01,
         0.0000e+00,  3.2166e-01,  1.9962e-03,  1.3337e-01,  0.0000e+00,
         1.0312e-01,  9.8649e-04,  0.0000e+00,  0.0000e+00,  6.8767e-02,
         4.5025e-04,  0.0000e+00,  0.0000e+00,  6.1879e-02,  1.6517e-04,
         0.0000e+00,  0.0000e+00,  5.5077e-02,  7.1429e-05,  0.0000e+00,
         0.0000e+00,  4.4419e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.9456e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.0135e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  7.7585e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  1.4573e-03,  0.0000e+00,  0.0000e+00])  tensor([1.4272, 0.0000, 0.0000, 0.0000, 0.1513, 0.0000, 0.1345, 0.0086, 0.1597,
        0.0000, 0.0495, 0.0057, 0.0000, 0.0000, 0.0358, 0.0035, 0.0000, 0.0000,
        0.0348, 0.0021, 0.0000, 0.0000, 0.0335, 0.0016, 0.0000, 0.0000, 0.0291,
        0.0000, 0.0000, 0.0000, 0.0278, 0.0000, 0.0000, 0.0000, 0.0219, 0.0000,
        0.0000, 0.0000, 0.0108, 0.0000, 0.0000, 0.0000, 0.0049, 0.0000, 0.0000]) (500)
2024-04-24 14:50:00,362 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.41459452331694174
2024-04-24 14:50:00,364 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:50:00,395 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #146: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.02, '(min, 0)': 0.45, '(min, 1)': 0.22}}
2024-04-24 14:50:00,395 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:00,396 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4155367575350623
2024-04-24 14:50:00,411 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #146: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.49, '(min, 1)': 0.08}}
2024-04-24 14:50:00,411 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:00,412 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4155367575350623
2024-04-24 14:50:00,822 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #146: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.51, '(min, 1)': 0.08}}
2024-04-24 14:50:00,822 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:00,823 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4155367575350623
2024-04-24 14:50:00,932 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #146: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.18, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:50:00,932 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:00,933 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4155367575350623
2024-04-24 14:50:01,284 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #146: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 4)': 0.01, '(ado, 7)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.61, '(min, 1)': 0.08}}
2024-04-24 14:50:01,284 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:01,285 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4155367575350623
2024-04-24 14:50:01,485 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #146: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.23}}
2024-04-24 14:50:01,485 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:01,485 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4155367575350623
2024-04-24 14:50:01,957 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #146: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.02, '(ado, 8)': 0.02, '(min, 0)': 0.48, '(min, 1)': 0.24, '(rev, 1)': 0.01}}
2024-04-24 14:50:01,957 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:01,957 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4155367575350623
2024-04-24 14:50:02,142 - MainProcess - INFO - text_logger.py - 51 - Train epoch #146
2024-04-24 14:50:02,145 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-4.5010e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4411e-01,
         0.0000e+00,  3.5800e-01,  1.0648e-03,  1.4846e-01,  0.0000e+00,
         8.1611e-02,  5.2349e-04,  0.0000e+00,  0.0000e+00,  6.0310e-02,
         1.9307e-04,  0.0000e+00,  0.0000e+00,  5.1730e-02,  7.1429e-05,
         0.0000e+00,  0.0000e+00,  4.6823e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  3.7948e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.4656e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.6576e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  6.8143e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  1.1101e-03,  0.0000e+00,  0.0000e+00])  tensor([1.9707e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6081e-01, 0.0000e+00,
        1.6090e-01, 7.1607e-03, 1.6738e-01, 0.0000e+00, 4.2326e-02, 3.7744e-03,
        0.0000e+00, 0.0000e+00, 3.3764e-02, 2.2417e-03, 0.0000e+00, 0.0000e+00,
        3.1772e-02, 1.5972e-03, 0.0000e+00, 0.0000e+00, 3.1148e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.7740e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7328e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3357e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0634e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.1742e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:02,158 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4136522890988211
2024-04-24 14:50:02,160 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:50:02,173 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #147: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.39, '(min, 1)': 0.19}}
2024-04-24 14:50:02,173 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:02,174 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41459452331694174
2024-04-24 14:50:02,204 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #147: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 5, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.13}}
2024-04-24 14:50:02,206 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:02,206 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41459452331694174
2024-04-24 14:50:02,230 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #147: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.11627906976744186, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.26, '(rev, 1)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:50:02,230 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:02,230 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41459452331694174
2024-04-24 14:50:02,660 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #147: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32653061224489793, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.14, '(rev, 6)': 0.01}}
2024-04-24 14:50:02,660 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:02,660 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41459452331694174
2024-04-24 14:50:02,756 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #147: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.28846153846153844, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 8)': 0.02, '(min, 0)': 0.41, '(min, 1)': 0.29, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 6)': 0.01}}
2024-04-24 14:50:02,756 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:02,757 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41459452331694174
2024-04-24 14:50:02,926 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #147: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.29545454545454547, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.25, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:50:02,926 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:02,927 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41459452331694174
2024-04-24 14:50:03,843 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #147: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 5, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0975609756097561, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.26, '(rev, 3)': 0.01}}
2024-04-24 14:50:03,843 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:03,844 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41459452331694174
2024-04-24 14:50:04,030 - MainProcess - INFO - text_logger.py - 51 - Train epoch #147
2024-04-24 14:50:04,032 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-6.0318e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.6513e-01,
         0.0000e+00,  2.8501e-01,  1.5497e-03,  1.7003e-01,  0.0000e+00,
         1.0215e-01,  1.8539e-03,  0.0000e+00,  0.0000e+00,  6.2745e-02,
         1.7886e-03,  0.0000e+00,  0.0000e+00,  5.5057e-02,  4.6168e-04,
         0.0000e+00,  0.0000e+00,  4.8059e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  3.9982e-02,  6.8966e-05,  0.0000e+00,  0.0000e+00,
         3.3653e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.5306e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  6.1652e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  9.8754e-04,  0.0000e+00,  0.0000e+00])  tensor([1.4239, 0.0000, 0.0000, 0.0000, 0.1659, 0.0000, 0.1329, 0.0075, 0.1671,
        0.0000, 0.0633, 0.0086, 0.0000, 0.0000, 0.0425, 0.0095, 0.0000, 0.0000,
        0.0406, 0.0043, 0.0000, 0.0000, 0.0374, 0.0000, 0.0000, 0.0000, 0.0333,
        0.0015, 0.0000, 0.0000, 0.0305, 0.0000, 0.0000, 0.0000, 0.0257, 0.0000,
        0.0000, 0.0000, 0.0110, 0.0000, 0.0000, 0.0000, 0.0040, 0.0000, 0.0000]) (500)
2024-04-24 14:50:04,045 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4130365854929454
2024-04-24 14:50:04,046 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.163270.16327
2024-04-24 14:50:04,061 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #148: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.42, '(min, 1)': 0.19}}
2024-04-24 14:50:04,061 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:04,061 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4136522890988211
2024-04-24 14:50:04,076 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #148: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.56, '(min, 1)': 0.07}}
2024-04-24 14:50:04,076 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:04,077 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4136522890988211
2024-04-24 14:50:04,107 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #148: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.41025641025641024, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.24, '(min, 1)': 0.39, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:50:04,107 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:04,108 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4136522890988211
2024-04-24 14:50:04,176 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #148: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2926829268292683, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.39, '(rev, 1)': 0.11, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:50:04,176 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:04,177 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4136522890988211
2024-04-24 14:50:04,644 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #148: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5882352941176471, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.35, '(rev, 1)': 0.02, '(rev, 2)': 0.03, '(rev, 3)': 0.04, '(rev, 4)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:50:04,644 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:04,645 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4136522890988211
2024-04-24 14:50:04,927 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #148: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.28, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:50:04,927 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:04,928 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4136522890988211
2024-04-24 14:50:05,876 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #148: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.18, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.33, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:50:05,876 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:05,877 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4136522890988211
2024-04-24 14:50:06,062 - MainProcess - INFO - text_logger.py - 51 - Train epoch #148
2024-04-24 14:50:06,065 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0252e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3738e-01, 0.0000e+00,
        2.8764e-01, 3.3703e-03, 2.4286e-01, 0.0000e+00, 5.1060e-02, 2.8756e-03,
        0.0000e+00, 0.0000e+00, 3.8639e-02, 3.2626e-03, 0.0000e+00, 0.0000e+00,
        3.3058e-02, 1.5359e-03, 0.0000e+00, 0.0000e+00, 2.9828e-02, 2.6294e-04,
        0.0000e+00, 0.0000e+00, 2.4469e-02, 1.8746e-04, 0.0000e+00, 0.0000e+00,
        2.1916e-02, 6.8966e-05, 0.0000e+00, 0.0000e+00, 1.6613e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.1433e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.3220e-04, 0.0000e+00, 0.0000e+00])  tensor([2.2117e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9026e-01, 0.0000e+00,
        1.9499e-01, 1.0731e-02, 1.9217e-01, 0.0000e+00, 4.8693e-02, 1.1615e-02,
        0.0000e+00, 0.0000e+00, 4.0195e-02, 1.5964e-02, 0.0000e+00, 0.0000e+00,
        3.6413e-02, 9.1956e-03, 0.0000e+00, 0.0000e+00, 3.3995e-02, 2.3788e-03,
        0.0000e+00, 0.0000e+00, 2.8905e-02, 2.0146e-03, 0.0000e+00, 0.0000e+00,
        2.7439e-02, 1.5421e-03, 0.0000e+00, 0.0000e+00, 2.1627e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.1865e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.1631e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:06,080 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4125046076850813
2024-04-24 14:50:06,082 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.205130.20513
2024-04-24 14:50:06,094 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #149: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.26666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.13, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-04-24 14:50:06,094 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:06,094 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4130365854929454
2024-04-24 14:50:06,110 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #149: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0851063829787234, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.35, '(rev, 1)': 0.03, '(rev, 2)': 0.01}}
2024-04-24 14:50:06,110 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:06,110 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4130365854929454
2024-04-24 14:50:06,127 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #149: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.49, '(min, 1)': 0.14}}
2024-04-24 14:50:06,127 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:06,128 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4130365854929454
2024-04-24 14:50:06,169 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #149: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 0, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.358974358974359, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.42, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:50:06,169 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:06,170 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4130365854929454
2024-04-24 14:50:06,443 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #149: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17391304347826086, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.26, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:50:06,444 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:06,445 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4130365854929454
2024-04-24 14:50:06,941 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #149: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.25, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:50:06,941 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:06,941 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4130365854929454
2024-04-24 14:50:07,711 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #149: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6122448979591837, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.39, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:50:07,711 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:07,711 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4130365854929454
2024-04-24 14:50:07,886 - MainProcess - INFO - text_logger.py - 51 - Train epoch #149
2024-04-24 14:50:07,889 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.9765e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7802e-01, 0.0000e+00,
        2.1620e-01, 3.2671e-03, 2.8842e-01, 0.0000e+00, 5.0110e-02, 4.0361e-03,
        0.0000e+00, 0.0000e+00, 3.3051e-02, 4.8190e-03, 0.0000e+00, 0.0000e+00,
        2.9956e-02, 2.5086e-03, 0.0000e+00, 0.0000e+00, 2.6768e-02, 6.0657e-04,
        0.0000e+00, 0.0000e+00, 2.2365e-02, 3.4164e-04, 0.0000e+00, 0.0000e+00,
        2.1026e-02, 3.4164e-04, 0.0000e+00, 0.0000e+00, 1.4853e-02, 1.4737e-04,
        0.0000e+00, 0.0000e+00, 2.6984e-03, 3.1746e-05, 0.0000e+00, 0.0000e+00,
        4.3727e-04, 0.0000e+00, 0.0000e+00])  tensor([2.9181e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8253e-01, 0.0000e+00,
        1.8194e-01, 9.4647e-03, 1.8797e-01, 0.0000e+00, 6.1781e-02, 1.2156e-02,
        0.0000e+00, 0.0000e+00, 4.5654e-02, 1.6398e-02, 0.0000e+00, 0.0000e+00,
        4.3692e-02, 9.5210e-03, 0.0000e+00, 0.0000e+00, 4.0146e-02, 3.6784e-03,
        0.0000e+00, 0.0000e+00, 3.4219e-02, 2.2144e-03, 0.0000e+00, 0.0000e+00,
        3.3257e-02, 2.2144e-03, 0.0000e+00, 0.0000e+00, 2.4211e-02, 1.4817e-03,
        0.0000e+00, 0.0000e+00, 7.8942e-03, 7.0986e-04, 0.0000e+00, 0.0000e+00,
        3.0052e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:07,903 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.41182904013362737
2024-04-24 14:50:07,904 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.133330.13333
2024-04-24 14:50:07,917 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #150: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3870967741935484, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(min, 0)': 0.47, '(min, 1)': 0.22, '(rev, 2)': 0.02}}
2024-04-24 14:50:07,917 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:07,917 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #150: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.48, '(min, 1)': 0.15, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.03}}
2024-04-24 14:50:07,917 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:07,918 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4125046076850813
2024-04-24 14:50:07,918 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4125046076850813
2024-04-24 14:50:07,948 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #150: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 6, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 0, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.18421052631578946, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.11, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:50:07,948 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:07,949 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4125046076850813
2024-04-24 14:50:07,963 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #150: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.21621621621621623, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.24, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:50:07,963 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:07,963 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #150: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.02857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 4)': 0.01, '(min, 0)': 0.58, '(min, 1)': 0.09, '(rev, 1)': 0.02}}
2024-04-24 14:50:07,964 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
ation 0.4125046076850813
2024-04-24 14:50:07,964 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4125046076850813
2024-04-24 14:50:09,333 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #150: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5116279069767442, 'length': 100, 'actions': {'(ado, 1)': 0.09, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.38, '(rev, 1)': 0.12, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:50:09,333 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:09,334 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4125046076850813
2024-04-24 14:50:09,551 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #150: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 3, 0, 1),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 4, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.23255813953488372, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.34, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:50:09,551 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:09,552 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4125046076850813
2024-04-24 14:50:09,731 - MainProcess - INFO - text_logger.py - 51 - Train epoch #150
2024-04-24 14:50:09,733 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.1719e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5299e-01, 0.0000e+00,
        2.5925e-01, 4.1345e-03, 2.5238e-01, 0.0000e+00, 5.2184e-02, 4.1247e-03,
        0.0000e+00, 0.0000e+00, 3.7771e-02, 3.6176e-03, 0.0000e+00, 0.0000e+00,
        3.2699e-02, 1.1973e-03, 0.0000e+00, 0.0000e+00, 3.0444e-02, 1.0869e-04,
        0.0000e+00, 0.0000e+00, 2.6051e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.2088e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7073e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.4242e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.6489e-04, 0.0000e+00, 0.0000e+00])  tensor([2.0352e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8868e-01, 0.0000e+00,
        1.7737e-01, 1.0828e-02, 1.8839e-01, 0.0000e+00, 5.7822e-02, 1.1575e-02,
        0.0000e+00, 0.0000e+00, 4.4427e-02, 1.2260e-02, 0.0000e+00, 0.0000e+00,
        4.0327e-02, 6.1558e-03, 0.0000e+00, 0.0000e+00, 3.8322e-02, 1.4065e-03,
        0.0000e+00, 0.0000e+00, 3.3855e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9961e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4418e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.5504e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7785e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:09,746 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4114961249119226
2024-04-24 14:50:09,748 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.304660.08244
2024-04-24 14:50:09,762 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #151: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 4, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.4, '(min, 1)': 0.24}}
2024-04-24 14:50:09,762 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:09,763 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41182904013362737
2024-04-24 14:50:09,794 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #151: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.57, '(min, 1)': 0.02}}
2024-04-24 14:50:09,794 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:09,795 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41182904013362737
2024-04-24 14:50:09,810 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #151: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 8, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 8, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.43, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:50:09,810 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:09,811 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41182904013362737
2024-04-24 14:50:09,848 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #151: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 8)': 0.01, '(min, 0)': 0.54, '(min, 1)': 0.14}}
2024-04-24 14:50:09,848 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:09,848 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41182904013362737
2024-04-24 14:50:10,131 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #151: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.28, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.28, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:50:10,131 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:10,132 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41182904013362737
2024-04-24 14:50:10,575 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #151: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(min, 0)': 0.48, '(min, 1)': 0.18}}
2024-04-24 14:50:10,575 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:10,575 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41182904013362737
2024-04-24 14:50:11,270 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #151: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 4)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 6, 0, 0)', 'reward_ratio': '0/4', 'revenue': 0.1276595744680851, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.61, '(min, 1)': 0.05, '(rev, 1)': 0.03, '(rev, 2)': 0.02}}
2024-04-24 14:50:11,270 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:11,272 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41182904013362737
2024-04-24 14:50:11,451 - MainProcess - INFO - text_logger.py - 51 - Train epoch #151
2024-04-24 14:50:11,453 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.0225,  0.0000,  0.0000,  0.0000,  0.2118,  0.0000,  0.2180,  0.0030,
         0.2124,  0.0000,  0.0639,  0.0015,  0.0000,  0.0000,  0.0608,  0.0008,
         0.0000,  0.0000,  0.0550,  0.0003,  0.0000,  0.0000,  0.0494,  0.0000,
         0.0000,  0.0000,  0.0432,  0.0000,  0.0000,  0.0000,  0.0417,  0.0000,
         0.0000,  0.0000,  0.0307,  0.0000,  0.0000,  0.0000,  0.0064,  0.0000,
         0.0000,  0.0000,  0.0011,  0.0000,  0.0000])  tensor([1.7540, 0.0000, 0.0000, 0.0000, 0.1985, 0.0000, 0.1559, 0.0093, 0.2039,
        0.0000, 0.0515, 0.0067, 0.0000, 0.0000, 0.0516, 0.0051, 0.0000, 0.0000,
        0.0483, 0.0030, 0.0000, 0.0000, 0.0446, 0.0000, 0.0000, 0.0000, 0.0399,
        0.0000, 0.0000, 0.0000, 0.0405, 0.0000, 0.0000, 0.0000, 0.0317, 0.0000,
        0.0000, 0.0000, 0.0113, 0.0000, 0.0000, 0.0000, 0.0046, 0.0000, 0.0000]) (500)
2024-04-24 14:50:11,467 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.410553890693802
2024-04-24 14:50:11,469 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:50:11,481 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #152: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2777777777777778, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.24, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:50:11,481 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:11,481 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #152: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.19, '(rev, 1)': 0.04, '(rev, 2)': 0.01}}
2024-04-24 14:50:11,481 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:11,482 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4114961249119226
2024-04-24 14:50:11,482 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4114961249119226
2024-04-24 14:50:11,497 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #152: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.23076923076923078, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.4, '(min, 1)': 0.19, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:50:11,497 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:11,497 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4114961249119226
2024-04-24 14:50:11,501 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #152: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.53, '(min, 1)': 0.06}}
2024-04-24 14:50:11,501 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:11,502 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4114961249119226
2024-04-24 14:50:11,804 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #152: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46938775510204084, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.42, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:50:11,804 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:11,805 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4114961249119226
2024-04-24 14:50:11,948 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #152: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.09615384615384616, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.27, '(rev, 1)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:50:11,948 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:11,949 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4114961249119226
2024-04-24 14:50:12,797 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #152: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.44, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 8)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.38, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:50:12,797 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:12,798 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4114961249119226
2024-04-24 14:50:12,980 - MainProcess - INFO - text_logger.py - 51 - Train epoch #152
2024-04-24 14:50:12,982 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.4981e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1142e-01, 0.0000e+00,
        1.8637e-01, 5.5172e-03, 3.1292e-01, 0.0000e+00, 4.0879e-02, 2.4447e-03,
        0.0000e+00, 0.0000e+00, 3.3140e-02, 1.2396e-03, 0.0000e+00, 0.0000e+00,
        2.6541e-02, 2.1366e-04, 0.0000e+00, 0.0000e+00, 2.5403e-02, 6.8966e-05,
        0.0000e+00, 0.0000e+00, 2.0926e-02, 7.1429e-05, 0.0000e+00, 0.0000e+00,
        1.8101e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1910e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.3906e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.4729e-04, 0.0000e+00, 0.0000e+00])  tensor([1.5449e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8635e-01, 0.0000e+00,
        1.6126e-01, 1.2008e-02, 1.8985e-01, 0.0000e+00, 5.2215e-02, 8.4647e-03,
        0.0000e+00, 0.0000e+00, 4.5525e-02, 6.5322e-03, 0.0000e+00, 0.0000e+00,
        3.8554e-02, 2.4008e-03, 0.0000e+00, 0.0000e+00, 3.8760e-02, 1.5421e-03,
        0.0000e+00, 0.0000e+00, 3.2811e-02, 1.5972e-03, 0.0000e+00, 0.0000e+00,
        3.0385e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1597e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.0674e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.6839e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:12,995 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.40993774343220307
2024-04-24 14:50:12,997 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.163040.16304
2024-04-24 14:50:13,027 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #153: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(min, 0)': 0.19, '(min, 1)': 0.5, '(rev, 1)': 0.07, '(rev, 2)': 0.09, '(rev, 3)': 0.01, '(rev, 9)': 0.01}}
2024-04-24 14:50:13,027 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:13,027 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.410553890693802
2024-04-24 14:50:13,042 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #153: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.38636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.3, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 6)': 0.01}}
2024-04-24 14:50:13,042 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:13,042 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.410553890693802
2024-04-24 14:50:13,043 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #153: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.46, '(min, 1)': 0.16, '(rev, 1)': 0.01}}
2024-04-24 14:50:13,043 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:13,044 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.410553890693802
2024-04-24 14:50:13,726 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #153: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 3, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.9024390243902439, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 8)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.23, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.04}}
2024-04-24 14:50:13,726 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:13,727 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.410553890693802
2024-04-24 14:50:13,821 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #153: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.39215686274509803, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.27, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:50:13,821 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:13,822 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.410553890693802
2024-04-24 14:50:14,230 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #153: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 5, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.43, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:50:14,230 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:14,231 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.410553890693802
2024-04-24 14:50:14,271 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #153: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.18, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(ado, 7)': 0.02, '(min, 0)': 0.35, '(min, 1)': 0.32, '(rev, 1)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:50:14,272 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:14,272 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.410553890693802
2024-04-24 14:50:14,446 - MainProcess - INFO - text_logger.py - 51 - Train epoch #153
2024-04-24 14:50:14,448 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.1279e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4416e-01, 0.0000e+00,
        1.7112e-01, 6.1278e-03, 3.5513e-01, 0.0000e+00, 2.8798e-02, 4.8385e-03,
        0.0000e+00, 0.0000e+00, 1.9774e-02, 3.6792e-03, 0.0000e+00, 0.0000e+00,
        1.7930e-02, 1.4059e-03, 0.0000e+00, 0.0000e+00, 1.4833e-02, 1.9076e-04,
        0.0000e+00, 0.0000e+00, 1.2585e-02, 5.4054e-05, 0.0000e+00, 0.0000e+00,
        1.0690e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.5923e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.3204e-04, 8.0000e-05, 0.0000e+00, 0.0000e+00,
        7.5472e-05, 0.0000e+00, 0.0000e+00])  tensor([1.8093e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6102e-01, 0.0000e+00,
        1.6146e-01, 1.2750e-02, 1.6546e-01, 0.0000e+00, 4.8455e-02, 1.2521e-02,
        0.0000e+00, 0.0000e+00, 3.7543e-02, 1.3784e-02, 0.0000e+00, 0.0000e+00,
        3.6621e-02, 6.5890e-03, 0.0000e+00, 0.0000e+00, 3.1984e-02, 2.2051e-03,
        0.0000e+00, 0.0000e+00, 2.8579e-02, 1.2087e-03, 0.0000e+00, 0.0000e+00,
        2.6529e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0806e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.9365e-03, 1.7889e-03, 0.0000e+00, 0.0000e+00,
        1.1921e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:14,462 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.40989794823847286
2024-04-24 14:50:14,465 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.451220.45122
2024-04-24 14:50:14,493 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #154: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.47, '(min, 1)': 0.13}}
2024-04-24 14:50:14,493 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:14,494 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40993774343220307
2024-04-24 14:50:14,508 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #154: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.14634146341463414, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 4)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.26, '(rev, 1)': 0.01, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:50:14,509 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:14,509 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40993774343220307
2024-04-24 14:50:14,968 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #154: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.57}}
2024-04-24 14:50:14,968 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:14,969 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40993774343220307
2024-04-24 14:50:15,155 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #154: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.15789473684210525, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.31, '(rev, 1)': 0.03, '(rev, 2)': 0.02}}
2024-04-24 14:50:15,155 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:15,156 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40993774343220307
2024-04-24 14:50:15,161 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #154: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5813953488372093, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 4)': 0.02, '(min, 0)': 0.48, '(min, 1)': 0.26, '(rev, 1)': 0.02, '(rev, 4)': 0.01, '(rev, 9)': 0.01}}
2024-04-24 14:50:15,161 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:15,162 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40993774343220307
2024-04-24 14:50:15,707 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #154: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.16326530612244897, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.24, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:50:15,708 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:15,708 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40993774343220307
2024-04-24 14:50:15,763 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #154: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4411764705882353, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 3)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.44, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 6)': 0.01}}
2024-04-24 14:50:15,764 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:15,764 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40993774343220307
2024-04-24 14:50:15,944 - MainProcess - INFO - text_logger.py - 51 - Train epoch #154
2024-04-24 14:50:15,946 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.3593e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1974e-01, 0.0000e+00,
        2.2319e-01, 3.1044e-03, 2.2322e-01, 0.0000e+00, 6.7876e-02, 1.8800e-03,
        0.0000e+00, 0.0000e+00, 5.5979e-02, 9.6925e-04, 0.0000e+00, 0.0000e+00,
        5.0612e-02, 4.0187e-04, 0.0000e+00, 0.0000e+00, 4.5425e-02, 6.6667e-05,
        0.0000e+00, 0.0000e+00, 3.9384e-02, 7.1429e-05, 0.0000e+00, 0.0000e+00,
        3.5947e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6661e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.8901e-03, 8.0000e-05, 0.0000e+00, 0.0000e+00,
        5.0543e-04, 0.0000e+00, 0.0000e+00])  tensor([1.7328e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9200e-01, 0.0000e+00,
        1.4809e-01, 9.6970e-03, 1.9526e-01, 0.0000e+00, 5.7121e-02, 7.6116e-03,
        0.0000e+00, 0.0000e+00, 5.0977e-02, 6.6851e-03, 0.0000e+00, 0.0000e+00,
        4.8482e-02, 3.6536e-03, 0.0000e+00, 0.0000e+00, 4.5503e-02, 1.4907e-03,
        0.0000e+00, 0.0000e+00, 4.0474e-02, 1.5972e-03, 0.0000e+00, 0.0000e+00,
        3.8816e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0736e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0289e-02, 1.7889e-03, 0.0000e+00, 0.0000e+00,
        2.8275e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:15,961 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4089557140203523
2024-04-24 14:50:15,963 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:50:16,021 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #155: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.037037037037037035, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.6, '(min, 1)': 0.09, '(rev, 2)': 0.01}}
2024-04-24 14:50:16,022 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:16,022 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40989794823847286
2024-04-24 14:50:16,212 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #155: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.41, '(min, 1)': 0.2}}
2024-04-24 14:50:16,212 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:16,213 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40989794823847286
2024-04-24 14:50:16,268 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #155: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.17, '(rev, 1)': 0.02}}
2024-04-24 14:50:16,268 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:16,268 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40989794823847286
2024-04-24 14:50:16,402 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #155: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.15}}
2024-04-24 14:50:16,402 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:16,403 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40989794823847286
2024-04-24 14:50:16,454 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #155: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(ado, 7)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.12}}
2024-04-24 14:50:16,454 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:16,454 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40989794823847286
2024-04-24 14:50:17,079 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #155: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.13725490196078433, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.06, '(ado, 6)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.13, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:50:17,079 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:17,079 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40989794823847286
2024-04-24 14:50:17,213 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #155: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.175, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.22, '(rev, 1)': 0.04, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:50:17,213 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:17,213 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40989794823847286
2024-04-24 14:50:17,382 - MainProcess - INFO - text_logger.py - 51 - Train epoch #155
2024-04-24 14:50:17,385 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-9.4576e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.3839e-01,
         0.0000e+00,  2.5547e-01,  1.6836e-03,  1.3638e-01,  0.0000e+00,
         8.5522e-02,  8.0394e-04,  0.0000e+00,  0.0000e+00,  8.3764e-02,
         3.5670e-04,  0.0000e+00,  0.0000e+00,  7.1286e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.7785e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  5.6551e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         5.3369e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.6018e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0249e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  2.3766e-03,  0.0000e+00,  0.0000e+00])  tensor([1.1493, 0.0000, 0.0000, 0.0000, 0.1698, 0.0000, 0.1148, 0.0073, 0.1693,
        0.0000, 0.0456, 0.0048, 0.0000, 0.0000, 0.0472, 0.0033, 0.0000, 0.0000,
        0.0426, 0.0000, 0.0000, 0.0000, 0.0420, 0.0000, 0.0000, 0.0000, 0.0361,
        0.0000, 0.0000, 0.0000, 0.0359, 0.0000, 0.0000, 0.0000, 0.0266, 0.0000,
        0.0000, 0.0000, 0.0123, 0.0000, 0.0000, 0.0000, 0.0060, 0.0000, 0.0000]) (500)
2024-04-24 14:50:17,400 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4082634798022317
2024-04-24 14:50:17,402 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.125000.12500
2024-04-24 14:50:17,524 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #156: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.55, '(min, 1)': 0.08}}
2024-04-24 14:50:17,524 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:17,524 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4089557140203523
2024-04-24 14:50:17,797 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #156: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.16071428571428573, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.55, '(min, 1)': 0.04, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:50:17,798 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:17,799 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4089557140203523
2024-04-24 14:50:17,957 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #156: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7547169811320755, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 8)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.38, '(rev, 1)': 0.06, '(rev, 2)': 0.03}}
2024-04-24 14:50:17,957 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:17,958 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4089557140203523
2024-04-24 14:50:18,205 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #156: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 3, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3829787234042553, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.23, '(rev, 1)': 0.08, '(rev, 2)': 0.01}}
2024-04-24 14:50:18,205 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:18,205 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4089557140203523
2024-04-24 14:50:18,685 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #156: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.19230769230769232, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.23, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:50:18,685 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:18,686 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4089557140203523
2024-04-24 14:50:18,803 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #156: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.34, '(rev, 1)': 0.08, '(rev, 2)': 0.05}}
2024-04-24 14:50:18,803 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:18,804 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4089557140203523
2024-04-24 14:50:19,249 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #156: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 5, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40425531914893614, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 10)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.31, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 7)': 0.01}}
2024-04-24 14:50:19,249 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:19,250 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4089557140203523
2024-04-24 14:50:19,429 - MainProcess - INFO - text_logger.py - 51 - Train epoch #156
2024-04-24 14:50:19,432 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.8047e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7267e-01, 0.0000e+00,
        1.7987e-01, 3.9938e-03, 2.8692e-01, 0.0000e+00, 5.0936e-02, 2.2459e-03,
        0.0000e+00, 0.0000e+00, 4.3654e-02, 1.8777e-03, 0.0000e+00, 0.0000e+00,
        3.9793e-02, 6.4466e-04, 0.0000e+00, 0.0000e+00, 3.4638e-02, 9.3506e-05,
        0.0000e+00, 0.0000e+00, 3.0058e-02, 1.4061e-04, 0.0000e+00, 0.0000e+00,
        2.7008e-02, 6.2500e-05, 0.0000e+00, 0.0000e+00, 2.0399e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.1149e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.8316e-04, 0.0000e+00, 0.0000e+00])  tensor([2.3126e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9388e-01, 0.0000e+00,
        1.4544e-01, 1.0927e-02, 2.0396e-01, 0.0000e+00, 5.6880e-02, 8.7911e-03,
        0.0000e+00, 0.0000e+00, 5.2259e-02, 9.1131e-03, 0.0000e+00, 0.0000e+00,
        4.9876e-02, 4.2234e-03, 0.0000e+00, 0.0000e+00, 4.4758e-02, 1.5132e-03,
        0.0000e+00, 0.0000e+00, 4.0318e-02, 2.2421e-03, 0.0000e+00, 0.0000e+00,
        3.7667e-02, 1.3975e-03, 0.0000e+00, 0.0000e+00, 2.9719e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.9680e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.8185e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:19,444 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.40807596256524314
2024-04-24 14:50:19,446 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.377360.37736
2024-04-24 14:50:19,492 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #157: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(min, 0)': 0.46, '(min, 1)': 0.15, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-24 14:50:19,492 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:19,492 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #157: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.54, '(min, 1)': 0.03}}
2024-04-24 14:50:19,493 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:19,493 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4082634798022317
2024-04-24 14:50:19,494 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4082634798022317
2024-04-24 14:50:19,519 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #157: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 1, 2, 10, 0, 0),(ado, 6)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 4, 0, 0)', 'reward_ratio': '0/6', 'revenue': 0.40816326530612246, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.26, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.03}}
2024-04-24 14:50:19,519 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:19,520 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4082634798022317
2024-04-24 14:50:19,582 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #157: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 4, 0, 0),(rev, 5)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '5/5', 'revenue': 0.22, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.27, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 5)': 0.01}}
2024-04-24 14:50:19,582 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:19,582 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4082634798022317
2024-04-24 14:50:20,118 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #157: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 5, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 5, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5945945945945946, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.02, '(min, 0)': 0.39, '(min, 1)': 0.33, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 5)': 0.02}}
2024-04-24 14:50:20,118 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:20,119 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4082634798022317
2024-04-24 14:50:20,245 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #157: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.4888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.15, '(rev, 1)': 0.11, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:50:20,245 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:20,246 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4082634798022317
2024-04-24 14:50:20,758 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #157: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.06521739130434782, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.17, '(rev, 1)': 0.05, '(rev, 2)': 0.02}}
2024-04-24 14:50:20,758 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:20,758 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4082634798022317
2024-04-24 14:50:20,934 - MainProcess - INFO - text_logger.py - 51 - Train epoch #157
2024-04-24 14:50:20,936 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.2380e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9401e-01, 0.0000e+00,
        1.9307e-01, 6.2266e-03, 3.0956e-01, 0.0000e+00, 4.2893e-02, 5.2179e-03,
        0.0000e+00, 0.0000e+00, 3.2665e-02, 2.8518e-03, 0.0000e+00, 0.0000e+00,
        2.7392e-02, 8.5915e-04, 0.0000e+00, 0.0000e+00, 2.5809e-02, 1.4835e-04,
        0.0000e+00, 0.0000e+00, 2.1585e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9398e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3471e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.9549e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.8404e-04, 0.0000e+00, 0.0000e+00])  tensor([1.8002, 0.0000, 0.0000, 0.0000, 0.1798, 0.0000, 0.1487, 0.0142, 0.1865,
        0.0000, 0.0569, 0.0127, 0.0000, 0.0000, 0.0474, 0.0118, 0.0000, 0.0000,
        0.0422, 0.0049, 0.0000, 0.0000, 0.0416, 0.0023, 0.0000, 0.0000, 0.0357,
        0.0000, 0.0000, 0.0000, 0.0334, 0.0000, 0.0000, 0.0000, 0.0245, 0.0000,
        0.0000, 0.0000, 0.0096, 0.0000, 0.0000, 0.0000, 0.0041, 0.0000, 0.0000]) (500)
2024-04-24 14:50:20,950 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.40754281925621355
2024-04-24 14:50:20,952 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.204550.20455
2024-04-24 14:50:20,995 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #158: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(min, 0)': 0.6, '(min, 1)': 0.07}}
2024-04-24 14:50:20,995 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:20,996 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40807596256524314
2024-04-24 14:50:21,428 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #158: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(ado, 7)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.15}}
2024-04-24 14:50:21,428 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:21,429 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40807596256524314
2024-04-24 14:50:21,543 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #158: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 4, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4186046511627907, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.09, '(min, 1)': 0.52, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:50:21,544 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:21,544 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40807596256524314
2024-04-24 14:50:21,614 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #158: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.01, '(min, 0)': 0.54, '(min, 1)': 0.1, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-04-24 14:50:21,614 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:21,615 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40807596256524314
2024-04-24 14:50:21,847 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #158: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4772727272727273, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 8)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.39, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-04-24 14:50:21,848 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:21,848 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40807596256524314
2024-04-24 14:50:22,075 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #158: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 8, 5, 0, 0),(rev, 6)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '6/6', 'revenue': 0.39215686274509803, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.22, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:50:22,075 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:22,076 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40807596256524314
2024-04-24 14:50:22,092 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #158: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.625, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 3)': 0.02, '(min, 0)': 0.36, '(min, 1)': 0.31, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-04-24 14:50:22,093 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:22,093 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40807596256524314
2024-04-24 14:50:22,272 - MainProcess - INFO - text_logger.py - 51 - Train epoch #158
2024-04-24 14:50:22,274 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.4100e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0130e-01, 0.0000e+00,
        1.8032e-01, 6.2105e-03, 3.1474e-01, 0.0000e+00, 3.5126e-02, 7.0497e-03,
        0.0000e+00, 0.0000e+00, 3.1923e-02, 6.6437e-03, 0.0000e+00, 0.0000e+00,
        2.7498e-02, 2.9706e-03, 0.0000e+00, 0.0000e+00, 2.6508e-02, 3.8468e-04,
        0.0000e+00, 0.0000e+00, 2.1681e-02, 2.5610e-04, 0.0000e+00, 0.0000e+00,
        2.0270e-02, 1.0854e-04, 0.0000e+00, 0.0000e+00, 1.3647e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.0597e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.1002e-04, 0.0000e+00, 0.0000e+00])  tensor([2.4491e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7560e-01, 0.0000e+00,
        1.4583e-01, 1.3946e-02, 1.8253e-01, 0.0000e+00, 4.9574e-02, 1.5649e-02,
        0.0000e+00, 0.0000e+00, 4.8879e-02, 1.7610e-02, 0.0000e+00, 0.0000e+00,
        4.3897e-02, 9.1213e-03, 0.0000e+00, 0.0000e+00, 4.3430e-02, 2.8159e-03,
        0.0000e+00, 0.0000e+00, 3.5902e-02, 2.1999e-03, 0.0000e+00, 0.0000e+00,
        3.4563e-02, 1.3991e-03, 0.0000e+00, 0.0000e+00, 2.5056e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.7091e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3125e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:22,287 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4066005850380929
2024-04-24 14:50:22,289 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:50:22,996 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #159: {'transition': '(exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 7, 8, 1, 1),(min, 0)->(exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 8, 8, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.55, '(min, 1)': 0.09}}
2024-04-24 14:50:22,996 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:22,996 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40754281925621355
2024-04-24 14:50:23,050 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #159: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0392156862745098, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.13, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-04-24 14:50:23,051 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:23,051 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40754281925621355
2024-04-24 14:50:23,079 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #159: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.48, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 10)': 0.01, '(ado, 2)': 0.02, '(min, 0)': 0.38, '(min, 1)': 0.29, '(rev, 1)': 0.06, '(rev, 2)': 0.1, '(rev, 3)': 0.02}}
2024-04-24 14:50:23,080 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:23,080 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40754281925621355
2024-04-24 14:50:23,111 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #159: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5686274509803921, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.38, '(rev, 1)': 0.07, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-04-24 14:50:23,111 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:23,111 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40754281925621355
2024-04-24 14:50:23,278 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #159: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1875, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.29, '(rev, 1)': 0.05, '(rev, 2)': 0.04}}
2024-04-24 14:50:23,278 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:23,278 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40754281925621355
2024-04-24 14:50:23,567 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #159: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.16, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:50:23,567 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:23,568 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40754281925621355
2024-04-24 14:50:24,002 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #159: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.30612244897959184, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.05, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.19, '(rev, 1)': 0.05, '(rev, 2)': 0.02}}
2024-04-24 14:50:24,002 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:24,003 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40754281925621355
2024-04-24 14:50:24,176 - MainProcess - INFO - text_logger.py - 51 - Train epoch #159
2024-04-24 14:50:24,178 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.9521e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5073e-01, 0.0000e+00,
        1.8441e-01, 5.0175e-03, 2.5912e-01, 0.0000e+00, 5.2106e-02, 3.8791e-03,
        0.0000e+00, 0.0000e+00, 5.3894e-02, 2.2819e-03, 0.0000e+00, 0.0000e+00,
        4.7177e-02, 8.3496e-04, 0.0000e+00, 0.0000e+00, 4.2402e-02, 2.3273e-04,
        0.0000e+00, 0.0000e+00, 3.5159e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4533e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2681e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.7664e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.7741e-04, 0.0000e+00, 0.0000e+00])  tensor([2.0855e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9650e-01, 0.0000e+00,
        1.3828e-01, 1.2398e-02, 2.0653e-01, 0.0000e+00, 5.3940e-02, 1.0972e-02,
        0.0000e+00, 0.0000e+00, 5.7942e-02, 9.2041e-03, 0.0000e+00, 0.0000e+00,
        5.2116e-02, 4.5548e-03, 0.0000e+00, 0.0000e+00, 4.7671e-02, 1.9993e-03,
        0.0000e+00, 0.0000e+00, 4.0293e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.2171e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0468e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0445e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.6673e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:24,193 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4062269782709527
2024-04-24 14:50:24,194 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.284310.28431
2024-04-24 14:50:24,329 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #160: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.23404255319148937, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(ado, 3)': 0.02, '(min, 0)': 0.43, '(min, 1)': 0.16, '(rev, 1)': 0.08, '(rev, 2)': 0.05}}
2024-04-24 14:50:24,329 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:24,330 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4066005850380929
2024-04-24 14:50:24,771 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #160: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4883720930232558, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(min, 0)': 0.39, '(min, 1)': 0.27, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 6)': 0.01}}
2024-04-24 14:50:24,771 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:24,772 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4066005850380929
2024-04-24 14:50:24,860 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #160: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 5, 1, 0, 1),(rev, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 1, 5, 1, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.5714285714285714, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.19, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:50:24,860 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:24,862 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4066005850380929
2024-04-24 14:50:24,933 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #160: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.16, '(min, 1)': 0.44, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:50:24,933 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:24,933 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4066005850380929
2024-04-24 14:50:24,951 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #160: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0),(rev, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.5434782608695652, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.12, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:50:24,951 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:24,951 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4066005850380929
2024-04-24 14:50:25,286 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #160: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.16, '(rev, 1)': 0.05, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-04-24 14:50:25,287 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:25,287 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4066005850380929
2024-04-24 14:50:25,361 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #160: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4594594594594595, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(min, 0)': 0.38, '(min, 1)': 0.29, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:50:25,361 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:25,362 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4066005850380929
2024-04-24 14:50:25,456 - MainProcess - INFO - text_logger.py - 51 - Train epoch #160
2024-04-24 14:50:25,458 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.3948e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4013e-01, 0.0000e+00,
        8.7566e-02, 8.7107e-03, 4.5009e-01, 0.0000e+00, 2.8540e-03, 5.0727e-03,
        0.0000e+00, 0.0000e+00, 5.2712e-04, 3.6034e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.0649e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0801e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2751e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.4537e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8159e-02, 0.0000e+00,
        1.1217e-01, 1.5903e-02, 6.2330e-02, 0.0000e+00, 9.9640e-03, 1.2758e-02,
        0.0000e+00, 0.0000e+00, 3.9795e-03, 1.1933e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.9108e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5410e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1493e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:25,473 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4063156320837202
2024-04-24 14:50:25,475 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.515440.05598
2024-04-24 14:50:25,699 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #161: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.01, '(min, 0)': 0.1, '(min, 1)': 0.46, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:50:25,699 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:25,700 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4062269782709527
2024-04-24 14:50:26,229 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #161: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.3125, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.02, '(min, 0)': 0.43, '(min, 1)': 0.13, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:50:26,229 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:26,230 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4062269782709527
2024-04-24 14:50:26,536 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #161: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7659574468085106, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 4)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.17, '(rev, 1)': 0.1, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:50:26,536 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:26,537 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4062269782709527
2024-04-24 14:50:26,641 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #161: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6086956521739131, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.35, '(rev, 1)': 0.12, '(rev, 2)': 0.08, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:50:26,641 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:26,642 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4062269782709527
2024-04-24 14:50:26,696 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #161: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.19148936170212766, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 7)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.33, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:50:26,696 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:26,697 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4062269782709527
2024-04-24 14:50:26,952 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #161: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40816326530612246, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.12, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:50:26,952 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:26,953 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4062269782709527
2024-04-24 14:50:26,986 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #161: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 6, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 5, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.13513513513513514, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(min, 0)': 0.49, '(min, 1)': 0.17, '(rev, 1)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:50:26,987 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:26,987 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4062269782709527
2024-04-24 14:50:27,054 - MainProcess - INFO - text_logger.py - 51 - Train epoch #161
2024-04-24 14:50:27,056 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([9.2391e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0733e-01, 0.0000e+00,
        1.0857e-01, 8.4689e-03, 4.1728e-01, 0.0000e+00, 1.0433e-02, 4.8292e-03,
        0.0000e+00, 0.0000e+00, 9.0920e-03, 2.8250e-03, 0.0000e+00, 0.0000e+00,
        7.6383e-03, 6.5229e-04, 0.0000e+00, 0.0000e+00, 7.0296e-03, 2.1842e-04,
        0.0000e+00, 0.0000e+00, 5.8711e-03, 9.7959e-05, 0.0000e+00, 0.0000e+00,
        5.7514e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3197e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.3587e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.1427e-05, 0.0000e+00, 0.0000e+00])  tensor([1.6880e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2139e-01, 0.0000e+00,
        1.2988e-01, 1.5705e-02, 1.2363e-01, 0.0000e+00, 2.8706e-02, 1.2147e-02,
        0.0000e+00, 0.0000e+00, 3.0270e-02, 1.0714e-02, 0.0000e+00, 0.0000e+00,
        2.6878e-02, 4.1064e-03, 0.0000e+00, 0.0000e+00, 2.5342e-02, 2.1912e-03,
        0.0000e+00, 0.0000e+00, 2.1459e-02, 1.5687e-03, 0.0000e+00, 0.0000e+00,
        2.1309e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4549e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.7872e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.9071e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:27,073 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4059166962660408
2024-04-24 14:50:27,075 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.271650.13651
2024-04-24 14:50:27,601 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #162: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5681818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.04, '(min, 0)': 0.46, '(min, 1)': 0.15, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:50:27,601 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:27,602 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4063156320837202
2024-04-24 14:50:27,813 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #162: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2558139534883721, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.04, '(min, 0)': 0.42, '(min, 1)': 0.18, '(rev, 1)': 0.09, '(rev, 2)': 0.03}}
2024-04-24 14:50:27,813 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:27,813 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #162: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6444444444444445, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(min, 0)': 0.47, '(min, 1)': 0.16, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-04-24 14:50:27,814 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:27,814 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4063156320837202
2024-04-24 14:50:27,814 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4063156320837202
2024-04-24 14:50:28,094 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #162: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2978723404255319, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(ado, 4)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.1, '(rev, 1)': 0.09, '(rev, 2)': 0.05}}
2024-04-24 14:50:28,095 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:28,096 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4063156320837202
2024-04-24 14:50:28,114 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #162: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3829787234042553, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(min, 0)': 0.17, '(min, 1)': 0.43, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:50:28,115 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:28,116 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4063156320837202
2024-04-24 14:50:28,252 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #162: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.38, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.16, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.03}}
2024-04-24 14:50:28,252 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:28,253 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4063156320837202
2024-04-24 14:50:28,563 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #162: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 1.0232558139534884, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(min, 0)': 0.14, '(min, 1)': 0.45, '(rev, 1)': 0.12, '(rev, 2)': 0.1, '(rev, 3)': 0.01}}
2024-04-24 14:50:28,563 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:28,564 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4063156320837202
2024-04-24 14:50:28,631 - MainProcess - INFO - text_logger.py - 51 - Train epoch #162
2024-04-24 14:50:28,633 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.1372e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3214e-01, 0.0000e+00,
        9.6810e-02, 8.6303e-03, 4.4435e-01, 0.0000e+00, 4.6469e-03, 4.7946e-03,
        0.0000e+00, 0.0000e+00, 1.7683e-03, 3.6156e-03, 0.0000e+00, 0.0000e+00,
        9.3621e-04, 1.3773e-03, 0.0000e+00, 0.0000e+00, 3.8942e-04, 3.6311e-04,
        0.0000e+00, 0.0000e+00, 1.4426e-04, 3.5714e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.8020e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7619e-02, 0.0000e+00,
        1.1998e-01, 1.6110e-02, 7.5612e-02, 0.0000e+00, 1.6601e-02, 1.3159e-02,
        0.0000e+00, 0.0000e+00, 8.9636e-03, 1.2937e-02, 0.0000e+00, 0.0000e+00,
        6.5397e-03, 5.8798e-03, 0.0000e+00, 0.0000e+00, 3.7545e-03, 2.9621e-03,
        0.0000e+00, 0.0000e+00, 2.4850e-03, 7.9860e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:28,647 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.40637771786187377
2024-04-24 14:50:28,649 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.701630.32163
2024-04-24 14:50:29,266 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #163: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.11764705882352941, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.3, '(rev, 1)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:50:29,266 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:29,266 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4059166962660408
2024-04-24 14:50:29,274 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #163: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(min, 0)': 0.26, '(min, 1)': 0.4, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-04-24 14:50:29,275 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:29,275 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4059166962660408
2024-04-24 14:50:29,430 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #163: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 5, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.47, '(min, 1)': 0.2, '(rev, 1)': 0.01}}
2024-04-24 14:50:29,431 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:29,431 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4059166962660408
2024-04-24 14:50:29,483 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #163: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(min, 0)': 0.5, '(min, 1)': 0.07, '(rev, 1)': 0.12, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-04-24 14:50:29,483 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:29,484 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #163: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3404255319148936, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.28, '(min, 1)': 0.34, '(rev, 1)': 0.08, '(rev, 2)': 0.06}}
2024-04-24 14:50:29,484 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:29,484 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4059166962660408
2024-04-24 14:50:29,484 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4059166962660408
2024-04-24 14:50:29,803 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #163: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.44680851063829785, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.15, '(rev, 1)': 0.07, '(rev, 2)': 0.03}}
2024-04-24 14:50:29,803 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:29,803 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4059166962660408
2024-04-24 14:50:30,006 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #163: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1794871794871795, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(min, 0)': 0.54, '(min, 1)': 0.08, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:50:30,006 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:30,007 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4059166962660408
2024-04-24 14:50:30,072 - MainProcess - INFO - text_logger.py - 51 - Train epoch #163
2024-04-24 14:50:30,074 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-4.0008e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7973e-01,
         0.0000e+00,  1.6793e-01,  6.4994e-03,  2.8721e-01,  0.0000e+00,
         4.4569e-02,  3.8946e-03,  0.0000e+00,  0.0000e+00,  4.6010e-02,
         2.3665e-03,  0.0000e+00,  0.0000e+00,  4.1727e-02,  1.3571e-03,
         0.0000e+00,  0.0000e+00,  3.6587e-02,  3.1157e-04,  0.0000e+00,
         0.0000e+00,  2.9943e-02,  1.9176e-04,  0.0000e+00,  0.0000e+00,
         2.9566e-02,  1.1046e-04,  0.0000e+00,  0.0000e+00,  1.8221e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.2906e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  4.8957e-04,  0.0000e+00,  0.0000e+00])  tensor([2.4018e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9190e-01, 0.0000e+00,
        1.3464e-01, 1.5086e-02, 1.9660e-01, 0.0000e+00, 5.1404e-02, 1.1288e-02,
        0.0000e+00, 0.0000e+00, 5.6256e-02, 8.9426e-03, 0.0000e+00, 0.0000e+00,
        5.3223e-02, 5.5814e-03, 0.0000e+00, 0.0000e+00, 4.7659e-02, 2.3505e-03,
        0.0000e+00, 0.0000e+00, 4.0166e-02, 1.9970e-03, 0.0000e+00, 0.0000e+00,
        4.1029e-02, 1.4234e-03, 0.0000e+00, 0.0000e+00, 2.8512e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.4381e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9218e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:30,090 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4060932316928056
2024-04-24 14:50:30,092 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.328870.14939
2024-04-24 14:50:30,741 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #164: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.06666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.17, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:50:30,741 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:30,742 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40637771786187377
2024-04-24 14:50:31,003 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #164: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.32653061224489793, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.17, '(rev, 1)': 0.02, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-04-24 14:50:31,003 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:31,004 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40637771786187377
2024-04-24 14:50:31,113 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #164: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 2, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4523809523809524, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.34, '(min, 1)': 0.32, '(rev, 1)': 0.02, '(rev, 2)': 0.07, '(rev, 3)': 0.02}}
2024-04-24 14:50:31,113 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:31,114 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40637771786187377
2024-04-24 14:50:31,353 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #164: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7058823529411765, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(min, 0)': 0.52, '(min, 1)': 0.19, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:50:31,353 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:31,354 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40637771786187377
2024-04-24 14:50:31,415 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #164: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.02, '(min, 0)': 0.47, '(min, 1)': 0.2, '(rev, 4)': 0.01}}
2024-04-24 14:50:31,415 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:31,416 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40637771786187377
2024-04-24 14:50:31,762 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #164: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 1.0, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(min, 0)': 0.24, '(min, 1)': 0.42, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.03}}
2024-04-24 14:50:31,763 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:31,763 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40637771786187377
2024-04-24 14:50:31,948 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #164: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.56, '(min, 1)': 0.1}}
2024-04-24 14:50:31,948 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:31,948 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40637771786187377
2024-04-24 14:50:32,009 - MainProcess - INFO - text_logger.py - 51 - Train epoch #164
2024-04-24 14:50:32,012 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-6.2910e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.5056e-01,
         0.0000e+00,  1.9087e-01,  5.2479e-03,  2.6325e-01,  0.0000e+00,
         5.2813e-02,  3.4092e-03,  0.0000e+00,  0.0000e+00,  5.2660e-02,
         2.4925e-03,  0.0000e+00,  0.0000e+00,  4.8417e-02,  4.0305e-04,
         0.0000e+00,  0.0000e+00,  4.1687e-02,  1.2051e-04,  0.0000e+00,
         0.0000e+00,  3.3941e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.2274e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.8567e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8703e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  4.1487e-04,  0.0000e+00,  0.0000e+00])  tensor([2.4772e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9048e-01, 0.0000e+00,
        1.4756e-01, 1.5540e-02, 2.0069e-01, 0.0000e+00, 5.2065e-02, 1.0618e-02,
        0.0000e+00, 0.0000e+00, 5.6088e-02, 1.0361e-02, 0.0000e+00, 0.0000e+00,
        5.3272e-02, 3.2496e-03, 0.0000e+00, 0.0000e+00, 4.7572e-02, 1.5606e-03,
        0.0000e+00, 0.0000e+00, 3.9620e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.1309e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7990e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.7689e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5893e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:32,027 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.40585687982762625
2024-04-24 14:50:32,029 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.352940.35294
2024-04-24 14:50:32,792 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #165: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2653061224489796, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.09, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:50:32,792 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:32,792 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4060932316928056
2024-04-24 14:50:32,896 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #165: {'transition': '(exi, not, exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 3, 5, 1, 1),(min, 0)->(exi, not, exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 3, 6, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.5348837209302325, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 4)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.36, '(rev, 1)': 0.06, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-04-24 14:50:32,896 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:32,897 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4060932316928056
2024-04-24 14:50:32,913 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #165: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5526315789473685, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.41, '(min, 1)': 0.28, '(rev, 1)': 0.03, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:50:32,913 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:32,914 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4060932316928056
2024-04-24 14:50:33,156 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #165: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 8, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 8, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.45454545454545453, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.22, '(rev, 1)': 0.03, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:50:33,156 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:33,157 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4060932316928056
2024-04-24 14:50:33,276 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #165: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.11904761904761904, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.2, '(rev, 1)': 0.05, '(rev, 2)': 0.02}}
2024-04-24 14:50:33,276 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:33,277 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4060932316928056
2024-04-24 14:50:33,387 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #165: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40425531914893614, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.15, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:50:33,387 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:33,388 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4060932316928056
2024-04-24 14:50:33,741 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #165: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.42857142857142855, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.14, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-04-24 14:50:33,741 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:33,741 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4060932316928056
2024-04-24 14:50:33,818 - MainProcess - INFO - text_logger.py - 51 - Train epoch #165
2024-04-24 14:50:33,820 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.8201e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.5865e-01,
         0.0000e+00,  1.7815e-01,  7.1666e-03,  2.6661e-01,  0.0000e+00,
         4.8965e-02,  5.8353e-03,  0.0000e+00,  0.0000e+00,  5.0157e-02,
         4.1996e-03,  0.0000e+00,  0.0000e+00,  4.6287e-02,  1.7925e-03,
         0.0000e+00,  0.0000e+00,  4.2496e-02,  1.6104e-04,  0.0000e+00,
         0.0000e+00,  3.4392e-02,  8.1633e-05,  0.0000e+00,  0.0000e+00,
         3.3327e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.8998e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.3980e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.3389e-04,  0.0000e+00,  0.0000e+00])  tensor([2.4577e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8875e-01, 0.0000e+00,
        1.3565e-01, 1.7534e-02, 1.9692e-01, 0.0000e+00, 5.3262e-02, 1.6078e-02,
        0.0000e+00, 0.0000e+00, 5.6593e-02, 1.4496e-02, 0.0000e+00, 0.0000e+00,
        5.3920e-02, 7.0877e-03, 0.0000e+00, 0.0000e+00, 5.0400e-02, 1.7963e-03,
        0.0000e+00, 0.0000e+00, 4.1474e-02, 1.2894e-03, 0.0000e+00, 0.0000e+00,
        4.2508e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8683e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.0427e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3680e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:33,833 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.405747472357226
2024-04-24 14:50:33,836 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.416410.01216
2024-04-24 14:50:34,468 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #166: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.20408163265306123, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.14, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-04-24 14:50:34,468 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:34,469 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40585687982762625
2024-04-24 14:50:34,706 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #166: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3125, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.29, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 3)': 0.03}}
2024-04-24 14:50:34,706 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:34,707 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40585687982762625
2024-04-24 14:50:34,729 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #166: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.6222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.15, '(min, 1)': 0.49, '(rev, 1)': 0.11, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-04-24 14:50:34,729 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:34,730 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40585687982762625
2024-04-24 14:50:34,778 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #166: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8125, 'length': 100, 'actions': {'(ado, 1)': 0.07, '(ado, 2)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.39, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.05, '(rev, 4)': 0.03, '(rev, 7)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:50:34,778 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:34,778 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40585687982762625
2024-04-24 14:50:34,887 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #166: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.02, '(min, 0)': 0.42, '(min, 1)': 0.17, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-24 14:50:34,888 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:34,888 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40585687982762625
2024-04-24 14:50:35,414 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #166: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.14035087719298245, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.03, '(ado, 5)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.35, '(rev, 1)': 0.02, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:50:35,414 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:35,415 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40585687982762625
2024-04-24 14:50:35,841 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #166: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.02702702702702703, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.18, '(rev, 1)': 0.02, '(rev, 2)': 0.01}}
2024-04-24 14:50:35,841 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:35,842 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40585687982762625
2024-04-24 14:50:35,905 - MainProcess - INFO - text_logger.py - 51 - Train epoch #166
2024-04-24 14:50:35,907 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.5310e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2649e-01, 0.0000e+00,
        1.5943e-01, 8.6192e-03, 3.5569e-01, 0.0000e+00, 2.1193e-02, 1.5676e-02,
        0.0000e+00, 0.0000e+00, 1.7139e-02, 2.2552e-02, 0.0000e+00, 0.0000e+00,
        1.6149e-02, 6.9162e-03, 0.0000e+00, 0.0000e+00, 1.4698e-02, 6.7581e-04,
        0.0000e+00, 0.0000e+00, 1.2528e-02, 5.3237e-04, 0.0000e+00, 0.0000e+00,
        1.1397e-02, 4.3411e-04, 0.0000e+00, 0.0000e+00, 7.7251e-03, 3.0303e-04,
        0.0000e+00, 0.0000e+00, 1.4471e-03, 5.8925e-05, 0.0000e+00, 0.0000e+00,
        3.5120e-04, 0.0000e+00, 0.0000e+00])  tensor([3.0633e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5537e-01, 0.0000e+00,
        1.6159e-01, 2.0085e-02, 1.6157e-01, 0.0000e+00, 3.9819e-02, 3.6001e-02,
        0.0000e+00, 0.0000e+00, 4.0091e-02, 6.6479e-02, 0.0000e+00, 0.0000e+00,
        3.9885e-02, 2.2108e-02, 0.0000e+00, 0.0000e+00, 3.6887e-02, 3.3731e-03,
        0.0000e+00, 0.0000e+00, 3.2063e-02, 3.0642e-03, 0.0000e+00, 0.0000e+00,
        2.9745e-02, 3.1142e-03, 0.0000e+00, 0.0000e+00, 2.0861e-02, 2.8015e-03,
        0.0000e+00, 0.0000e+00, 5.8649e-03, 9.3495e-04, 0.0000e+00, 0.0000e+00,
        2.7911e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:35,922 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4052100429439103
2024-04-24 14:50:35,924 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.202400.17538
2024-04-24 14:50:35,936 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #167: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6578947368421053, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.01, '(min, 0)': 0.08, '(min, 1)': 0.55, '(rev, 1)': 0.2, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:50:35,936 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:35,937 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.405747472357226
2024-04-24 14:50:36,162 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #167: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.04, '(min, 0)': 0.04, '(min, 1)': 0.54, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:50:36,163 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:36,163 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.405747472357226
2024-04-24 14:50:36,205 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #167: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34210526315789475, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(min, 0)': 0.3, '(min, 1)': 0.3, '(rev, 1)': 0.12, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:50:36,205 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:36,206 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.405747472357226
2024-04-24 14:50:36,454 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #167: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5609756097560976, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(min, 0)': 0.42, '(min, 1)': 0.21, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 5)': 0.01, '(rev, 6)': 0.02}}
2024-04-24 14:50:36,455 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:36,455 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.405747472357226
2024-04-24 14:50:36,550 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #167: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7441860465116279, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.42, '(min, 1)': 0.22, '(rev, 1)': 0.12, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-04-24 14:50:36,550 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:36,551 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.405747472357226
2024-04-24 14:50:36,900 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #167: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34146341463414637, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.34, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:50:36,901 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:36,901 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.405747472357226
2024-04-24 14:50:37,823 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #167: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.14}}
2024-04-24 14:50:37,823 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:37,823 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.405747472357226
2024-04-24 14:50:37,889 - MainProcess - INFO - text_logger.py - 51 - Train epoch #167
2024-04-24 14:50:37,891 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.4985e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1709e-01, 0.0000e+00,
        1.3372e-01, 1.1124e-02, 4.1570e-01, 0.0000e+00, 3.0937e-03, 1.0682e-02,
        0.0000e+00, 0.0000e+00, 6.0215e-04, 5.5736e-03, 0.0000e+00, 0.0000e+00,
        7.5472e-05, 2.1555e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8058e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7942e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.8180e-02, 0.0000e+00,
        1.3024e-01, 1.8693e-02, 7.4437e-02, 0.0000e+00, 1.0886e-02, 2.0055e-02,
        0.0000e+00, 0.0000e+00, 4.6262e-03, 1.6106e-02, 0.0000e+00, 0.0000e+00,
        1.6876e-03, 8.4858e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3773e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:37,904 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4048287843355457
2024-04-24 14:50:37,905 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.280490.28049
2024-04-24 14:50:37,921 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #168: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.05405405405405406, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.5, '(min, 1)': 0.13, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-04-24 14:50:37,921 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #168: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.3695652173913043, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.18, '(rev, 1)': 0.08, '(rev, 2)': 0.06}}
2024-04-24 14:50:37,921 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:37,921 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:37,922 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4052100429439103
2024-04-24 14:50:37,922 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4052100429439103
2024-04-24 14:50:37,937 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #168: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.32, '(rev, 1)': 0.08, '(rev, 2)': 0.11, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:50:37,938 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:37,938 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4052100429439103
2024-04-24 14:50:37,954 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #168: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(min, 0)': 0.36, '(min, 1)': 0.23, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.04, '(rev, 4)': 0.01}}
2024-04-24 14:50:37,954 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:37,954 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4052100429439103
2024-04-24 14:50:37,968 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #168: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 1, 0, 1),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 2, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.04, '(min, 0)': 0.44, '(min, 1)': 0.17, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-04-24 14:50:37,968 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:37,969 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4052100429439103
2024-04-24 14:50:38,087 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #168: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.44, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(min, 0)': 0.32, '(min, 1)': 0.27, '(rev, 1)': 0.06, '(rev, 2)': 0.07, '(rev, 3)': 0.02}}
2024-04-24 14:50:38,087 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:38,087 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4052100429439103
2024-04-24 14:50:39,054 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #168: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 3, 7, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 4, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.6, '(min, 1)': 0.05}}
2024-04-24 14:50:39,054 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:39,055 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4052100429439103
2024-04-24 14:50:39,121 - MainProcess - INFO - text_logger.py - 51 - Train epoch #168
2024-04-24 14:50:39,123 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.1649e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1481e-01, 0.0000e+00,
        1.0911e-01, 1.2777e-02, 4.3944e-01, 0.0000e+00, 3.5474e-03, 9.3685e-03,
        0.0000e+00, 0.0000e+00, 6.0275e-04, 8.1899e-03, 0.0000e+00, 0.0000e+00,
        8.0000e-05, 2.0372e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1250e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7188e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.0459e-02, 0.0000e+00,
        1.2850e-01, 2.1541e-02, 7.8542e-02, 0.0000e+00, 1.2053e-02, 2.0513e-02,
        0.0000e+00, 0.0000e+00, 4.9841e-03, 3.0190e-02, 0.0000e+00, 0.0000e+00,
        1.7889e-03, 9.4126e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9877e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:39,139 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4039406041714792
2024-04-24 14:50:39,140 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.027030.02703
2024-04-24 14:50:39,179 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #169: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.48, '(min, 1)': 0.12}}
2024-04-24 14:50:39,179 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:39,180 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4048287843355457
2024-04-24 14:50:39,283 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #169: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3469387755102041, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.4, '(rev, 1)': 0.02, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-04-24 14:50:39,283 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:39,284 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4048287843355457
2024-04-24 14:50:39,492 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #169: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4583333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.23, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:50:39,493 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:39,493 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4048287843355457
2024-04-24 14:50:39,510 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #169: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.03, '(min, 0)': 0.16, '(min, 1)': 0.46, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:50:39,511 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:39,511 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4048287843355457
2024-04-24 14:50:39,571 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #169: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40540540540540543, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(min, 0)': 0.54, '(min, 1)': 0.11, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:50:39,571 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:39,572 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4048287843355457
2024-04-24 14:50:39,788 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #169: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8372093023255814, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.47, '(min, 1)': 0.15, '(rev, 1)': 0.07, '(rev, 2)': 0.08, '(rev, 3)': 0.03, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:50:39,788 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:39,789 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4048287843355457
2024-04-24 14:50:40,333 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #169: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.44, '(min, 1)': 0.2}}
2024-04-24 14:50:40,334 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:40,334 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4048287843355457
2024-04-24 14:50:40,400 - MainProcess - INFO - text_logger.py - 51 - Train epoch #169
2024-04-24 14:50:40,402 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.8475e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6965e-01, 0.0000e+00,
        1.2271e-01, 8.2456e-03, 3.6792e-01, 0.0000e+00, 2.1630e-02, 5.7522e-03,
        0.0000e+00, 0.0000e+00, 2.3207e-02, 4.3132e-03, 0.0000e+00, 0.0000e+00,
        1.9955e-02, 1.5716e-03, 0.0000e+00, 0.0000e+00, 1.8154e-02, 3.2329e-04,
        0.0000e+00, 0.0000e+00, 1.4673e-02, 6.4516e-05, 0.0000e+00, 0.0000e+00,
        1.4147e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9671e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.5596e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.7210e-05, 0.0000e+00, 0.0000e+00])  tensor([2.1885e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6139e-01, 0.0000e+00,
        1.2819e-01, 1.7481e-02, 1.5872e-01, 0.0000e+00, 3.9773e-02, 1.6558e-02,
        0.0000e+00, 0.0000e+00, 4.7394e-02, 1.7882e-02, 0.0000e+00, 0.0000e+00,
        4.2303e-02, 7.6882e-03, 0.0000e+00, 0.0000e+00, 3.9762e-02, 3.0183e-03,
        0.0000e+00, 0.0000e+00, 3.2998e-02, 1.4426e-03, 0.0000e+00, 0.0000e+00,
        3.3841e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8722e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.6545e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.2262e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:40,414 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.40299836995335864
2024-04-24 14:50:40,416 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:50:40,564 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #170: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4583333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(min, 0)': 0.54, '(min, 1)': 0.05, '(rev, 1)': 0.04, '(rev, 2)': 0.1, '(rev, 3)': 0.01}}
2024-04-24 14:50:40,564 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:40,564 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4039406041714792
2024-04-24 14:50:40,593 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #170: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:50:40,593 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:40,594 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4039406041714792
2024-04-24 14:50:41,018 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #170: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2653061224489796, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(ado, 8)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.17, '(rev, 1)': 0.09, '(rev, 2)': 0.05}}
2024-04-24 14:50:41,018 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:41,019 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4039406041714792
2024-04-24 14:50:41,141 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #170: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.225, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 4)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.34, '(rev, 1)': 0.06, '(rev, 2)': 0.04}}
2024-04-24 14:50:41,141 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:41,142 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4039406041714792
2024-04-24 14:50:41,279 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #170: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5675675675675675, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.23, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:50:41,279 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:41,280 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4039406041714792
2024-04-24 14:50:41,435 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #170: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1276595744680851, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 8)': 0.02, '(min, 0)': 0.54, '(min, 1)': 0.14, '(rev, 1)': 0.06, '(rev, 2)': 0.03}}
2024-04-24 14:50:41,435 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:41,436 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4039406041714792
2024-04-24 14:50:41,816 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #170: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 3)': 0.03, '(min, 0)': 0.5, '(min, 1)': 0.1, '(rev, 1)': 0.12, '(rev, 2)': 0.07}}
2024-04-24 14:50:41,817 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:41,817 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4039406041714792
2024-04-24 14:50:41,886 - MainProcess - INFO - text_logger.py - 51 - Train epoch #170
2024-04-24 14:50:41,888 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.8475e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.6679e-01,
         0.0000e+00,  1.2974e-01,  7.7702e-03,  3.8264e-01,  0.0000e+00,
         2.0132e-02,  5.5949e-03,  0.0000e+00,  0.0000e+00,  2.0424e-02,
         4.1827e-03,  0.0000e+00,  0.0000e+00,  1.7383e-02,  1.3336e-03,
         0.0000e+00,  0.0000e+00,  1.4594e-02,  1.1014e-04,  0.0000e+00,
         0.0000e+00,  1.1641e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         1.1427e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  5.5182e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  5.0604e-04,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  2.1493e-04,  0.0000e+00,  0.0000e+00])  tensor([1.4930, 0.0000, 0.0000, 0.0000, 0.1534, 0.0000, 0.1325, 0.0173, 0.1559,
        0.0000, 0.0382, 0.0183, 0.0000, 0.0000, 0.0438, 0.0200, 0.0000, 0.0000,
        0.0398, 0.0064, 0.0000, 0.0000, 0.0356, 0.0018, 0.0000, 0.0000, 0.0299,
        0.0000, 0.0000, 0.0000, 0.0316, 0.0000, 0.0000, 0.0000, 0.0166, 0.0000,
        0.0000, 0.0000, 0.0031, 0.0000, 0.0000, 0.0000, 0.0023, 0.0000, 0.0000]) (500)
2024-04-24 14:50:41,902 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4030343966048033
2024-04-24 14:50:41,904 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.489130.14130
2024-04-24 14:50:41,981 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #171: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:50:41,981 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:41,981 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40299836995335864
2024-04-24 14:50:42,092 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #171: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 0, 1, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.29, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:50:42,092 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:42,093 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40299836995335864
2024-04-24 14:50:42,188 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #171: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4186046511627907, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.25, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-24 14:50:42,188 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:42,188 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40299836995335864
2024-04-24 14:50:42,541 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #171: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0),(rev, 3)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.21153846153846154, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.16, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:50:42,541 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:42,542 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40299836995335864
2024-04-24 14:50:42,667 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #171: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(min, 0)': 0.06, '(min, 1)': 0.52, '(rev, 1)': 0.08, '(rev, 2)': 0.07}}
2024-04-24 14:50:42,667 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:42,668 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40299836995335864
2024-04-24 14:50:43,152 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #171: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.16, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.23, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-04-24 14:50:43,153 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:43,153 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40299836995335864
2024-04-24 14:50:43,586 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #171: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 5, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.9743589743589743, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(min, 0)': 0.37, '(min, 1)': 0.3, '(rev, 1)': 0.12, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 6)': 0.01}}
2024-04-24 14:50:43,586 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:43,586 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40299836995335864
2024-04-24 14:50:43,652 - MainProcess - INFO - text_logger.py - 51 - Train epoch #171
2024-04-24 14:50:43,655 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-5.7090e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.4455e-01,
         0.0000e+00,  1.3916e-01,  6.9328e-03,  3.4218e-01,  0.0000e+00,
         2.4705e-02,  4.1493e-03,  0.0000e+00,  0.0000e+00,  2.9974e-02,
         1.2924e-03,  0.0000e+00,  0.0000e+00,  2.6705e-02,  5.5556e-05,
         0.0000e+00,  0.0000e+00,  2.4926e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  2.0576e-02,  8.0000e-05,  0.0000e+00,  0.0000e+00,
         2.1493e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0778e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.9253e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  5.1898e-04,  0.0000e+00,  0.0000e+00])  tensor([1.3351e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7387e-01, 0.0000e+00,
        1.2244e-01, 1.6586e-02, 1.7313e-01, 0.0000e+00, 3.8431e-02, 1.2491e-02,
        0.0000e+00, 0.0000e+00, 5.2354e-02, 7.1642e-03, 0.0000e+00, 0.0000e+00,
        4.8163e-02, 1.2423e-03, 0.0000e+00, 0.0000e+00, 4.5716e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.9102e-02, 1.7889e-03, 0.0000e+00, 0.0000e+00,
        4.1432e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2286e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.9705e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8972e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:43,667 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4035331880277083
2024-04-24 14:50:43,669 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.720510.25385
2024-04-24 14:50:43,699 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #172: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.3125, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.57, '(min, 1)': 0.06, '(rev, 1)': 0.08, '(rev, 2)': 0.05}}
2024-04-24 14:50:43,699 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:43,700 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4030343966048033
2024-04-24 14:50:43,715 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #172: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.9347826086956522, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.18, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.03}}
2024-04-24 14:50:43,715 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:43,715 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4030343966048033
2024-04-24 14:50:43,731 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #172: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5641025641025641, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.29, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:50:43,731 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:43,731 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4030343966048033
2024-04-24 14:50:43,779 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #172: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(min, 0)': 0.43, '(min, 1)': 0.18, '(rev, 1)': 0.09, '(rev, 2)': 0.08, '(rev, 3)': 0.02}}
2024-04-24 14:50:43,779 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:43,780 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4030343966048033
2024-04-24 14:50:44,420 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #172: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.24, '(rev, 1)': 0.03, '(rev, 2)': 0.06}}
2024-04-24 14:50:44,420 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:44,420 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4030343966048033
2024-04-24 14:50:45,319 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #172: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.8936170212765957, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(min, 0)': 0.29, '(min, 1)': 0.36, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:50:45,319 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:45,319 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4030343966048033
2024-04-24 14:50:45,421 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #172: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5227272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.17, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:50:45,421 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:45,422 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4030343966048033
2024-04-24 14:50:45,488 - MainProcess - INFO - text_logger.py - 51 - Train epoch #172
2024-04-24 14:50:45,490 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.4436e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6131e-01, 0.0000e+00,
        1.3548e-01, 9.6877e-03, 3.7672e-01, 0.0000e+00, 2.0872e-02, 5.9047e-03,
        0.0000e+00, 0.0000e+00, 2.0052e-02, 2.2092e-03, 0.0000e+00, 0.0000e+00,
        1.7552e-02, 3.6937e-04, 0.0000e+00, 0.0000e+00, 1.6113e-02, 5.8824e-05,
        0.0000e+00, 0.0000e+00, 1.3046e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2885e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.3559e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1237e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.6420e-04, 0.0000e+00, 0.0000e+00])  tensor([1.7403e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5267e-01, 0.0000e+00,
        1.3030e-01, 1.9009e-02, 1.5762e-01, 0.0000e+00, 3.9679e-02, 1.6271e-02,
        0.0000e+00, 0.0000e+00, 4.3665e-02, 1.1050e-02, 0.0000e+00, 0.0000e+00,
        4.0492e-02, 3.8025e-03, 0.0000e+00, 0.0000e+00, 3.9209e-02, 1.3153e-03,
        0.0000e+00, 0.0000e+00, 3.2809e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.3493e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7173e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.6667e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.1046e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:45,502 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4040484636910107
2024-04-24 14:50:45,505 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.728750.20603
2024-04-24 14:50:45,519 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #173: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37254901960784315, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.05, '(ado, 5)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.43, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:50:45,519 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #173: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5714285714285714, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.02, '(min, 0)': 0.11, '(min, 1)': 0.53, '(rev, 1)': 0.12, '(rev, 2)': 0.03, '(rev, 3)': 0.04, '(rev, 4)': 0.01}}
2024-04-24 14:50:45,519 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:45,520 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4035331880277083
2024-04-24 14:50:45,520 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4035331880277083
2024-04-24 14:50:45,535 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #173: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(min, 0)': 0.06, '(min, 1)': 0.51, '(rev, 1)': 0.12, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:50:45,535 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:45,536 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4035331880277083
2024-04-24 14:50:45,875 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #173: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.8181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.24, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 7)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:50:45,875 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:45,876 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4035331880277083
2024-04-24 14:50:46,144 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #173: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6078431372549019, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 9)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.18, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:50:46,144 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:46,145 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4035331880277083
2024-04-24 14:50:46,694 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #173: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10638297872340426, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.07}}
2024-04-24 14:50:46,694 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:46,694 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4035331880277083
2024-04-24 14:50:47,205 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #173: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.574468085106383, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 3)': 0.04, '(min, 0)': 0.41, '(min, 1)': 0.21, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:50:47,205 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:47,205 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4035331880277083
2024-04-24 14:50:47,268 - MainProcess - INFO - text_logger.py - 51 - Train epoch #173
2024-04-24 14:50:47,270 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.7324e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7549e-01, 0.0000e+00,
        1.4118e-01, 1.0241e-02, 3.8783e-01, 0.0000e+00, 1.3973e-02, 1.3194e-02,
        0.0000e+00, 0.0000e+00, 1.0366e-02, 1.1856e-02, 0.0000e+00, 0.0000e+00,
        8.3648e-03, 3.3314e-03, 0.0000e+00, 0.0000e+00, 7.7459e-03, 6.9482e-05,
        0.0000e+00, 0.0000e+00, 6.4932e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.8022e-03, 7.4074e-05, 0.0000e+00, 0.0000e+00, 3.3914e-03, 8.0000e-05,
        0.0000e+00, 0.0000e+00, 4.4637e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.0262e-05, 0.0000e+00, 0.0000e+00])  tensor([2.0287e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3140e-01, 0.0000e+00,
        1.4381e-01, 2.1023e-02, 1.3196e-01, 0.0000e+00, 3.3026e-02, 3.2828e-02,
        0.0000e+00, 0.0000e+00, 3.1904e-02, 4.2028e-02, 0.0000e+00, 0.0000e+00,
        2.8552e-02, 1.3945e-02, 0.0000e+00, 0.0000e+00, 2.7858e-02, 1.1016e-03,
        0.0000e+00, 0.0000e+00, 2.4023e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3211e-02, 1.6563e-03, 0.0000e+00, 0.0000e+00, 1.3979e-02, 1.7889e-03,
        0.0000e+00, 0.0000e+00, 3.0419e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1105e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:47,282 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4042806975579965
2024-04-24 14:50:47,284 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.587230.01277
2024-04-24 14:50:47,315 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #174: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3902439024390244, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.15, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:50:47,315 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:47,315 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #174: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.43902439024390244, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.32, '(rev, 1)': 0.15, '(rev, 2)': 0.04}}
2024-04-24 14:50:47,315 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:47,316 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4040484636910107
2024-04-24 14:50:47,317 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4040484636910107
2024-04-24 14:50:47,331 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #174: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.35, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.05}}
2024-04-24 14:50:47,331 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:47,332 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4040484636910107
2024-04-24 14:50:47,347 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #174: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 2, 7, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13513513513513514, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:50:47,347 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:47,347 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4040484636910107
2024-04-24 14:50:47,437 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #174: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.2, '(rev, 1)': 0.13, '(rev, 2)': 0.01}}
2024-04-24 14:50:47,438 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:47,439 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4040484636910107
2024-04-24 14:50:48,009 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #174: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.26, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.04, '(rev, 4)': 0.01}}
2024-04-24 14:50:48,009 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:48,009 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4040484636910107
2024-04-24 14:50:49,226 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #174: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6595744680851063, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.25, '(rev, 1)': 0.12, '(rev, 2)': 0.01}}
2024-04-24 14:50:49,227 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:49,227 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4040484636910107
2024-04-24 14:50:49,293 - MainProcess - INFO - text_logger.py - 51 - Train epoch #174
2024-04-24 14:50:49,295 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.3217e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0672e-01, 0.0000e+00,
        1.2532e-01, 1.2705e-02, 4.1476e-01, 0.0000e+00, 2.8891e-03, 1.9012e-02,
        0.0000e+00, 0.0000e+00, 5.2655e-04, 1.4673e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.2702e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2429e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.2344, 0.0000, 0.0000, 0.0000, 0.0859, 0.0000, 0.1205, 0.0231, 0.0806,
        0.0000, 0.0101, 0.0358, 0.0000, 0.0000, 0.0042, 0.0396, 0.0000, 0.0000,
        0.0000, 0.0132, 0.0000, 0.0000, 0.0000, 0.0016, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-04-24 14:50:49,310 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.40413317294309614
2024-04-24 14:50:49,311 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.397350.26222
2024-04-24 14:50:49,340 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #175: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.44680851063829785, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.02, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 6)': 0.02}}
2024-04-24 14:50:49,340 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #175: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 7)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.32, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:50:49,340 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:49,340 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:49,341 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4042806975579965
2024-04-24 14:50:49,341 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4042806975579965
2024-04-24 14:50:49,355 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #175: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.27906976744186046, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.19, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:50:49,356 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:49,355 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #175: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.53, '(min, 1)': 0.07}}
2024-04-24 14:50:49,356 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #175: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.06521739130434782, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.27, '(rev, 1)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:50:49,356 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:49,356 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:49,356 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4042806975579965
2024-04-24 14:50:49,357 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4042806975579965
2024-04-24 14:50:49,358 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4042806975579965
2024-04-24 14:50:49,796 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #175: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.20930232558139536, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.05, '(min, 0)': 0.33, '(min, 1)': 0.29, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:50:49,796 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:49,797 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4042806975579965
2024-04-24 14:50:50,754 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #175: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5526315789473685, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.42, '(min, 1)': 0.3, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:50:50,754 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:50,754 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4042806975579965
2024-04-24 14:50:50,825 - MainProcess - INFO - text_logger.py - 51 - Train epoch #175
2024-04-24 14:50:50,828 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.1545e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2270e-01, 0.0000e+00,
        1.6591e-01, 7.0322e-03, 3.3568e-01, 0.0000e+00, 3.0147e-02, 7.6731e-03,
        0.0000e+00, 0.0000e+00, 2.8160e-02, 9.0031e-03, 0.0000e+00, 0.0000e+00,
        2.4131e-02, 3.1577e-03, 0.0000e+00, 0.0000e+00, 2.1343e-02, 3.0086e-04,
        0.0000e+00, 0.0000e+00, 1.7479e-02, 1.7043e-04, 0.0000e+00, 0.0000e+00,
        1.6798e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.4958e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.5998e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.1733e-04, 0.0000e+00, 0.0000e+00])  tensor([2.1587e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6897e-01, 0.0000e+00,
        1.5290e-01, 1.7983e-02, 1.7226e-01, 0.0000e+00, 4.5801e-02, 2.5344e-02,
        0.0000e+00, 0.0000e+00, 4.8629e-02, 3.3012e-02, 0.0000e+00, 0.0000e+00,
        4.4818e-02, 1.1515e-02, 0.0000e+00, 0.0000e+00, 4.1361e-02, 2.4379e-03,
        0.0000e+00, 0.0000e+00, 3.5847e-02, 2.2821e-03, 0.0000e+00, 0.0000e+00,
        3.6393e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9492e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.6959e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8552e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:50,840 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.403743570303923
2024-04-24 14:50:50,842 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.276320.27632
2024-04-24 14:50:50,856 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #176: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.38, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.03}}
2024-04-24 14:50:50,856 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:50,856 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #176: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(min, 0)': 0.62, '(min, 1)': 0.04}}
2024-04-24 14:50:50,856 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:50,856 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #176: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.39215686274509803, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.51, '(min, 1)': 0.15, '(rev, 1)': 0.05, '(rev, 2)': 0.06, '(rev, 7)': 0.01}}
2024-04-24 14:50:50,857 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40413317294309614
2024-04-24 14:50:50,857 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:50,857 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40413317294309614
2024-04-24 14:50:50,857 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40413317294309614
2024-04-24 14:50:50,903 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #176: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 4, 7, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 5, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35714285714285715, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.02, '(ado, 9)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.31, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:50:50,903 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:50,904 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40413317294309614
2024-04-24 14:50:51,179 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #176: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2708333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.18, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:50:51,179 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:51,180 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40413317294309614
2024-04-24 14:50:51,182 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #176: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.509090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(ado, 8)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.16, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:50:51,182 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:51,184 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40413317294309614
2024-04-24 14:50:52,078 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #176: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.47, '(min, 1)': 0.11}}
2024-04-24 14:50:52,078 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:52,079 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40413317294309614
2024-04-24 14:50:52,152 - MainProcess - INFO - text_logger.py - 51 - Train epoch #176
2024-04-24 14:50:52,154 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.1060e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6844e-01, 0.0000e+00,
        1.4348e-01, 1.0435e-02, 3.7782e-01, 0.0000e+00, 2.1918e-02, 6.3251e-03,
        0.0000e+00, 0.0000e+00, 1.8180e-02, 3.6251e-03, 0.0000e+00, 0.0000e+00,
        1.4455e-02, 1.5505e-03, 0.0000e+00, 0.0000e+00, 1.1898e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.6950e-03, 5.7143e-05, 0.0000e+00, 0.0000e+00,
        8.1446e-03, 1.2702e-04, 0.0000e+00, 0.0000e+00, 3.5799e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.3756e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.7037e-05, 0.0000e+00, 0.0000e+00])  tensor([1.5849e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5022e-01, 0.0000e+00,
        1.5024e-01, 2.0284e-02, 1.4936e-01, 0.0000e+00, 4.2540e-02, 2.0971e-02,
        0.0000e+00, 0.0000e+00, 4.1177e-02, 1.8257e-02, 0.0000e+00, 0.0000e+00,
        3.6165e-02, 8.1638e-03, 0.0000e+00, 0.0000e+00, 3.1648e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.7396e-02, 1.2778e-03, 0.0000e+00, 0.0000e+00,
        2.5433e-02, 2.0065e-03, 0.0000e+00, 0.0000e+00, 1.2510e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.2069e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.2817e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:52,169 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.40280133608580243
2024-04-24 14:50:52,170 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:50:52,228 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #177: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.52, '(min, 1)': 0.09, '(rev, 1)': 0.01}}
2024-04-24 14:50:52,228 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:52,228 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.403743570303923
2024-04-24 14:50:52,232 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #177: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.54, '(min, 1)': 0.04}}
2024-04-24 14:50:52,232 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:52,232 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.403743570303923
2024-04-24 14:50:52,379 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #177: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3137254901960784, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.26, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:50:52,380 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:52,380 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.403743570303923
2024-04-24 14:50:52,508 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #177: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5652173913043478, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(min, 0)': 0.47, '(min, 1)': 0.13, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.04}}
2024-04-24 14:50:52,508 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:52,508 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.403743570303923
2024-04-24 14:50:52,658 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #177: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4375, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(min, 0)': 0.48, '(min, 1)': 0.17, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:50:52,658 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:52,659 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.403743570303923
2024-04-24 14:50:52,962 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #177: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.05405405405405406, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 8)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.22, '(rev, 1)': 0.02, '(rev, 2)': 0.01}}
2024-04-24 14:50:52,962 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:52,963 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.403743570303923
2024-04-24 14:50:53,830 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #177: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.37735849056603776, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.16, '(rev, 1)': 0.07, '(rev, 2)': 0.04}}
2024-04-24 14:50:53,830 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:53,831 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.403743570303923
2024-04-24 14:50:53,900 - MainProcess - INFO - text_logger.py - 51 - Train epoch #177
2024-04-24 14:50:53,902 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-6.2968e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7983e-01,
         0.0000e+00,  1.7507e-01,  6.1281e-03,  2.8548e-01,  0.0000e+00,
         4.4540e-02,  4.1661e-03,  0.0000e+00,  0.0000e+00,  4.8640e-02,
         3.2028e-03,  0.0000e+00,  0.0000e+00,  4.0809e-02,  7.5930e-04,
         0.0000e+00,  0.0000e+00,  3.6107e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  2.9809e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.9857e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.3112e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.1004e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.9259e-04,  0.0000e+00,  0.0000e+00])  tensor([1.7779, 0.0000, 0.0000, 0.0000, 0.1886, 0.0000, 0.1458, 0.0162, 0.1919,
        0.0000, 0.0510, 0.0165, 0.0000, 0.0000, 0.0604, 0.0181, 0.0000, 0.0000,
        0.0525, 0.0056, 0.0000, 0.0000, 0.0481, 0.0000, 0.0000, 0.0000, 0.0402,
        0.0000, 0.0000, 0.0000, 0.0422, 0.0000, 0.0000, 0.0000, 0.0217, 0.0000,
        0.0000, 0.0000, 0.0064, 0.0000, 0.0000, 0.0000, 0.0025, 0.0000, 0.0000]) (500)
2024-04-24 14:50:53,915 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4022364603582479
2024-04-24 14:50:53,917 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.188680.18868
2024-04-24 14:50:53,932 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #178: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3191489361702128, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.15, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 8)': 0.01}}
2024-04-24 14:50:53,932 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:53,933 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40280133608580243
2024-04-24 14:50:53,934 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #178: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.39, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-04-24 14:50:53,934 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:53,934 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40280133608580243
2024-04-24 14:50:53,948 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #178: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.26, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.02}}
2024-04-24 14:50:53,948 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:53,949 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40280133608580243
2024-04-24 14:50:54,356 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #178: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.18, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-04-24 14:50:54,356 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:54,357 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40280133608580243
2024-04-24 14:50:54,362 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #178: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.03389830508474576, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 7)': 0.03, '(ado, 9)': 0.01, '(min, 0)': 0.6, '(min, 1)': 0.1, '(rev, 1)': 0.04}}
2024-04-24 14:50:54,362 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:54,363 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40280133608580243
2024-04-24 14:50:54,662 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #178: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.13}}
2024-04-24 14:50:54,662 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:54,663 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40280133608580243
2024-04-24 14:50:55,267 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #178: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40425531914893614, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 3)': 0.03, '(min, 0)': 0.52, '(min, 1)': 0.14, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:50:55,268 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:55,268 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40280133608580243
2024-04-24 14:50:55,340 - MainProcess - INFO - text_logger.py - 51 - Train epoch #178
2024-04-24 14:50:55,342 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.4546e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2989e-01, 0.0000e+00,
        1.6140e-01, 7.1088e-03, 3.3973e-01, 0.0000e+00, 2.9847e-02, 6.5525e-03,
        0.0000e+00, 0.0000e+00, 2.8976e-02, 1.0642e-02, 0.0000e+00, 0.0000e+00,
        2.3174e-02, 2.9189e-03, 0.0000e+00, 0.0000e+00, 2.0181e-02, 2.1436e-04,
        0.0000e+00, 0.0000e+00, 1.6461e-02, 1.3436e-04, 0.0000e+00, 0.0000e+00,
        1.5202e-02, 1.3436e-04, 0.0000e+00, 0.0000e+00, 6.4497e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.4844e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3450e-04, 0.0000e+00, 0.0000e+00])  tensor([2.2248e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6746e-01, 0.0000e+00,
        1.4234e-01, 1.7983e-02, 1.6841e-01, 0.0000e+00, 4.7008e-02, 2.2986e-02,
        0.0000e+00, 0.0000e+00, 5.1711e-02, 4.6609e-02, 0.0000e+00, 0.0000e+00,
        4.3237e-02, 1.3430e-02, 0.0000e+00, 0.0000e+00, 3.9209e-02, 2.3322e-03,
        0.0000e+00, 0.0000e+00, 3.3080e-02, 1.5036e-03, 0.0000e+00, 0.0000e+00,
        3.2761e-02, 1.5036e-03, 0.0000e+00, 0.0000e+00, 1.5765e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.9209e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.5152e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:55,355 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.40169848145927617
2024-04-24 14:50:55,358 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.202130.20213
2024-04-24 14:50:55,407 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #179: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.45, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:50:55,407 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:55,407 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4022364603582479
2024-04-24 14:50:55,446 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #179: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43902439024390244, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.03, '(ado, 5)': 0.01, '(min, 0)': 0.15, '(min, 1)': 0.48, '(rev, 1)': 0.13, '(rev, 2)': 0.02, '(rev, 3)': 0.04, '(rev, 4)': 0.02}}
2024-04-24 14:50:55,447 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:55,447 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4022364603582479
2024-04-24 14:50:55,541 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #179: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 3, 0, 0),(rev, 4)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '4/4', 'revenue': 0.7272727272727273, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.45, '(rev, 1)': 0.13, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-04-24 14:50:55,541 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:55,542 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4022364603582479
2024-04-24 14:50:55,848 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #179: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 4)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.56, '(min, 1)': 0.11, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:50:55,848 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:55,849 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4022364603582479
2024-04-24 14:50:55,982 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #179: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.54, '(min, 1)': 0.07}}
2024-04-24 14:50:55,982 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:55,982 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4022364603582479
2024-04-24 14:50:55,986 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #179: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2682926829268293, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 3)': 0.04, '(min, 0)': 0.14, '(min, 1)': 0.5, '(rev, 1)': 0.14, '(rev, 3)': 0.01}}
2024-04-24 14:50:55,986 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:55,986 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4022364603582479
2024-04-24 14:50:57,553 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #179: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 1, 1, 7, 0, 1),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 1, 1, 8, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.3170731707317073, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 9)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.36, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:50:57,553 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:57,554 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4022364603582479
2024-04-24 14:50:57,617 - MainProcess - INFO - text_logger.py - 51 - Train epoch #179
2024-04-24 14:50:57,619 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.7597e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4589e-01, 0.0000e+00,
        1.6583e-01, 8.2906e-03, 3.5654e-01, 0.0000e+00, 2.1020e-02, 9.4412e-03,
        0.0000e+00, 0.0000e+00, 1.8564e-02, 9.8281e-03, 0.0000e+00, 0.0000e+00,
        1.5781e-02, 4.8980e-03, 0.0000e+00, 0.0000e+00, 1.3845e-02, 8.0000e-05,
        0.0000e+00, 0.0000e+00, 1.1781e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1357e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1817e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2998e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.7557e-04, 0.0000e+00, 0.0000e+00])  tensor([1.8622e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4977e-01, 0.0000e+00,
        1.4143e-01, 1.8280e-02, 1.4971e-01, 0.0000e+00, 4.1145e-02, 2.4955e-02,
        0.0000e+00, 0.0000e+00, 4.2650e-02, 3.7383e-02, 0.0000e+00, 0.0000e+00,
        3.9000e-02, 2.0729e-02, 0.0000e+00, 0.0000e+00, 3.5605e-02, 1.7889e-03,
        0.0000e+00, 0.0000e+00, 3.1552e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2047e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5195e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.0977e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5309e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:57,631 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.40107332041188737
2024-04-24 14:50:57,638 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.158540.15854
2024-04-24 14:50:57,663 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #180: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 1.0, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.26, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.04, '(rev, 4)': 0.01}}
2024-04-24 14:50:57,663 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:57,663 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #180: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(min, 0)': 0.4, '(min, 1)': 0.2, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:50:57,663 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:57,664 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40169848145927617
2024-04-24 14:50:57,664 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40169848145927617
2024-04-24 14:50:57,680 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #180: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.34, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 6)': 0.01}}
2024-04-24 14:50:57,680 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:57,680 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40169848145927617
2024-04-24 14:50:57,694 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #180: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32558139534883723, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(min, 0)': 0.34, '(min, 1)': 0.24, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-04-24 14:50:57,695 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:57,695 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40169848145927617
2024-04-24 14:50:57,734 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #180: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.045454545454545456, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.59, '(min, 1)': 0.07, '(rev, 1)': 0.04}}
2024-04-24 14:50:57,734 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:57,735 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40169848145927617
2024-04-24 14:50:58,115 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #180: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5319148936170213, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.33, '(rev, 1)': 0.06, '(rev, 10)': 0.01, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:50:58,115 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:58,117 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40169848145927617
2024-04-24 14:50:58,827 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #180: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2619047619047619, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.17, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-04-24 14:50:58,827 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:58,828 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40169848145927617
2024-04-24 14:50:58,899 - MainProcess - INFO - text_logger.py - 51 - Train epoch #180
2024-04-24 14:50:58,901 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([9.9981e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7074e-01, 0.0000e+00,
        1.3267e-01, 9.5156e-03, 3.8528e-01, 0.0000e+00, 1.7534e-02, 6.6747e-03,
        0.0000e+00, 0.0000e+00, 1.6119e-02, 7.7814e-03, 0.0000e+00, 0.0000e+00,
        1.3396e-02, 3.1074e-03, 0.0000e+00, 0.0000e+00, 1.1876e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0359e-02, 7.4074e-05, 0.0000e+00, 0.0000e+00,
        9.6375e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1566e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.6652e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.1161e-04, 0.0000e+00, 0.0000e+00])  tensor([2.2575e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4396e-01, 0.0000e+00,
        1.3364e-01, 2.0606e-02, 1.4719e-01, 0.0000e+00, 3.8358e-02, 2.0154e-02,
        0.0000e+00, 0.0000e+00, 4.1009e-02, 2.9786e-02, 0.0000e+00, 0.0000e+00,
        3.6087e-02, 1.4251e-02, 0.0000e+00, 0.0000e+00, 3.3243e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.9556e-02, 1.6563e-03, 0.0000e+00, 0.0000e+00,
        2.8478e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2858e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.0084e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9386e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:50:58,913 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4009249058492886
2024-04-24 14:50:58,915 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.396910.13501
2024-04-24 14:50:58,968 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #181: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5813953488372093, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.03, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.11, '(rev, 2)': 0.07, '(rev, 3)': 0.04, '(rev, 4)': 0.01}}
2024-04-24 14:50:58,969 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:58,969 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40107332041188737
2024-04-24 14:50:59,014 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #181: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.35714285714285715, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.27, '(rev, 1)': 0.13, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:50:59,015 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:59,015 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40107332041188737
2024-04-24 14:50:59,404 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #181: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.75, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.2, '(min, 1)': 0.43, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.04, '(rev, 4)': 0.02, '(rev, 6)': 0.01}}
2024-04-24 14:50:59,404 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:59,405 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40107332041188737
2024-04-24 14:50:59,472 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #181: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.27, '(rev, 1)': 0.12, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-24 14:50:59,472 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:59,473 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40107332041188737
2024-04-24 14:50:59,561 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #181: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.18181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.14, '(min, 1)': 0.44, '(rev, 1)': 0.06, '(rev, 2)': 0.03}}
2024-04-24 14:50:59,561 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:59,561 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40107332041188737
2024-04-24 14:50:59,717 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #181: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.46, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 3)': 0.05}}
2024-04-24 14:50:59,717 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:50:59,719 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40107332041188737
2024-04-24 14:51:00,351 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #181: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 6, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4418604651162791, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.23, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:51:00,351 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:00,351 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40107332041188737
2024-04-24 14:51:00,417 - MainProcess - INFO - text_logger.py - 51 - Train epoch #181
2024-04-24 14:51:00,419 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.5774e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0225e-01, 0.0000e+00,
        1.3933e-01, 1.0202e-02, 4.1750e-01, 0.0000e+00, 4.6811e-03, 9.3393e-03,
        0.0000e+00, 0.0000e+00, 1.4140e-03, 1.0007e-02, 0.0000e+00, 0.0000e+00,
        5.0588e-04, 4.2101e-03, 0.0000e+00, 0.0000e+00, 2.4462e-04, 1.6379e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5460e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.2242e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.1370e-02, 0.0000e+00,
        1.4814e-01, 1.9503e-02, 9.1952e-02, 0.0000e+00, 1.5087e-02, 1.9937e-02,
        0.0000e+00, 0.0000e+00, 8.2338e-03, 2.8534e-02, 0.0000e+00, 0.0000e+00,
        4.5185e-03, 1.6317e-02, 0.0000e+00, 0.0000e+00, 2.7821e-03, 1.8287e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1100e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:51:00,434 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4011454623288424
2024-04-24 14:51:00,436 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.581400.13953
2024-04-24 14:51:00,449 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #182: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5227272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.22, '(min, 1)': 0.4, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:51:00,449 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:00,450 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4009249058492886
2024-04-24 14:51:00,499 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #182: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5454545454545454, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.37, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:51:00,499 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:00,500 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4009249058492886
2024-04-24 14:51:00,755 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #182: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5116279069767442, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.15, '(min, 1)': 0.47, '(rev, 1)': 0.13, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-24 14:51:00,755 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:00,756 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4009249058492886
2024-04-24 14:51:01,617 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #182: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 6, 2, 0, 0),(rev, 6)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '6/6', 'revenue': 0.6530612244897959, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.14, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:51:01,617 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:01,617 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4009249058492886
2024-04-24 14:51:01,804 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #182: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5531914893617021, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.04, '(min, 0)': 0.42, '(min, 1)': 0.18, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:51:01,805 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:01,805 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4009249058492886
2024-04-24 14:51:01,844 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #182: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.9210526315789473, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.45, '(min, 1)': 0.2, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:51:01,844 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:01,845 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4009249058492886
2024-04-24 14:51:02,388 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #182: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6578947368421053, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.38, '(min, 1)': 0.24, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.04, '(rev, 4)': 0.02}}
2024-04-24 14:51:02,388 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:02,388 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4009249058492886
2024-04-24 14:51:02,462 - MainProcess - INFO - text_logger.py - 51 - Train epoch #182
2024-04-24 14:51:02,464 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.1110e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7575e-01, 0.0000e+00,
        1.3460e-01, 1.0575e-02, 3.9318e-01, 0.0000e+00, 1.3626e-02, 7.8943e-03,
        0.0000e+00, 0.0000e+00, 1.2642e-02, 9.3880e-03, 0.0000e+00, 0.0000e+00,
        1.0279e-02, 4.6432e-03, 0.0000e+00, 0.0000e+00, 9.0750e-03, 8.1667e-05,
        0.0000e+00, 0.0000e+00, 7.3455e-03, 1.1143e-04, 0.0000e+00, 0.0000e+00,
        7.2506e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7054e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.2426e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3025e-04, 0.0000e+00, 0.0000e+00])  tensor([2.2523e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2918e-01, 0.0000e+00,
        1.3574e-01, 2.0610e-02, 1.3429e-01, 0.0000e+00, 3.2269e-02, 1.9952e-02,
        0.0000e+00, 0.0000e+00, 3.6950e-02, 2.9144e-02, 0.0000e+00, 0.0000e+00,
        3.1953e-02, 1.5781e-02, 0.0000e+00, 0.0000e+00, 2.9307e-02, 1.2902e-03,
        0.0000e+00, 0.0000e+00, 2.4588e-02, 1.8290e-03, 0.0000e+00, 0.0000e+00,
        2.5284e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1079e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.5852e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9525e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:51:02,478 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4017821754791429
2024-04-24 14:51:02,480 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.789470.13158
2024-04-24 14:51:02,493 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #183: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 6, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5365853658536586, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.24, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 5)': 0.01}}
2024-04-24 14:51:02,493 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:02,494 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4011454623288424
2024-04-24 14:51:02,524 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #183: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.31, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 9)': 0.01}}
2024-04-24 14:51:02,524 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:02,525 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4011454623288424
2024-04-24 14:51:02,540 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #183: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2608695652173913, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.16, '(rev, 1)': 0.09, '(rev, 2)': 0.04}}
2024-04-24 14:51:02,540 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:02,541 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4011454623288424
2024-04-24 14:51:02,756 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #183: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.12, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03}}
2024-04-24 14:51:02,756 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:02,756 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4011454623288424
2024-04-24 14:51:03,067 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #183: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.49, '(min, 1)': 0.1}}
2024-04-24 14:51:03,067 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:03,068 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4011454623288424
2024-04-24 14:51:03,110 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #183: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 6, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2558139534883721, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.51, '(min, 1)': 0.12, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:51:03,110 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:03,110 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4011454623288424
2024-04-24 14:51:03,955 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #183: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(ado, 7)': 0.01, '(min, 0)': 0.57, '(min, 1)': 0.03}}
2024-04-24 14:51:03,955 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:03,956 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4011454623288424
2024-04-24 14:51:04,026 - MainProcess - INFO - text_logger.py - 51 - Train epoch #183
2024-04-24 14:51:04,029 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.0953e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9609e-01, 0.0000e+00,
        1.3242e-01, 1.0125e-02, 4.0118e-01, 0.0000e+00, 1.3687e-02, 4.6696e-03,
        0.0000e+00, 0.0000e+00, 1.1697e-02, 2.6881e-03, 0.0000e+00, 0.0000e+00,
        8.8958e-03, 7.5115e-04, 0.0000e+00, 0.0000e+00, 6.8979e-03, 5.5556e-05,
        0.0000e+00, 0.0000e+00, 5.0737e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.0209e-03, 8.0000e-05, 0.0000e+00, 0.0000e+00, 1.3455e-03, 7.1429e-05,
        0.0000e+00, 0.0000e+00, 1.4400e-04, 7.4074e-05, 0.0000e+00, 0.0000e+00,
        3.5714e-05, 0.0000e+00, 0.0000e+00])  tensor([1.7152e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2468e-01, 0.0000e+00,
        1.5105e-01, 1.9670e-02, 1.2437e-01, 0.0000e+00, 3.2026e-02, 1.3436e-02,
        0.0000e+00, 0.0000e+00, 3.3713e-02, 1.1902e-02, 0.0000e+00, 0.0000e+00,
        2.8134e-02, 5.1924e-03, 0.0000e+00, 0.0000e+00, 2.3925e-02, 1.2423e-03,
        0.0000e+00, 0.0000e+00, 1.9968e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9732e-02, 1.7889e-03, 0.0000e+00, 0.0000e+00, 7.5343e-03, 1.5972e-03,
        0.0000e+00, 0.0000e+00, 1.6157e-03, 1.6563e-03, 0.0000e+00, 0.0000e+00,
        7.9860e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:51:04,042 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4008399412610223
2024-04-24 14:51:04,044 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:51:04,088 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #184: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.6, '(min, 1)': 0.05}}
2024-04-24 14:51:04,088 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:04,088 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4017821754791429
2024-04-24 14:51:04,103 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #184: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.14, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:51:04,103 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:04,104 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4017821754791429
2024-04-24 14:51:04,210 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #184: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.19, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:51:04,210 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:04,211 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4017821754791429
2024-04-24 14:51:04,262 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #184: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.8636363636363636, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(min, 0)': 0.21, '(min, 1)': 0.38, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-04-24 14:51:04,262 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:04,263 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4017821754791429
2024-04-24 14:51:04,270 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #184: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.46, '(min, 1)': 0.13}}
2024-04-24 14:51:04,270 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:04,271 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4017821754791429
2024-04-24 14:51:04,708 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #184: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5306122448979592, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.19, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:51:04,709 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:04,709 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4017821754791429
2024-04-24 14:51:05,891 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #184: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.55, '(min, 1)': 0.06}}
2024-04-24 14:51:05,891 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:05,891 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4017821754791429
2024-04-24 14:51:05,961 - MainProcess - INFO - text_logger.py - 51 - Train epoch #184
2024-04-24 14:51:05,964 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-7.1204e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.0704e-01,
         0.0000e+00,  1.4755e-01,  6.2597e-03,  3.1584e-01,  0.0000e+00,
         3.5579e-02,  2.7512e-03,  0.0000e+00,  0.0000e+00,  4.2881e-02,
         2.0899e-03,  0.0000e+00,  0.0000e+00,  3.7167e-02,  1.2775e-03,
         0.0000e+00,  0.0000e+00,  3.2450e-02,  2.8169e-05,  0.0000e+00,
         0.0000e+00,  2.7719e-02,  2.8169e-05,  0.0000e+00,  0.0000e+00,
         2.7499e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1224e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.1410e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  4.7908e-04,  0.0000e+00,  0.0000e+00])  tensor([2.2079e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8519e-01, 0.0000e+00,
        1.2865e-01, 1.6114e-02, 1.9203e-01, 0.0000e+00, 4.7958e-02, 1.0434e-02,
        0.0000e+00, 0.0000e+00, 6.1690e-02, 1.1245e-02, 0.0000e+00, 0.0000e+00,
        5.4466e-02, 8.2611e-03, 0.0000e+00, 0.0000e+00, 4.8733e-02, 6.2988e-04,
        0.0000e+00, 0.0000e+00, 4.2482e-02, 6.2988e-04, 0.0000e+00, 0.0000e+00,
        4.4201e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9262e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.2368e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7597e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:51:05,977 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.39989770704290173
2024-04-24 14:51:05,979 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:51:05,990 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #185: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5652173913043478, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.43, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 6)': 0.01, '(rev, 9)': 0.01}}
2024-04-24 14:51:05,990 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:05,991 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4008399412610223
2024-04-24 14:51:06,009 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #185: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.574468085106383, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(min, 0)': 0.48, '(min, 1)': 0.18, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 7)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:51:06,009 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:06,009 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4008399412610223
2024-04-24 14:51:06,024 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #185: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3191489361702128, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 6)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.26, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:51:06,025 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:06,025 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4008399412610223
2024-04-24 14:51:06,040 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #185: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.58, '(min, 1)': 0.03}}
2024-04-24 14:51:06,040 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:06,041 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4008399412610223
2024-04-24 14:51:06,127 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #185: {'transition': '(exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 2, 4, 1, 1),(min, 0)->(exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 2, 5, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.03, '(min, 0)': 0.4, '(min, 1)': 0.2, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-24 14:51:06,127 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:06,127 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4008399412610223
2024-04-24 14:51:06,378 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #185: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.02, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.29, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:51:06,379 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:06,379 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4008399412610223
2024-04-24 14:51:07,285 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #185: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.55, '(min, 1)': 0.06}}
2024-04-24 14:51:07,285 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:07,286 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4008399412610223
2024-04-24 14:51:07,349 - MainProcess - INFO - text_logger.py - 51 - Train epoch #185
2024-04-24 14:51:07,352 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0148e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5612e-01, 0.0000e+00,
        1.4781e-01, 8.9569e-03, 3.6265e-01, 0.0000e+00, 2.1143e-02, 5.1436e-03,
        0.0000e+00, 0.0000e+00, 2.1543e-02, 9.3914e-03, 0.0000e+00, 0.0000e+00,
        1.7217e-02, 7.0398e-03, 0.0000e+00, 0.0000e+00, 1.4499e-02, 1.6766e-04,
        0.0000e+00, 0.0000e+00, 1.1739e-02, 6.9412e-05, 0.0000e+00, 0.0000e+00,
        1.1395e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2705e-03, 8.0000e-05,
        0.0000e+00, 0.0000e+00, 5.7801e-04, 7.4074e-05, 0.0000e+00, 0.0000e+00,
        1.1970e-04, 0.0000e+00, 0.0000e+00])  tensor([2.1285e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5722e-01, 0.0000e+00,
        1.5586e-01, 2.0240e-02, 1.5475e-01, 0.0000e+00, 3.9846e-02, 1.6691e-02,
        0.0000e+00, 0.0000e+00, 4.7675e-02, 3.8426e-02, 0.0000e+00, 0.0000e+00,
        4.0287e-02, 2.9447e-02, 0.0000e+00, 0.0000e+00, 3.5370e-02, 1.7013e-03,
        0.0000e+00, 0.0000e+00, 2.9311e-02, 1.1091e-03, 0.0000e+00, 0.0000e+00,
        2.9689e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2292e-02, 1.7889e-03,
        0.0000e+00, 0.0000e+00, 3.2145e-03, 1.6563e-03, 0.0000e+00, 0.0000e+00,
        1.3507e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:51:07,365 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.39895547282478117
2024-04-24 14:51:07,367 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:51:07,424 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #186: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.58, '(min, 1)': 0.03}}
2024-04-24 14:51:07,424 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:07,425 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39989770704290173
2024-04-24 14:51:07,737 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #186: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6744186046511628, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(min, 0)': 0.28, '(min, 1)': 0.4, '(rev, 1)': 0.13, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:51:07,738 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:07,738 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39989770704290173
2024-04-24 14:51:07,749 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #186: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 3)': 0.03, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.28, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:51:07,749 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:07,750 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39989770704290173
2024-04-24 14:51:07,837 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #186: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 3)': 0.04, '(ado, 7)': 0.01, '(min, 0)': 0.55, '(min, 1)': 0.12, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:51:07,837 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:07,838 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39989770704290173
2024-04-24 14:51:07,869 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #186: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.44, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:51:07,869 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:07,870 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39989770704290173
2024-04-24 14:51:07,965 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #186: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.17777777777777778, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.16, '(rev, 1)': 0.05, '(rev, 2)': 0.05}}
2024-04-24 14:51:07,965 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:07,965 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39989770704290173
2024-04-24 14:51:08,573 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #186: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.59, '(min, 1)': 0.04}}
2024-04-24 14:51:08,573 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:08,574 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39989770704290173
2024-04-24 14:51:08,644 - MainProcess - INFO - text_logger.py - 51 - Train epoch #186
2024-04-24 14:51:08,647 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.7896e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3690e-01, 0.0000e+00,
        1.8179e-01, 8.8743e-03, 3.4849e-01, 0.0000e+00, 2.3540e-02, 8.5922e-03,
        0.0000e+00, 0.0000e+00, 1.8740e-02, 1.1535e-02, 0.0000e+00, 0.0000e+00,
        1.5702e-02, 5.4604e-03, 0.0000e+00, 0.0000e+00, 1.3348e-02, 4.2553e-05,
        0.0000e+00, 0.0000e+00, 1.1368e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0790e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2686e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.8869e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.5579e-05, 0.0000e+00, 0.0000e+00])  tensor([1.8945e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4857e-01, 0.0000e+00,
        1.5555e-01, 1.9877e-02, 1.4962e-01, 0.0000e+00, 4.2194e-02, 2.1758e-02,
        0.0000e+00, 0.0000e+00, 4.2225e-02, 5.0945e-02, 0.0000e+00, 0.0000e+00,
        4.0149e-02, 2.6867e-02, 0.0000e+00, 0.0000e+00, 3.5732e-02, 9.5152e-04,
        0.0000e+00, 0.0000e+00, 3.1706e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.1784e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3247e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.0333e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1947e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:51:08,661 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3980132386066606
2024-04-24 14:51:08,663 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:51:08,725 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #187: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 1, 7, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 2, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.53, '(min, 1)': 0.06}}
2024-04-24 14:51:08,725 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:08,726 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39895547282478117
2024-04-24 14:51:09,440 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #187: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4358974358974359, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.46, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:51:09,440 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:09,441 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39895547282478117
2024-04-24 14:51:09,500 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #187: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5476190476190477, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.35, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.02}}
2024-04-24 14:51:09,501 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:09,501 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39895547282478117
2024-04-24 14:51:09,510 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #187: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.36, '(rev, 1)': 0.01, '(rev, 2)': 0.02, '(rev, 3)': 0.04, '(rev, 4)': 0.02, '(rev, 5)': 0.02, '(rev, 6)': 0.01}}
2024-04-24 14:51:09,510 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:09,510 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39895547282478117
2024-04-24 14:51:09,528 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #187: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.32, '(min, 1)': 0.33, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 7)': 0.01}}
2024-04-24 14:51:09,528 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:09,529 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39895547282478117
2024-04-24 14:51:09,952 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #187: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.5, '(min, 1)': 0.12}}
2024-04-24 14:51:09,952 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:09,953 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39895547282478117
2024-04-24 14:51:10,051 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #187: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 5, 0, 1),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 6, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.7142857142857143, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.04, '(min, 0)': 0.26, '(min, 1)': 0.38, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:51:10,051 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:10,051 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39895547282478117
2024-04-24 14:51:10,229 - MainProcess - INFO - text_logger.py - 51 - Train epoch #187
2024-04-24 14:51:10,232 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.6158e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6732e-01, 0.0000e+00,
        1.9010e-01, 1.0160e-02, 3.7991e-01, 0.0000e+00, 1.0263e-02, 1.0553e-02,
        0.0000e+00, 0.0000e+00, 4.2493e-03, 1.2523e-02, 0.0000e+00, 0.0000e+00,
        2.4123e-03, 7.4764e-03, 0.0000e+00, 0.0000e+00, 1.5045e-03, 4.3374e-04,
        0.0000e+00, 0.0000e+00, 1.2673e-03, 1.5692e-04, 0.0000e+00, 0.0000e+00,
        1.0589e-03, 6.4516e-05, 0.0000e+00, 0.0000e+00, 4.9495e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.5556e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.3149e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1694e-01, 0.0000e+00,
        1.8141e-01, 2.0813e-02, 1.1373e-01, 0.0000e+00, 2.5393e-02, 2.2779e-02,
        0.0000e+00, 0.0000e+00, 1.7939e-02, 3.2120e-02, 0.0000e+00, 0.0000e+00,
        1.3689e-02, 2.2963e-02, 0.0000e+00, 0.0000e+00, 1.1267e-02, 3.2393e-03,
        0.0000e+00, 0.0000e+00, 1.0087e-02, 2.4792e-03, 0.0000e+00, 0.0000e+00,
        9.4340e-03, 1.4426e-03, 0.0000e+00, 0.0000e+00, 4.5595e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2423e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:51:10,246 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.39707100438854004
2024-04-24 14:51:10,249 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:51:10,275 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #188: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.52, '(min, 1)': 0.09}}
2024-04-24 14:51:10,276 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:10,277 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3980132386066606
2024-04-24 14:51:10,985 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #188: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.02, '(min, 0)': 0.13, '(min, 1)': 0.48, '(rev, 1)': 0.12, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:51:10,985 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:10,985 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3980132386066606
2024-04-24 14:51:11,050 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #188: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40425531914893614, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.19, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-04-24 14:51:11,051 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:11,051 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3980132386066606
2024-04-24 14:51:11,151 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #188: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(ado, 4)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.13, '(rev, 1)': 0.09, '(rev, 2)': 0.05}}
2024-04-24 14:51:11,151 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:11,152 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3980132386066606
2024-04-24 14:51:11,212 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #188: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.17, '(rev, 1)': 0.03, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:51:11,212 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:11,212 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3980132386066606
2024-04-24 14:51:11,879 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #188: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.21, '(rev, 1)': 0.11, '(rev, 2)': 0.05}}
2024-04-24 14:51:11,880 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:11,881 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3980132386066606
2024-04-24 14:51:12,267 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #188: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 6, 0, 1),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 6, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.56, '(min, 1)': 0.1}}
2024-04-24 14:51:12,267 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:12,268 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3980132386066606
2024-04-24 14:51:12,348 - MainProcess - INFO - text_logger.py - 51 - Train epoch #188
2024-04-24 14:51:12,350 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.3038e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2336e-01, 0.0000e+00,
        1.2156e-01, 1.2352e-02, 4.2876e-01, 0.0000e+00, 3.8628e-03, 4.9883e-03,
        0.0000e+00, 0.0000e+00, 1.3180e-03, 2.0387e-03, 0.0000e+00, 0.0000e+00,
        5.2997e-04, 7.4198e-04, 0.0000e+00, 0.0000e+00, 2.9984e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2311e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.0606e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([0.9026, 0.0000, 0.0000, 0.0000, 0.0742, 0.0000, 0.1307, 0.0213, 0.0755,
        0.0000, 0.0134, 0.0131, 0.0000, 0.0000, 0.0089, 0.0094, 0.0000, 0.0000,
        0.0047, 0.0054, 0.0000, 0.0000, 0.0036, 0.0000, 0.0000, 0.0000, 0.0019,
        0.0000, 0.0000, 0.0000, 0.0014, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-04-24 14:51:12,366 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3961287701704194
2024-04-24 14:51:12,368 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:51:12,518 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #189: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3617021276595745, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.02, '(min, 0)': 0.12, '(min, 1)': 0.45, '(rev, 1)': 0.12, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:51:12,518 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:12,519 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39707100438854004
2024-04-24 14:51:12,566 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #189: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5185185185185185, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.13, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:51:12,566 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:12,567 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39707100438854004
2024-04-24 14:51:13,152 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #189: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(ado, 4)': 0.02, '(min, 0)': 0.1, '(min, 1)': 0.52, '(rev, 1)': 0.12, '(rev, 2)': 0.01}}
2024-04-24 14:51:13,152 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:13,153 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39707100438854004
2024-04-24 14:51:13,302 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #189: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.42857142857142855, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.5, '(min, 1)': 0.18, '(rev, 1)': 0.03, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:51:13,302 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:13,302 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39707100438854004
2024-04-24 14:51:13,553 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #189: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46511627906976744, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.29, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:51:13,553 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:13,554 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39707100438854004
2024-04-24 14:51:13,999 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #189: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.14, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-04-24 14:51:13,999 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:14,000 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39707100438854004
2024-04-24 14:51:14,383 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #189: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 8)': 0.01, '(min, 0)': 0.55, '(min, 1)': 0.07, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-04-24 14:51:14,383 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:14,383 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39707100438854004
2024-04-24 14:51:14,449 - MainProcess - INFO - text_logger.py - 51 - Train epoch #189
2024-04-24 14:51:14,453 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.8897e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7843e-01, 0.0000e+00,
        1.2070e-01, 1.1169e-02, 3.9358e-01, 0.0000e+00, 1.6431e-02, 6.9143e-03,
        0.0000e+00, 0.0000e+00, 1.6289e-02, 6.6723e-03, 0.0000e+00, 0.0000e+00,
        1.2946e-02, 2.5548e-03, 0.0000e+00, 0.0000e+00, 1.1258e-02, 1.3942e-04,
        0.0000e+00, 0.0000e+00, 9.3836e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.9753e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9569e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.6461e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.7037e-05, 0.0000e+00, 0.0000e+00])  tensor([2.0857e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3897e-01, 0.0000e+00,
        1.3750e-01, 2.2038e-02, 1.4499e-01, 0.0000e+00, 3.6800e-02, 1.6703e-02,
        0.0000e+00, 0.0000e+00, 4.3030e-02, 2.1481e-02, 0.0000e+00, 0.0000e+00,
        3.6069e-02, 1.1340e-02, 0.0000e+00, 0.0000e+00, 3.2934e-02, 2.2141e-03,
        0.0000e+00, 0.0000e+00, 2.7800e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7447e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2598e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.4976e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.2817e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:51:14,466 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3959876631664696
2024-04-24 14:51:14,468 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.400560.11795
2024-04-24 14:51:14,526 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #190: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.02, '(min, 0)': 0.47, '(min, 1)': 0.14, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.02}}
2024-04-24 14:51:14,526 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:14,527 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3961287701704194
2024-04-24 14:51:14,916 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #190: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.9555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.44, '(min, 1)': 0.18, '(rev, 1)': 0.12, '(rev, 2)': 0.09}}
2024-04-24 14:51:14,916 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:14,917 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3961287701704194
2024-04-24 14:51:14,998 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #190: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8297872340425532, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.21, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 5)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:51:14,999 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:14,999 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3961287701704194
2024-04-24 14:51:15,355 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #190: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5869565217391305, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.54, '(min, 1)': 0.07, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-04-24 14:51:15,355 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:15,356 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3961287701704194
2024-04-24 14:51:15,540 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #190: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.02, '(min, 0)': 0.52, '(min, 1)': 0.13, '(rev, 1)': 0.03, '(rev, 2)': 0.02}}
2024-04-24 14:51:15,540 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:15,541 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3961287701704194
2024-04-24 14:51:15,968 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #190: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.16666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.51, '(min, 1)': 0.1, '(rev, 1)': 0.02, '(rev, 2)': 0.04}}
2024-04-24 14:51:15,968 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:15,968 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3961287701704194
2024-04-24 14:51:16,126 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #190: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.027777777777777776, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.46, '(min, 1)': 0.18, '(rev, 1)': 0.01}}
2024-04-24 14:51:16,126 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:16,127 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3961287701704194
2024-04-24 14:51:16,195 - MainProcess - INFO - text_logger.py - 51 - Train epoch #190
2024-04-24 14:51:16,198 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.7531e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.3885e-01,
         0.0000e+00,  1.3715e-01,  7.4365e-03,  3.4872e-01,  0.0000e+00,
         2.8093e-02,  2.7624e-03,  0.0000e+00,  0.0000e+00,  3.3816e-02,
         9.5473e-04,  0.0000e+00,  0.0000e+00,  2.8217e-02,  5.9649e-04,
         0.0000e+00,  0.0000e+00,  2.3652e-02,  5.5556e-05,  0.0000e+00,
         0.0000e+00,  1.9666e-02,  7.4074e-05,  0.0000e+00,  0.0000e+00,
         2.0031e-02,  6.0606e-05,  0.0000e+00,  0.0000e+00,  8.4198e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.3197e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  1.2500e-04,  0.0000e+00,  0.0000e+00])  tensor([2.0564e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6851e-01, 0.0000e+00,
        1.2682e-01, 1.7027e-02, 1.7638e-01, 0.0000e+00, 4.3802e-02, 9.4239e-03,
        0.0000e+00, 0.0000e+00, 5.8001e-02, 6.7685e-03, 0.0000e+00, 0.0000e+00,
        5.0376e-02, 4.1474e-03, 0.0000e+00, 0.0000e+00, 4.3453e-02, 1.2423e-03,
        0.0000e+00, 0.0000e+00, 3.6926e-02, 1.6563e-03, 0.0000e+00, 0.0000e+00,
        3.9488e-02, 1.3552e-03, 0.0000e+00, 0.0000e+00, 1.7687e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.1141e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4115e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:51:16,214 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3954732067261267
2024-04-24 14:51:16,216 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.213890.18611
2024-04-24 14:51:16,342 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #191: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5217391304347826, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.38, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:51:16,342 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:16,343 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3959876631664696
2024-04-24 14:51:16,391 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #191: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0),(rev, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.4186046511627907, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.4, '(rev, 1)': 0.11, '(rev, 2)': 0.05, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:51:16,392 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:16,392 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3959876631664696
2024-04-24 14:51:16,525 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #191: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.05, '(ado, 4)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.19, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:51:16,525 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:16,526 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3959876631664696
2024-04-24 14:51:17,273 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #191: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.15384615384615385, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.25, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:51:17,273 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:17,274 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3959876631664696
2024-04-24 14:51:17,466 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #191: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 4, 0, 0),(rev, 4)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.9523809523809523, 'length': 100, 'actions': {'(ado, 1)': 0.06, '(ado, 3)': 0.02, '(min, 0)': 0.44, '(min, 1)': 0.31, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.03, '(rev, 5)': 0.02, '(rev, 6)': 0.01}}
2024-04-24 14:51:17,467 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:17,467 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3959876631664696
2024-04-24 14:51:17,522 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #191: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.56, '(min, 1)': 0.07}}
2024-04-24 14:51:17,523 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:17,524 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3959876631664696
2024-04-24 14:51:17,914 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #191: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.16, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:51:17,914 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:17,914 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3959876631664696
2024-04-24 14:51:18,099 - MainProcess - INFO - text_logger.py - 51 - Train epoch #191
2024-04-24 14:51:18,101 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.2686e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6164e-01, 0.0000e+00,
        1.4873e-01, 1.2940e-02, 3.7645e-01, 0.0000e+00, 1.7487e-02, 9.0300e-03,
        0.0000e+00, 0.0000e+00, 1.5983e-02, 7.4526e-03, 0.0000e+00, 0.0000e+00,
        1.2739e-02, 3.6654e-03, 0.0000e+00, 0.0000e+00, 1.0613e-02, 5.9511e-04,
        0.0000e+00, 0.0000e+00, 9.1549e-03, 5.7143e-05, 0.0000e+00, 0.0000e+00,
        8.7599e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7679e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.1028e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.2061e-04, 0.0000e+00, 0.0000e+00])  tensor([2.1614e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3880e-01, 0.0000e+00,
        1.4751e-01, 2.5368e-02, 1.4294e-01, 0.0000e+00, 3.5935e-02, 1.9277e-02,
        0.0000e+00, 0.0000e+00, 4.2349e-02, 2.3617e-02, 0.0000e+00, 0.0000e+00,
        3.6564e-02, 1.2443e-02, 0.0000e+00, 0.0000e+00, 3.1610e-02, 3.7895e-03,
        0.0000e+00, 0.0000e+00, 2.7470e-02, 1.2778e-03, 0.0000e+00, 0.0000e+00,
        2.7843e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2299e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.7197e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8815e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:51:18,115 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.395052711638441
2024-04-24 14:51:18,116 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.260870.26087
2024-04-24 14:51:18,161 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #192: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5869565217391305, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.27, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:51:18,162 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:18,162 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #192: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(min, 0)': 0.1, '(min, 1)': 0.49, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.03}}
2024-04-24 14:51:18,162 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:18,162 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3954732067261267
2024-04-24 14:51:18,163 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3954732067261267
2024-04-24 14:51:18,665 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #192: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 6, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.04, '(ado, 5)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.2, '(rev, 1)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:51:18,665 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:18,666 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3954732067261267
2024-04-24 14:51:18,944 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #192: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.45, '(min, 1)': 0.18}}
2024-04-24 14:51:18,944 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:18,945 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3954732067261267
2024-04-24 14:51:18,974 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #192: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.58, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.46, '(min, 1)': 0.16, '(rev, 1)': 0.07, '(rev, 2)': 0.09, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:51:18,974 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:18,975 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3954732067261267
2024-04-24 14:51:19,341 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #192: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 6, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 3, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.35, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:51:19,341 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:19,342 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3954732067261267
2024-04-24 14:51:19,496 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #192: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.09, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.35, '(rev, 1)': 0.12, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 6)': 0.01}}
2024-04-24 14:51:19,497 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:19,498 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3954732067261267
2024-04-24 14:51:19,669 - MainProcess - INFO - text_logger.py - 51 - Train epoch #192
2024-04-24 14:51:19,672 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0594e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9887e-01, 0.0000e+00,
        1.3335e-01, 1.4341e-02, 4.1568e-01, 0.0000e+00, 5.5006e-03, 1.0636e-02,
        0.0000e+00, 0.0000e+00, 1.7484e-03, 1.2153e-02, 0.0000e+00, 0.0000e+00,
        7.6204e-04, 5.7109e-03, 0.0000e+00, 0.0000e+00, 3.7719e-04, 2.0916e-04,
        0.0000e+00, 0.0000e+00, 2.3793e-04, 2.1435e-04, 0.0000e+00, 0.0000e+00,
        5.5556e-05, 1.4923e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.3529e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.6281e-02, 0.0000e+00,
        1.5318e-01, 2.5856e-02, 9.2866e-02, 0.0000e+00, 1.6466e-02, 2.2228e-02,
        0.0000e+00, 0.0000e+00, 1.0721e-02, 3.6914e-02, 0.0000e+00, 0.0000e+00,
        6.5356e-03, 1.9302e-02, 0.0000e+00, 0.0000e+00, 3.9203e-03, 1.9218e-03,
        0.0000e+00, 0.0000e+00, 3.4657e-03, 2.3386e-03, 0.0000e+00, 0.0000e+00,
        1.2423e-03, 2.0975e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:51:19,686 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.39443656437684216
2024-04-24 14:51:19,688 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.163040.16304
2024-04-24 14:51:19,732 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #193: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.04, '(min, 0)': 0.42, '(min, 1)': 0.17, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:51:19,733 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:19,733 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.395052711638441
2024-04-24 14:51:20,286 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #193: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.5, '(min, 1)': 0.1}}
2024-04-24 14:51:20,286 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:20,287 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.395052711638441
2024-04-24 14:51:20,373 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #193: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.66, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(min, 0)': 0.42, '(min, 1)': 0.16, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 6)': 0.01}}
2024-04-24 14:51:20,373 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:20,374 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.395052711638441
2024-04-24 14:51:20,498 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #193: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.45652173913043476, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(ado, 7)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.16, '(rev, 1)': 0.08, '(rev, 2)': 0.04}}
2024-04-24 14:51:20,499 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:20,499 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.395052711638441
2024-04-24 14:51:20,782 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #193: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.16666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.04, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.19, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:51:20,783 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:20,783 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.395052711638441
2024-04-24 14:51:20,788 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #193: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6363636363636364, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.03, '(min, 0)': 0.39, '(min, 1)': 0.28, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:51:20,788 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:20,789 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.395052711638441
2024-04-24 14:51:21,171 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #193: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4489795918367347, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(min, 0)': 0.41, '(min, 1)': 0.19, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:51:21,171 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:21,172 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.395052711638441
2024-04-24 14:51:21,349 - MainProcess - INFO - text_logger.py - 51 - Train epoch #193
2024-04-24 14:51:21,352 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.4531e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8880e-01, 0.0000e+00,
        1.2337e-01, 9.8615e-03, 4.0346e-01, 0.0000e+00, 1.2120e-02, 5.0587e-03,
        0.0000e+00, 0.0000e+00, 1.2184e-02, 4.8215e-03, 0.0000e+00, 0.0000e+00,
        9.7303e-03, 3.5860e-03, 0.0000e+00, 0.0000e+00, 8.5514e-03, 1.9384e-04,
        0.0000e+00, 0.0000e+00, 6.9852e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.3172e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2460e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.4373e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7755e-04, 0.0000e+00, 0.0000e+00])  tensor([2.1003, 0.0000, 0.0000, 0.0000, 0.1277, 0.0000, 0.1310, 0.0204, 0.1308,
        0.0000, 0.0313, 0.0154, 0.0000, 0.0000, 0.0385, 0.0212, 0.0000, 0.0000,
        0.0330, 0.0155, 0.0000, 0.0000, 0.0295, 0.0023, 0.0000, 0.0000, 0.0246,
        0.0000, 0.0000, 0.0000, 0.0264, 0.0000, 0.0000, 0.0000, 0.0121, 0.0000,
        0.0000, 0.0000, 0.0034, 0.0000, 0.0000, 0.0000, 0.0022, 0.0000, 0.0000]) (500)
2024-04-24 14:51:21,364 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3937769388543737
2024-04-24 14:51:21,366 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.141300.14130
2024-04-24 14:51:21,411 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #194: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 4)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.17, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:51:21,411 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:21,412 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39443656437684216
2024-04-24 14:51:21,589 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #194: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.42, '(min, 1)': 0.15}}
2024-04-24 14:51:21,589 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:21,590 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39443656437684216
2024-04-24 14:51:21,761 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #194: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 4)': 0.02, '(min, 0)': 0.37, '(min, 1)': 0.25, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.02}}
2024-04-24 14:51:21,762 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:21,762 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39443656437684216
2024-04-24 14:51:22,282 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #194: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.4666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 3)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.47, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-04-24 14:51:22,282 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:22,283 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39443656437684216
2024-04-24 14:51:22,522 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #194: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6590909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.36, '(min, 1)': 0.27, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-04-24 14:51:22,522 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:22,524 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39443656437684216
2024-04-24 14:51:22,841 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #194: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5227272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.03, '(min, 0)': 0.32, '(min, 1)': 0.33, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 6)': 0.02, '(rev, 8)': 0.01}}
2024-04-24 14:51:22,841 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:22,842 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39443656437684216
2024-04-24 14:51:23,638 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #194: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34210526315789475, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.03, '(ado, 6)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.37, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:51:23,638 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:23,638 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39443656437684216
2024-04-24 14:51:23,825 - MainProcess - INFO - text_logger.py - 51 - Train epoch #194
2024-04-24 14:51:23,827 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.5767e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8885e-01, 0.0000e+00,
        1.5810e-01, 1.2539e-02, 3.9667e-01, 0.0000e+00, 1.1001e-02, 6.7220e-03,
        0.0000e+00, 0.0000e+00, 6.6047e-03, 4.3203e-03, 0.0000e+00, 0.0000e+00,
        4.5173e-03, 1.4596e-03, 0.0000e+00, 0.0000e+00, 3.3861e-03, 7.8462e-05,
        0.0000e+00, 0.0000e+00, 2.5715e-03, 7.8462e-05, 0.0000e+00, 0.0000e+00,
        2.2129e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.0844e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.0000e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7044e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1313e-01, 0.0000e+00,
        1.6689e-01, 2.3384e-02, 1.1317e-01, 0.0000e+00, 2.7838e-02, 1.4718e-02,
        0.0000e+00, 0.0000e+00, 2.5906e-02, 1.4407e-02, 0.0000e+00, 0.0000e+00,
        2.0319e-02, 7.2457e-03, 0.0000e+00, 0.0000e+00, 1.7569e-02, 1.2396e-03,
        0.0000e+00, 0.0000e+00, 1.4212e-02, 1.2396e-03, 0.0000e+00, 0.0000e+00,
        1.2798e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8279e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.7889e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:51:23,840 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3932260089840793
2024-04-24 14:51:23,843 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.195650.19565
2024-04-24 14:51:23,855 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #195: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28205128205128205, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.34, '(min, 1)': 0.28, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-04-24 14:51:23,856 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:23,856 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3937769388543737
2024-04-24 14:51:23,871 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #195: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.61, '(min, 1)': 0.01}}
2024-04-24 14:51:23,871 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:23,872 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3937769388543737
2024-04-24 14:51:23,887 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #195: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.45454545454545453, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 3)': 0.02, '(min, 0)': 0.32, '(min, 1)': 0.29, '(rev, 1)': 0.13, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:51:23,888 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:23,888 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3937769388543737
2024-04-24 14:51:23,903 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #195: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.07, '(min, 0)': 0.38, '(min, 1)': 0.21, '(rev, 1)': 0.08}}
2024-04-24 14:51:23,904 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:23,905 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3937769388543737
2024-04-24 14:51:24,105 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #195: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43478260869565216, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 4)': 0.02, '(min, 0)': 0.46, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-04-24 14:51:24,106 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:24,106 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3937769388543737
2024-04-24 14:51:24,181 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #195: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5833333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.45, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-24 14:51:24,181 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:24,183 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3937769388543737
2024-04-24 14:51:24,904 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #195: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 2)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.1}}
2024-04-24 14:51:24,904 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:24,904 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3937769388543737
2024-04-24 14:51:25,099 - MainProcess - INFO - text_logger.py - 51 - Train epoch #195
2024-04-24 14:51:25,102 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-5.1586e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.4520e-01,
         0.0000e+00,  1.2968e-01,  9.4073e-03,  3.5440e-01,  0.0000e+00,
         2.4809e-02,  3.5355e-03,  0.0000e+00,  0.0000e+00,  2.9421e-02,
         1.7147e-03,  0.0000e+00,  0.0000e+00,  2.5264e-02,  8.8275e-04,
         0.0000e+00,  0.0000e+00,  2.3099e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  1.9597e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.0357e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.9583e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.2136e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  4.6608e-04,  0.0000e+00,  0.0000e+00])  tensor([1.6134, 0.0000, 0.0000, 0.0000, 0.1659, 0.0000, 0.1148, 0.0212, 0.1714,
        0.0000, 0.0431, 0.0112, 0.0000, 0.0000, 0.0559, 0.0094, 0.0000, 0.0000,
        0.0491, 0.0073, 0.0000, 0.0000, 0.0453, 0.0000, 0.0000, 0.0000, 0.0388,
        0.0000, 0.0000, 0.0000, 0.0406, 0.0000, 0.0000, 0.0000, 0.0203, 0.0000,
        0.0000, 0.0000, 0.0065, 0.0000, 0.0000, 0.0000, 0.0028, 0.0000, 0.0000]) (500)
2024-04-24 14:51:25,117 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.39256582604801
2024-04-24 14:51:25,119 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.141030.14103
2024-04-24 14:51:25,124 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #196: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.44, '(min, 1)': 0.15}}
2024-04-24 14:51:25,124 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:25,124 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3932260089840793
2024-04-24 14:51:25,212 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #196: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.55, '(min, 1)': 0.06}}
2024-04-24 14:51:25,212 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:25,213 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3932260089840793
2024-04-24 14:51:25,516 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #196: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.11904761904761904, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 8)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.27, '(rev, 1)': 0.05, '(rev, 2)': 0.01}}
2024-04-24 14:51:25,516 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:25,517 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3932260089840793
2024-04-24 14:51:25,610 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #196: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(min, 0)': 0.54, '(min, 1)': 0.02, '(rev, 1)': 0.11, '(rev, 2)': 0.07}}
2024-04-24 14:51:25,610 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:25,611 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3932260089840793
2024-04-24 14:51:25,799 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #196: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.41, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.04, '(rev, 4)': 0.01}}
2024-04-24 14:51:25,799 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:25,799 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3932260089840793
2024-04-24 14:51:25,942 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #196: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3953488372093023, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.03, '(min, 0)': 0.27, '(min, 1)': 0.41, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:51:25,942 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:25,943 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3932260089840793
2024-04-24 14:51:27,118 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #196: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.375, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.19, '(rev, 1)': 0.01, '(rev, 2)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:51:27,118 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:27,119 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3932260089840793
2024-04-24 14:51:27,295 - MainProcess - INFO - text_logger.py - 51 - Train epoch #196
2024-04-24 14:51:27,302 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-4.0498e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.1069e-01,
         0.0000e+00,  1.5229e-01,  9.6481e-03,  3.1546e-01,  0.0000e+00,
         3.5905e-02,  5.3707e-03,  0.0000e+00,  0.0000e+00,  3.9377e-02,
         4.3350e-03,  0.0000e+00,  0.0000e+00,  3.2917e-02,  3.1541e-03,
         0.0000e+00,  0.0000e+00,  2.8961e-02,  7.1096e-05,  0.0000e+00,
         0.0000e+00,  2.4462e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.4559e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0510e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.8857e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  4.0828e-04,  0.0000e+00,  0.0000e+00])  tensor([2.2107e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7914e-01, 0.0000e+00,
        1.3434e-01, 2.2752e-02, 1.8127e-01, 0.0000e+00, 5.0838e-02, 1.6992e-02,
        0.0000e+00, 0.0000e+00, 6.1568e-02, 1.8859e-02, 0.0000e+00, 0.0000e+00,
        5.2997e-02, 1.5051e-02, 0.0000e+00, 0.0000e+00, 4.7635e-02, 1.1660e-03,
        0.0000e+00, 0.0000e+00, 4.0597e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.1693e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9756e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.9922e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5409e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:51:27,319 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3916235918298894
2024-04-24 14:51:27,322 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:51:27,342 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #197: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.47, '(min, 1)': 0.12}}
2024-04-24 14:51:27,342 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:27,342 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39256582604801
2024-04-24 14:51:27,357 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #197: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8823529411764706, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 9)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.21, '(rev, 1)': 0.06, '(rev, 2)': 0.06}}
2024-04-24 14:51:27,357 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:27,358 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39256582604801
2024-04-24 14:51:27,372 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #197: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.23, '(rev, 1)': 0.08, '(rev, 2)': 0.07}}
2024-04-24 14:51:27,372 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:27,372 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #197: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4186046511627907, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.29, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 3)': 0.03}}
2024-04-24 14:51:27,373 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39256582604801
2024-04-24 14:51:27,373 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:27,374 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39256582604801
2024-04-24 14:51:27,455 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #197: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17307692307692307, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.12, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:51:27,455 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:27,455 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39256582604801
2024-04-24 14:51:27,783 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #197: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5909090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(min, 0)': 0.16, '(min, 1)': 0.46, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:51:27,783 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:27,783 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39256582604801
2024-04-24 14:51:29,041 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #197: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6136363636363636, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.05, '(min, 0)': 0.45, '(min, 1)': 0.15, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:51:29,041 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:29,041 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39256582604801
2024-04-24 14:51:29,225 - MainProcess - INFO - text_logger.py - 51 - Train epoch #197
2024-04-24 14:51:29,228 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.9830e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7758e-01, 0.0000e+00,
        1.2606e-01, 1.2059e-02, 3.9118e-01, 0.0000e+00, 1.2700e-02, 7.5230e-03,
        0.0000e+00, 0.0000e+00, 1.3072e-02, 6.0513e-03, 0.0000e+00, 0.0000e+00,
        1.1854e-02, 2.5183e-03, 0.0000e+00, 0.0000e+00, 1.1053e-02, 7.6923e-05,
        0.0000e+00, 0.0000e+00, 9.9872e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0546e-02, 8.0000e-05, 0.0000e+00, 0.0000e+00, 5.4183e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.6831e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.6135e-04, 0.0000e+00, 0.0000e+00])  tensor([2.3233e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3778e-01, 0.0000e+00,
        1.3349e-01, 2.4492e-02, 1.4187e-01, 0.0000e+00, 3.1628e-02, 1.8497e-02,
        0.0000e+00, 0.0000e+00, 3.9934e-02, 2.2979e-02, 0.0000e+00, 0.0000e+00,
        3.6545e-02, 1.3451e-02, 0.0000e+00, 0.0000e+00, 3.4423e-02, 1.7201e-03,
        0.0000e+00, 0.0000e+00, 3.1167e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.3029e-02, 1.7889e-03, 0.0000e+00, 0.0000e+00, 1.7024e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.0024e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.1084e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:51:29,240 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.39156371055294525
2024-04-24 14:51:29,242 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.441180.44118
2024-04-24 14:51:29,256 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #198: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5609756097560976, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(min, 0)': 0.35, '(min, 1)': 0.27, '(rev, 1)': 0.12, '(rev, 2)': 0.04, '(rev, 3)': 0.04}}
2024-04-24 14:51:29,256 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #198: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13953488372093023, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.03, '(ado, 4)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.21, '(rev, 1)': 0.1, '(rev, 2)': 0.02}}
2024-04-24 14:51:29,256 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:29,256 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:29,257 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3916235918298894
2024-04-24 14:51:29,257 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3916235918298894
2024-04-24 14:51:29,272 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #198: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.30952380952380953, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.05, '(min, 0)': 0.31, '(min, 1)': 0.29, '(rev, 1)': 0.14, '(rev, 2)': 0.02}}
2024-04-24 14:51:29,272 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:29,273 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3916235918298894
2024-04-24 14:51:29,288 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #198: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 2, 7, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.46, '(min, 1)': 0.13}}
2024-04-24 14:51:29,288 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #198: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4523809523809524, 'length': 100, 'actions': {'(ado, 1)': 0.09, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.4, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.06, '(rev, 4)': 0.01}}
2024-04-24 14:51:29,288 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:29,288 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:29,289 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3916235918298894
2024-04-24 14:51:29,289 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3916235918298894
2024-04-24 14:51:29,949 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #198: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.14583333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.3, '(rev, 1)': 0.01, '(rev, 2)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:51:29,949 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:29,949 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3916235918298894
2024-04-24 14:51:30,763 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #198: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.4186046511627907, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.05, '(min, 0)': 0.44, '(min, 1)': 0.17, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:51:30,763 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:30,764 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3916235918298894
2024-04-24 14:51:30,942 - MainProcess - INFO - text_logger.py - 51 - Train epoch #198
2024-04-24 14:51:30,945 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0202e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6178e-01, 0.0000e+00,
        1.5751e-01, 1.0424e-02, 3.6909e-01, 0.0000e+00, 1.7599e-02, 1.1160e-02,
        0.0000e+00, 0.0000e+00, 1.2598e-02, 1.4480e-02, 0.0000e+00, 0.0000e+00,
        9.5457e-03, 9.0465e-03, 0.0000e+00, 0.0000e+00, 8.3486e-03, 1.5250e-04,
        0.0000e+00, 0.0000e+00, 7.1192e-03, 5.8472e-05, 0.0000e+00, 0.0000e+00,
        6.5935e-03, 5.8472e-05, 0.0000e+00, 0.0000e+00, 3.4594e-03, 3.0303e-05,
        0.0000e+00, 0.0000e+00, 7.8415e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6185e-04, 0.0000e+00, 0.0000e+00])  tensor([2.1084e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3903e-01, 0.0000e+00,
        1.5311e-01, 2.3402e-02, 1.3928e-01, 0.0000e+00, 4.2514e-02, 2.6838e-02,
        0.0000e+00, 0.0000e+00, 3.6257e-02, 4.7634e-02, 0.0000e+00, 0.0000e+00,
        3.0080e-02, 3.2188e-02, 0.0000e+00, 0.0000e+00, 2.7836e-02, 1.5451e-03,
        0.0000e+00, 0.0000e+00, 2.4411e-02, 9.2421e-04, 0.0000e+00, 0.0000e+00,
        2.4160e-02, 9.2421e-04, 0.0000e+00, 0.0000e+00, 1.3513e-02, 6.7760e-04,
        0.0000e+00, 0.0000e+00, 4.2478e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6339e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:51:30,961 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.39118245194458073
2024-04-24 14:51:30,963 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.280490.28049
2024-04-24 14:51:31,022 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #199: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.08823529411764706, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.44, '(min, 1)': 0.21, '(rev, 1)': 0.02, '(rev, 2)': 0.02}}
2024-04-24 14:51:31,022 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:31,023 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39156371055294525
2024-04-24 14:51:31,191 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #199: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.45652173913043476, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.05, '(ado, 5)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.25, '(rev, 1)': 0.14, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:51:31,191 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:31,192 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39156371055294525
2024-04-24 14:51:31,402 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #199: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(min, 0)': 0.41, '(min, 1)': 0.21, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-24 14:51:31,402 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:31,402 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39156371055294525
2024-04-24 14:51:31,607 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #199: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5869565217391305, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(min, 0)': 0.33, '(min, 1)': 0.26, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:51:31,607 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:31,608 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39156371055294525
2024-04-24 14:51:31,715 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #199: {'transition': '(exi, not, exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 3, 1, 1, 1),(rev, 1)->(exi, not, exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 1, 3, 1, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.5227272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.21, '(min, 1)': 0.43, '(rev, 1)': 0.05, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-24 14:51:31,715 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:31,715 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39156371055294525
2024-04-24 14:51:31,754 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #199: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 7)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.22}}
2024-04-24 14:51:31,754 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:31,755 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39156371055294525
2024-04-24 14:51:32,484 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #199: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4146341463414634, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 6)': 0.01, '(min, 0)': 0.57, '(min, 1)': 0.08, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:51:32,484 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:32,484 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39156371055294525
2024-04-24 14:51:32,670 - MainProcess - INFO - text_logger.py - 51 - Train epoch #199
2024-04-24 14:51:32,672 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.2106e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1349e-01, 0.0000e+00,
        1.2235e-01, 1.3235e-02, 4.3036e-01, 0.0000e+00, 5.1258e-03, 7.2030e-03,
        0.0000e+00, 0.0000e+00, 1.8110e-03, 3.7334e-03, 0.0000e+00, 0.0000e+00,
        8.8587e-04, 9.9227e-04, 0.0000e+00, 0.0000e+00, 4.1640e-04, 2.1587e-04,
        0.0000e+00, 0.0000e+00, 1.8573e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.4076, 0.0000, 0.0000, 0.0000, 0.0816, 0.0000, 0.1357, 0.0246, 0.0841,
        0.0000, 0.0188, 0.0165, 0.0000, 0.0000, 0.0107, 0.0140, 0.0000, 0.0000,
        0.0067, 0.0055, 0.0000, 0.0000, 0.0040, 0.0026, 0.0000, 0.0000, 0.0031,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-04-24 14:51:32,690 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.39032845302057784
2024-04-24 14:51:32,692 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.044120.04412
2024-04-24 14:51:32,718 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #200: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.34, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 9)': 0.01}}
2024-04-24 14:51:32,718 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:32,719 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39118245194458073
2024-04-24 14:51:33,084 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #200: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40476190476190477, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.26, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-24 14:51:33,084 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:33,085 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39118245194458073
2024-04-24 14:51:33,349 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #200: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 3, 0, 0),(ado, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/3', 'revenue': 0.4791666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 3)': 0.04, '(ado, 6)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.47, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:51:33,350 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:33,350 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39118245194458073
2024-04-24 14:51:33,632 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #200: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(min, 0)': 0.44, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.03}}
2024-04-24 14:51:33,632 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:33,632 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39118245194458073
2024-04-24 14:51:33,678 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #200: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.325, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.41, '(min, 1)': 0.23, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:51:33,678 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:33,679 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39118245194458073
2024-04-24 14:51:34,143 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #200: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6590909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.32, '(rev, 1)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:51:34,143 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:34,144 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39118245194458073
2024-04-24 14:51:34,781 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #200: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.11363636363636363, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.54, '(min, 1)': 0.18, '(rev, 1)': 0.01, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:51:34,781 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:34,782 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39118245194458073
2024-04-24 14:51:47,161 - MainProcess - INFO - text_logger.py - 51 - Train epoch #200
2024-04-24 14:51:47,164 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.5415e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3259e-01, 0.0000e+00,
        1.6329e-01, 9.7860e-03, 3.4208e-01, 0.0000e+00, 2.6899e-02, 7.1985e-03,
        0.0000e+00, 0.0000e+00, 2.6177e-02, 8.9776e-03, 0.0000e+00, 0.0000e+00,
        2.0467e-02, 6.6442e-03, 0.0000e+00, 0.0000e+00, 1.7668e-02, 2.8843e-04,
        0.0000e+00, 0.0000e+00, 1.5681e-02, 7.5904e-05, 0.0000e+00, 0.0000e+00,
        1.4403e-02, 1.5590e-04, 0.0000e+00, 0.0000e+00, 6.3414e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1300e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.5182e-04, 0.0000e+00, 0.0000e+00])  tensor([2.3841e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5827e-01, 0.0000e+00,
        1.5086e-01, 2.2837e-02, 1.6295e-01, 0.0000e+00, 4.6020e-02, 1.9275e-02,
        0.0000e+00, 0.0000e+00, 5.1770e-02, 3.4755e-02, 0.0000e+00, 0.0000e+00,
        4.3323e-02, 2.7031e-02, 0.0000e+00, 0.0000e+00, 3.8485e-02, 2.6944e-03,
        0.0000e+00, 0.0000e+00, 3.4899e-02, 1.2024e-03, 0.0000e+00, 0.0000e+00,
        3.4317e-02, 2.1526e-03, 0.0000e+00, 0.0000e+00, 1.6614e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.3211e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.5379e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:51:47,180 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.39011955213579064
2024-04-24 14:51:47,206 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.366670.01111
2024-04-24 14:51:47,207 - MainProcess - INFO - text_logger.py - 51 - Simulated Policy Revenue 0.413860.03114
2024-04-24 14:51:47,239 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #201: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6190476190476191, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.34, '(rev, 1)': 0.13, '(rev, 2)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:51:47,240 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:47,241 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39032845302057784
2024-04-24 14:51:48,028 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #201: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 5)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.18, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-04-24 14:51:48,028 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:48,029 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39032845302057784
2024-04-24 14:51:48,083 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #201: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2553191489361702, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.32, '(min, 1)': 0.31, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:51:48,083 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:48,084 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39032845302057784
2024-04-24 14:51:48,768 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #201: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.68, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.25, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.02, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:51:48,769 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:48,769 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39032845302057784
2024-04-24 14:51:48,926 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #201: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.1, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:51:48,926 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:48,927 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39032845302057784
2024-04-24 14:51:49,153 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #201: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0),(ado, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/3', 'revenue': 0.8913043478260869, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 3)': 0.03, '(min, 0)': 0.53, '(min, 1)': 0.1, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:51:49,153 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:49,153 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39032845302057784
2024-04-24 14:51:49,256 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #201: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6818181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.37, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:51:49,256 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:49,258 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39032845302057784
2024-04-24 14:51:49,349 - MainProcess - INFO - text_logger.py - 51 - Train epoch #201
2024-04-24 14:51:49,352 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.2663e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3717e-01, 0.0000e+00,
        1.5331e-01, 1.0235e-02, 3.5578e-01, 0.0000e+00, 2.5257e-02, 6.8076e-03,
        0.0000e+00, 0.0000e+00, 2.5374e-02, 5.9345e-03, 0.0000e+00, 0.0000e+00,
        2.0291e-02, 3.7870e-03, 0.0000e+00, 0.0000e+00, 1.7023e-02, 1.6479e-04,
        0.0000e+00, 0.0000e+00, 1.4998e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4955e-02, 1.6000e-04, 0.0000e+00, 0.0000e+00, 6.8079e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.6071e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4334e-04, 0.0000e+00, 0.0000e+00])  tensor([2.8897e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5982e-01, 0.0000e+00,
        1.5502e-01, 2.2611e-02, 1.6824e-01, 0.0000e+00, 4.4579e-02, 1.8347e-02,
        0.0000e+00, 0.0000e+00, 5.2031e-02, 2.5417e-02, 0.0000e+00, 0.0000e+00,
        4.3717e-02, 1.8119e-02, 0.0000e+00, 0.0000e+00, 3.7756e-02, 2.0561e-03,
        0.0000e+00, 0.0000e+00, 3.4038e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5478e-02, 2.5273e-03, 0.0000e+00, 0.0000e+00, 1.8000e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.9547e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.4425e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:51:49,370 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3904781837185359
2024-04-24 14:51:49,372 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.650430.03139
2024-04-24 14:51:49,840 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #202: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 4)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.1}}
2024-04-24 14:51:49,840 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:49,841 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39011955213579064
2024-04-24 14:51:49,930 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #202: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 4, 0, 0),(ado, 4)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/4', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.26, '(min, 1)': 0.35, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-04-24 14:51:49,930 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:49,931 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39011955213579064
2024-04-24 14:51:50,816 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #202: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(min, 0)': 0.15, '(min, 1)': 0.43, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-04-24 14:51:50,816 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:50,817 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39011955213579064
2024-04-24 14:51:51,010 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #202: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10416666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.21, '(rev, 1)': 0.07, '(rev, 2)': 0.01}}
2024-04-24 14:51:51,010 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:51,011 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39011955213579064
2024-04-24 14:51:51,102 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #202: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6739130434782609, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.03, '(min, 0)': 0.18, '(min, 1)': 0.44, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:51:51,102 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:51,103 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39011955213579064
2024-04-24 14:51:51,132 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #202: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 8)': 0.02, '(min, 0)': 0.53, '(min, 1)': 0.2}}
2024-04-24 14:51:51,132 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:51,133 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39011955213579064
2024-04-24 14:51:51,141 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #202: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.15789473684210525, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.29, '(rev, 1)': 0.05, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:51:51,141 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:51,142 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39011955213579064
2024-04-24 14:51:51,332 - MainProcess - INFO - text_logger.py - 51 - Train epoch #202
2024-04-24 14:51:51,335 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-8.9284e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.9061e-01,
         0.0000e+00,  1.5729e-01,  7.2132e-03,  2.8647e-01,  0.0000e+00,
         4.2718e-02,  2.9842e-03,  0.0000e+00,  0.0000e+00,  5.1286e-02,
         1.4148e-03,  0.0000e+00,  0.0000e+00,  4.1195e-02,  6.4395e-04,
         0.0000e+00,  0.0000e+00,  3.6777e-02,  7.6923e-05,  0.0000e+00,
         0.0000e+00,  3.1566e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.1447e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4998e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.9372e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.7309e-04,  0.0000e+00,  0.0000e+00])  tensor([1.6390, 0.0000, 0.0000, 0.0000, 0.1889, 0.0000, 0.1241, 0.0193, 0.1892,
        0.0000, 0.0522, 0.0107, 0.0000, 0.0000, 0.0668, 0.0089, 0.0000, 0.0000,
        0.0551, 0.0063, 0.0000, 0.0000, 0.0503, 0.0017, 0.0000, 0.0000, 0.0440,
        0.0000, 0.0000, 0.0000, 0.0458, 0.0000, 0.0000, 0.0000, 0.0226, 0.0000,
        0.0000, 0.0000, 0.0076, 0.0000, 0.0000, 0.0000, 0.0025, 0.0000, 0.0000]) (500)
2024-04-24 14:51:51,355 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.39020986254389356
2024-04-24 14:51:51,357 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.336960.33696
2024-04-24 14:51:51,760 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #203: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.19, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:51:51,761 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:51,761 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3904781837185359
2024-04-24 14:51:52,224 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #203: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.11904761904761904, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.28, '(rev, 1)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:51:52,225 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:52,225 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3904781837185359
2024-04-24 14:51:52,851 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #203: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.22, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:51:52,852 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:52,853 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3904781837185359
2024-04-24 14:51:53,071 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #203: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 2)': 0.01, '(min, 0)': 0.56, '(min, 1)': 0.09}}
2024-04-24 14:51:53,072 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:53,073 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3904781837185359
2024-04-24 14:51:53,721 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #203: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5319148936170213, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(min, 0)': 0.5, '(min, 1)': 0.15, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 4)': 0.02}}
2024-04-24 14:51:53,722 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:53,727 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3904781837185359
2024-04-24 14:51:54,654 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #203: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.5555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.35, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-04-24 14:51:54,654 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:54,655 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3904781837185359
2024-04-24 14:51:55,087 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #203: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 8)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.21, '(rev, 1)': 0.03, '(rev, 2)': 0.02}}
2024-04-24 14:51:55,087 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:55,088 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3904781837185359
2024-04-24 14:51:55,170 - MainProcess - INFO - text_logger.py - 51 - Train epoch #203
2024-04-24 14:51:55,173 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-2.3802e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8808e-01,
         0.0000e+00,  1.4349e-01,  1.0063e-02,  3.0436e-01,  0.0000e+00,
         3.9059e-02,  6.7947e-03,  0.0000e+00,  0.0000e+00,  4.3794e-02,
         9.4265e-03,  0.0000e+00,  0.0000e+00,  3.6672e-02,  8.9409e-03,
         0.0000e+00,  0.0000e+00,  3.3219e-02,  3.9216e-05,  0.0000e+00,
         0.0000e+00,  2.9319e-02,  8.0000e-05,  0.0000e+00,  0.0000e+00,
         2.9422e-02,  8.0000e-05,  0.0000e+00,  0.0000e+00,  1.3940e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8957e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.2565e-04,  0.0000e+00,  0.0000e+00])  tensor([2.3125e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8277e-01, 0.0000e+00,
        1.2890e-01, 2.4650e-02, 1.9264e-01, 0.0000e+00, 5.4414e-02, 2.1177e-02,
        0.0000e+00, 0.0000e+00, 6.4132e-02, 4.0373e-02, 0.0000e+00, 0.0000e+00,
        5.4484e-02, 4.0108e-02, 0.0000e+00, 0.0000e+00, 4.9976e-02, 8.7689e-04,
        0.0000e+00, 0.0000e+00, 4.4870e-02, 1.7889e-03, 0.0000e+00, 0.0000e+00,
        4.5916e-02, 1.7889e-03, 0.0000e+00, 0.0000e+00, 2.2366e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.6665e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3123e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:51:55,186 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.39015651721466177
2024-04-24 14:51:55,188 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.444440.11111
2024-04-24 14:51:55,217 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #204: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7380952380952381, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.13, '(min, 1)': 0.49, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-24 14:51:55,217 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:55,218 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39020986254389356
2024-04-24 14:51:56,024 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #204: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.06, '(min, 0)': 0.18, '(min, 1)': 0.47, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 6)': 0.01}}
2024-04-24 14:51:56,025 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:56,025 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39020986254389356
2024-04-24 14:51:56,103 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #204: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.14814814814814814, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.36, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:51:56,104 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:56,104 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39020986254389356
2024-04-24 14:51:56,401 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #204: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 4, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3953488372093023, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.23, '(rev, 1)': 0.07, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-04-24 14:51:56,401 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:56,402 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39020986254389356
2024-04-24 14:51:56,912 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #204: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.44, '(min, 1)': 0.17}}
2024-04-24 14:51:56,912 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:56,913 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39020986254389356
2024-04-24 14:51:56,944 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #204: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.68, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.41, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:51:56,944 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:56,944 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39020986254389356
2024-04-24 14:51:57,390 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #204: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.775, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 3)': 0.01, '(min, 0)': 0.14, '(min, 1)': 0.56, '(rev, 1)': 0.04, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:51:57,390 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:57,391 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39020986254389356
2024-04-24 14:51:57,471 - MainProcess - INFO - text_logger.py - 51 - Train epoch #204
2024-04-24 14:51:57,474 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([9.5252e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7815e-01, 0.0000e+00,
        1.5366e-01, 1.2881e-02, 3.8164e-01, 0.0000e+00, 1.2984e-02, 1.3405e-02,
        0.0000e+00, 0.0000e+00, 7.7748e-03, 1.2146e-02, 0.0000e+00, 0.0000e+00,
        5.7433e-03, 6.8130e-03, 0.0000e+00, 0.0000e+00, 5.0300e-03, 2.7027e-05,
        0.0000e+00, 0.0000e+00, 4.1634e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5957e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8280e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2493e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5714e-05, 0.0000e+00, 0.0000e+00])  tensor([2.0713e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2168e-01, 0.0000e+00,
        1.5248e-01, 2.7837e-02, 1.2219e-01, 0.0000e+00, 3.2597e-02, 3.0647e-02,
        0.0000e+00, 0.0000e+00, 2.9292e-02, 4.0319e-02, 0.0000e+00, 0.0000e+00,
        2.4209e-02, 2.9327e-02, 0.0000e+00, 0.0000e+00, 2.2465e-02, 6.0434e-04,
        0.0000e+00, 0.0000e+00, 1.9422e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8004e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.6485e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.6268e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.9860e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:51:57,487 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3899892829965413
2024-04-24 14:51:57,489 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.387500.38750
2024-04-24 14:51:57,517 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #205: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.627906976744186, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(min, 0)': 0.39, '(min, 1)': 0.3, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.03, '(rev, 5)': 0.01}}
2024-04-24 14:51:57,517 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:57,518 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39015651721466177
2024-04-24 14:51:57,611 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #205: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(min, 0)': 0.39, '(min, 1)': 0.2, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:51:57,611 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:57,612 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39015651721466177
2024-04-24 14:51:58,150 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #205: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.3, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.03}}
2024-04-24 14:51:58,150 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:58,151 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39015651721466177
2024-04-24 14:51:58,330 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #205: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.15555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.05, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.21, '(rev, 1)': 0.11, '(rev, 2)': 0.02}}
2024-04-24 14:51:58,331 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:58,332 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39015651721466177
2024-04-24 14:51:59,005 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #205: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.43, '(min, 1)': 0.15}}
2024-04-24 14:51:59,006 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:59,007 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39015651721466177
2024-04-24 14:51:59,319 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #205: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0975609756097561, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.18, '(rev, 1)': 0.05}}
2024-04-24 14:51:59,320 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:51:59,321 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39015651721466177
2024-04-24 14:52:01,921 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #205: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 0, 1, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 10)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.13}}
2024-04-24 14:52:01,921 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:01,922 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39015651721466177
2024-04-24 14:52:02,005 - MainProcess - INFO - text_logger.py - 51 - Train epoch #205
2024-04-24 14:52:02,009 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([9.3132e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4375e-01, 0.0000e+00,
        1.6227e-01, 1.1867e-02, 3.5813e-01, 0.0000e+00, 2.2236e-02, 9.3000e-03,
        0.0000e+00, 0.0000e+00, 1.8391e-02, 9.4604e-03, 0.0000e+00, 0.0000e+00,
        1.4366e-02, 7.0051e-03, 0.0000e+00, 0.0000e+00, 1.3019e-02, 1.3812e-04,
        0.0000e+00, 0.0000e+00, 1.1538e-02, 3.5088e-05, 0.0000e+00, 0.0000e+00,
        1.0810e-02, 3.5088e-05, 0.0000e+00, 0.0000e+00, 5.7676e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.5179e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.6109e-04, 0.0000e+00, 0.0000e+00])  tensor([2.0224e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4928e-01, 0.0000e+00,
        1.4915e-01, 2.5385e-02, 1.5273e-01, 0.0000e+00, 4.7707e-02, 2.2654e-02,
        0.0000e+00, 0.0000e+00, 4.4401e-02, 3.4346e-02, 0.0000e+00, 0.0000e+00,
        3.6660e-02, 3.1727e-02, 0.0000e+00, 0.0000e+00, 3.4463e-02, 1.8673e-03,
        0.0000e+00, 0.0000e+00, 3.1255e-02, 7.8459e-04, 0.0000e+00, 0.0000e+00,
        3.0689e-02, 7.8459e-04, 0.0000e+00, 0.0000e+00, 1.7394e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.2064e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5546e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:52:02,030 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3890470487784207
2024-04-24 14:52:02,033 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:52:02,038 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #206: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4166666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.09, '(min, 1)': 0.5, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:52:02,038 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:02,040 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3899892829965413
2024-04-24 14:52:02,054 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #206: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.38636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.45, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:52:02,054 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:02,056 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3899892829965413
2024-04-24 14:52:02,085 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #206: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.48, '(min, 1)': 0.12}}
2024-04-24 14:52:02,086 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:02,087 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3899892829965413
2024-04-24 14:52:02,313 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #206: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.47619047619047616, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(ado, 5)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.32, '(rev, 1)': 0.05, '(rev, 2)': 0.03}}
2024-04-24 14:52:02,314 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:02,315 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3899892829965413
2024-04-24 14:52:02,351 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #206: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.28, '(rev, 1)': 0.04, '(rev, 2)': 0.03}}
2024-04-24 14:52:02,352 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:02,353 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3899892829965413
2024-04-24 14:52:02,427 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #206: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.12244897959183673, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.16, '(rev, 1)': 0.04, '(rev, 2)': 0.02}}
2024-04-24 14:52:02,427 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:02,428 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3899892829965413
2024-04-24 14:52:04,401 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #206: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40425531914893614, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 2)': 0.02, '(min, 0)': 0.12, '(min, 1)': 0.43, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:52:04,401 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:04,402 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3899892829965413
2024-04-24 14:52:04,468 - MainProcess - INFO - text_logger.py - 51 - Train epoch #206
2024-04-24 14:52:04,470 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.4703e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2427e-01, 0.0000e+00,
        1.3982e-01, 9.5868e-03, 3.2411e-01, 0.0000e+00, 3.4743e-02, 5.7932e-03,
        0.0000e+00, 0.0000e+00, 3.6863e-02, 3.9600e-03, 0.0000e+00, 0.0000e+00,
        2.9755e-02, 2.2245e-03, 0.0000e+00, 0.0000e+00, 2.7633e-02, 1.3556e-04,
        0.0000e+00, 0.0000e+00, 2.3920e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3304e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1133e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.4573e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9435e-04, 0.0000e+00, 0.0000e+00])  tensor([1.9086, 0.0000, 0.0000, 0.0000, 0.1787, 0.0000, 0.1215, 0.0226, 0.1802,
        0.0000, 0.0534, 0.0177, 0.0000, 0.0000, 0.0595, 0.0179, 0.0000, 0.0000,
        0.0492, 0.0116, 0.0000, 0.0000, 0.0465, 0.0022, 0.0000, 0.0000, 0.0410,
        0.0000, 0.0000, 0.0000, 0.0418, 0.0000, 0.0000, 0.0000, 0.0220, 0.0000,
        0.0000, 0.0000, 0.0076, 0.0000, 0.0000, 0.0000, 0.0022, 0.0000, 0.0000]) (500)
2024-04-24 14:52:04,487 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38850906987944905
2024-04-24 14:52:04,489 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.202130.20213
2024-04-24 14:52:04,499 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #207: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1276595744680851, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.06, '(min, 0)': 0.45, '(min, 1)': 0.11, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:52:04,499 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:04,501 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3890470487784207
2024-04-24 14:52:04,521 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #207: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(min, 0)': 0.62, '(min, 1)': 0.05}}
2024-04-24 14:52:04,522 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:04,523 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3890470487784207
2024-04-24 14:52:04,601 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #207: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.21818181818181817, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 4)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.24, '(rev, 1)': 0.05, '(rev, 2)': 0.05}}
2024-04-24 14:52:04,601 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:04,602 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3890470487784207
2024-04-24 14:52:04,808 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #207: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5957446808510638, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.42, '(min, 1)': 0.19, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03}}
2024-04-24 14:52:04,808 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:04,810 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3890470487784207
2024-04-24 14:52:04,828 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #207: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.13953488372093023, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.2, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-04-24 14:52:04,828 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:04,828 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3890470487784207
2024-04-24 14:52:04,869 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #207: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.14285714285714285, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.03, '(min, 0)': 0.42, '(min, 1)': 0.14, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:52:04,870 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:04,870 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3890470487784207
2024-04-24 14:52:06,245 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #207: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.5111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.03, '(min, 0)': 0.23, '(min, 1)': 0.39, '(rev, 1)': 0.1, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:52:06,245 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:06,246 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3890470487784207
2024-04-24 14:52:06,324 - MainProcess - INFO - text_logger.py - 51 - Train epoch #207
2024-04-24 14:52:06,327 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.5615e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6761e-01, 0.0000e+00,
        1.2332e-01, 1.0113e-02, 3.7984e-01, 0.0000e+00, 2.0863e-02, 4.6692e-03,
        0.0000e+00, 0.0000e+00, 2.1890e-02, 3.1495e-03, 0.0000e+00, 0.0000e+00,
        1.7162e-02, 1.5990e-03, 0.0000e+00, 0.0000e+00, 1.5416e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.3357e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3361e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.4057e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0734e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6736e-04, 0.0000e+00, 0.0000e+00])  tensor([1.6963e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5017e-01, 0.0000e+00,
        1.2045e-01, 2.3273e-02, 1.5631e-01, 0.0000e+00, 4.4001e-02, 1.4367e-02,
        0.0000e+00, 0.0000e+00, 4.9620e-02, 2.2341e-02, 0.0000e+00, 0.0000e+00,
        4.0451e-02, 1.9166e-02, 0.0000e+00, 0.0000e+00, 3.7025e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2618e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4043e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7775e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.8907e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6910e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:52:06,344 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3880779467724396
2024-04-24 14:52:06,347 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.255560.25556
2024-04-24 14:52:06,403 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #208: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.58, '(min, 1)': 0.06}}
2024-04-24 14:52:06,404 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:06,405 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38850906987944905
2024-04-24 14:52:06,525 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #208: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3488372093023256, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(min, 0)': 0.34, '(min, 1)': 0.25, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:52:06,525 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:06,526 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38850906987944905
2024-04-24 14:52:06,664 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #208: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4878048780487805, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.35, '(min, 1)': 0.27, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:52:06,664 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:06,665 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38850906987944905
2024-04-24 14:52:06,781 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #208: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2608695652173913, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.04, '(min, 0)': 0.16, '(min, 1)': 0.4, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:52:06,782 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:06,782 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38850906987944905
2024-04-24 14:52:06,938 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #208: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3125, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.04, '(min, 0)': 0.23, '(min, 1)': 0.37, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-04-24 14:52:06,938 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:06,938 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38850906987944905
2024-04-24 14:52:07,001 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #208: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.36363636363636365, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.5, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:52:07,003 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:07,003 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38850906987944905
2024-04-24 14:52:08,656 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #208: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.22, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:52:08,658 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:08,660 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38850906987944905
2024-04-24 14:52:08,736 - MainProcess - INFO - text_logger.py - 51 - Train epoch #208
2024-04-24 14:52:08,738 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.9409e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2442e-01, 0.0000e+00,
        1.2279e-01, 1.2521e-02, 4.2715e-01, 0.0000e+00, 2.8147e-03, 5.6821e-03,
        0.0000e+00, 0.0000e+00, 1.3248e-04, 2.9688e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.4024e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2692e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([0.9832, 0.0000, 0.0000, 0.0000, 0.0719, 0.0000, 0.1303, 0.0252, 0.0749,
        0.0000, 0.0092, 0.0163, 0.0000, 0.0000, 0.0017, 0.0128, 0.0000, 0.0000,
        0.0000, 0.0099, 0.0000, 0.0000, 0.0000, 0.0020, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-04-24 14:52:08,751 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38764682366543013
2024-04-24 14:52:08,754 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.255560.25556
2024-04-24 14:52:08,776 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #209: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.22, '(min, 1)': 0.43, '(rev, 1)': 0.11, '(rev, 2)': 0.01, '(rev, 3)': 0.03, '(rev, 8)': 0.01}}
2024-04-24 14:52:08,776 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:08,776 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3880779467724396
2024-04-24 14:52:08,798 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #209: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.52, '(min, 1)': 0.08}}
2024-04-24 14:52:08,798 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:08,800 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3880779467724396
2024-04-24 14:52:08,826 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #209: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2926829268292683, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(min, 0)': 0.22, '(min, 1)': 0.37, '(rev, 1)': 0.12, '(rev, 2)': 0.03}}
2024-04-24 14:52:08,826 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:08,827 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3880779467724396
2024-04-24 14:52:09,031 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #209: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2127659574468085, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.42, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:52:09,031 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:09,031 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3880779467724396
2024-04-24 14:52:09,195 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #209: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5952380952380952, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.08, '(min, 0)': 0.4, '(min, 1)': 0.21, '(rev, 1)': 0.13, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-24 14:52:09,195 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:09,196 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3880779467724396
2024-04-24 14:52:09,273 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #209: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35714285714285715, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(min, 0)': 0.12, '(min, 1)': 0.47, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:52:09,273 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:09,274 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3880779467724396
2024-04-24 14:52:10,716 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #209: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(min, 0)': 0.1, '(min, 1)': 0.5, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-24 14:52:10,716 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:10,717 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3880779467724396
2024-04-24 14:52:10,784 - MainProcess - INFO - text_logger.py - 51 - Train epoch #209
2024-04-24 14:52:10,786 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.9445e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8192e-01, 0.0000e+00,
        1.4783e-01, 1.2758e-02, 3.9328e-01, 0.0000e+00, 1.1086e-02, 6.7951e-03,
        0.0000e+00, 0.0000e+00, 8.5470e-03, 5.2137e-03, 0.0000e+00, 0.0000e+00,
        6.8552e-03, 4.6794e-03, 0.0000e+00, 0.0000e+00, 5.9897e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.4683e-03, 6.6667e-05, 0.0000e+00, 0.0000e+00,
        5.7177e-03, 6.2500e-05, 0.0000e+00, 0.0000e+00, 2.9197e-03, 6.8966e-05,
        0.0000e+00, 0.0000e+00, 6.1811e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2834e-04, 0.0000e+00, 0.0000e+00])  tensor([1.6695e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2148e-01, 0.0000e+00,
        1.4701e-01, 2.4580e-02, 1.2410e-01, 0.0000e+00, 3.2005e-02, 1.6974e-02,
        0.0000e+00, 0.0000e+00, 3.2168e-02, 2.5248e-02, 0.0000e+00, 0.0000e+00,
        2.7293e-02, 2.6398e-02, 0.0000e+00, 0.0000e+00, 2.4372e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.2424e-02, 1.4907e-03, 0.0000e+00, 0.0000e+00,
        2.3871e-02, 1.3975e-03, 0.0000e+00, 0.0000e+00, 1.2511e-02, 1.5421e-03,
        0.0000e+00, 0.0000e+00, 3.7059e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4513e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:52:10,806 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38705241553426606
2024-04-24 14:52:10,808 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.173910.17391
2024-04-24 14:52:10,895 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #210: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.03, '(min, 0)': 0.43, '(min, 1)': 0.17, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:52:10,895 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:10,896 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38764682366543013
2024-04-24 14:52:10,948 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #210: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 3)': 0.02, '(min, 0)': 0.05, '(min, 1)': 0.58, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:52:10,948 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:10,951 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38764682366543013
2024-04-24 14:52:11,199 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #210: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4772727272727273, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.03, '(min, 0)': 0.39, '(min, 1)': 0.24, '(rev, 1)': 0.08, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:52:11,200 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:11,200 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38764682366543013
2024-04-24 14:52:11,256 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #210: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1590909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.03, '(min, 0)': 0.44, '(min, 1)': 0.12, '(rev, 1)': 0.07, '(rev, 2)': 0.03}}
2024-04-24 14:52:11,256 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:11,257 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38764682366543013
2024-04-24 14:52:11,275 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #210: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.05, '(min, 0)': 0.35, '(min, 1)': 0.26, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-04-24 14:52:11,275 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:11,276 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38764682366543013
2024-04-24 14:52:12,688 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #210: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 3, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.15384615384615385, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.25, '(rev, 1)': 0.02, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:52:12,688 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:12,689 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38764682366543013
2024-04-24 14:52:13,803 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #210: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.05405405405405406, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.41, '(min, 1)': 0.22, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-04-24 14:52:13,803 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:13,804 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38764682366543013
2024-04-24 14:52:13,882 - MainProcess - INFO - text_logger.py - 51 - Train epoch #210
2024-04-24 14:52:13,885 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.7972e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9573e-01, 0.0000e+00,
        1.2203e-01, 1.2367e-02, 4.0413e-01, 0.0000e+00, 1.1887e-02, 5.4730e-03,
        0.0000e+00, 0.0000e+00, 1.0507e-02, 2.9901e-03, 0.0000e+00, 0.0000e+00,
        8.6950e-03, 1.4967e-03, 0.0000e+00, 0.0000e+00, 7.6634e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.7300e-03, 6.0606e-05, 0.0000e+00, 0.0000e+00,
        6.6101e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9584e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.4168e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3489e-04, 0.0000e+00, 0.0000e+00])  tensor([1.4653e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2269e-01, 0.0000e+00,
        1.3146e-01, 2.5938e-02, 1.2655e-01, 0.0000e+00, 3.2307e-02, 1.6491e-02,
        0.0000e+00, 0.0000e+00, 3.5333e-02, 1.4864e-02, 0.0000e+00, 0.0000e+00,
        3.0267e-02, 1.0952e-02, 0.0000e+00, 0.0000e+00, 2.7591e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.4849e-02, 1.3552e-03, 0.0000e+00, 0.0000e+00,
        2.5200e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2560e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.5016e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.5242e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:52:13,900 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38651979092575517
2024-04-24 14:52:13,902 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.204800.15075
2024-04-24 14:52:13,930 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #211: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(min, 0)': 0.39, '(min, 1)': 0.25, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:52:13,930 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #211: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 7, 4, 0, 0),(rev, 4)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 7, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35135135135135137, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.05, '(min, 0)': 0.27, '(min, 1)': 0.36, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-24 14:52:13,930 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:13,930 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:13,930 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:13,931 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38705241553426606
2024-04-24 14:52:13,931 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38705241553426606
2024-04-24 14:52:13,931 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38705241553426606
2024-04-24 14:52:13,956 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #211: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17777777777777778, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.35, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:52:13,957 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:13,968 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38705241553426606
2024-04-24 14:52:14,424 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #211: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4473684210526316, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.29, '(min, 1)': 0.39, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:52:14,425 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:14,427 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38705241553426606
2024-04-24 14:52:14,882 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #211: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.03, '(ado, 7)': 0.01, '(min, 0)': 0.18, '(min, 1)': 0.39, '(rev, 1)': 0.09, '(rev, 2)': 0.05}}
2024-04-24 14:52:14,883 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:14,883 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38705241553426606
2024-04-24 14:52:16,367 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #211: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 10)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.34, '(rev, 1)': 0.09, '(rev, 8)': 0.01}}
2024-04-24 14:52:16,367 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:16,367 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38705241553426606
2024-04-24 14:52:16,445 - MainProcess - INFO - text_logger.py - 51 - Train epoch #211
2024-04-24 14:52:16,448 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.1607e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6161e-01, 0.0000e+00,
        1.5399e-01, 1.0995e-02, 3.6929e-01, 0.0000e+00, 1.9624e-02, 6.3479e-03,
        0.0000e+00, 0.0000e+00, 1.6561e-02, 4.7408e-03, 0.0000e+00, 0.0000e+00,
        1.3263e-02, 3.3907e-03, 0.0000e+00, 0.0000e+00, 1.1854e-02, 2.7615e-04,
        0.0000e+00, 0.0000e+00, 1.0833e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0743e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1870e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0527e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3432e-04, 0.0000e+00, 0.0000e+00])  tensor([1.5749, 0.0000, 0.0000, 0.0000, 0.1464, 0.0000, 0.1508, 0.0251, 0.1489,
        0.0000, 0.0438, 0.0178, 0.0000, 0.0000, 0.0423, 0.0196, 0.0000, 0.0000,
        0.0362, 0.0170, 0.0000, 0.0000, 0.0334, 0.0027, 0.0000, 0.0000, 0.0309,
        0.0000, 0.0000, 0.0000, 0.0324, 0.0000, 0.0000, 0.0000, 0.0162, 0.0000,
        0.0000, 0.0000, 0.0049, 0.0000, 0.0000, 0.0000, 0.0020, 0.0000, 0.0000]) (500)
2024-04-24 14:52:16,460 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3865955747256526
2024-04-24 14:52:16,463 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.509010.15766
2024-04-24 14:52:16,477 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #212: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7692307692307693, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.13, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:52:16,477 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #212: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6585365853658537, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.03, '(ado, 3)': 0.02, '(min, 0)': 0.17, '(min, 1)': 0.46, '(rev, 1)': 0.14, '(rev, 2)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:52:16,477 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:16,477 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:16,478 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38651979092575517
2024-04-24 14:52:16,478 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38651979092575517
2024-04-24 14:52:16,509 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #212: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.4339622641509434, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.37, '(rev, 1)': 0.05, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:52:16,509 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #212: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46511627906976744, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.03, '(min, 0)': 0.15, '(min, 1)': 0.46, '(rev, 1)': 0.13, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-24 14:52:16,509 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
nsition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.625, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.05, '(min, 0)': 0.34, '(min, 1)': 0.28, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 7)': 0.01}}
2024-04-24 14:52:16,510 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:16,510 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:16,510 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38651979092575517
2024-04-24 14:52:16,510 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38651979092575517
2024-04-24 14:52:16,511 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38651979092575517
2024-04-24 14:52:16,525 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #212: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.41, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:52:16,525 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:16,526 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38651979092575517
2024-04-24 14:52:18,427 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #212: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.46808510638297873, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.42, '(rev, 1)': 0.06, '(rev, 2)': 0.06, '(rev, 4)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:52:18,428 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:18,428 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38651979092575517
2024-04-24 14:52:18,508 - MainProcess - INFO - text_logger.py - 51 - Train epoch #212
2024-04-24 14:52:18,510 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.8990e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0049e-01, 0.0000e+00,
        1.3337e-01, 1.5096e-02, 4.1356e-01, 0.0000e+00, 6.0260e-03, 7.0337e-03,
        0.0000e+00, 0.0000e+00, 3.5493e-03, 5.1711e-03, 0.0000e+00, 0.0000e+00,
        2.8855e-03, 4.2088e-03, 0.0000e+00, 0.0000e+00, 2.4861e-03, 1.1329e-04,
        0.0000e+00, 0.0000e+00, 2.3873e-03, 6.0606e-05, 0.0000e+00, 0.0000e+00,
        2.3762e-03, 6.8966e-05, 0.0000e+00, 0.0000e+00, 1.0381e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.2078e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.6421e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9035e-02, 0.0000e+00,
        1.4105e-01, 2.8851e-02, 9.8071e-02, 0.0000e+00, 1.9301e-02, 1.6596e-02,
        0.0000e+00, 0.0000e+00, 2.0403e-02, 2.2817e-02, 0.0000e+00, 0.0000e+00,
        1.8016e-02, 2.1224e-02, 0.0000e+00, 0.0000e+00, 1.6654e-02, 1.9011e-03,
        0.0000e+00, 0.0000e+00, 1.5980e-02, 1.3552e-03, 0.0000e+00, 0.0000e+00,
        1.6001e-02, 1.5421e-03, 0.0000e+00, 0.0000e+00, 7.1752e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1386e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:52:18,520 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38689065638314574
2024-04-24 14:52:18,522 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.618660.15057
2024-04-24 14:52:18,540 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #213: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.375, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.05, '(min, 0)': 0.31, '(min, 1)': 0.32, '(rev, 1)': 0.12, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:52:18,540 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:18,540 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3865955747256526
2024-04-24 14:52:18,555 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #213: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(min, 0)': 0.52, '(min, 1)': 0.08, '(rev, 1)': 0.07, '(rev, 2)': 0.08}}
2024-04-24 14:52:18,555 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:18,556 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3865955747256526
2024-04-24 14:52:18,571 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #213: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(min, 0)': 0.46, '(min, 1)': 0.15, '(rev, 1)': 0.09, '(rev, 2)': 0.08, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:52:18,572 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:18,572 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3865955747256526
2024-04-24 14:52:18,708 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #213: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6744186046511628, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(min, 0)': 0.35, '(min, 1)': 0.31, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.05, '(rev, 4)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:52:18,709 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:18,709 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3865955747256526
2024-04-24 14:52:19,373 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #213: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.525, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.48, '(min, 1)': 0.19, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:52:19,374 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:19,375 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3865955747256526
2024-04-24 14:52:19,558 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #213: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7659574468085106, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 3)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.45, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 4)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:52:19,559 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:19,559 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3865955747256526
2024-04-24 14:52:20,963 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #213: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.49, '(min, 1)': 0.13}}
2024-04-24 14:52:20,963 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:20,964 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3865955747256526
2024-04-24 14:52:21,037 - MainProcess - INFO - text_logger.py - 51 - Train epoch #213
2024-04-24 14:52:21,039 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.3197e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9817e-01, 0.0000e+00,
        1.3048e-01, 1.4701e-02, 4.1086e-01, 0.0000e+00, 7.6858e-03, 7.4232e-03,
        0.0000e+00, 0.0000e+00, 5.5578e-03, 4.8158e-03, 0.0000e+00, 0.0000e+00,
        4.2793e-03, 3.4504e-03, 0.0000e+00, 0.0000e+00, 3.6845e-03, 2.1445e-04,
        0.0000e+00, 0.0000e+00, 3.2854e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.3668e-03, 5.7143e-05, 0.0000e+00, 0.0000e+00, 1.7164e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.8463e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.0846e-05, 0.0000e+00, 0.0000e+00])  tensor([1.9846e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0968e-01, 0.0000e+00,
        1.4697e-01, 2.9689e-02, 1.1223e-01, 0.0000e+00, 2.4615e-02, 1.9452e-02,
        0.0000e+00, 0.0000e+00, 2.5490e-02, 2.0661e-02, 0.0000e+00, 0.0000e+00,
        2.1186e-02, 1.7311e-02, 0.0000e+00, 0.0000e+00, 1.9406e-02, 2.7791e-03,
        0.0000e+00, 0.0000e+00, 1.7642e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8668e-02, 1.2778e-03, 0.0000e+00, 0.0000e+00, 1.0001e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.8487e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1195e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:52:21,054 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3866228407696763
2024-04-24 14:52:21,057 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.337210.33721
2024-04-24 14:52:21,084 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #214: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.09, '(min, 1)': 0.53, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:52:21,084 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:21,085 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38689065638314574
2024-04-24 14:52:21,100 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #214: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.04, '(ado, 7)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.44, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:52:21,100 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #214: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.21, '(min, 1)': 0.38, '(rev, 1)': 0.1, '(rev, 2)': 0.08}}
2024-04-24 14:52:21,100 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:21,100 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:21,101 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38689065638314574
2024-04-24 14:52:21,101 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38689065638314574
2024-04-24 14:52:21,185 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #214: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 9)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.19}}
2024-04-24 14:52:21,185 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:21,186 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38689065638314574
2024-04-24 14:52:21,308 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #214: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.02, '(ado, 3)': 0.04, '(min, 0)': 0.18, '(min, 1)': 0.46, '(rev, 1)': 0.13, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:52:21,308 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:21,309 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38689065638314574
2024-04-24 14:52:21,725 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #214: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3137254901960784, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.19, '(rev, 1)': 0.03, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:52:21,726 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:21,727 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38689065638314574
2024-04-24 14:52:23,005 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #214: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.4, '(min, 1)': 0.19}}
2024-04-24 14:52:23,006 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:23,007 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38689065638314574
2024-04-24 14:52:23,074 - MainProcess - INFO - text_logger.py - 51 - Train epoch #214
2024-04-24 14:52:23,077 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-2.8974e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8560e-01,
         0.0000e+00,  1.8011e-01,  8.3630e-03,  2.9465e-01,  0.0000e+00,
         4.4135e-02,  4.3314e-03,  0.0000e+00,  0.0000e+00,  4.1013e-02,
         2.4086e-03,  0.0000e+00,  0.0000e+00,  3.4158e-02,  2.1865e-03,
         0.0000e+00,  0.0000e+00,  3.0994e-02,  1.6295e-04,  0.0000e+00,
         0.0000e+00,  2.7620e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.6629e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4615e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7364e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  2.8124e-04,  0.0000e+00,  0.0000e+00])  tensor([1.9063, 0.0000, 0.0000, 0.0000, 0.1765, 0.0000, 0.1412, 0.0217, 0.1823,
        0.0000, 0.0581, 0.0143, 0.0000, 0.0000, 0.0581, 0.0118, 0.0000, 0.0000,
        0.0504, 0.0145, 0.0000, 0.0000, 0.0470, 0.0022, 0.0000, 0.0000, 0.0435,
        0.0000, 0.0000, 0.0000, 0.0442, 0.0000, 0.0000, 0.0000, 0.0246, 0.0000,
        0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.0021, 0.0000, 0.0000]) (500)
2024-04-24 14:52:23,097 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3860719108993818
2024-04-24 14:52:23,101 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.195650.19565
2024-04-24 14:52:23,388 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #215: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.36538461538461536, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.31, '(rev, 1)': 0.05, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:52:23,388 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:23,389 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3866228407696763
2024-04-24 14:52:23,490 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #215: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(ado, 6)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.19, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:52:23,491 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:23,491 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3866228407696763
2024-04-24 14:52:23,868 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #215: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.45652173913043476, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.28, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 4)': 0.03}}
2024-04-24 14:52:23,868 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:23,868 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3866228407696763
2024-04-24 14:52:23,907 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #215: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 10)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.52, '(min, 1)': 0.21, '(rev, 1)': 0.03, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:52:23,907 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:23,908 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3866228407696763
2024-04-24 14:52:24,194 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #215: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.625, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.55, '(min, 1)': 0.16, '(rev, 1)': 0.02, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:52:24,194 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:24,195 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3866228407696763
2024-04-24 14:52:24,452 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #215: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6046511627906976, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.48, '(min, 1)': 0.22, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:52:24,453 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:24,453 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3866228407696763
2024-04-24 14:52:25,567 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #215: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.37037037037037035, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.54, '(min, 1)': 0.11, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:52:25,567 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:25,568 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3866228407696763
2024-04-24 14:52:25,646 - MainProcess - INFO - text_logger.py - 51 - Train epoch #215
2024-04-24 14:52:25,650 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.2244e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0903e-01, 0.0000e+00,
        1.7026e-01, 1.3949e-02, 3.2505e-01, 0.0000e+00, 3.1776e-02, 7.9809e-03,
        0.0000e+00, 0.0000e+00, 2.8761e-02, 9.0325e-03, 0.0000e+00, 0.0000e+00,
        2.4303e-02, 8.5608e-03, 0.0000e+00, 0.0000e+00, 2.1428e-02, 4.1752e-04,
        0.0000e+00, 0.0000e+00, 1.9310e-02, 1.6611e-04, 0.0000e+00, 0.0000e+00,
        1.8856e-02, 1.2444e-04, 0.0000e+00, 0.0000e+00, 9.6046e-03, 3.2787e-05,
        0.0000e+00, 0.0000e+00, 1.1823e-03, 3.2787e-05, 0.0000e+00, 0.0000e+00,
        1.4425e-04, 0.0000e+00, 0.0000e+00])  tensor([3.2666e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6679e-01, 0.0000e+00,
        1.5798e-01, 3.0964e-02, 1.7013e-01, 0.0000e+00, 5.1670e-02, 2.0677e-02,
        0.0000e+00, 0.0000e+00, 5.1661e-02, 2.8709e-02, 0.0000e+00, 0.0000e+00,
        4.6412e-02, 2.7282e-02, 0.0000e+00, 0.0000e+00, 4.2256e-02, 2.8443e-03,
        0.0000e+00, 0.0000e+00, 3.8909e-02, 1.6757e-03, 0.0000e+00, 0.0000e+00,
        4.0071e-02, 1.3965e-03, 0.0000e+00, 0.0000e+00, 2.1309e-02, 7.3314e-04,
        0.0000e+00, 0.0000e+00, 4.9518e-03, 7.3314e-04, 0.0000e+00, 0.0000e+00,
        1.6084e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:52:25,670 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38612504705163164
2024-04-24 14:52:25,673 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.497690.12731
2024-04-24 14:52:25,710 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #216: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10204081632653061, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 3)': 0.03, '(ado, 7)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.28, '(rev, 1)': 0.03, '(rev, 2)': 0.02}}
2024-04-24 14:52:25,712 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:25,713 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3860719108993818
2024-04-24 14:52:25,726 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #216: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.44, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(ado, 7)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.33, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:52:25,727 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:25,728 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3860719108993818
2024-04-24 14:52:25,888 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #216: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 7)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.17, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:52:25,888 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:25,890 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3860719108993818
2024-04-24 14:52:26,368 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #216: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 3, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4523809523809524, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.36, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:52:26,369 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:26,370 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3860719108993818
2024-04-24 14:52:27,103 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #216: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.24, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:52:27,104 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:27,104 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3860719108993818
2024-04-24 14:52:27,266 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #216: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6808510638297872, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 3)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.32, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:52:27,267 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:27,267 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3860719108993818
2024-04-24 14:52:28,014 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #216: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0),(ado, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/3', 'revenue': 0.4489795918367347, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.02, '(min, 0)': 0.13, '(min, 1)': 0.53, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 6)': 0.02}}
2024-04-24 14:52:28,014 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:28,015 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3860719108993818
2024-04-24 14:52:28,085 - MainProcess - INFO - text_logger.py - 51 - Train epoch #216
2024-04-24 14:52:28,087 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0019e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3065e-01, 0.0000e+00,
        1.6467e-01, 1.4358e-02, 3.4731e-01, 0.0000e+00, 2.3544e-02, 1.1830e-02,
        0.0000e+00, 0.0000e+00, 1.7552e-02, 1.5828e-02, 0.0000e+00, 0.0000e+00,
        1.3851e-02, 1.7479e-02, 0.0000e+00, 0.0000e+00, 1.2470e-02, 3.8029e-04,
        0.0000e+00, 0.0000e+00, 1.1242e-02, 3.8207e-04, 0.0000e+00, 0.0000e+00,
        1.0497e-02, 4.6844e-04, 0.0000e+00, 0.0000e+00, 5.7370e-03, 1.0220e-04,
        0.0000e+00, 0.0000e+00, 1.3030e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4187e-04, 0.0000e+00, 0.0000e+00])  tensor([3.6852e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5614e-01, 0.0000e+00,
        1.7193e-01, 3.2481e-02, 1.5502e-01, 0.0000e+00, 4.5890e-02, 2.9939e-02,
        0.0000e+00, 0.0000e+00, 4.0615e-02, 5.7556e-02, 0.0000e+00, 0.0000e+00,
        3.5295e-02, 7.9199e-02, 0.0000e+00, 0.0000e+00, 3.3608e-02, 2.7980e-03,
        0.0000e+00, 0.0000e+00, 3.1569e-02, 2.7955e-03, 0.0000e+00, 0.0000e+00,
        3.1680e-02, 3.5852e-03, 0.0000e+00, 0.0000e+00, 1.8548e-02, 1.3280e-03,
        0.0000e+00, 0.0000e+00, 5.4197e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.4298e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:52:28,108 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38588179242534776
2024-04-24 14:52:28,110 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.349490.09949
2024-04-24 14:52:28,113 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #217: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.16, '(rev, 1)': 0.03, '(rev, 2)': 0.01}}
2024-04-24 14:52:28,114 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:28,114 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38612504705163164
2024-04-24 14:52:28,364 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #217: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5909090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.47, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.02}}
2024-04-24 14:52:28,364 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:28,365 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38612504705163164
2024-04-24 14:52:28,555 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #217: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.2653061224489796, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.15, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-04-24 14:52:28,556 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:28,557 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38612504705163164
2024-04-24 14:52:28,700 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #217: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1875, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.21, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:52:28,700 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:28,701 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38612504705163164
2024-04-24 14:52:29,049 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #217: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.42, '(min, 1)': 0.18}}
2024-04-24 14:52:29,049 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:29,051 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38612504705163164
2024-04-24 14:52:30,402 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #217: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5384615384615384, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.2, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:52:30,402 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:30,403 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38612504705163164
2024-04-24 14:52:30,823 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #217: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7631578947368421, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 3)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.29, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:52:30,823 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:30,824 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38612504705163164
2024-04-24 14:52:30,892 - MainProcess - INFO - text_logger.py - 51 - Train epoch #217
2024-04-24 14:52:30,895 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.9989e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3106e-01, 0.0000e+00,
        1.6781e-01, 1.0057e-02, 3.3691e-01, 0.0000e+00, 3.2211e-02, 5.3360e-03,
        0.0000e+00, 0.0000e+00, 2.6592e-02, 3.0907e-03, 0.0000e+00, 0.0000e+00,
        2.1920e-02, 1.3093e-03, 0.0000e+00, 0.0000e+00, 1.9508e-02, 2.7834e-04,
        0.0000e+00, 0.0000e+00, 1.7564e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6097e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.9360e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1776e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4783e-04, 0.0000e+00, 0.0000e+00])  tensor([1.8385e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6605e-01, 0.0000e+00,
        1.5645e-01, 2.5185e-02, 1.6904e-01, 0.0000e+00, 5.3335e-02, 1.4858e-02,
        0.0000e+00, 0.0000e+00, 4.9110e-02, 1.1521e-02, 0.0000e+00, 0.0000e+00,
        4.4084e-02, 6.9401e-03, 0.0000e+00, 0.0000e+00, 4.0526e-02, 2.8767e-03,
        0.0000e+00, 0.0000e+00, 3.7217e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5587e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1001e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.2128e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6498e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:52:30,908 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38570271610196405
2024-04-24 14:52:30,911 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.381580.38158
2024-04-24 14:52:30,955 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #218: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.02702702702702703, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.02, '(min, 0)': 0.47, '(min, 1)': 0.17, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-04-24 14:52:30,955 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #218: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1320754716981132, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.2, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:52:30,956 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:30,956 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38588179242534776
2024-04-24 14:52:30,956 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38588179242534776
2024-04-24 14:52:30,971 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #218: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2653061224489796, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.21, '(rev, 1)': 0.05, '(rev, 2)': 0.06}}
2024-04-24 14:52:30,971 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #218: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.20930232558139536, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.03, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.26, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 5)': 0.01}}
2024-04-24 14:52:30,972 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:30,973 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38588179242534776
2024-04-24 14:52:31,318 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #218: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.18}}
2024-04-24 14:52:31,318 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:31,319 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38588179242534776
2024-04-24 14:52:32,180 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #218: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22916666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.16, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-04-24 14:52:32,180 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:32,181 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38588179242534776
2024-04-24 14:52:33,269 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #218: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 3, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 8)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.15}}
2024-04-24 14:52:33,269 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:33,270 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38588179242534776
2024-04-24 14:52:33,336 - MainProcess - INFO - text_logger.py - 51 - Train epoch #218
2024-04-24 14:52:33,339 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.8002,  0.0000,  0.0000,  0.0000,  0.2510,  0.0000,  0.1773,  0.0097,
         0.2557,  0.0000,  0.0504,  0.0038,  0.0000,  0.0000,  0.0543,  0.0016,
         0.0000,  0.0000,  0.0465,  0.0015,  0.0000,  0.0000,  0.0436,  0.0000,
         0.0000,  0.0000,  0.0386,  0.0000,  0.0000,  0.0000,  0.0385,  0.0000,
         0.0000,  0.0000,  0.0219,  0.0000,  0.0000,  0.0000,  0.0047,  0.0000,
         0.0000,  0.0000,  0.0010,  0.0000,  0.0000])  tensor([1.8173, 0.0000, 0.0000, 0.0000, 0.1895, 0.0000, 0.1500, 0.0278, 0.1935,
        0.0000, 0.0563, 0.0131, 0.0000, 0.0000, 0.0641, 0.0102, 0.0000, 0.0000,
        0.0571, 0.0112, 0.0000, 0.0000, 0.0543, 0.0000, 0.0000, 0.0000, 0.0489,
        0.0000, 0.0000, 0.0000, 0.0497, 0.0000, 0.0000, 0.0000, 0.0292, 0.0000,
        0.0000, 0.0000, 0.0093, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000]) (500)
2024-04-24 14:52:33,353 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38476048188384343
2024-04-24 14:52:33,355 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:52:33,367 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #219: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.45, '(min, 0)': 0.55}}
2024-04-24 14:52:33,368 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:33,368 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38570271610196405
2024-04-24 14:52:33,383 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #219: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 1, 0, 0),(rev, 4)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '4/4', 'revenue': 0.5319148936170213, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.31, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.03, '(rev, 5)': 0.01}}
2024-04-24 14:52:33,384 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:33,384 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38570271610196405
2024-04-24 14:52:33,400 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #219: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.19, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-04-24 14:52:33,400 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #219: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.28205128205128205, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 3)': 0.03, '(min, 0)': 0.22, '(min, 1)': 0.41, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.03}}
2024-04-24 14:52:33,400 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:33,400 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:33,401 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38570271610196405
2024-04-24 14:52:33,401 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38570271610196405
2024-04-24 14:52:33,816 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #219: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0),(rev, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.625, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.23, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:52:33,816 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:33,816 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38570271610196405
2024-04-24 14:52:33,965 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #219: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.32, '(rev, 1)': 0.08, '(rev, 2)': 0.06}}
2024-04-24 14:52:33,965 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:33,966 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38570271610196405
2024-04-24 14:52:36,171 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #219: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7692307692307693, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 8)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.23, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-24 14:52:36,171 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:36,172 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38570271610196405
2024-04-24 14:52:36,244 - MainProcess - INFO - text_logger.py - 51 - Train epoch #219
2024-04-24 14:52:36,246 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.0052e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6744e-01, 0.0000e+00,
        1.5251e-01, 1.4553e-02, 3.8317e-01, 0.0000e+00, 1.6537e-02, 8.9985e-03,
        0.0000e+00, 0.0000e+00, 1.1385e-02, 7.4966e-03, 0.0000e+00, 0.0000e+00,
        8.7083e-03, 5.7059e-03, 0.0000e+00, 0.0000e+00, 7.6161e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.4793e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.7712e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2006e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.4872e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.6197e-05, 0.0000e+00, 0.0000e+00])  tensor([2.5959e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3071e-01, 0.0000e+00,
        1.5341e-01, 3.1452e-02, 1.3043e-01, 0.0000e+00, 4.0780e-02, 2.3422e-02,
        0.0000e+00, 0.0000e+00, 3.4376e-02, 3.3254e-02, 0.0000e+00, 0.0000e+00,
        2.9023e-02, 3.3583e-02, 0.0000e+00, 0.0000e+00, 2.6944e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.3722e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.2864e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3283e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.6140e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2036e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:52:36,261 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3845874784349537
2024-04-24 14:52:36,263 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.384620.38462
2024-04-24 14:52:36,276 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #220: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.38095238095238093, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.41, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:52:36,277 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:36,277 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38476048188384343
2024-04-24 14:52:36,293 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #220: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(min, 0)': 0.51, '(min, 1)': 0.15, '(rev, 1)': 0.01}}
2024-04-24 14:52:36,293 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:36,294 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38476048188384343
2024-04-24 14:52:36,309 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #220: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.022727272727272728, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.35, '(rev, 1)': 0.05, '(rev, 2)': 0.01}}
2024-04-24 14:52:36,309 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:36,310 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38476048188384343
2024-04-24 14:52:36,324 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #220: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 0, 0, 0),(rev, 3)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.2553191489361702, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.13, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.03}}
2024-04-24 14:52:36,325 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #220: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.02, '(min, 0)': 0.2, '(min, 1)': 0.44, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-04-24 14:52:36,325 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:36,325 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:36,326 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38476048188384343
2024-04-24 14:52:36,326 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38476048188384343
2024-04-24 14:52:36,415 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #220: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 3, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.475, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(min, 0)': 0.1, '(min, 1)': 0.51, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:52:36,415 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:36,416 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38476048188384343
2024-04-24 14:52:38,255 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #220: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5869565217391305, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(min, 0)': 0.21, '(min, 1)': 0.48, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.03}}
2024-04-24 14:52:38,255 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:38,256 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38476048188384343
2024-04-24 14:52:38,323 - MainProcess - INFO - text_logger.py - 51 - Train epoch #220
2024-04-24 14:52:38,325 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.2583e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2650e-01, 0.0000e+00,
        1.9467e-01, 1.2911e-02, 3.2777e-01, 0.0000e+00, 3.0509e-02, 8.7210e-03,
        0.0000e+00, 0.0000e+00, 2.1519e-02, 6.5537e-03, 0.0000e+00, 0.0000e+00,
        1.7167e-02, 5.7752e-03, 0.0000e+00, 0.0000e+00, 1.4822e-02, 6.6667e-05,
        0.0000e+00, 0.0000e+00, 1.3347e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1991e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0042e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.6522e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.9533e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6454e-01, 0.0000e+00,
        1.9028e-01, 3.2184e-02, 1.6367e-01, 0.0000e+00, 5.4796e-02, 2.4942e-02,
        0.0000e+00, 0.0000e+00, 4.5022e-02, 2.6554e-02, 0.0000e+00, 0.0000e+00,
        3.8947e-02, 3.0282e-02, 0.0000e+00, 0.0000e+00, 3.5350e-02, 1.4907e-03,
        0.0000e+00, 0.0000e+00, 3.2863e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.1179e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9771e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.0130e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:52:38,343 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3842322007385723
2024-04-24 14:52:38,345 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.293480.29348
2024-04-24 14:52:38,384 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #221: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.35, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(min, 0)': 0.36, '(min, 1)': 0.25, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-04-24 14:52:38,385 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:38,385 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3845874784349537
2024-04-24 14:52:38,402 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #221: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(min, 0)': 0.46, '(min, 1)': 0.21}}
2024-04-24 14:52:38,402 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:38,403 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3845874784349537
2024-04-24 14:52:38,568 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #221: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 3, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.25, '(rev, 1)': 0.07, '(rev, 2)': 0.03}}
2024-04-24 14:52:38,568 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:38,569 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3845874784349537
2024-04-24 14:52:38,573 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #221: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3877551020408163, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.24, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:52:38,573 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:38,574 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3845874784349537
2024-04-24 14:52:39,117 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #221: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6904761904761905, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.23, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 7)': 0.01}}
2024-04-24 14:52:39,118 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:39,118 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3845874784349537
2024-04-24 14:52:39,197 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #221: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.08, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.27, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:52:39,197 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:39,198 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3845874784349537
2024-04-24 14:52:40,115 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #221: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4878048780487805, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.03, '(min, 0)': 0.35, '(min, 1)': 0.29, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:52:40,115 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:40,116 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3845874784349537
2024-04-24 14:52:40,181 - MainProcess - INFO - text_logger.py - 51 - Train epoch #221
2024-04-24 14:52:40,183 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([0.3671, 0.0000, 0.0000, 0.0000, 0.3016, 0.0000, 0.1883, 0.0099, 0.3161,
        0.0000, 0.0335, 0.0071, 0.0000, 0.0000, 0.0296, 0.0053, 0.0000, 0.0000,
        0.0253, 0.0044, 0.0000, 0.0000, 0.0235, 0.0000, 0.0000, 0.0000, 0.0207,
        0.0000, 0.0000, 0.0000, 0.0196, 0.0000, 0.0000, 0.0000, 0.0121, 0.0000,
        0.0000, 0.0000, 0.0026, 0.0000, 0.0000, 0.0000, 0.0004, 0.0000, 0.0000])  tensor([2.0200, 0.0000, 0.0000, 0.0000, 0.1687, 0.0000, 0.1674, 0.0266, 0.1753,
        0.0000, 0.0522, 0.0210, 0.0000, 0.0000, 0.0522, 0.0236, 0.0000, 0.0000,
        0.0470, 0.0246, 0.0000, 0.0000, 0.0454, 0.0000, 0.0000, 0.0000, 0.0410,
        0.0000, 0.0000, 0.0000, 0.0405, 0.0000, 0.0000, 0.0000, 0.0261, 0.0000,
        0.0000, 0.0000, 0.0079, 0.0000, 0.0000, 0.0000, 0.0027, 0.0000, 0.0000]) (500)
2024-04-24 14:52:40,199 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38377777139850044
2024-04-24 14:52:40,202 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.243900.24390
2024-04-24 14:52:40,210 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #222: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5813953488372093, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(min, 0)': 0.28, '(min, 1)': 0.37, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 3)': 0.04, '(rev, 4)': 0.03}}
2024-04-24 14:52:40,210 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:40,211 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3842322007385723
2024-04-24 14:52:40,330 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #222: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.21818181818181817, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.35, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 4)': 0.01}}
2024-04-24 14:52:40,330 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:40,331 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3842322007385723
2024-04-24 14:52:40,636 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #222: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 8)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.14}}
2024-04-24 14:52:40,636 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:40,637 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3842322007385723
2024-04-24 14:52:41,146 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #222: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7307692307692307, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.41, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:52:41,146 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:41,147 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3842322007385723
2024-04-24 14:52:41,188 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #222: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.425531914893617, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.3, '(rev, 1)': 0.03, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:52:41,188 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:41,188 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3842322007385723
2024-04-24 14:52:41,713 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #222: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.24}}
2024-04-24 14:52:41,713 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:41,714 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3842322007385723
2024-04-24 14:52:42,242 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #222: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3673469387755102, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 3)': 0.04, '(min, 0)': 0.18, '(min, 1)': 0.46, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:52:42,242 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:42,243 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3842322007385723
2024-04-24 14:52:42,326 - MainProcess - INFO - text_logger.py - 51 - Train epoch #222
2024-04-24 14:52:42,329 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.6932e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1450e-01, 0.0000e+00,
        1.5386e-01, 1.2809e-02, 3.1443e-01, 0.0000e+00, 3.2493e-02, 7.4035e-03,
        0.0000e+00, 0.0000e+00, 3.3151e-02, 4.2758e-03, 0.0000e+00, 0.0000e+00,
        2.8933e-02, 3.0401e-03, 0.0000e+00, 0.0000e+00, 2.7616e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.3973e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.4189e-02, 2.2222e-04, 0.0000e+00, 0.0000e+00, 1.4885e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.4017e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.1578e-04, 0.0000e+00, 0.0000e+00])  tensor([2.2527, 0.0000, 0.0000, 0.0000, 0.1813, 0.0000, 0.1578, 0.0322, 0.1828,
        0.0000, 0.0507, 0.0208, 0.0000, 0.0000, 0.0565, 0.0167, 0.0000, 0.0000,
        0.0509, 0.0176, 0.0000, 0.0000, 0.0491, 0.0000, 0.0000, 0.0000, 0.0429,
        0.0000, 0.0000, 0.0000, 0.0437, 0.0029, 0.0000, 0.0000, 0.0275, 0.0000,
        0.0000, 0.0000, 0.0084, 0.0000, 0.0000, 0.0000, 0.0042, 0.0000, 0.0000]) (500)
2024-04-24 14:52:42,350 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3832028841191553
2024-04-24 14:52:42,353 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.183670.18367
2024-04-24 14:52:42,543 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #223: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.55, '(min, 1)': 0.08}}
2024-04-24 14:52:42,544 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:42,545 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38377777139850044
2024-04-24 14:52:42,710 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #223: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.6428571428571429, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.47, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:52:42,710 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:42,711 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38377777139850044
2024-04-24 14:52:43,727 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #223: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2978723404255319, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.44, '(rev, 1)': 0.11, '(rev, 3)': 0.03}}
2024-04-24 14:52:43,727 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:43,728 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38377777139850044
2024-04-24 14:52:44,003 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #223: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.37, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:52:44,003 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:44,004 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38377777139850044
2024-04-24 14:52:44,466 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #223: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.21153846153846154, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.21, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-04-24 14:52:44,466 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:44,467 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38377777139850044
2024-04-24 14:52:45,362 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #223: {'transition': '(exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 3, 5, 1, 1),(min, 0)->(exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 3, 6, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.5416666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 10)': 0.01, '(ado, 2)': 0.03, '(min, 0)': 0.33, '(min, 1)': 0.38, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 7)': 0.01}}
2024-04-24 14:52:45,363 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:45,363 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38377777139850044
2024-04-24 14:52:45,790 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #223: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 1.0454545454545454, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.26, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 5)': 0.01, '(rev, 6)': 0.01, '(rev, 9)': 0.01}}
2024-04-24 14:52:45,790 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:45,791 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38377777139850044
2024-04-24 14:52:45,859 - MainProcess - INFO - text_logger.py - 51 - Train epoch #223
2024-04-24 14:52:45,864 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0743e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3043e-01, 0.0000e+00,
        1.7721e-01, 1.2421e-02, 3.4808e-01, 0.0000e+00, 2.1957e-02, 1.1101e-02,
        0.0000e+00, 0.0000e+00, 1.8356e-02, 1.0427e-02, 0.0000e+00, 0.0000e+00,
        1.5052e-02, 1.0060e-02, 0.0000e+00, 0.0000e+00, 1.3774e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1697e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1495e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0398e-03, 7.1429e-05,
        0.0000e+00, 0.0000e+00, 7.0787e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1846e-04, 0.0000e+00, 0.0000e+00])  tensor([2.4582e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5164e-01, 0.0000e+00,
        1.7372e-01, 3.0079e-02, 1.5853e-01, 0.0000e+00, 4.5414e-02, 2.7213e-02,
        0.0000e+00, 0.0000e+00, 4.4073e-02, 3.6912e-02, 0.0000e+00, 0.0000e+00,
        3.7812e-02, 4.3009e-02, 0.0000e+00, 0.0000e+00, 3.5871e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.0931e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.1075e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9900e-02, 1.5972e-03,
        0.0000e+00, 0.0000e+00, 3.9873e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9833e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:52:45,883 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3833061044464894
2024-04-24 14:52:45,886 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.522730.52273
2024-04-24 14:52:45,890 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #224: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4878048780487805, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.13, '(min, 1)': 0.48, '(rev, 1)': 0.13, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:52:45,891 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:45,891 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3832028841191553
2024-04-24 14:52:45,906 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #224: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.54, '(min, 1)': 0.05}}
2024-04-24 14:52:45,907 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:45,908 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3832028841191553
2024-04-24 14:52:45,937 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #224: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4418604651162791, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(min, 0)': 0.13, '(min, 1)': 0.5, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 5)': 0.01}}
2024-04-24 14:52:45,938 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:45,938 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3832028841191553
2024-04-24 14:52:46,244 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #224: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.23404255319148937, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.38, '(rev, 1)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:52:46,244 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:46,245 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3832028841191553
2024-04-24 14:52:46,908 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #224: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6444444444444445, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.05, '(min, 0)': 0.24, '(min, 1)': 0.42, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 5)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:52:46,909 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:46,909 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3832028841191553
2024-04-24 14:52:47,640 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #224: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.41, '(rev, 1)': 0.14, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:52:47,641 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:47,641 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3832028841191553
2024-04-24 14:52:48,083 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #224: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5957446808510638, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.37, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:52:48,084 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:48,084 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3832028841191553
2024-04-24 14:52:48,279 - MainProcess - INFO - text_logger.py - 51 - Train epoch #224
2024-04-24 14:52:48,282 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.1900e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5401e-01, 0.0000e+00,
        1.6985e-01, 1.3360e-02, 3.5223e-01, 0.0000e+00, 1.7177e-02, 1.1930e-02,
        0.0000e+00, 0.0000e+00, 1.4086e-02, 1.0062e-02, 0.0000e+00, 0.0000e+00,
        1.2167e-02, 7.7708e-03, 0.0000e+00, 0.0000e+00, 1.1204e-02, 4.2316e-04,
        0.0000e+00, 0.0000e+00, 9.5030e-03, 1.4381e-04, 0.0000e+00, 0.0000e+00,
        9.5853e-03, 7.1429e-05, 0.0000e+00, 0.0000e+00, 5.6197e-03, 7.1429e-05,
        0.0000e+00, 0.0000e+00, 6.6175e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.4099e-05, 0.0000e+00, 0.0000e+00])  tensor([2.8937e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4396e-01, 0.0000e+00,
        1.6613e-01, 3.0539e-02, 1.4498e-01, 0.0000e+00, 4.0142e-02, 2.5924e-02,
        0.0000e+00, 0.0000e+00, 3.9223e-02, 3.0969e-02, 0.0000e+00, 0.0000e+00,
        3.5380e-02, 2.9139e-02, 0.0000e+00, 0.0000e+00, 3.3301e-02, 3.5460e-03,
        0.0000e+00, 0.0000e+00, 2.8913e-02, 2.0193e-03, 0.0000e+00, 0.0000e+00,
        3.0194e-02, 1.5972e-03, 0.0000e+00, 0.0000e+00, 1.8256e-02, 1.5972e-03,
        0.0000e+00, 0.0000e+00, 3.8699e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1706e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:52:48,296 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38264958451408304
2024-04-24 14:52:48,298 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.142860.14286
2024-04-24 14:52:48,311 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #225: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.5, '(min, 1)': 0.09}}
2024-04-24 14:52:48,312 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:48,312 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3833061044464894
2024-04-24 14:52:48,343 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #225: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.02, '(min, 0)': 0.51, '(min, 1)': 0.06, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:52:48,344 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:48,345 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3833061044464894
2024-04-24 14:52:48,358 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #225: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(min, 0)': 0.45, '(min, 1)': 0.15, '(rev, 1)': 0.1, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-04-24 14:52:48,358 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:48,360 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3833061044464894
2024-04-24 14:52:48,755 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #225: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 8, 4, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 8, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(min, 0)': 0.53, '(min, 1)': 0.09, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-24 14:52:48,756 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:48,757 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3833061044464894
2024-04-24 14:52:48,926 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #225: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6458333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.31, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-04-24 14:52:48,926 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:48,927 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3833061044464894
2024-04-24 14:52:49,981 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #225: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.51, '(min, 1)': 0.13}}
2024-04-24 14:52:49,981 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:49,982 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3833061044464894
2024-04-24 14:52:50,197 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #225: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2127659574468085, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.04, '(min, 0)': 0.12, '(min, 1)': 0.44, '(rev, 1)': 0.07, '(rev, 2)': 0.04}}
2024-04-24 14:52:50,198 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:50,199 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3833061044464894
2024-04-24 14:52:50,396 - MainProcess - INFO - text_logger.py - 51 - Train epoch #225
2024-04-24 14:52:50,399 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.8025e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0704e-01, 0.0000e+00,
        1.2093e-01, 1.6723e-02, 4.3048e-01, 0.0000e+00, 4.3943e-03, 7.3716e-03,
        0.0000e+00, 0.0000e+00, 2.2534e-03, 3.6738e-03, 0.0000e+00, 0.0000e+00,
        1.4218e-03, 2.8495e-03, 0.0000e+00, 0.0000e+00, 1.1245e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.5127e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.5761e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1793e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.4226, 0.0000, 0.0000, 0.0000, 0.0866, 0.0000, 0.1380, 0.0345, 0.0919,
        0.0000, 0.0205, 0.0215, 0.0000, 0.0000, 0.0154, 0.0152, 0.0000, 0.0000,
        0.0102, 0.0155, 0.0000, 0.0000, 0.0088, 0.0000, 0.0000, 0.0000, 0.0073,
        0.0000, 0.0000, 0.0000, 0.0057, 0.0000, 0.0000, 0.0000, 0.0036, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-04-24 14:52:50,417 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3817073502959624
2024-04-24 14:52:50,419 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:52:50,622 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #226: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6341463414634146, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(min, 0)': 0.11, '(min, 1)': 0.5, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-24 14:52:50,622 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:50,622 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38264958451408304
2024-04-24 14:52:50,811 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #226: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6538461538461539, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.04, '(ado, 8)': 0.01, '(min, 0)': 0.14, '(min, 1)': 0.51, '(rev, 1)': 0.08, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:52:50,811 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:50,812 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38264958451408304
2024-04-24 14:52:51,007 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #226: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.14285714285714285, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.25, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:52:51,007 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:51,008 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38264958451408304
2024-04-24 14:52:51,143 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #226: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5208333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.53, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-04-24 14:52:51,143 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:51,144 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38264958451408304
2024-04-24 14:52:51,523 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #226: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(min, 0)': 0.06, '(min, 1)': 0.58, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 8)': 0.01}}
2024-04-24 14:52:51,523 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:51,524 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38264958451408304
2024-04-24 14:52:51,991 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #226: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4318181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.07, '(min, 1)': 0.51, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-04-24 14:52:51,991 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:51,992 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38264958451408304
2024-04-24 14:52:52,460 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #226: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3137254901960784, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.04, '(ado, 8)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.31, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:52:52,460 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:52,461 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38264958451408304
2024-04-24 14:52:52,540 - MainProcess - INFO - text_logger.py - 51 - Train epoch #226
2024-04-24 14:52:52,543 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.2359e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4746e-01, 0.0000e+00,
        1.5301e-01, 1.3491e-02, 3.3960e-01, 0.0000e+00, 2.4826e-02, 8.1208e-03,
        0.0000e+00, 0.0000e+00, 2.3100e-02, 3.7529e-03, 0.0000e+00, 0.0000e+00,
        2.0379e-02, 3.2192e-03, 0.0000e+00, 0.0000e+00, 1.8469e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.5771e-02, 7.4074e-05, 0.0000e+00, 0.0000e+00,
        1.5916e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0295e-02, 7.1429e-05,
        0.0000e+00, 0.0000e+00, 2.0610e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.7955e-04, 0.0000e+00, 0.0000e+00])  tensor([2.1801e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6849e-01, 0.0000e+00,
        1.6927e-01, 3.1585e-02, 1.6567e-01, 0.0000e+00, 4.8829e-02, 2.0202e-02,
        0.0000e+00, 0.0000e+00, 4.9108e-02, 1.3092e-02, 0.0000e+00, 0.0000e+00,
        4.4682e-02, 1.6289e-02, 0.0000e+00, 0.0000e+00, 4.0854e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.5409e-02, 1.6563e-03, 0.0000e+00, 0.0000e+00,
        3.7444e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4383e-02, 1.5972e-03,
        0.0000e+00, 0.0000e+00, 6.8092e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5605e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:52:52,559 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38173268772188407
2024-04-24 14:52:52,562 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.483790.17006
2024-04-24 14:52:52,647 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #227: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24489795918367346, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.4, '(min, 1)': 0.19, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:52:52,648 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:52,648 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3817073502959624
2024-04-24 14:52:52,711 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #227: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 3, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.27906976744186046, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.37, '(min, 1)': 0.28, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:52:52,711 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:52,712 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3817073502959624
2024-04-24 14:52:54,457 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #227: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.05, '(ado, 4)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.13, '(rev, 1)': 0.07, '(rev, 2)': 0.03}}
2024-04-24 14:52:54,458 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:54,458 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3817073502959624
2024-04-24 14:52:54,650 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #227: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.9574468085106383, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.03, '(min, 0)': 0.28, '(min, 1)': 0.35, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.05, '(rev, 4)': 0.01}}
2024-04-24 14:52:54,651 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:54,651 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3817073502959624
2024-04-24 14:52:54,680 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #227: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.05660377358490566, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.17, '(rev, 1)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:52:54,680 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:54,681 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3817073502959624
2024-04-24 14:52:54,754 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #227: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.04, '(min, 0)': 0.46, '(min, 1)': 0.11, '(rev, 1)': 0.1, '(rev, 2)': 0.05}}
2024-04-24 14:52:54,754 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:54,755 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3817073502959624
2024-04-24 14:52:54,997 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #227: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7142857142857143, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.24, '(rev, 1)': 0.01, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:52:54,997 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:54,998 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3817073502959624
2024-04-24 14:52:55,206 - MainProcess - INFO - text_logger.py - 51 - Train epoch #227
2024-04-24 14:52:55,210 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-6.6432e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.2037e-01,
         0.0000e+00,  1.4215e-01,  1.3220e-02,  3.5120e-01,  0.0000e+00,
         2.8936e-02,  5.9162e-03,  0.0000e+00,  0.0000e+00,  2.8036e-02,
         2.5160e-03,  0.0000e+00,  0.0000e+00,  2.5550e-02,  1.4877e-03,
         0.0000e+00,  0.0000e+00,  2.3147e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  1.9973e-02,  5.0000e-05,  0.0000e+00,  0.0000e+00,
         2.1256e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.3102e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.5908e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  4.9508e-04,  0.0000e+00,  0.0000e+00])  tensor([2.2039e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6557e-01, 0.0000e+00,
        1.4380e-01, 3.3769e-02, 1.8313e-01, 0.0000e+00, 4.8263e-02, 1.9239e-02,
        0.0000e+00, 0.0000e+00, 5.1753e-02, 1.2014e-02, 0.0000e+00, 0.0000e+00,
        4.9155e-02, 8.4089e-03, 0.0000e+00, 0.0000e+00, 4.5390e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.9590e-02, 1.1180e-03, 0.0000e+00, 0.0000e+00,
        4.3118e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6838e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.4823e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.1346e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:52:55,234 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38153535146294726
2024-04-24 14:52:55,237 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.372450.12755
2024-04-24 14:52:55,544 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #228: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 3, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.45652173913043476, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 4)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.54, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:52:55,544 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:55,545 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38173268772188407
2024-04-24 14:52:56,054 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #228: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.18, '(min, 1)': 0.45, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-24 14:52:56,054 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:56,055 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38173268772188407
2024-04-24 14:52:56,896 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #228: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.2727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.04, '(min, 0)': 0.13, '(min, 1)': 0.48, '(rev, 1)': 0.12, '(rev, 2)': 0.04}}
2024-04-24 14:52:56,896 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:56,897 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38173268772188407
2024-04-24 14:52:57,018 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #228: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.09, '(min, 1)': 0.5, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-04-24 14:52:57,018 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:57,019 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38173268772188407
2024-04-24 14:52:57,101 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #228: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2926829268292683, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.24, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:52:57,102 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:57,102 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38173268772188407
2024-04-24 14:52:57,409 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #228: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(min, 0)': 0.55, '(min, 1)': 0.1, '(rev, 1)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-24 14:52:57,409 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:57,409 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38173268772188407
2024-04-24 14:52:57,923 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #228: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5581395348837209, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.43, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-24 14:52:57,923 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:57,924 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38173268772188407
2024-04-24 14:52:58,115 - MainProcess - INFO - text_logger.py - 51 - Train epoch #228
2024-04-24 14:52:58,118 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.6364e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8434e-01, 0.0000e+00,
        1.5076e-01, 1.5784e-02, 3.7218e-01, 0.0000e+00, 1.4170e-02, 1.0084e-02,
        0.0000e+00, 0.0000e+00, 9.7262e-03, 6.2253e-03, 0.0000e+00, 0.0000e+00,
        8.3732e-03, 4.9204e-03, 0.0000e+00, 0.0000e+00, 7.2245e-03, 6.9881e-05,
        0.0000e+00, 0.0000e+00, 6.2279e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.7543e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7010e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.5751e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.9350e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3260e-01, 0.0000e+00,
        1.5361e-01, 3.4995e-02, 1.2811e-01, 0.0000e+00, 3.8789e-02, 2.9264e-02,
        0.0000e+00, 0.0000e+00, 3.0895e-02, 2.9292e-02, 0.0000e+00, 0.0000e+00,
        2.9284e-02, 2.9247e-02, 0.0000e+00, 0.0000e+00, 2.6536e-02, 1.1039e-03,
        0.0000e+00, 0.0000e+00, 2.3499e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3234e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5655e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.3066e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:52:58,131 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3812153394670489
2024-04-24 14:52:58,133 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.311110.20000
2024-04-24 14:52:58,177 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #229: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35714285714285715, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.31, '(rev, 1)': 0.13, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:52:58,177 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:58,178 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38153535146294726
2024-04-24 14:52:58,219 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #229: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 6, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 2, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43478260869565216, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.03, '(min, 0)': 0.4, '(min, 1)': 0.3, '(rev, 1)': 0.06, '(rev, 10)': 0.01, '(rev, 2)': 0.01, '(rev, 5)': 0.02}}
2024-04-24 14:52:58,219 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:58,219 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38153535146294726
2024-04-24 14:52:59,374 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #229: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.21, '(rev, 1)': 0.13, '(rev, 3)': 0.03}}
2024-04-24 14:52:59,374 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:59,375 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38153535146294726
2024-04-24 14:52:59,466 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #229: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5348837209302325, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(min, 0)': 0.24, '(min, 1)': 0.41, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:52:59,466 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:59,467 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38153535146294726
2024-04-24 14:52:59,621 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #229: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.25, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:52:59,621 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:52:59,622 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38153535146294726
2024-04-24 14:53:00,205 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #229: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.20454545454545456, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 3)': 0.03, '(min, 0)': 0.23, '(min, 1)': 0.36, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-24 14:53:00,206 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:53:00,207 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38153535146294726
2024-04-24 14:53:00,700 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #229: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 8)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.17}}
2024-04-24 14:53:00,700 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:53:00,701 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38153535146294726
2024-04-24 14:53:00,778 - MainProcess - INFO - text_logger.py - 51 - Train epoch #229
2024-04-24 14:53:00,781 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.9976e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6383e-01, 0.0000e+00,
        1.8329e-01, 1.2868e-02, 3.9660e-01, 0.0000e+00, 1.0462e-02, 8.9242e-03,
        0.0000e+00, 0.0000e+00, 3.9340e-03, 6.0702e-03, 0.0000e+00, 0.0000e+00,
        2.6444e-03, 5.1621e-03, 0.0000e+00, 0.0000e+00, 1.9755e-03, 3.0769e-05,
        0.0000e+00, 0.0000e+00, 1.6879e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3699e-03, 6.8966e-05, 0.0000e+00, 0.0000e+00, 8.1245e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.9639e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.0000e-05, 0.0000e+00])  tensor([1.6876e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1712e-01, 0.0000e+00,
        1.9092e-01, 3.1175e-02, 1.2317e-01, 0.0000e+00, 2.9841e-02, 2.7154e-02,
        0.0000e+00, 0.0000e+00, 1.7842e-02, 2.5838e-02, 0.0000e+00, 0.0000e+00,
        1.5307e-02, 2.6892e-02, 0.0000e+00, 0.0000e+00, 1.3259e-02, 6.8802e-04,
        0.0000e+00, 0.0000e+00, 1.1953e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2208e-02, 1.5421e-03, 0.0000e+00, 0.0000e+00, 7.5713e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.5424e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.7889e-03, 0.0000e+00]) (500)
2024-04-24 14:53:00,797 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3806302481060711
2024-04-24 14:53:00,799 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.178570.17857
2024-04-24 14:53:01,083 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #230: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.17142857142857143, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(min, 0)': 0.5, '(min, 1)': 0.18, '(rev, 1)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:53:01,090 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:53:01,094 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3812153394670489
2024-04-24 14:53:01,574 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #230: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.03, '(ado, 6)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.33, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:53:01,574 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:53:01,575 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3812153394670489
2024-04-24 14:53:01,713 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #230: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 5, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4722222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.32, '(rev, 1)': 0.12, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-04-24 14:53:01,713 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:53:01,714 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3812153394670489
2024-04-24 14:53:01,738 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #230: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 3, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 4, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3235294117647059, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.19, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 6)': 0.02}}
2024-04-24 14:53:01,738 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:53:01,739 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3812153394670489
2024-04-24 14:53:01,798 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #230: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.08695652173913043, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.26, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-24 14:53:01,798 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:53:01,799 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3812153394670489
2024-04-24 14:53:02,337 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #230: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 3, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 6, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3170731707317073, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.16, '(min, 1)': 0.47, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-24 14:53:02,338 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:53:02,338 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3812153394670489
2024-04-24 14:53:02,755 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #230: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 8, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 9, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(min, 0)': 0.54, '(min, 1)': 0.13, '(rev, 1)': 0.01}}
2024-04-24 14:53:02,755 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:53:02,756 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3812153394670489
2024-04-24 14:53:02,830 - MainProcess - INFO - text_logger.py - 51 - Train epoch #230
2024-04-24 14:53:02,833 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.2350e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1312e-01, 0.0000e+00,
        2.1921e-01, 1.0954e-02, 3.0179e-01, 0.0000e+00, 3.6046e-02, 6.7532e-03,
        0.0000e+00, 0.0000e+00, 2.4818e-02, 3.7996e-03, 0.0000e+00, 0.0000e+00,
        2.1386e-02, 2.6794e-03, 0.0000e+00, 0.0000e+00, 1.7883e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.4766e-02, 1.5032e-04, 0.0000e+00, 0.0000e+00,
        1.4751e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.3823e-03, 8.0000e-05,
        0.0000e+00, 0.0000e+00, 2.2419e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9499e-04, 0.0000e+00, 0.0000e+00])  tensor([1.5966, 0.0000, 0.0000, 0.0000, 0.1678, 0.0000, 0.1913, 0.0302, 0.1596,
        0.0000, 0.0552, 0.0207, 0.0000, 0.0000, 0.0458, 0.0175, 0.0000, 0.0000,
        0.0425, 0.0154, 0.0000, 0.0000, 0.0380, 0.0000, 0.0000, 0.0000, 0.0335,
        0.0021, 0.0000, 0.0000, 0.0359, 0.0000, 0.0000, 0.0000, 0.0242, 0.0018,
        0.0000, 0.0000, 0.0080, 0.0000, 0.0000, 0.0000, 0.0018, 0.0000, 0.0000]) (500)
2024-04-24 14:53:02,848 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.37985944245937914
2024-04-24 14:53:02,852 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.085710.08571
2024-04-24 14:53:02,913 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #231: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.35, '(min, 1)': 0.24}}
2024-04-24 14:53:02,913 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:53:02,914 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3806302481060711
2024-04-24 14:53:03,788 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #231: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.16, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:53:03,788 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:53:03,788 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3806302481060711
2024-04-24 14:53:03,820 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #231: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.022727272727272728, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.3, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-24 14:53:03,820 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:53:03,821 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3806302481060711
2024-04-24 14:53:04,057 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #231: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.46, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:53:04,057 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:53:04,058 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3806302481060711
2024-04-24 14:53:04,240 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #231: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3191489361702128, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.22, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-24 14:53:04,241 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:53:04,241 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3806302481060711
2024-04-24 14:53:04,455 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #231: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.37, '(min, 1)': 0.21}}
2024-04-24 14:53:04,455 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:53:04,455 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3806302481060711
2024-04-24 14:53:04,829 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #231: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 5, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4489795918367347, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 10)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.34, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:53:04,830 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:53:04,831 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3806302481060711
2024-04-24 14:53:05,080 - MainProcess - INFO - text_logger.py - 51 - Train epoch #231
2024-04-24 14:53:05,084 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-5.2733e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7316e-01,
         0.0000e+00,  1.9188e-01,  1.0885e-02,  2.9836e-01,  0.0000e+00,
         4.2215e-02,  6.4646e-03,  0.0000e+00,  0.0000e+00,  3.6206e-02,
         3.1708e-03,  0.0000e+00,  0.0000e+00,  3.3110e-02,  2.6219e-03,
         0.0000e+00,  0.0000e+00,  2.9290e-02,  2.9851e-05,  0.0000e+00,
         0.0000e+00,  2.5763e-02,  8.0000e-05,  0.0000e+00,  0.0000e+00,
         2.5200e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.6998e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.1538e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  4.1269e-04,  0.0000e+00,  0.0000e+00])  tensor([1.9113e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7083e-01, 0.0000e+00,
        1.6961e-01, 2.9687e-02, 1.8425e-01, 0.0000e+00, 5.7571e-02, 1.9310e-02,
        0.0000e+00, 0.0000e+00, 5.4517e-02, 1.4944e-02, 0.0000e+00, 0.0000e+00,
        5.1881e-02, 1.7321e-02, 0.0000e+00, 0.0000e+00, 4.7279e-02, 6.6748e-04,
        0.0000e+00, 0.0000e+00, 4.2604e-02, 1.7889e-03, 0.0000e+00, 0.0000e+00,
        4.3754e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0165e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0616e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.6689e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-24 14:53:05,100 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3789172082412586
2024-04-24 14:53:05,103 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-24 14:53:05,540 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #232: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.25, '(rev, 1)': 0.02}}
2024-04-24 14:53:05,541 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:53:05,542 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37985944245937914
2024-04-24 14:53:08,616 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #232: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 3, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.15, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(ado, 3)': 0.03, '(ado, 4)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.34, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-24 14:53:08,616 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:53:08,618 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37985944245937914
2024-04-24 14:53:08,883 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #232: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5416666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.46, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 5)': 0.02, '(rev, 8)': 0.01, '(rev, 9)': 0.01}}
2024-04-24 14:53:08,884 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:53:08,885 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37985944245937914
2024-04-24 14:53:09,554 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #232: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.39, '(min, 1)': 0.22}}
2024-04-24 14:53:09,555 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:53:09,556 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37985944245937914
2024-04-24 14:53:10,249 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #232: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17073170731707318, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 7)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.28, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-24 14:53:10,249 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:53:10,251 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37985944245937914
2024-04-24 14:53:10,424 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #232: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 3, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6842105263157895, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.27, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-04-24 14:53:10,425 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:53:10,426 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37985944245937914
2024-04-24 14:53:12,335 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #232: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3584905660377358, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.18, '(min, 1)': 0.47, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-04-24 14:53:12,335 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-24 14:53:12,336 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37985944245937914
2024-04-24 14:53:12,420 - Test Agent 2 - INFO - util.py - 54 - process shutting down
2024-04-24 14:53:12,420 - Train Agent 4 - INFO - util.py - 54 - process shutting down
2024-04-24 14:53:12,420 - Train Agent 1 - INFO - util.py - 54 - process shutting down
2024-04-24 14:53:12,422 - Train Agent 5 - INFO - util.py - 54 - process shutting down
2024-04-24 14:53:12,422 - Train Agent 3 - INFO - util.py - 54 - process shutting down
2024-04-24 14:53:12,422 - Test Agent 1 - INFO - util.py - 54 - process shutting down
2024-04-24 14:53:12,423 - Train Agent 2 - INFO - util.py - 54 - process shutting down
2024-04-24 14:53:12,845 - Train Agent 4 - INFO - util.py - 54 - process exiting with exitcode 1
2024-04-24 14:53:12,856 - Train Agent 2 - INFO - util.py - 54 - process exiting with exitcode 1
2024-04-24 14:53:12,856 - Test Agent 1 - INFO - util.py - 54 - process exiting with exitcode 1
2024-04-24 14:53:13,076 - MainProcess - INFO - util.py - 54 - sending shutdown message to manager
2024-04-24 14:53:14,102 - MainProcess - INFO - util.py - 54 - manager still alive
2024-04-24 14:53:14,104 - MainProcess - INFO - util.py - 54 - trying to `terminate()` manager process
2024-04-24 14:53:14,291 - MainProcess - INFO - util.py - 54 - process shutting down
