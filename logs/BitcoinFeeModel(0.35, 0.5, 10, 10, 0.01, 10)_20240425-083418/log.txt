2024-04-25 08:34:28,089 - MainProcess - INFO - text_logger.py - 51 - Starting to train trainer:
instance(SynchronizedMultiProcessOrchestrator):
  Type: typing.Literal['single_process', 'multi_process', 'synced_multi_process'],
  agent: {'type': 'MCTSAgent', 'exploration_mechanism': {'type': 'EpsilonGreedyExploration', 'epsilon_schedule': {'type': 'ParameterSchedule', 'starting_parameter': 0.05, 'step_change': 0, 'end_parameter': 0}}, 'depth': 5, 'simulations': 25, 'ground_initial_state': False, 'value_clip': 0, 'nn_factor': 0.0001},
  algorithm: instance(MCTSAlgorithm):
    agent: {'type': 'MCTSAgent', 'exploration_mechanism': {'type': 'EpsilonGreedyExploration', 'epsilon_schedule': {'type': 'ParameterSchedule', 'starting_parameter': 0.05, 'step_change': 0, 'end_parameter': 0}}, 'depth': 5, 'simulations': 25, 'ground_initial_state': False, 'value_clip': 0, 'nn_factor': 0.0001},
    approximator: MCTSApproximator(
  (model): Sequential(
    (0): Linear(in_features=46, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=88, bias=True)
  )
),
    blockchain_model: BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01, 10),
    creation_args: {
      'batch_size': 100,
      'bind_all': False,
      'build_info': None,
      'bva_smart_init': 0.47111710906028753,
      'depth': 5,
      'dropout': 0,
      'epoch_shuffles': 2,
      'epsilon_step': 0,
      'evaluate_episode_length': 100,
      'ground_initial_state': False,
      'learning_rate': 0.0002,
      'length_factor': 10,
      'lower_priority': True,
      'lr_decay_epoch': 1000,
      'mc_simulations': 25,
      'nn_factor': 0.0001,
      'normalize_target_values': True,
      'num_of_episodes_for_average': 1000,
      'num_of_epochs': 5001,
      'number_of_evaluation_agents': 2,
      'number_of_training_agents': 5,
      'output_profile': False,
      'output_root': None,
      'prune_tree_rate': 250,
      'starting_epsilon': 0.05,
      'train_episode_length': 100,
      'use_base_approximation': True,
      'use_cached_values': False,
    },
    device: device(type='cpu'),
    loss_fn: MCTSLossFunction(
  (approximator): MCTSApproximator(
    (model): Sequential(
      (0): Linear(in_features=46, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=88, bias=True)
    )
  )
),
    lr_scheduler: instance(StepLR):
      base_lrs: [0.0002],
      gamma: 0.1,
      last_epoch: 0,
      optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0002
    lr: 0.0002
    weight_decay: 0
),
      step_size: 1000,
      verbose: False,
    optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0002
    lr: 0.0002
    weight_decay: 0
),
    simulator: instance(MDPBlockchainSimulator):
      action_space: instance(MultiDimensionalDiscreteSpace):
        dimension: 2,
        intervals: [
          instance(Interval):
            boundaries: (0, 3),
            enum: class(Action):
              Adopt: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Adopt',
                numerator: 1,
                real: 1,
                value: 1,
              Illegal: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Illegal',
                numerator: 0,
                real: 0,
                value: 0,
              Mine: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Mine',
                numerator: 3,
                real: 3,
                value: 3,
              Reveal: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Reveal',
                numerator: 2,
                real: 2,
                value: 2,
            size: 4
          instance(Interval):
            boundaries: (0, 10),
            enum: None,
            size: 11
        ],
        size: 44,
      check_valid_states: False,
      device: device(type='cpu'),
      expected_horizon: 10000,
      final_state: (
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Fork):
          denominator: 1,
          imag: 0,
          name: 'Irrelevant',
          numerator: 0,
          real: 0,
          value: 0
        -1,
        -1,
        -1,
        -1,
        -1,
      ),
      include_transition_info: True,
      initial_state: (
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Fork):
          denominator: 1,
          imag: 0,
          name: 'Irrelevant',
          numerator: 0,
          real: 0,
          value: 0
        0,
        0,
        0,
        0,
        0,
      ),
      num_of_actions: 44,
      num_of_states: 531232341494857729,
      state_space: instance(DefaultValueSpace):
        default_value: (
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Fork):
            denominator: 1,
            imag: 0,
            name: 'Irrelevant',
            numerator: 0,
            real: 0,
            value: 0
          -1,
          -1,
          -1,
          -1,
          -1,
        ),
        dimension: 46,
        size: 531232341494857729,
        underlying_space: instance(MultiDimensionalDiscreteSpace):
          dimension: 46,
          intervals: [
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 2),
              enum: class(Fork):
                Active: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Active',
                  numerator: 2,
                  real: 2,
                  value: 2,
                Irrelevant: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Irrelevant',
                  numerator: 0,
                  real: 0,
                  value: 0,
                Relevant: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Relevant',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 3
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
          ],
          size: 531232341494857728,
      state_space_dim: 46,
  approximator: MCTSApproximator(
  (model): Sequential(
    (0): Linear(in_features=46, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=88, bias=True)
  )
),
  batch_size: 100,
  bind_all: False,
  blockchain_model: BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01, 10),
  build_info: None,
  callback: instance(CompositionCallback):
    callbacks: (
      instance(CompositionCallback):
        callbacks: (
          instance(TextLoggingCallback):
            logger: instance(TextLogger):
              file_name: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                          10)_20240425-083418\\log.txt',
              logger: <Logger multiprocessing (INFO)>,
              output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                           10)_20240425-083418',
            logger_name: 'text',
            orchestrator: <Recursion on instance(SynchronizedMultiProcessOrchestrator) with id=2069889347440>,
            output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                         10)_20240425-083418'
          instance(TensorboardLoggingCallback):
            bind_all: False,
            logger: None,
            logger_name: 'tensorboard',
            max_num_of_agents: 5,
            max_number_of_actions: 3,
            num_of_q_values_in_approximator: 0,
            orchestrator: None,
            tensorboard_popen: None
          instance(BVACallback):
            agent: None,
            episode_values: deque([], maxlen=1000),
            episode_values_synchronizer: None,
            epoch_history: [],
            num_of_episodes_for_average: 1000,
            own_sync_manager: False,
            smart_init: 0.47111710906028753,
            sort_episodes: True,
            stop_goal: None,
            sync_dict: None,
            sync_manager: None
          instance(BVATextLoggingCallback):
            agent: None,
            bva_callback: instance(BVACallback):
              agent: None,
              episode_values: deque([], maxlen=1000),
              episode_values_synchronizer: None,
              epoch_history: [],
              num_of_episodes_for_average: 1000,
              own_sync_manager: False,
              smart_init: 0.47111710906028753,
              sort_episodes: True,
              stop_goal: None,
              sync_dict: None,
              sync_manager: None,
            logger: None,
            logger_name: 'text'
          instance(BVATensorboardLoggingCallback):
            bva_callback: instance(BVACallback):
              agent: None,
              episode_values: deque([], maxlen=1000),
              episode_values_synchronizer: None,
              epoch_history: [],
              num_of_episodes_for_average: 1000,
              own_sync_manager: False,
              smart_init: 0.47111710906028753,
              sort_episodes: True,
              stop_goal: None,
              sync_dict: None,
              sync_manager: None,
            logger: None,
            logger_name: 'tensorboard'
          instance(CheckpointCallback):
            bva_before: 0,
            bva_callback: instance(BVACallback):
              agent: None,
              episode_values: deque([], maxlen=1000),
              episode_values_synchronizer: None,
              epoch_history: [],
              num_of_episodes_for_average: 1000,
              own_sync_manager: False,
              smart_init: 0.47111710906028753,
              sort_episodes: True,
              stop_goal: None,
              sync_dict: None,
              sync_manager: None,
            latest_approximator: None,
            load_epoch: None,
            load_experiment: None,
            load_seed: True,
            nn_state_before: None,
            orchestrator: None,
            output_dir: None,
            own_sync_manager: False,
            random_seed_dict: None,
            save_rate: 100,
            sync_dict: None,
            sync_manager: None
          instance(PolicyRevenueCallback):
            agent: None,
            confidence: 0.99,
            dump_path: '',
            dump_trajectories: False,
            episode_values: None,
            episode_values_synchronizer: None,
            length_factor: 10,
            long_simulation_rate: 100,
            num_of_agents: 0,
            num_of_evaluation_agents: 0,
            orchestrator: None,
            own_sync_manager: False,
            policy_revenue: 0,
            policy_revenue_confidence_radius: 0,
            policy_test_revenue: 0,
            policy_test_revenue_confidence_radius: 0,
            repeats: 1,
            sync_dict: None,
            sync_manager: None,
            test_episode_values: None,
            test_episode_values_synchronizer: None
          instance(PolicyRevenueTextLoggingCallback):
            logger: None,
            logger_name: 'text',
            policy_revenue_callback: instance(PolicyRevenueCallback):
              agent: None,
              confidence: 0.99,
              dump_path: '',
              dump_trajectories: False,
              episode_values: None,
              episode_values_synchronizer: None,
              length_factor: 10,
              long_simulation_rate: 100,
              num_of_agents: 0,
              num_of_evaluation_agents: 0,
              orchestrator: None,
              own_sync_manager: False,
              policy_revenue: 0,
              policy_revenue_confidence_radius: 0,
              policy_test_revenue: 0,
              policy_test_revenue_confidence_radius: 0,
              repeats: 1,
              sync_dict: None,
              sync_manager: None,
              test_episode_values: None,
              test_episode_values_synchronizer: None
          instance(PolicyRevenueTensorboardLoggingCallback):
            logger: None,
            logger_name: 'tensorboard',
            policy_revenue_callback: instance(PolicyRevenueCallback):
              agent: None,
              confidence: 0.99,
              dump_path: '',
              dump_trajectories: False,
              episode_values: None,
              episode_values_synchronizer: None,
              length_factor: 10,
              long_simulation_rate: 100,
              num_of_agents: 0,
              num_of_evaluation_agents: 0,
              orchestrator: None,
              own_sync_manager: False,
              policy_revenue: 0,
              policy_revenue_confidence_radius: 0,
              policy_test_revenue: 0,
              policy_test_revenue_confidence_radius: 0,
              repeats: 1,
              sync_dict: None,
              sync_manager: None,
              test_episode_values: None,
              test_episode_values_synchronizer: None
        )
      instance(MCTSTensorboardLoggingCallback):
        agent: None,
        logger: None,
        logger_name: 'tensorboard',
        max_num_of_agents: 5,
        orchestrator: None
    ),
  creation_args: {
    'bva_smart_init': 0.47111710906028753,
    'depth': 5,
    'device': device(type='cpu')
    'dropout': 0,
    'epsilon_step': 0,
    'ground_initial_state': False,
    'length_factor': 10,
    'lr_decay_epoch': 1000,
    'mc_simulations': 25,
    'nn_factor': 0.0001,
    'normalize_target_values': True,
    'num_of_episodes_for_average': 1000,
    'prune_tree_rate': 250,
    'simulator': instance(MDPBlockchainSimulator):
      action_space: instance(MultiDimensionalDiscreteSpace):
        dimension: 2,
        intervals: [
          instance(Interval):
            boundaries: (0, 3),
            enum: class(Action):
              Adopt: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Adopt',
                numerator: 1,
                real: 1,
                value: 1,
              Illegal: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Illegal',
                numerator: 0,
                real: 0,
                value: 0,
              Mine: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Mine',
                numerator: 3,
                real: 3,
                value: 3,
              Reveal: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Reveal',
                numerator: 2,
                real: 2,
                value: 2,
            size: 4
          instance(Interval):
            boundaries: (0, 10),
            enum: None,
            size: 11
        ],
        size: 44,
      check_valid_states: False,
      device: device(type='cpu'),
      expected_horizon: 10000,
      final_state: (
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Fork):
          denominator: 1,
          imag: 0,
          name: 'Irrelevant',
          numerator: 0,
          real: 0,
          value: 0
        -1,
        -1,
        -1,
        -1,
        -1,
      ),
      include_transition_info: True,
      initial_state: (
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Fork):
          denominator: 1,
          imag: 0,
          name: 'Irrelevant',
          numerator: 0,
          real: 0,
          value: 0
        0,
        0,
        0,
        0,
        0,
      ),
      num_of_actions: 44,
      num_of_states: 531232341494857729,
      state_space: instance(DefaultValueSpace):
        default_value: (
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Fork):
            denominator: 1,
            imag: 0,
            name: 'Irrelevant',
            numerator: 0,
            real: 0,
            value: 0
          -1,
          -1,
          -1,
          -1,
          -1,
        ),
        dimension: 46,
        size: 531232341494857729,
        underlying_space: instance(MultiDimensionalDiscreteSpace):
          dimension: 46,
          intervals: [
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 2),
              enum: class(Fork):
                Active: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Active',
                  numerator: 2,
                  real: 2,
                  value: 2,
                Irrelevant: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Irrelevant',
                  numerator: 0,
                  real: 0,
                  value: 0,
                Relevant: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Relevant',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 3
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
          ],
          size: 531232341494857728,
      state_space_dim: 46
    'starting_epsilon': 0.05,
    'use_base_approximation': True,
    'use_cached_values': False,
  },
  episode_reset_rate: 10,
  episode_synchronizer: {'type': 'BufferSynchronizer', 'target_buffer': <reinforcement_learning.base.utility.dummy_buffer.DummyBuffer object at 0x000001E1EF105760>},
  epoch_length: 1000,
  epoch_size: 2000,
  evaluate_episode_length: 100,
  expected_horizon: 10000,
  experiment_name: 'BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                    10)_20240425-083418',
  learning_rate: 0.0002,
  loggers: {
    'tensorboard': instance(SynchronizedLogger):
      base_logger: instance(TensorboardLogger):
        flush_secs: 15,
        hparam_dict: {
        },
        hparam_domain_discrete: {
        },
        layout: {
        },
        metric_dict: {
        },
        output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                     10)_20240425-083418',
        started_logging: False,
        tensorboard_writer: instance(SummaryWriter):
          all_writers: {
            'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01, 10)_20240425-083418': instance(FileWriter):
              event_writer: instance(EventFileWriter)
          },
          default_bins: [-9.920775621859783e+19, -9.018886928963438e+19, -8.198988117239489e+19, -7.453625561126807e+19, -6.776023237388005e+19, -6.160021124898186e+19, -5.600019204452896e+19, -5.090926549502632e+19, -4.628115045002392e+19, -4.2073773136385384e+19, -3.824888466944125e+19, -3.477171333585568e+19, -3.1610648487141528e+19, -2.873695317012866e+19, -2.6124502881935143e+19, -2.3749548074486493e+19, -2.1590498249533174e+19, -1.962772568139379e+19, -1.7843386983085265e+19, -1.6221260893713875e+19, -1.4746600812467157e+19, -1.3406000738606506e+19, -1.2187273398733187e+19, -1.1079339453393805e+19, -1.0072126775812549e+19, -9.156478887102316e+18, -8.324071715547559e+18, -7.567337923225053e+18, -6.879398112022775e+18, -6.253998283657068e+18, -5.685452985142788e+18, -5.16859362285708e+18, -4.698721475324618e+18, -4.271564977567834e+18, -3.8832408886980306e+18, -3.530218989725482e+18, -3.2092899906595287e+18, -2.917536355145026e+18, -2.652305777404569e+18, -2.41118707036779e+18, -2.1919882457888998e+18, -1.992716587080818e+18, -1.8115605337098342e+18, -1.6468732124634854e+18, -1.4971574658758958e+18, -1.3610522417053596e+18, -1.237320219732145e+18, -1.1248365633928589e+18, -1.022578693993508e+18, -9.296169945395526e+17, -8.451063586723205e+17, -7.682785078839277e+17, -6.984350071672069e+17, -6.349409156065517e+17, -5.772190141877742e+17, -5.247445583525219e+17, -4.770405075932017e+17, -4.336731887210924e+17, -3.9424835338281126e+17, -3.584075939843738e+17, -3.2582508544033984e+17, -2.9620462312758163e+17, -2.6927693011598326e+17, -2.447972091963484e+17, -2.2254291745122582e+17, -2.02311743137478e+17, -1.8391976648861635e+17, -1.6719978771692394e+17, -1.5199980701538538e+17, -1.3818164274125942e+17, -1.2561967521932674e+17, -1.1419970474484248e+17, -1.0381791340440224e+17, -9.43799212767293e+16, -8.579992843339026e+16, -7.799993493944568e+16, -7.090903176313243e+16, -6.446275614830221e+16, -5.860250558936564e+16, -5.327500508124149e+16, -4.843182280112862e+16, -4.402892981920784e+16, -4.002629983564349e+16, -3.638754530513044e+16, -3.3079586641027668e+16, -3.0072351491843332e+16, -2.733850135622121e+16, -2.4853183051110188e+16, -2.2593802773736532e+16, -2.0539820703396844e+16, -1.867256427581531e+16, -1.6975058432559372e+16, -1.54318713023267e+16, -1.402897391120609e+16, -1.275361264655099e+16, -1.1594193315046354e+16, -1.054017574095123e+16, -9581977946319300.0, -8710889042108454.0, -7918990038280412.0, -7199081852982192.0, -6544619866347447.0, -5949654423952224.0, -5408776749047476.0, -4917069771861341.0, -4470063428964855.0, -4063694026331686.0, -3694267296665169.0, -3358424815150153.5, -3053113468318321.0, -2775557698471200.5, -2523234271337455.0, -2293849337579504.5, -2085317579617731.2, -1895743254197937.2, -1723402958361761.0, -1566729962147055.2, -1424299965588232.0, -1294818150534756.2, -1177107409577051.0, -1070097645070046.2, -972816040972769.2, -884378219066153.8, -803980199151048.8, -730891090137317.0, -664446445579379.0, -604042223253980.9, -549129293867255.25, -499208448970232.0, -453825862700210.9, -412568966091100.75, -375062696446455.2, -340966087678595.6, -309969170616905.06, -281790155106277.3, -256172868278433.9, -232884425707667.16, -211713114279697.4, -192466467526997.62, -174969515933634.2, -159063196303303.78, -144602905730276.16, -131457187027523.78, -119506533661385.25, -108642303328532.03, -98765730298665.47, -89787027544241.33, -81624570494764.84, -74204154995240.77, -67458322722946.15, -61325747929951.04, -55750679936319.125, -50682436305744.66, -46074942096131.5, -41886310996483.18, -38078464542257.43, -34616785947506.754, -31469805406824.32, -28608914006203.926, -26008103642003.566, -23643730583639.605, -21494300530581.457, -19540273209619.504, -17763884736017.73, -16148986123652.482, -14680896476047.71, -13346269523679.736, -12132972294254.305, -11029974812958.457, -10027249829962.232, -9115681663602.03, -8286983330547.298, -7533621209588.452, -6848746554171.319, -6226133231064.835, -5660121119149.85, -5145564653772.59, -4677786048884.172, -4252532771712.8833, -3865938883375.348, -3514489893977.589, -3194990812706.899, -2904537102460.817, -2640488274964.379, -2400443886331.2534, -2182221714846.594, -1983837922587.8125, -1803489020534.3748, -1639535473213.0679, -1490486793830.0615, -1354987994390.9648, -1231807267628.1497, -1119824788752.8633, -1018022535229.8757, -925475032027.1597, -841340938206.5087, -764855398369.5532, -695323089426.8665, -632111899478.9695, -574647181344.5177, -522406528495.01605, -474915025904.56, -431740932640.50903, -392491756945.9173, -356810688132.65204, -324373352847.8655, -294884866225.3322, -268077151113.93835, -243706501012.6712, -221551364556.97382, -201410331415.43073, -183100301286.7552, -166454819351.5956, -151322563046.9051, -137565966406.27734, -125059969460.25212, -113690881327.50192, -103355346661.36537, -93959406055.7867, -85417641868.89699, -77652401698.99725, -70593092453.63387, -64175538594.21259, -58341398722.011444, -53037635201.82858, -48216032001.662346, -43832756365.14758, -39847960331.95235, -36225418483.59304, -32932198621.448215, -29938362383.13474, -27216693075.577034, -24742448250.524574, -22493134773.204155, -20448304339.276505, -18589367581.160458, -16899425073.782234, -15363113703.438393, -13966467003.12581, -12696788184.659826, -11542534713.327114, -10493213375.75192, -9539284887.0472, -8672077170.042908, -7883706518.220825, -7167005925.655295, -6515459932.413904, -5923145393.103549, -5384677630.094135, -4895161481.903759, -4450146801.73069, -4045588001.5733542, -3677807274.1575947, -3343461158.3250856, -3039510143.9318957, -2763191039.938087, -2511991854.4891696, -2283628958.626518, -2076026326.0241067, -1887296660.021915, -1715724236.383559, -1559749305.8032353, -1417953914.3665774, -1289049013.0605247, -1171862739.1459315, -1065329762.8599375, -968481602.5999432, -880437820.5454028, -800398018.6776388, -727634562.434217, -661485965.8492881, -601350878.0448073, -546682616.4043702, -496984196.7312456, -451803815.2102232, -410730741.10020286, -373391582.8183662, -339446893.471242, -308588084.97385633, -280534622.70350575, -255031475.1850052, -231846795.62273198, -210769814.2024836, -191608922.0022578, -174189929.0929616, -158354480.99360144, -143958619.08509222, -130871471.89553836, -118974065.35958032, -108158241.2359821, -98325673.85089281, -89386976.22808437, -81260887.4800767, -73873534.072797, -67157758.24799727, -61052507.49817933, -55502279.543799385, -50456617.76709034, -45869652.51553667, -41699684.10503334, -37908803.731848486, -34462548.847134985, -31329589.861031804, -28481445.32821073, -25892223.025646117, -23538384.568769194, -21398531.426153813, -19453210.387412556, -17684736.715829596, -16077033.378026905, -14615484.889115367, -13286804.444650333, -12078913.131500302, -10980830.119545728, -9982572.835950661, -9075066.2145006, -8250060.195000546, -7500054.722727768, -6818231.566116152, -6198392.332832865, -5634902.1207571495, -5122638.291597408, -4656943.901452189, -4233585.364956535, -3848713.9681423046, -3498830.8801293676, -3180755.345572152, -2891595.768701956, -2628723.426092687, -2389748.56917517, -2172498.699250154, -1974998.81750014, -1795453.4704546726, -1632230.427686066, -1483845.8433509688, -1348950.7666826989, -1226318.8788024534, -1114835.3443658666, -1013486.6766962423, -921351.5242693111, -837592.2947902827, -761447.5407184388, -692225.0370167625, -629295.4881970568, -572086.8074518698, -520078.91586533614, -472799.0144230328, -429817.2858391207, -390742.98712647334, -355220.897387703, -322928.0885342754, -293570.989576614, -266882.7177969218, -242620.65254265617, -220564.22958423287, -200512.93598566623, -182284.48725969656, -165713.17023608775, -150648.33657826157, -136953.03325296505, -124502.75750269549, -113184.32500245044, -102894.84091131858, -93540.76446483507, -85037.05860439551, -77306.41691308682, -70278.56083007893, -63889.60075461721, -58081.45523147019, -52801.32293770016, -48001.20267063651, -43637.45697330591, -39670.415430278095, -36064.01402752554, -32785.46729775049, -29804.97027068226, -27095.427518802055, -24632.206835274592, -22392.915304795082, -20357.19573163189, -18506.54157421081, -16824.128703828006, -15294.66245802546, -13904.238598204962, -12640.216907459055, -11491.10627950823, -10446.46025409839, -9496.782049180354, -8633.438226527594, -7848.580205934176, -7135.072914485614, -6486.429922259648, -5896.754474781498, -5360.685886164998, -4873.350805604543, -4430.3189141859475, -4027.5626492599517, -3661.4205902363196, -3328.5641729421086, -3025.9674299473713, -2750.8794817703374, -2500.799528882125, -2273.454117165568, -2066.776470150516, -1878.8877001368326, -1708.0797273971205, -1552.7997521792004, -1411.6361383447274, -1283.3055803133884, -1166.6414366485349, -1060.5831242259408, -964.166476569037, -876.5149786991244, -796.8317988173858, -724.3925443794416, -658.5386767085832, -598.6715242805302, -544.2468402550275, -494.76985477729767, -449.79077707027056, -408.9007064275187, -371.72791493410784, -337.9344681219162, -307.2131528381056, -279.2846843982778, -253.89516763479799, -230.81378875890724, -209.830717053552, -190.7551973214109, -173.41381574673716, -157.64892340612468, -143.31720309647696, -130.28836645134268, -118.44396950122061, -107.67633591020055, -97.88757810018231, -88.98870736380209, -80.89882487618371, -73.54438625107609, -66.85853295552371, -60.78048450502155, -55.25498591365595, -50.23180537605086, -45.66527761459169, -41.513888740537894, -37.73989885503445, -34.30899895912222, -31.18999905374747, -28.35454459431588, -25.77685872210534, -23.43350792918667, -21.303189026533335, -19.366535478666666, -17.60594134424242, -16.005401222038564, -14.550364747307786, -13.22760431573435, -12.025094832485772, -10.931904393168884, -9.938094902880803, -9.034631729891638, -8.213301572628762, -7.466637793298873, -6.7878525393626115, -6.1707750357841915, -5.609795487076537, -5.099814079160488, -4.636194617418625, -4.214722379471477, -3.8315657995195243, -3.48324163592684, -3.1665833053880363, -2.8787120958073054, -2.6170109961884593, -2.379100905625872, -2.1628190051144287, -1.9661990955585713, -1.7874537232350647, -1.624957930213695, -1.47723448201245, -1.3429404381931362, -1.220854943811942, -1.109868130738129, -1.0089710279437536, -0.917246389039776, -0.8338603536725235, -0.7580548669750213, -0.6891407881591103, -0.6264916255991911, -0.56953784145381, -0.5177616740489182, -0.47069243095356195, -0.42790220995778355, -0.38900200905253046, -0.35363819004775493, -0.3214892636797772, -0.29226296698161564, -0.2656936063469233, -0.24153964213356663, -0.2195814928486969, -0.19961953895336082, -0.18147230813941892, -0.16497482558128992, -0.14997711416480902, -0.13634283105891729, -0.12394802823537933, -0.11268002566852665, -0.10243638697138786, -0.09312398815580714, -0.08465817105073375, -0.07696197368248522, -0.06996543062044111, -0.06360493692767373, -0.057822669934248845, -0.052566063576589855, -0.04778733052417259, -0.043443027749247805, -0.03949366159022527, -0.035903328718386605, -0.03263938974398782, -0.02967217249453438, -0.026974702267758523, -0.0245224566070532, -0.022293142370048362, -0.02026649306368033, -0.018424084603345752, -0.01674916782122341, -0.01522651620111219, -0.013842287455556535, -0.012583897686869577, -0.01143990698806325, -0.010399915443693864, -0.00945446858517624, -0.008594971441069308, -0.007813610400972098, -0.007103282182701907, -0.006457529257001733, -0.005870481142728848, -0.005336801038844407, -0.00485163730804037, -0.00441057937094579, -0.004009617609950718, -0.0036451069181370156, -0.003313733561942741, -0.0030124850563115826, -0.002738622778465075, -0.0024896570713318863, -0.0022633246103017147, -0.0020575678275470133, -0.001870516206860921, -0.0017004692789644735, -0.0015458811626949758, -0.001405346511540887, -0.0012775877377644426, -0.001161443397967675, -0.001055857634516068, -0.0009598705768327891, -0.0008726096153025355, -0.0007932814684568504, -0.0007211649713244094, -0.0006556045193858267, -0.0005960041085325697, -0.0005418219168477906, -0.0004925653789525368, -0.0004477867081386698, -0.0004070788255806089, -0.0003700716596187353, -0.00033642878147157755, -0.0003058443467923432, -0.0002780403152657665, -0.00025276392296887866, -0.0002297853845171624, -0.00020889580410651126, -0.00018990527646046477, -0.00017264116041860433, -0.00015694650947145847, -0.00014267864497405315, -0.00012970785906732103, -0.00011791623551574639, -0.00010719657774158762, -9.745143431053419e-05, -8.859221300957652e-05, -8.053837546325138e-05, -7.321670496659217e-05, -6.656064087872014e-05, -6.050967352610922e-05, -5.500879411464474e-05, -5.000799464967703e-05, -4.546181331788821e-05, -4.132892119808019e-05, -3.757174654370926e-05, -3.415613322155387e-05, -3.1051030201412604e-05, -2.822820927401146e-05, -2.5662008430919505e-05, -2.3329098573563184e-05, -2.1208271430511985e-05, -1.9280246755010893e-05, -1.7527497050009902e-05, -1.593408822728173e-05, -1.44855347520743e-05, -1.316866795643118e-05, -1.1971516324028345e-05, -1.0883196658207586e-05, -9.893815143825077e-06, -8.994377403477343e-06, -8.176706730433948e-06, -7.4333697549399525e-06, -6.757608868127229e-06, -6.143280789206572e-06, -5.584800717460519e-06, -5.077091561327744e-06, -4.615537783025222e-06, -4.1959434391138375e-06, -3.8144940355580335e-06, -3.467721850507303e-06, -3.1524744095520932e-06, -2.865885826865539e-06, -2.605350751695944e-06, -2.368500683359949e-06, -2.153182439418135e-06, -1.9574385812892137e-06, -1.7794896193538304e-06, -1.6177178357762093e-06, -1.470652577978372e-06, -1.3369568890712472e-06, -1.2154153537011338e-06, -1.1049230488192125e-06, -1.0044754989265568e-06, -9.131595444786879e-07, -8.301450404351707e-07, -7.546773094865188e-07, -6.860702813513807e-07, -6.237002557739824e-07, -5.670002325218022e-07, -5.15454756838002e-07, -4.6859523348909267e-07, -4.2599566680826603e-07, -3.8726878800751456e-07, -3.5206253455228594e-07, -3.200568495929872e-07, -2.909607723572611e-07, -2.645097930520555e-07, -2.4046344822914135e-07, -2.1860313475376482e-07, -1.9873012250342254e-07, -1.8066374773038411e-07, -1.6423977066398553e-07, -1.4930888242180502e-07, -1.3573534765618637e-07, -1.2339577059653305e-07, -1.1217797326957548e-07, -1.0197997569961407e-07, -9.270906881783097e-08, -8.42809716525736e-08, -7.661906513870326e-08, -6.965369558063933e-08, -6.332154143694484e-08, -5.756503766994985e-08, -5.2331852427227134e-08, -4.757441129747921e-08, -4.324946481589019e-08, -3.9317695287172896e-08, -3.574335935197536e-08, -3.249396304725032e-08, -2.95399664065912e-08, -2.6854514915082908e-08, -2.4413195377348097e-08, -2.219381397940736e-08, -2.017619452673396e-08, -1.83419950243036e-08, -1.667454093118509e-08, -1.5158673573804625e-08, -1.3780612339822385e-08, -1.2527829399838531e-08, -1.1388935818035027e-08, -1.0353578016395478e-08, -9.412343651268615e-09, -8.556676046607832e-09, -7.778796406007119e-09, -7.071633096370107e-09, -6.428757360336461e-09, -5.8443248730331455e-09, -5.313022611848313e-09, -4.830020556225739e-09, -4.390927778387036e-09, -3.991752525806396e-09, -3.628865932551268e-09, -3.2989690295920617e-09, -2.9990627541746013e-09, -2.7264206856132736e-09, -2.47856425964843e-09, -2.253240236044027e-09, -2.048400214585479e-09, -1.8621820132595262e-09, -1.6928927393268418e-09, -1.5389933993880379e-09, -1.3990849085345797e-09, -1.2718953713950723e-09, -1.1562685194500657e-09, -1.0511531995000597e-09, -9.55593817727327e-10, -8.68721652479388e-10, -7.897469567994436e-10, -7.179517789085851e-10, -6.52683435371441e-10, -5.933485776104008e-10, -5.394077978276371e-10, -4.903707252978519e-10, -4.4579156845259254e-10, -4.0526506222962957e-10, -3.684227838451178e-10, -3.349298034955616e-10, -3.0448163954141963e-10, -2.7680149049219964e-10, -2.516377186292724e-10, -2.287615623902476e-10, -2.079650567184069e-10, -1.89059142471279e-10, -1.718719477011627e-10, -1.5624722518287518e-10, -1.4204293198443196e-10, -1.291299381676654e-10, -1.173908528796958e-10, -1.067189571633598e-10, -9.701723378487254e-11, -8.819748525897503e-11, -8.017953205361366e-11, -7.289048368510333e-11, -6.626407607736665e-11, -6.02400691612424e-11, -5.4763699237493095e-11, -4.978518112499372e-11, -4.5259255568176104e-11, -4.1144777789251e-11, -3.7404343444773633e-11, -3.400394858615785e-11, -3.091268053287077e-11, -2.8102436848064334e-11, -2.5547669861876665e-11, -2.3225154419887876e-11, -2.111377674535261e-11, -1.91943424957751e-11, -1.7449402268886454e-11, -1.5863092971714956e-11, -1.4420993610649957e-11, -1.310999419149996e-11, -1.1918176537727236e-11, -1.0834705943388396e-11, -9.849732675807632e-12, -8.954302432552392e-12, -8.140274938683992e-12, -7.400249944258175e-12, -6.727499949325613e-12, -6.115909044841466e-12, -5.559917313492241e-12, -5.054470284992946e-12, -4.594972986357223e-12, -4.177248169415657e-12, -3.797498335832415e-12, -3.452271214393104e-12, -3.1384283767210032e-12, -2.8531167061100027e-12, -2.593742460100002e-12, -2.357947691000002e-12, -2.1435888100000016e-12, -1.9487171000000014e-12, -1.771561000000001e-12, -1.6105100000000008e-12, -1.4641000000000006e-12, -1.3310000000000005e-12, -1.2100000000000003e-12, -1.1000000000000002e-12, -1e-12, 0, 1e-12, 1.1000000000000002e-12, 1.2100000000000003e-12, 1.3310000000000005e-12, 1.4641000000000006e-12, 1.6105100000000008e-12, 1.771561000000001e-12, 1.9487171000000014e-12, 2.1435888100000016e-12, 2.357947691000002e-12, 2.593742460100002e-12, 2.8531167061100027e-12, 3.1384283767210032e-12, 3.452271214393104e-12, 3.797498335832415e-12, 4.177248169415657e-12, 4.594972986357223e-12, 5.054470284992946e-12, 5.559917313492241e-12, 6.115909044841466e-12, 6.727499949325613e-12, 7.400249944258175e-12, 8.140274938683992e-12, 8.954302432552392e-12, 9.849732675807632e-12, 1.0834705943388396e-11, 1.1918176537727236e-11, 1.310999419149996e-11, 1.4420993610649957e-11, 1.5863092971714956e-11, 1.7449402268886454e-11, 1.91943424957751e-11, 2.111377674535261e-11, 2.3225154419887876e-11, 2.5547669861876665e-11, 2.8102436848064334e-11, 3.091268053287077e-11, 3.400394858615785e-11, 3.7404343444773633e-11, 4.1144777789251e-11, 4.5259255568176104e-11, 4.978518112499372e-11, 5.4763699237493095e-11, 6.02400691612424e-11, 6.626407607736665e-11, 7.289048368510333e-11, 8.017953205361366e-11, 8.819748525897503e-11, 9.701723378487254e-11, 1.067189571633598e-10, 1.173908528796958e-10, 1.291299381676654e-10, 1.4204293198443196e-10, 1.5624722518287518e-10, 1.718719477011627e-10, 1.89059142471279e-10, 2.079650567184069e-10, 2.287615623902476e-10, 2.516377186292724e-10, 2.7680149049219964e-10, 3.0448163954141963e-10, 3.349298034955616e-10, 3.684227838451178e-10, 4.0526506222962957e-10, 4.4579156845259254e-10, 4.903707252978519e-10, 5.394077978276371e-10, 5.933485776104008e-10, 6.52683435371441e-10, 7.179517789085851e-10, 7.897469567994436e-10, 8.68721652479388e-10, 9.55593817727327e-10, 1.0511531995000597e-09, 1.1562685194500657e-09, 1.2718953713950723e-09, 1.3990849085345797e-09, 1.5389933993880379e-09, 1.6928927393268418e-09, 1.8621820132595262e-09, 2.048400214585479e-09, 2.253240236044027e-09, 2.47856425964843e-09, 2.7264206856132736e-09, 2.9990627541746013e-09, 3.2989690295920617e-09, 3.628865932551268e-09, 3.991752525806396e-09, 4.390927778387036e-09, 4.830020556225739e-09, 5.313022611848313e-09, 5.8443248730331455e-09, 6.428757360336461e-09, 7.071633096370107e-09, 7.778796406007119e-09, 8.556676046607832e-09, 9.412343651268615e-09, 1.0353578016395478e-08, 1.1388935818035027e-08, 1.2527829399838531e-08, 1.3780612339822385e-08, 1.5158673573804625e-08, 1.667454093118509e-08, 1.83419950243036e-08, 2.017619452673396e-08, 2.219381397940736e-08, 2.4413195377348097e-08, 2.6854514915082908e-08, 2.95399664065912e-08, 3.249396304725032e-08, 3.574335935197536e-08, 3.9317695287172896e-08, 4.324946481589019e-08, 4.757441129747921e-08, 5.2331852427227134e-08, 5.756503766994985e-08, 6.332154143694484e-08, 6.965369558063933e-08, 7.661906513870326e-08, 8.42809716525736e-08, 9.270906881783097e-08, 1.0197997569961407e-07, 1.1217797326957548e-07, 1.2339577059653305e-07, 1.3573534765618637e-07, 1.4930888242180502e-07, 1.6423977066398553e-07, 1.8066374773038411e-07, 1.9873012250342254e-07, 2.1860313475376482e-07, 2.4046344822914135e-07, 2.645097930520555e-07, 2.909607723572611e-07, 3.200568495929872e-07, 3.5206253455228594e-07, 3.8726878800751456e-07, 4.2599566680826603e-07, 4.6859523348909267e-07, 5.15454756838002e-07, 5.670002325218022e-07, 6.237002557739824e-07, 6.860702813513807e-07, 7.546773094865188e-07, 8.301450404351707e-07, 9.131595444786879e-07, 1.0044754989265568e-06, 1.1049230488192125e-06, 1.2154153537011338e-06, 1.3369568890712472e-06, 1.470652577978372e-06, 1.6177178357762093e-06, 1.7794896193538304e-06, 1.9574385812892137e-06, 2.153182439418135e-06, 2.368500683359949e-06, 2.605350751695944e-06, 2.865885826865539e-06, 3.1524744095520932e-06, 3.467721850507303e-06, 3.8144940355580335e-06, 4.1959434391138375e-06, 4.615537783025222e-06, 5.077091561327744e-06, 5.584800717460519e-06, 6.143280789206572e-06, 6.757608868127229e-06, 7.4333697549399525e-06, 8.176706730433948e-06, 8.994377403477343e-06, 9.893815143825077e-06, 1.0883196658207586e-05, 1.1971516324028345e-05, 1.316866795643118e-05, 1.44855347520743e-05, 1.593408822728173e-05, 1.7527497050009902e-05, 1.9280246755010893e-05, 2.1208271430511985e-05, 2.3329098573563184e-05, 2.5662008430919505e-05, 2.822820927401146e-05, 3.1051030201412604e-05, 3.415613322155387e-05, 3.757174654370926e-05, 4.132892119808019e-05, 4.546181331788821e-05, 5.000799464967703e-05, 5.500879411464474e-05, 6.050967352610922e-05, 6.656064087872014e-05, 7.321670496659217e-05, 8.053837546325138e-05, 8.859221300957652e-05, 9.745143431053419e-05, 0.00010719657774158762, 0.00011791623551574639, 0.00012970785906732103, 0.00014267864497405315, 0.00015694650947145847, 0.00017264116041860433, 0.00018990527646046477, 0.00020889580410651126, 0.0002297853845171624, 0.00025276392296887866, 0.0002780403152657665, 0.0003058443467923432, 0.00033642878147157755, 0.0003700716596187353, 0.0004070788255806089, 0.0004477867081386698, 0.0004925653789525368, 0.0005418219168477906, 0.0005960041085325697, 0.0006556045193858267, 0.0007211649713244094, 0.0007932814684568504, 0.0008726096153025355, 0.0009598705768327891, 0.001055857634516068, 0.001161443397967675, 0.0012775877377644426, 0.001405346511540887, 0.0015458811626949758, 0.0017004692789644735, 0.001870516206860921, 0.0020575678275470133, 0.0022633246103017147, 0.0024896570713318863, 0.002738622778465075, 0.0030124850563115826, 0.003313733561942741, 0.0036451069181370156, 0.004009617609950718, 0.00441057937094579, 0.00485163730804037, 0.005336801038844407, 0.005870481142728848, 0.006457529257001733, 0.007103282182701907, 0.007813610400972098, 0.008594971441069308, 0.00945446858517624, 0.010399915443693864, 0.01143990698806325, 0.012583897686869577, 0.013842287455556535, 0.01522651620111219, 0.01674916782122341, 0.018424084603345752, 0.02026649306368033, 0.022293142370048362, 0.0245224566070532, 0.026974702267758523, 0.02967217249453438, 0.03263938974398782, 0.035903328718386605, 0.03949366159022527, 0.043443027749247805, 0.04778733052417259, 0.052566063576589855, 0.057822669934248845, 0.06360493692767373, 0.06996543062044111, 0.07696197368248522, 0.08465817105073375, 0.09312398815580714, 0.10243638697138786, 0.11268002566852665, 0.12394802823537933, 0.13634283105891729, 0.14997711416480902, 0.16497482558128992, 0.18147230813941892, 0.19961953895336082, 0.2195814928486969, 0.24153964213356663, 0.2656936063469233, 0.29226296698161564, 0.3214892636797772, 0.35363819004775493, 0.38900200905253046, 0.42790220995778355, 0.47069243095356195, 0.5177616740489182, 0.56953784145381, 0.6264916255991911, 0.6891407881591103, 0.7580548669750213, 0.8338603536725235, 0.917246389039776, 1.0089710279437536, 1.109868130738129, 1.220854943811942, 1.3429404381931362, 1.47723448201245, 1.624957930213695, 1.7874537232350647, 1.9661990955585713, 2.1628190051144287, 2.379100905625872, 2.6170109961884593, 2.8787120958073054, 3.1665833053880363, 3.48324163592684, 3.8315657995195243, 4.214722379471477, 4.636194617418625, 5.099814079160488, 5.609795487076537, 6.1707750357841915, 6.7878525393626115, 7.466637793298873, 8.213301572628762, 9.034631729891638, 9.938094902880803, 10.931904393168884, 12.025094832485772, 13.22760431573435, 14.550364747307786, 16.005401222038564, 17.60594134424242, 19.366535478666666, 21.303189026533335, 23.43350792918667, 25.77685872210534, 28.35454459431588, 31.18999905374747, 34.30899895912222, 37.73989885503445, 41.513888740537894, 45.66527761459169, 50.23180537605086, 55.25498591365595, 60.78048450502155, 66.85853295552371, 73.54438625107609, 80.89882487618371, 88.98870736380209, 97.88757810018231, 107.67633591020055, 118.44396950122061, 130.28836645134268, 143.31720309647696, 157.64892340612468, 173.41381574673716, 190.7551973214109, 209.830717053552, 230.81378875890724, 253.89516763479799, 279.2846843982778, 307.2131528381056, 337.9344681219162, 371.72791493410784, 408.9007064275187, 449.79077707027056, 494.76985477729767, 544.2468402550275, 598.6715242805302, 658.5386767085832, 724.3925443794416, 796.8317988173858, 876.5149786991244, 964.166476569037, 1060.5831242259408, 1166.6414366485349, 1283.3055803133884, 1411.6361383447274, 1552.7997521792004, 1708.0797273971205, 1878.8877001368326, 2066.776470150516, 2273.454117165568, 2500.799528882125, 2750.8794817703374, 3025.9674299473713, 3328.5641729421086, 3661.4205902363196, 4027.5626492599517, 4430.3189141859475, 4873.350805604543, 5360.685886164998, 5896.754474781498, 6486.429922259648, 7135.072914485614, 7848.580205934176, 8633.438226527594, 9496.782049180354, 10446.46025409839, 11491.10627950823, 12640.216907459055, 13904.238598204962, 15294.66245802546, 16824.128703828006, 18506.54157421081, 20357.19573163189, 22392.915304795082, 24632.206835274592, 27095.427518802055, 29804.97027068226, 32785.46729775049, 36064.01402752554, 39670.415430278095, 43637.45697330591, 48001.20267063651, 52801.32293770016, 58081.45523147019, 63889.60075461721, 70278.56083007893, 77306.41691308682, 85037.05860439551, 93540.76446483507, 102894.84091131858, 113184.32500245044, 124502.75750269549, 136953.03325296505, 150648.33657826157, 165713.17023608775, 182284.48725969656, 200512.93598566623, 220564.22958423287, 242620.65254265617, 266882.7177969218, 293570.989576614, 322928.0885342754, 355220.897387703, 390742.98712647334, 429817.2858391207, 472799.0144230328, 520078.91586533614, 572086.8074518698, 629295.4881970568, 692225.0370167625, 761447.5407184388, 837592.2947902827, 921351.5242693111, 1013486.6766962423, 1114835.3443658666, 1226318.8788024534, 1348950.7666826989, 1483845.8433509688, 1632230.427686066, 1795453.4704546726, 1974998.81750014, 2172498.699250154, 2389748.56917517, 2628723.426092687, 2891595.768701956, 3180755.345572152, 3498830.8801293676, 3848713.9681423046, 4233585.364956535, 4656943.901452189, 5122638.291597408, 5634902.1207571495, 6198392.332832865, 6818231.566116152, 7500054.722727768, 8250060.195000546, 9075066.2145006, 9982572.835950661, 10980830.119545728, 12078913.131500302, 13286804.444650333, 14615484.889115367, 16077033.378026905, 17684736.715829596, 19453210.387412556, 21398531.426153813, 23538384.568769194, 25892223.025646117, 28481445.32821073, 31329589.861031804, 34462548.847134985, 37908803.731848486, 41699684.10503334, 45869652.51553667, 50456617.76709034, 55502279.543799385, 61052507.49817933, 67157758.24799727, 73873534.072797, 81260887.4800767, 89386976.22808437, 98325673.85089281, 108158241.2359821, 118974065.35958032, 130871471.89553836, 143958619.08509222, 158354480.99360144, 174189929.0929616, 191608922.0022578, 210769814.2024836, 231846795.62273198, 255031475.1850052, 280534622.70350575, 308588084.97385633, 339446893.471242, 373391582.8183662, 410730741.10020286, 451803815.2102232, 496984196.7312456, 546682616.4043702, 601350878.0448073, 661485965.8492881, 727634562.434217, 800398018.6776388, 880437820.5454028, 968481602.5999432, 1065329762.8599375, 1171862739.1459315, 1289049013.0605247, 1417953914.3665774, 1559749305.8032353, 1715724236.383559, 1887296660.021915, 2076026326.0241067, 2283628958.626518, 2511991854.4891696, 2763191039.938087, 3039510143.9318957, 3343461158.3250856, 3677807274.1575947, 4045588001.5733542, 4450146801.73069, 4895161481.903759, 5384677630.094135, 5923145393.103549, 6515459932.413904, 7167005925.655295, 7883706518.220825, 8672077170.042908, 9539284887.0472, 10493213375.75192, 11542534713.327114, 12696788184.659826, 13966467003.12581, 15363113703.438393, 16899425073.782234, 18589367581.160458, 20448304339.276505, 22493134773.204155, 24742448250.524574, 27216693075.577034, 29938362383.13474, 32932198621.448215, 36225418483.59304, 39847960331.95235, 43832756365.14758, 48216032001.662346, 53037635201.82858, 58341398722.011444, 64175538594.21259, 70593092453.63387, 77652401698.99725, 85417641868.89699, 93959406055.7867, 103355346661.36537, 113690881327.50192, 125059969460.25212, 137565966406.27734, 151322563046.9051, 166454819351.5956, 183100301286.7552, 201410331415.43073, 221551364556.97382, 243706501012.6712, 268077151113.93835, 294884866225.3322, 324373352847.8655, 356810688132.65204, 392491756945.9173, 431740932640.50903, 474915025904.56, 522406528495.01605, 574647181344.5177, 632111899478.9695, 695323089426.8665, 764855398369.5532, 841340938206.5087, 925475032027.1597, 1018022535229.8757, 1119824788752.8633, 1231807267628.1497, 1354987994390.9648, 1490486793830.0615, 1639535473213.0679, 1803489020534.3748, 1983837922587.8125, 2182221714846.594, 2400443886331.2534, 2640488274964.379, 2904537102460.817, 3194990812706.899, 3514489893977.589, 3865938883375.348, 4252532771712.8833, 4677786048884.172, 5145564653772.59, 5660121119149.85, 6226133231064.835, 6848746554171.319, 7533621209588.452, 8286983330547.298, 9115681663602.03, 10027249829962.232, 11029974812958.457, 12132972294254.305, 13346269523679.736, 14680896476047.71, 16148986123652.482, 17763884736017.73, 19540273209619.504, 21494300530581.457, 23643730583639.605, 26008103642003.566, 28608914006203.926, 31469805406824.32, 34616785947506.754, 38078464542257.43, 41886310996483.18, 46074942096131.5, 50682436305744.66, 55750679936319.125, 61325747929951.04, 67458322722946.15, 74204154995240.77, 81624570494764.84, 89787027544241.33, 98765730298665.47, 108642303328532.03, 119506533661385.25, 131457187027523.78, 144602905730276.16, 159063196303303.78, 174969515933634.2, 192466467526997.62, 211713114279697.4, 232884425707667.16, 256172868278433.9, 281790155106277.3, 309969170616905.06, 340966087678595.6, 375062696446455.2, 412568966091100.75, 453825862700210.9, 499208448970232.0, 549129293867255.25, 604042223253980.9, 664446445579379.0, 730891090137317.0, 803980199151048.8, 884378219066153.8, 972816040972769.2, 1070097645070046.2, 1177107409577051.0, 1294818150534756.2, 1424299965588232.0, 1566729962147055.2, 1723402958361761.0, 1895743254197937.2, 2085317579617731.2, 2293849337579504.5, 2523234271337455.0, 2775557698471200.5, 3053113468318321.0, 3358424815150153.5, 3694267296665169.0, 4063694026331686.0, 4470063428964855.0, 4917069771861341.0, 5408776749047476.0, 5949654423952224.0, 6544619866347447.0, 7199081852982192.0, 7918990038280412.0, 8710889042108454.0, 9581977946319300.0, 1.054017574095123e+16, 1.1594193315046354e+16, 1.275361264655099e+16, 1.402897391120609e+16, 1.54318713023267e+16, 1.6975058432559372e+16, 1.867256427581531e+16, 2.0539820703396844e+16, 2.2593802773736532e+16, 2.4853183051110188e+16, 2.733850135622121e+16, 3.0072351491843332e+16, 3.3079586641027668e+16, 3.638754530513044e+16, 4.002629983564349e+16, 4.402892981920784e+16, 4.843182280112862e+16, 5.327500508124149e+16, 5.860250558936564e+16, 6.446275614830221e+16, 7.090903176313243e+16, 7.799993493944568e+16, 8.579992843339026e+16, 9.43799212767293e+16, 1.0381791340440224e+17, 1.1419970474484248e+17, 1.2561967521932674e+17, 1.3818164274125942e+17, 1.5199980701538538e+17, 1.6719978771692394e+17, 1.8391976648861635e+17, 2.02311743137478e+17, 2.2254291745122582e+17, 2.447972091963484e+17, 2.6927693011598326e+17, 2.9620462312758163e+17, 3.2582508544033984e+17, 3.584075939843738e+17, 3.9424835338281126e+17, 4.336731887210924e+17, 4.770405075932017e+17, 5.247445583525219e+17, 5.772190141877742e+17, 6.349409156065517e+17, 6.984350071672069e+17, 7.682785078839277e+17, 8.451063586723205e+17, 9.296169945395526e+17, 1.022578693993508e+18, 1.1248365633928589e+18, 1.237320219732145e+18, 1.3610522417053596e+18, 1.4971574658758958e+18, 1.6468732124634854e+18, 1.8115605337098342e+18, 1.992716587080818e+18, 2.1919882457888998e+18, 2.41118707036779e+18, 2.652305777404569e+18, 2.917536355145026e+18, 3.2092899906595287e+18, 3.530218989725482e+18, 3.8832408886980306e+18, 4.271564977567834e+18, 4.698721475324618e+18, 5.16859362285708e+18, 5.685452985142788e+18, 6.253998283657068e+18, 6.879398112022775e+18, 7.567337923225053e+18, 8.324071715547559e+18, 9.156478887102316e+18, 1.0072126775812549e+19, 1.1079339453393805e+19, 1.2187273398733187e+19, 1.3406000738606506e+19, 1.4746600812467157e+19, 1.6221260893713875e+19, 1.7843386983085265e+19, 1.962772568139379e+19, 2.1590498249533174e+19, 2.3749548074486493e+19, 2.6124502881935143e+19, 2.873695317012866e+19, 3.1610648487141528e+19, 3.477171333585568e+19, 3.824888466944125e+19, 4.2073773136385384e+19, 4.628115045002392e+19, 5.090926549502632e+19, 5.600019204452896e+19, 6.160021124898186e+19, 6.776023237388005e+19, 7.453625561126807e+19, 8.198988117239489e+19, 9.018886928963438e+19, 9.920775621859783e+19],
          file_writer: instance(FileWriter):
            event_writer: instance(EventFileWriter),
          filename_suffix: '',
          flush_secs: 15,
          log_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                    10)_20240425-083418',
          max_queue: 10,
          purge_step: None,
      buffer_synchronizer: {'type': 'BufferSynchronizer', 'target_buffer': <reinforcement_learning.base.utility.deque_buffer_wrapper.DequeBufferWrapper object at 0x000001E1EF105D30>},
      output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                   10)_20240425-083418',
      own_sync_manager: False,
      sync_manager: instance(SyncManager):
        address: '\\\\.\\pipe\\pyc-18936-0-63pkytqm',
        shutdown: <Finalize object, callback=_finalize_manager, args=(<SpawnProcess name='SyncManager-1' pid=18936 parent=23288 started>, '\\\\.\\pipe\\pyc-18936-0-63pkytqm', b'\x8cz\xa4\x83\xd3\x0fl\xc4\xb4i\xfaX\xa39%\x1a\xc9^K6\x874\x16\xaf$\xb2\x16\x05@\xae\xa7=', <multiprocessing.managers.State object at 0x000001E1EF153670>, <function Client at 0x000001E1EE8035E0>), exitpriority=0>,
      writing_buffer: deque([], maxlen=5000)
    'text': instance(TextLogger):
      file_name: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                  10)_20240425-083418\\log.txt',
      logger: <Logger multiprocessing (INFO)>,
      output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                   10)_20240425-083418'
  },
  loss_fn: MCTSLossFunction(
  (approximator): MCTSApproximator(
    (model): Sequential(
      (0): Linear(in_features=46, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=88, bias=True)
    )
  )
),
  lower_priority: True,
  lr_scheduler: instance(StepLR):
    base_lrs: [0.0002],
    gamma: 0.1,
    last_epoch: 0,
    optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0002
    lr: 0.0002
    weight_decay: 0
),
    step_size: 1000,
    verbose: False,
  num_of_epochs: 5001,
  number_of_evaluation_agents: 2,
  number_of_training_agents: 5,
  optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0002
    lr: 0.0002
    weight_decay: 0
),
  original_affinity: None,
  output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
               10)_20240425-083418',
  output_profile: False,
  output_root: 'logs/',
  processes: [],
  random_seed: 0,
  replay_buffer: {'type': 'ShuffleReplayBuffer', 'batch_size': 100, 'buffer_size': 0},
  replay_buffer_agent_queue: {'type': 'SequentialReplayBuffer', 'batch_size': 100, 'buffer_size': 100},
  replay_buffer_queue: None,
  replay_buffer_size: 1000,
  replay_buffer_synchronizer: {'type': 'BufferSynchronizer', 'target_buffer': {'type': 'ShuffleReplayBuffer', 'batch_size': 100, 'buffer_size': 0}},
  sync_dict: <DictProxy object, typeid 'dict' at 0x1e1ef153760>,
  sync_manager: instance(SyncManager):
    address: '\\\\.\\pipe\\pyc-18936-0-63pkytqm',
    shutdown: <Finalize object, callback=_finalize_manager, args=(<SpawnProcess name='SyncManager-1' pid=18936 parent=23288 started>, '\\\\.\\pipe\\pyc-18936-0-63pkytqm', b'\x8cz\xa4\x83\xd3\x0fl\xc4\xb4i\xfaX\xa39%\x1a\xc9^K6\x874\x16\xaf$\xb2\x16\x05@\xae\xa7=', <multiprocessing.managers.State object at 0x000001E1EF153670>, <function Client at 0x000001E1EE8035E0>), exitpriority=0>,
  train_episode_length: 100,
  weight_decay: 0

2024-04-25 08:34:47,957 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #0: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, rel, 1, 2, 10, 0, 1),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, nob, not, irr, 1, 0, 9, 0, 1)', 'reward_ratio': '0/1', 'revenue': 0.11764705882352941, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.32, '(min, 1)': 0.34, '(rev, 1)': 0.04}}
2024-04-25 08:34:47,957 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:34:47,958 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-25 08:34:47,972 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #0: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 5, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.42, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-25 08:34:47,972 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:34:47,973 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-25 08:34:47,988 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #0: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 6, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 6, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.05128205128205128, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.31, '(rev, 2)': 0.01}}
2024-04-25 08:34:47,988 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:34:47,989 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-25 08:34:47,991 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #0: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.029411764705882353, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(min, 0)': 0.42, '(min, 1)': 0.24, '(rev, 1)': 0.01}}
2024-04-25 08:34:47,992 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:34:47,992 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-25 08:34:48,028 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #0: {'transition': '(exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, rel, 1, 6, 10, 1, 1),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, nob, not, irr, 1, 0, 9, 0, 1)', 'reward_ratio': '0/1', 'revenue': 0.11627906976744186, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 10)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.44, '(rev, 1)': 0.02, '(rev, 3)': 0.01}}
2024-04-25 08:34:48,028 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:34:48,029 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-25 08:34:48,029 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #0: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.025, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.26, '(rev, 1)': 0.01}}
2024-04-25 08:34:48,029 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:34:48,030 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-25 08:34:50,166 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #0: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.02631578947368421, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.36, '(rev, 1)': 0.01}}
2024-04-25 08:34:50,166 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:34:50,166 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-25 08:35:10,032 - MainProcess - INFO - text_logger.py - 51 - Train epoch #0
2024-04-25 08:35:10,056 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.0509,  0.0000,  0.0000,  0.0000,  0.1385,  0.0000,  0.1335,  0.0083,
         0.1518,  0.0000,  0.1096,  0.0032,  0.0000,  0.0000,  0.0756,  0.0021,
         0.0000,  0.0000,  0.0836,  0.0000,  0.0000,  0.0000,  0.0665,  0.0003,
         0.0000,  0.0000,  0.0628,  0.0000,  0.0000,  0.0000,  0.0472,  0.0000,
         0.0000,  0.0000,  0.0551,  0.0000,  0.0000,  0.0000,  0.0454,  0.0000,
         0.0000,  0.0000,  0.0165,  0.0000,  0.0000])  tensor([0.6359, 0.0000, 0.0000, 0.0000, 0.1162, 0.0000, 0.0713, 0.0498, 0.1125,
        0.0000, 0.0601, 0.0275, 0.0000, 0.0000, 0.0446, 0.0208, 0.0000, 0.0000,
        0.0502, 0.0000, 0.0000, 0.0000, 0.0443, 0.0072, 0.0000, 0.0000, 0.0450,
        0.0000, 0.0000, 0.0000, 0.0380, 0.0000, 0.0000, 0.0000, 0.0471, 0.0000,
        0.0000, 0.0000, 0.0498, 0.0000, 0.0000, 0.0000, 0.0397, 0.0000, 0.0000]) (500)
2024-04-25 08:35:10,217 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4703219336656964
2024-04-25 08:35:10,259 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.073530.04412
2024-04-25 08:35:10,259 - MainProcess - INFO - text_logger.py - 51 - Simulated Policy Revenue 0.017740.01269
2024-04-25 08:35:10,280 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #1: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.14893617021276595, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.34, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-25 08:35:10,281 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #1: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.32, '(min, 1)': 0.29}}
2024-04-25 08:35:10,281 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:10,282 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-25 08:35:10,282 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-25 08:35:10,295 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #1: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.32, '(min, 1)': 0.32}}
2024-04-25 08:35:10,295 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #1: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 4, 0, 0),(ado, 4)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/4', 'revenue': 0.05263157894736842, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.01, '(ado, 4)': 0.03, '(ado, 7)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.36, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-04-25 08:35:10,296 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:10,296 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:10,296 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-25 08:35:10,297 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-25 08:35:10,313 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #1: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 5, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.21}}
2024-04-25 08:35:10,313 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:10,317 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-25 08:35:10,531 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #1: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.02, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.33}}
2024-04-25 08:35:10,531 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:10,532 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-25 08:35:12,884 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #1: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, nob, not, irr, 1, 0, 9, 0, 1),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, rel, 1, 0, 10, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.022222222222222223, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 10)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.31, '(rev, 1)': 0.01}}
2024-04-25 08:35:12,884 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:12,884 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-04-25 08:35:13,041 - MainProcess - INFO - text_logger.py - 51 - Train epoch #1
2024-04-25 08:35:13,044 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.2491,  0.0000,  0.0000,  0.0000,  0.1124,  0.0000,  0.1309,  0.0014,
         0.1275,  0.0000,  0.1132,  0.0005,  0.0000,  0.0000,  0.0836,  0.0008,
         0.0000,  0.0000,  0.0929,  0.0004,  0.0000,  0.0000,  0.0774,  0.0000,
         0.0000,  0.0000,  0.0719,  0.0000,  0.0000,  0.0000,  0.0549,  0.0000,
         0.0000,  0.0000,  0.0623,  0.0000,  0.0000,  0.0000,  0.0508,  0.0000,
         0.0000,  0.0000,  0.0191,  0.0000,  0.0000])  tensor([0.6798, 0.0000, 0.0000, 0.0000, 0.0901, 0.0000, 0.0566, 0.0215, 0.0906,
        0.0000, 0.0469, 0.0118, 0.0000, 0.0000, 0.0367, 0.0122, 0.0000, 0.0000,
        0.0422, 0.0084, 0.0000, 0.0000, 0.0388, 0.0000, 0.0000, 0.0000, 0.0406,
        0.0000, 0.0000, 0.0000, 0.0358, 0.0000, 0.0000, 0.0000, 0.0455, 0.0000,
        0.0000, 0.0000, 0.0499, 0.0000, 0.0000, 0.0000, 0.0421, 0.0000, 0.0000]) (500)
2024-04-25 08:35:13,064 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46937969944757585
2024-04-25 08:35:13,067 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-25 08:35:13,089 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #2: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.57, '(min, 1)': 0.03}}
2024-04-25 08:35:13,090 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:13,090 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-04-25 08:35:13,106 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #2: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.41, '(min, 1)': 0.27}}
2024-04-25 08:35:13,107 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:13,107 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-04-25 08:35:13,121 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #2: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 3)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.22}}
2024-04-25 08:35:13,121 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:13,123 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-04-25 08:35:13,123 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #2: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.41, '(min, 1)': 0.2}}
2024-04-25 08:35:13,123 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:13,124 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-04-25 08:35:13,142 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #2: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 5, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 4)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.21, '(rev, 1)': 0.04, '(rev, 2)': 0.02}}
2024-04-25 08:35:13,142 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:13,143 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-04-25 08:35:15,142 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #2: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.36585365853658536, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.45, '(rev, 1)': 0.01, '(rev, 2)': 0.02}}
2024-04-25 08:35:15,143 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:15,143 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-04-25 08:35:17,393 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #2: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.29}}
2024-04-25 08:35:17,393 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:17,393 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-04-25 08:35:17,556 - MainProcess - INFO - text_logger.py - 51 - Train epoch #2
2024-04-25 08:35:17,559 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.2749,  0.0000,  0.0000,  0.0000,  0.1084,  0.0000,  0.1138,  0.0048,
         0.1192,  0.0000,  0.1043,  0.0024,  0.0000,  0.0000,  0.0860,  0.0000,
         0.0000,  0.0000,  0.0872,  0.0000,  0.0000,  0.0000,  0.0770,  0.0000,
         0.0000,  0.0000,  0.0825,  0.0000,  0.0000,  0.0000,  0.0593,  0.0000,
         0.0000,  0.0000,  0.0723,  0.0000,  0.0000,  0.0000,  0.0616,  0.0000,
         0.0000,  0.0000,  0.0212,  0.0000,  0.0000])  tensor([0.7598, 0.0000, 0.0000, 0.0000, 0.1003, 0.0000, 0.0513, 0.0379, 0.0988,
        0.0000, 0.0411, 0.0236, 0.0000, 0.0000, 0.0345, 0.0000, 0.0000, 0.0000,
        0.0360, 0.0000, 0.0000, 0.0000, 0.0336, 0.0000, 0.0000, 0.0000, 0.0381,
        0.0000, 0.0000, 0.0000, 0.0305, 0.0000, 0.0000, 0.0000, 0.0403, 0.0000,
        0.0000, 0.0000, 0.0503, 0.0000, 0.0000, 0.0000, 0.0408, 0.0000, 0.0000]) (500)
2024-04-25 08:35:17,576 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46843746522945523
2024-04-25 08:35:17,579 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-25 08:35:17,601 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #3: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 7)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.29}}
2024-04-25 08:35:17,602 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:17,602 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #3: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.32, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(ado, 8)': 0.02, '(min, 0)': 0.47, '(min, 1)': 0.25, '(rev, 1)': 0.02, '(rev, 2)': 0.02}}
2024-04-25 08:35:17,602 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:17,603 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-04-25 08:35:17,603 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-04-25 08:35:17,617 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #3: {'transition': '(exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 2, 9, 1, 1),(min, 0)->(exi, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 3, 9, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.29, '(min, 1)': 0.3}}
2024-04-25 08:35:17,617 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:17,618 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-04-25 08:35:17,635 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #3: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.51, '(min, 1)': 0.11}}
2024-04-25 08:35:17,636 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:17,636 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-04-25 08:35:17,639 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #3: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 0, 8, 0, 1),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 1, 8, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.02, '(min, 0)': 0.45, '(min, 1)': 0.26}}
2024-04-25 08:35:17,639 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:17,640 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-04-25 08:35:17,646 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #3: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.29}}
2024-04-25 08:35:17,647 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:17,648 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-04-25 08:35:19,565 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #3: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.43, '(min, 1)': 0.21}}
2024-04-25 08:35:19,565 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:19,566 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-04-25 08:35:19,723 - MainProcess - INFO - text_logger.py - 51 - Train epoch #3
2024-04-25 08:35:19,726 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.4370,  0.0000,  0.0000,  0.0000,  0.0995,  0.0000,  0.1134,  0.0012,
         0.1097,  0.0000,  0.1071,  0.0009,  0.0000,  0.0000,  0.0948,  0.0006,
         0.0000,  0.0000,  0.0875,  0.0000,  0.0000,  0.0000,  0.0875,  0.0000,
         0.0000,  0.0000,  0.0897,  0.0000,  0.0000,  0.0000,  0.0554,  0.0000,
         0.0000,  0.0000,  0.0753,  0.0000,  0.0000,  0.0000,  0.0595,  0.0000,
         0.0000,  0.0000,  0.0181,  0.0000,  0.0000])  tensor([0.7811, 0.0000, 0.0000, 0.0000, 0.0834, 0.0000, 0.0437, 0.0196, 0.0840,
        0.0000, 0.0341, 0.0141, 0.0000, 0.0000, 0.0304, 0.0089, 0.0000, 0.0000,
        0.0297, 0.0000, 0.0000, 0.0000, 0.0321, 0.0000, 0.0000, 0.0000, 0.0368,
        0.0000, 0.0000, 0.0000, 0.0260, 0.0000, 0.0000, 0.0000, 0.0410, 0.0000,
        0.0000, 0.0000, 0.0460, 0.0000, 0.0000, 0.0000, 0.0339, 0.0000, 0.0000]) (500)
2024-04-25 08:35:19,748 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46749523101133467
2024-04-25 08:35:19,750 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-25 08:35:19,887 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #4: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.21, '(min, 1)': 0.39}}
2024-04-25 08:35:19,887 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:19,888 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-04-25 08:35:19,986 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #4: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.29, '(min, 1)': 0.33}}
2024-04-25 08:35:19,986 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:19,987 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-04-25 08:35:20,133 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #4: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 4, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.44, '(min, 1)': 0.19}}
2024-04-25 08:35:20,133 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:20,133 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-04-25 08:35:20,713 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #4: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 4)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.32}}
2024-04-25 08:35:20,713 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:20,713 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-04-25 08:35:21,482 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #4: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 6, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.020833333333333332, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.27, '(rev, 1)': 0.01}}
2024-04-25 08:35:21,482 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:21,483 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-04-25 08:35:21,744 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #4: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 1, 1, 10, 1, 1),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 0, 9, 0, 1)', 'reward_ratio': '0/1', 'revenue': 0.20454545454545456, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 10)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.27, '(rev, 1)': 0.01, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-25 08:35:21,744 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:21,745 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-04-25 08:35:21,793 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #4: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.23}}
2024-04-25 08:35:21,793 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:21,794 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-04-25 08:35:21,952 - MainProcess - INFO - text_logger.py - 51 - Train epoch #4
2024-04-25 08:35:21,955 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.7685e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1046e-01,
         0.0000e+00,  1.2044e-01,  1.1654e-03,  1.1943e-01,  0.0000e+00,
         1.1254e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.5067e-02,
         2.4242e-04,  0.0000e+00,  0.0000e+00,  8.1553e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  8.9473e-02,  1.4815e-04,  0.0000e+00,
         0.0000e+00,  8.9990e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         4.7644e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  7.4368e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.8004e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  9.4771e-03,  0.0000e+00,  0.0000e+00])  tensor([0.6829, 0.0000, 0.0000, 0.0000, 0.0853, 0.0000, 0.0451, 0.0184, 0.0836,
        0.0000, 0.0378, 0.0000, 0.0000, 0.0000, 0.0326, 0.0054, 0.0000, 0.0000,
        0.0307, 0.0000, 0.0000, 0.0000, 0.0358, 0.0033, 0.0000, 0.0000, 0.0405,
        0.0000, 0.0000, 0.0000, 0.0244, 0.0000, 0.0000, 0.0000, 0.0409, 0.0000,
        0.0000, 0.0000, 0.0403, 0.0000, 0.0000, 0.0000, 0.0219, 0.0000, 0.0000]) (500)
2024-04-25 08:35:21,976 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4665529967932141
2024-04-25 08:35:21,979 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-25 08:35:22,091 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #5: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.24390243902439024, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.46, '(min, 1)': 0.22, '(rev, 10)': 0.01}}
2024-04-25 08:35:22,091 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:22,092 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-04-25 08:35:22,333 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #5: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.34, '(min, 1)': 0.29}}
2024-04-25 08:35:22,333 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:22,333 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-04-25 08:35:23,929 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #5: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, nob, not, nob, not, rel, 1, 1, 8, 0, 1),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, nob, not, nob, not, irr, 1, 2, 8, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.22641509433962265, 'length': 100, 'actions': {'(ado, 1)': 0.06, '(ado, 2)': 0.03, '(ado, 4)': 0.02, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.42, '(rev, 1)': 0.04, '(rev, 4)': 0.02}}
2024-04-25 08:35:23,930 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:23,930 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-04-25 08:35:24,508 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #5: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 4, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 10)': 0.01, '(ado, 3)': 0.02, '(ado, 9)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.25}}
2024-04-25 08:35:24,508 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:24,509 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-04-25 08:35:24,998 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #5: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.31}}
2024-04-25 08:35:24,998 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:24,998 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-04-25 08:35:25,900 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #5: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.03508771929824561, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 7)': 0.01, '(ado, 9)': 0.02, '(min, 0)': 0.32, '(min, 1)': 0.38, '(rev, 1)': 0.02}}
2024-04-25 08:35:25,900 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:25,901 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-04-25 08:35:26,064 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #5: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, rel, 1, 0, 10, 0, 1),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, nob, not, irr, 1, 0, 9, 0, 1)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.35, '(min, 1)': 0.29}}
2024-04-25 08:35:26,064 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:26,065 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-04-25 08:35:26,227 - MainProcess - INFO - text_logger.py - 51 - Train epoch #5
2024-04-25 08:35:26,230 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.3213e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2581e-01,
         0.0000e+00,  1.3036e-01,  3.2301e-03,  1.2873e-01,  0.0000e+00,
         1.1640e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.9801e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  7.7022e-02,  2.5714e-04,
         0.0000e+00,  0.0000e+00,  8.6918e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  9.1935e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.5495e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.1368e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.6515e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.1547e-03,  0.0000e+00,  0.0000e+00])  tensor([0.7028, 0.0000, 0.0000, 0.0000, 0.1011, 0.0000, 0.0541, 0.0293, 0.0961,
        0.0000, 0.0464, 0.0000, 0.0000, 0.0000, 0.0419, 0.0000, 0.0000, 0.0000,
        0.0373, 0.0041, 0.0000, 0.0000, 0.0441, 0.0000, 0.0000, 0.0000, 0.0523,
        0.0000, 0.0000, 0.0000, 0.0254, 0.0000, 0.0000, 0.0000, 0.0467, 0.0000,
        0.0000, 0.0000, 0.0384, 0.0000, 0.0000, 0.0000, 0.0140, 0.0000, 0.0000]) (500)
2024-04-25 08:35:26,251 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46585466501411793
2024-04-25 08:35:26,254 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.121950.12195
2024-04-25 08:35:26,275 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.44, '(min, 1)': 0.16}}
2024-04-25 08:35:26,275 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.26, '(rev, 1)': 0.01}}
2024-04-25 08:35:26,275 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:26,275 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:26,276 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-04-25 08:35:26,276 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-04-25 08:35:26,737 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 4, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.038461538461538464, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.27, '(rev, 2)': 0.01}}
2024-04-25 08:35:26,738 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:26,738 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-04-25 08:35:27,501 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 2, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.29}}
2024-04-25 08:35:27,501 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:27,502 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-04-25 08:35:28,047 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #6: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 4)': 0.01, '(ado, 6)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.37}}
2024-04-25 08:35:28,047 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:28,048 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-04-25 08:35:28,427 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.38, '(rev, 6)': 0.01}}
2024-04-25 08:35:28,428 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:28,428 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-04-25 08:35:29,925 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2653061224489796, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.37, '(rev, 1)': 0.03}}
2024-04-25 08:35:29,925 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:29,926 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-04-25 08:35:30,081 - MainProcess - INFO - text_logger.py - 51 - Train epoch #6
2024-04-25 08:35:30,084 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.1305e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2509e-01,
         0.0000e+00,  1.3462e-01,  1.4188e-03,  1.2737e-01,  0.0000e+00,
         1.1998e-01,  2.6667e-04,  0.0000e+00,  0.0000e+00,  1.0545e-01,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  7.6159e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  9.0372e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  9.2950e-02,  7.4074e-05,  0.0000e+00,  0.0000e+00,
         3.2772e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.2706e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8623e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  2.1467e-03,  0.0000e+00,  0.0000e+00])  tensor([0.8490, 0.0000, 0.0000, 0.0000, 0.0861, 0.0000, 0.0498, 0.0183, 0.0814,
        0.0000, 0.0433, 0.0060, 0.0000, 0.0000, 0.0401, 0.0000, 0.0000, 0.0000,
        0.0340, 0.0000, 0.0000, 0.0000, 0.0427, 0.0000, 0.0000, 0.0000, 0.0522,
        0.0017, 0.0000, 0.0000, 0.0216, 0.0000, 0.0000, 0.0000, 0.0457, 0.0000,
        0.0000, 0.0000, 0.0330, 0.0000, 0.0000, 0.0000, 0.0074, 0.0000, 0.0000]) (500)
2024-04-25 08:35:30,108 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46515687524044175
2024-04-25 08:35:30,111 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.122220.12222
2024-04-25 08:35:30,130 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #7: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5116279069767442, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 7)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.37, '(rev, 1)': 0.03, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-04-25 08:35:30,131 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:30,131 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-04-25 08:35:30,175 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #7: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 5, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.21}}
2024-04-25 08:35:30,175 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:30,176 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-04-25 08:35:30,584 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #7: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.28, '(min, 1)': 0.33}}
2024-04-25 08:35:30,585 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:30,585 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-04-25 08:35:30,872 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #7: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.020833333333333332, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 4)': 0.02, '(ado, 5)': 0.01, '(ado, 7)': 0.02, '(min, 0)': 0.3, '(min, 1)': 0.45, '(rev, 1)': 0.01}}
2024-04-25 08:35:30,872 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:30,873 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-04-25 08:35:32,047 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #7: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 5, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.36}}
2024-04-25 08:35:32,047 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:32,048 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-04-25 08:35:32,304 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #7: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(ado, 4)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.16}}
2024-04-25 08:35:32,305 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:32,305 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-04-25 08:35:32,813 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #7: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.09302325581395349, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.42, '(rev, 2)': 0.02}}
2024-04-25 08:35:32,814 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:32,815 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-04-25 08:35:32,970 - MainProcess - INFO - text_logger.py - 51 - Train epoch #7
2024-04-25 08:35:32,973 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.2760,  0.0000,  0.0000,  0.0000,  0.1087,  0.0000,  0.1350,  0.0004,
         0.1081,  0.0000,  0.1192,  0.0005,  0.0000,  0.0000,  0.1132,  0.0000,
         0.0000,  0.0000,  0.0839,  0.0000,  0.0000,  0.0000,  0.0997,  0.0000,
         0.0000,  0.0000,  0.1038,  0.0000,  0.0000,  0.0000,  0.0356,  0.0000,
         0.0000,  0.0000,  0.0653,  0.0000,  0.0000,  0.0000,  0.0253,  0.0000,
         0.0000,  0.0000,  0.0012,  0.0000,  0.0000])  tensor([0.7433, 0.0000, 0.0000, 0.0000, 0.0722, 0.0000, 0.0370, 0.0097, 0.0669,
        0.0000, 0.0313, 0.0067, 0.0000, 0.0000, 0.0301, 0.0000, 0.0000, 0.0000,
        0.0256, 0.0000, 0.0000, 0.0000, 0.0320, 0.0000, 0.0000, 0.0000, 0.0400,
        0.0000, 0.0000, 0.0000, 0.0171, 0.0000, 0.0000, 0.0000, 0.0390, 0.0000,
        0.0000, 0.0000, 0.0277, 0.0000, 0.0000, 0.0000, 0.0047, 0.0000, 0.0000]) (500)
2024-04-25 08:35:33,005 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4647262689292979
2024-04-25 08:35:33,010 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.255810.25581
2024-04-25 08:35:33,017 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #8: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 3, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.02, '(min, 0)': 0.42, '(min, 1)': 0.31}}
2024-04-25 08:35:33,017 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:33,018 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #8: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.44, '(min, 0)': 0.41, '(min, 1)': 0.15}}
2024-04-25 08:35:33,018 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:33,018 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-04-25 08:35:33,019 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-04-25 08:35:33,063 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #8: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.46, '(min, 1)': 0.16}}
2024-04-25 08:35:33,064 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:33,064 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-04-25 08:35:33,462 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #8: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.38636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.43, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-04-25 08:35:33,462 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:33,462 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-04-25 08:35:34,677 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #8: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(ado, 9)': 0.02, '(min, 0)': 0.25, '(min, 1)': 0.44}}
2024-04-25 08:35:34,677 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:34,678 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-04-25 08:35:35,074 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #8: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.34, '(rev, 1)': 0.03, '(rev, 4)': 0.01}}
2024-04-25 08:35:35,074 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:35,075 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-04-25 08:35:35,252 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #8: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.31}}
2024-04-25 08:35:35,252 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:35,253 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-04-25 08:35:35,416 - MainProcess - INFO - text_logger.py - 51 - Train epoch #8
2024-04-25 08:35:35,421 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.2338e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4610e-01,
         0.0000e+00,  1.4827e-01,  2.2367e-03,  1.4067e-01,  0.0000e+00,
         1.2631e-01,  1.6514e-04,  0.0000e+00,  0.0000e+00,  1.1219e-01,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  7.5760e-02,  1.3118e-04,
         0.0000e+00,  0.0000e+00,  8.3356e-02,  7.1429e-05,  0.0000e+00,
         0.0000e+00,  8.3329e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.6762e-02,  6.6667e-05,  0.0000e+00,  0.0000e+00,  4.2627e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1608e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.4037e-04,  0.0000e+00,  0.0000e+00])  tensor([0.9523, 0.0000, 0.0000, 0.0000, 0.1022, 0.0000, 0.0551, 0.0203, 0.0916,
        0.0000, 0.0482, 0.0037, 0.0000, 0.0000, 0.0473, 0.0000, 0.0000, 0.0000,
        0.0381, 0.0021, 0.0000, 0.0000, 0.0474, 0.0016, 0.0000, 0.0000, 0.0520,
        0.0000, 0.0000, 0.0000, 0.0198, 0.0015, 0.0000, 0.0000, 0.0387, 0.0000,
        0.0000, 0.0000, 0.0183, 0.0000, 0.0000, 0.0000, 0.0024, 0.0000, 0.0000]) (500)
2024-04-25 08:35:35,440 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46378403471117735
2024-04-25 08:35:35,443 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-25 08:35:35,463 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #9: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.47, '(min, 0)': 0.44, '(min, 1)': 0.09}}
2024-04-25 08:35:35,463 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:35,464 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-04-25 08:35:35,478 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #9: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.26, '(min, 1)': 0.31}}
2024-04-25 08:35:35,479 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
sition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 4)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.28}}
2024-04-25 08:35:35,479 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:35,479 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-04-25 08:35:35,479 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-04-25 08:35:35,931 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #9: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.04081632653061224, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.28, '(rev, 1)': 0.02}}
2024-04-25 08:35:35,931 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:35,932 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-04-25 08:35:37,483 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #9: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.19047619047619047, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.31, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-04-25 08:35:37,483 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:37,484 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-04-25 08:35:38,480 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #9: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 2, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 5)': 0.02, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.3}}
2024-04-25 08:35:38,480 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:38,480 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-04-25 08:35:39,776 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #9: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.38, '(min, 1)': 0.36, '(rev, 1)': 0.01, '(rev, 4)': 0.01}}
2024-04-25 08:35:39,776 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:39,776 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-04-25 08:35:39,959 - MainProcess - INFO - text_logger.py - 51 - Train epoch #9
2024-04-25 08:35:39,962 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.0845e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3351e-01, 0.0000e+00,
        1.5016e-01, 1.7154e-03, 1.2747e-01, 0.0000e+00, 1.2825e-01, 1.2903e-04,
        0.0000e+00, 0.0000e+00, 1.1680e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.0408e-02, 1.1765e-04, 0.0000e+00, 0.0000e+00, 9.0740e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.8899e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9282e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2512e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.5814e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.1614e-04, 0.0000e+00, 0.0000e+00])  tensor([0.7108, 0.0000, 0.0000, 0.0000, 0.0945, 0.0000, 0.0492, 0.0171, 0.0830,
        0.0000, 0.0425, 0.0029, 0.0000, 0.0000, 0.0429, 0.0000, 0.0000, 0.0000,
        0.0355, 0.0019, 0.0000, 0.0000, 0.0438, 0.0000, 0.0000, 0.0000, 0.0495,
        0.0000, 0.0000, 0.0000, 0.0190, 0.0000, 0.0000, 0.0000, 0.0377, 0.0000,
        0.0000, 0.0000, 0.0156, 0.0000, 0.0000, 0.0000, 0.0025, 0.0000, 0.0000]) (500)
2024-04-25 08:35:39,987 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4628418004930568
2024-04-25 08:35:39,990 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-25 08:35:40,007 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.027777777777777776, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.41, '(min, 1)': 0.23, '(rev, 1)': 0.01}}
2024-04-25 08:35:40,008 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:40,007 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #10: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 5, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.08695652173913043, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.54, '(min, 1)': 0.23, '(rev, 4)': 0.01}}
2024-04-25 08:35:40,008 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:40,008 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.52, '(min, 1)': 0.17}}
2024-04-25 08:35:40,008 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:40,008 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-04-25 08:35:40,009 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-04-25 08:35:40,009 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-04-25 08:35:40,394 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.15789473684210525, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(ado, 5)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.35, '(rev, 2)': 0.03}}
2024-04-25 08:35:40,395 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:40,395 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-04-25 08:35:40,605 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3684210526315789, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.42, '(rev, 1)': 0.01, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-25 08:35:40,605 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:40,606 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-04-25 08:35:40,970 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.48, '(min, 1)': 0.15}}
2024-04-25 08:35:40,970 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:40,971 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-04-25 08:35:43,453 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.11627906976744186, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.33, '(rev, 5)': 0.01}}
2024-04-25 08:35:43,454 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:43,454 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-04-25 08:35:43,612 - MainProcess - INFO - text_logger.py - 51 - Train epoch #10
2024-04-25 08:35:43,615 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.6141e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4978e-01,
         0.0000e+00,  1.6110e-01,  8.4094e-04,  1.3691e-01,  0.0000e+00,
         1.2972e-01,  7.2803e-04,  0.0000e+00,  0.0000e+00,  1.1509e-01,
         2.5941e-04,  0.0000e+00,  0.0000e+00,  7.5663e-02,  6.6667e-05,
         0.0000e+00,  0.0000e+00,  7.9413e-02,  6.6667e-05,  0.0000e+00,
         0.0000e+00,  7.7207e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.6002e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.7472e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  9.0707e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.2120e-04,  0.0000e+00,  0.0000e+00])  tensor([1.0480, 0.0000, 0.0000, 0.0000, 0.1091, 0.0000, 0.0564, 0.0095, 0.0934,
        0.0000, 0.0495, 0.0065, 0.0000, 0.0000, 0.0509, 0.0031, 0.0000, 0.0000,
        0.0395, 0.0015, 0.0000, 0.0000, 0.0457, 0.0015, 0.0000, 0.0000, 0.0489,
        0.0000, 0.0000, 0.0000, 0.0187, 0.0000, 0.0000, 0.0000, 0.0314, 0.0000,
        0.0000, 0.0000, 0.0139, 0.0000, 0.0000, 0.0000, 0.0031, 0.0000, 0.0000]) (500)
2024-04-25 08:35:43,635 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4619273440527139
2024-04-25 08:35:43,637 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.013890.01389
2024-04-25 08:35:43,660 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #11: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 5, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8043478260869565, 'length': 100, 'actions': {'(ado, 1)': 0.05, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.48, '(rev, 1)': 0.04, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.03}}
2024-04-25 08:35:43,660 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:43,661 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-04-25 08:35:43,690 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #11: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.49, '(min, 1)': 0.11}}

2024-04-25 08:35:43,691 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:43,691 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:43,691 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-04-25 08:35:43,691 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-04-25 08:35:43,999 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #11: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 4, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 9)': 0.02, '(min, 0)': 0.37, '(min, 1)': 0.3}}
2024-04-25 08:35:43,999 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:44,000 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-04-25 08:35:44,687 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #11: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.37}}
2024-04-25 08:35:44,687 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:44,687 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-04-25 08:35:45,296 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #11: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.18181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.42, '(min, 1)': 0.28, '(rev, 8)': 0.01}}
2024-04-25 08:35:45,296 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:45,297 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-04-25 08:35:45,989 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #11: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 6, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 5, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0425531914893617, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 3)': 0.01, '(ado, 5)': 0.02, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.27, '(rev, 2)': 0.01}}
2024-04-25 08:35:45,989 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:45,989 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-04-25 08:35:46,157 - MainProcess - INFO - text_logger.py - 51 - Train epoch #11
2024-04-25 08:35:46,160 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.2525e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7271e-01, 0.0000e+00,
        1.6679e-01, 3.3844e-03, 1.4920e-01, 0.0000e+00, 1.2736e-01, 1.9751e-03,
        0.0000e+00, 0.0000e+00, 1.1377e-01, 1.6745e-03, 0.0000e+00, 0.0000e+00,
        7.0703e-02, 9.9183e-04, 0.0000e+00, 0.0000e+00, 7.5141e-02, 5.7477e-04,
        0.0000e+00, 0.0000e+00, 6.5990e-02, 8.3464e-05, 0.0000e+00, 0.0000e+00,
        2.1871e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3034e-02, 6.2500e-05,
        0.0000e+00, 0.0000e+00, 4.3102e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.6525e-04, 0.0000e+00, 0.0000e+00])  tensor([1.4961e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2454e-01, 0.0000e+00,
        5.9621e-02, 1.6888e-02, 9.3327e-02, 0.0000e+00, 5.2142e-02, 8.7547e-03,
        0.0000e+00, 0.0000e+00, 5.3971e-02, 7.0405e-03, 0.0000e+00, 0.0000e+00,
        3.9460e-02, 4.5704e-03, 0.0000e+00, 0.0000e+00, 4.7493e-02, 3.5879e-03,
        0.0000e+00, 0.0000e+00, 4.8140e-02, 1.0814e-03, 0.0000e+00, 0.0000e+00,
        1.8439e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4696e-02, 1.3975e-03,
        0.0000e+00, 0.0000e+00, 9.5567e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3669e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:35:46,180 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46098510983459334
2024-04-25 08:35:46,182 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-25 08:35:46,203 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #12: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.39, '(min, 1)': 0.18}}
2024-04-25 08:35:46,204 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:46,205 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-04-25 08:35:46,984 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #12: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.55, '(min, 1)': 0.14}}
2024-04-25 08:35:46,984 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:46,985 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-04-25 08:35:47,460 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #12: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.46, '(min, 1)': 0.16}}
2024-04-25 08:35:47,460 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:47,461 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-04-25 08:35:47,495 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #12: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17391304347826086, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.28, '(rev, 1)': 0.01, '(rev, 7)': 0.01}}
2024-04-25 08:35:47,495 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:47,496 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-04-25 08:35:47,600 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #12: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.04878048780487805, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 8)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.17, '(rev, 2)': 0.01}}
2024-04-25 08:35:47,601 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:47,601 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-04-25 08:35:47,842 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #12: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.23}}
2024-04-25 08:35:47,842 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:47,843 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-04-25 08:35:48,555 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #12: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 6)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.2}}
2024-04-25 08:35:48,556 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:48,556 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-04-25 08:35:48,716 - MainProcess - INFO - text_logger.py - 51 - Train epoch #12
2024-04-25 08:35:48,719 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-4.5656e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1426e-01,
         0.0000e+00,  1.5901e-01,  2.1495e-04,  1.0502e-01,  0.0000e+00,
         1.3796e-01,  7.1429e-05,  0.0000e+00,  0.0000e+00,  1.3043e-01,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  8.9096e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  9.1562e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  9.2157e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.0433e-02,  6.6667e-05,  0.0000e+00,  0.0000e+00,  4.0114e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  8.2744e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  1.3347e-03,  0.0000e+00,  0.0000e+00])  tensor([0.7962, 0.0000, 0.0000, 0.0000, 0.0875, 0.0000, 0.0399, 0.0048, 0.0737,
        0.0000, 0.0332, 0.0016, 0.0000, 0.0000, 0.0359, 0.0000, 0.0000, 0.0000,
        0.0312, 0.0000, 0.0000, 0.0000, 0.0367, 0.0000, 0.0000, 0.0000, 0.0414,
        0.0000, 0.0000, 0.0000, 0.0162, 0.0015, 0.0000, 0.0000, 0.0262, 0.0000,
        0.0000, 0.0000, 0.0113, 0.0000, 0.0000, 0.0000, 0.0044, 0.0000, 0.0000]) (500)
2024-04-25 08:35:48,741 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4600428756164728
2024-04-25 08:35:48,744 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-25 08:35:48,940 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #13: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 0, 8, 0, 0),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 1, 8, 1, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.45, '(min, 1)': 0.16}}
2024-04-25 08:35:48,940 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:48,941 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-04-25 08:35:50,140 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #13: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.18}}
2024-04-25 08:35:50,141 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:50,141 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-04-25 08:35:50,824 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #13: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 3, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36585365853658536, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 7)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.24, '(rev, 5)': 0.01}}
2024-04-25 08:35:50,824 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:50,825 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-04-25 08:35:50,998 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #13: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.28}}
2024-04-25 08:35:50,998 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:50,999 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-04-25 08:35:51,214 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #13: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 3, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.29}}
2024-04-25 08:35:51,214 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:51,215 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-04-25 08:35:51,231 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #13: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 1, 1, 9, 1, 1),(min, 0)->(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 2, 9, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.36}}
2024-04-25 08:35:51,231 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:51,232 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-04-25 08:35:52,150 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #13: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2982456140350877, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 4)': 0.02, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.38, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-25 08:35:52,151 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:52,151 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-04-25 08:35:52,303 - MainProcess - INFO - text_logger.py - 51 - Train epoch #13
2024-04-25 08:35:52,306 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([9.0063e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5436e-01, 0.0000e+00,
        1.8150e-01, 6.1104e-04, 1.4030e-01, 0.0000e+00, 1.3727e-01, 6.0606e-05,
        0.0000e+00, 0.0000e+00, 1.1722e-01, 4.3478e-05, 0.0000e+00, 0.0000e+00,
        7.4198e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7105e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.3506e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5802e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4387e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2449e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.9423e-04, 0.0000e+00, 0.0000e+00])  tensor([1.1919e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0242e-01, 0.0000e+00,
        4.7654e-02, 6.4607e-03, 7.9749e-02, 0.0000e+00, 3.9105e-02, 1.3552e-03,
        0.0000e+00, 0.0000e+00, 4.2390e-02, 9.7220e-04, 0.0000e+00, 0.0000e+00,
        3.2807e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9199e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.6444e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7838e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2314e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.5063e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3684e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:35:52,326 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4594664950568888
2024-04-25 08:35:52,329 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.182930.18293
2024-04-25 08:35:53,005 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #14: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.61, '(min, 1)': 0.02}}
2024-04-25 08:35:53,005 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:53,006 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-04-25 08:35:53,032 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #14: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 4)': 0.01, '(ado, 5)': 0.03, '(min, 0)': 0.53, '(min, 1)': 0.13}}
2024-04-25 08:35:53,032 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:53,033 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-04-25 08:35:53,164 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #14: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 5, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 8)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.34, '(rev, 3)': 0.01}}
2024-04-25 08:35:53,164 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:53,165 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-04-25 08:35:53,341 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #14: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 6)': 0.02, '(min, 0)': 0.53, '(min, 1)': 0.16}}
2024-04-25 08:35:53,341 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:53,341 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-04-25 08:35:53,660 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #14: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2127659574468085, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.19, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-04-25 08:35:53,660 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:53,661 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-04-25 08:35:55,200 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #14: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 0, 9, 0, 1),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 1, 9, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.31}}
2024-04-25 08:35:55,200 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:55,200 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-04-25 08:35:55,367 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #14: {'transition': '(exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 1, 3, 8, 1, 1),(min, 0)->(exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 1, 3, 9, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.38636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.08, '(ado, 3)': 0.02, '(ado, 4)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.32, '(rev, 1)': 0.03, '(rev, 10)': 0.01, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-04-25 08:35:55,368 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:55,368 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-04-25 08:35:55,527 - MainProcess - INFO - text_logger.py - 51 - Train epoch #14
2024-04-25 08:35:55,530 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-4.8173e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2343e-01,
         0.0000e+00,  1.5561e-01,  1.0693e-03,  1.0808e-01,  0.0000e+00,
         1.3823e-01,  6.1929e-04,  0.0000e+00,  0.0000e+00,  1.3190e-01,
         2.6391e-04,  0.0000e+00,  0.0000e+00,  9.1785e-02,  1.0833e-04,
         0.0000e+00,  0.0000e+00,  9.0953e-02,  7.6923e-05,  0.0000e+00,
         0.0000e+00,  8.7833e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.8796e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.3285e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  6.7302e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  1.1562e-03,  6.4516e-05,  0.0000e+00])  tensor([1.1898, 0.0000, 0.0000, 0.0000, 0.1192, 0.0000, 0.0486, 0.0080, 0.0882,
        0.0000, 0.0428, 0.0040, 0.0000, 0.0000, 0.0467, 0.0025, 0.0000, 0.0000,
        0.0406, 0.0018, 0.0000, 0.0000, 0.0470, 0.0017, 0.0000, 0.0000, 0.0534,
        0.0000, 0.0000, 0.0000, 0.0200, 0.0000, 0.0000, 0.0000, 0.0256, 0.0000,
        0.0000, 0.0000, 0.0104, 0.0000, 0.0000, 0.0000, 0.0042, 0.0014, 0.0000]) (500)
2024-04-25 08:35:55,553 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.45880686953442046
2024-04-25 08:35:55,555 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.141300.14130
2024-04-25 08:35:55,558 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #15: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 6, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.44, '(min, 1)': 0.15}}
2024-04-25 08:35:55,558 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:55,559 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-04-25 08:35:55,573 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #15: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 6, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.34, '(min, 1)': 0.24}}
2024-04-25 08:35:55,574 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:55,575 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-04-25 08:35:55,857 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #15: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 1, 7, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 2, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.27}}
2024-04-25 08:35:55,857 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:55,857 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-04-25 08:35:56,006 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #15: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 4, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.23, '(rev, 10)': 0.01}}
2024-04-25 08:35:56,006 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:56,007 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-04-25 08:35:57,510 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #15: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 2, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.038461538461538464, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.34, '(rev, 2)': 0.01}}
2024-04-25 08:35:57,510 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:57,510 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-04-25 08:35:57,781 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #15: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.17}}
2024-04-25 08:35:57,782 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:57,782 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-04-25 08:35:59,363 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #15: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 3, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.06382978723404255, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 8)': 0.02, '(min, 0)': 0.4, '(min, 1)': 0.33, '(rev, 3)': 0.01}}
2024-04-25 08:35:59,363 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:59,363 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-04-25 08:35:59,523 - MainProcess - INFO - text_logger.py - 51 - Train epoch #15
2024-04-25 08:35:59,526 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.1737e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5253e-01, 0.0000e+00,
        1.9077e-01, 0.0000e+00, 1.3914e-01, 0.0000e+00, 1.4270e-01, 4.4444e-05,
        0.0000e+00, 0.0000e+00, 1.1073e-01, 6.0606e-05, 0.0000e+00, 0.0000e+00,
        7.7842e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0702e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.4214e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8052e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0754e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.2048e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8350e-04, 6.6667e-05, 0.0000e+00])  tensor([0.9119, 0.0000, 0.0000, 0.0000, 0.0906, 0.0000, 0.0489, 0.0000, 0.0682,
        0.0000, 0.0330, 0.0010, 0.0000, 0.0000, 0.0336, 0.0014, 0.0000, 0.0000,
        0.0304, 0.0000, 0.0000, 0.0000, 0.0315, 0.0000, 0.0000, 0.0000, 0.0325,
        0.0000, 0.0000, 0.0000, 0.0194, 0.0000, 0.0000, 0.0000, 0.0219, 0.0000,
        0.0000, 0.0000, 0.0063, 0.0000, 0.0000, 0.0000, 0.0017, 0.0015, 0.0000]) (500)
2024-04-25 08:35:59,549 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4578646353162999
2024-04-25 08:35:59,551 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-25 08:35:59,555 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #16: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.21, '(rev, 1)': 0.02, '(rev, 3)': 0.01}}
2024-04-25 08:35:59,555 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:59,556 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-04-25 08:35:59,570 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #16: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.11904761904761904, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.54, '(min, 1)': 0.22, '(rev, 5)': 0.01}}
2024-04-25 08:35:59,571 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:59,571 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-04-25 08:35:59,586 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #16: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.12195121951219512, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.28, '(rev, 5)': 0.01}}
2024-04-25 08:35:59,586 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:59,586 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-04-25 08:35:59,602 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #16: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.37, '(min, 1)': 0.25}}
2024-04-25 08:35:59,602 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:35:59,603 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-04-25 08:36:00,037 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #16: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 5, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.25, '(rev, 1)': 0.01, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-04-25 08:36:00,037 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:00,038 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-04-25 08:36:01,513 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #16: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 2, 7, 0, 0),(ado, 5)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 2, 0, 0)', 'reward_ratio': '0/5', 'revenue': 0.17777777777777778, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 5)': 0.02, '(min, 0)': 0.35, '(min, 1)': 0.31, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-04-25 08:36:01,514 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:01,514 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-04-25 08:36:01,634 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #16: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.15}}
2024-04-25 08:36:01,634 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:01,634 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-04-25 08:36:01,801 - MainProcess - INFO - text_logger.py - 51 - Train epoch #16
2024-04-25 08:36:01,804 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.7100e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.3308e-01,
         0.0000e+00,  1.6258e-01,  8.4530e-04,  1.1135e-01,  0.0000e+00,
         1.3481e-01,  5.3282e-04,  0.0000e+00,  0.0000e+00,  1.4233e-01,
         3.1351e-04,  0.0000e+00,  0.0000e+00,  8.8484e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  8.8593e-02,  1.4039e-04,  0.0000e+00,
         0.0000e+00,  7.4482e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.0433e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7011e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.4145e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.0313e-04,  0.0000e+00,  0.0000e+00])  tensor([1.2383, 0.0000, 0.0000, 0.0000, 0.1239, 0.0000, 0.0480, 0.0062, 0.0889,
        0.0000, 0.0424, 0.0038, 0.0000, 0.0000, 0.0532, 0.0029, 0.0000, 0.0000,
        0.0396, 0.0000, 0.0000, 0.0000, 0.0466, 0.0022, 0.0000, 0.0000, 0.0448,
        0.0000, 0.0000, 0.0000, 0.0205, 0.0000, 0.0000, 0.0000, 0.0238, 0.0000,
        0.0000, 0.0000, 0.0086, 0.0000, 0.0000, 0.0000, 0.0031, 0.0000, 0.0000]) (500)
2024-04-25 08:36:01,824 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4572335122092904
2024-04-25 08:36:01,826 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.155560.15556
2024-04-25 08:36:01,893 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #17: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.36, '(min, 1)': 0.26}}
2024-04-25 08:36:01,893 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:01,894 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-04-25 08:36:02,032 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #17: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.2}}
2024-04-25 08:36:02,032 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:02,033 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-04-25 08:36:02,047 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #17: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.2}}
2024-04-25 08:36:02,047 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:02,048 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-04-25 08:36:03,507 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #17: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 1, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4634146341463415, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.34, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-25 08:36:03,507 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:03,508 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-04-25 08:36:04,199 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #17: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 5, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.29, '(rev, 1)': 0.02, '(rev, 3)': 0.02}}
2024-04-25 08:36:04,199 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:04,200 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-04-25 08:36:04,255 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #17: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 2)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.33}}
2024-04-25 08:36:04,256 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:04,256 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-04-25 08:36:05,080 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #17: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.34, '(rev, 2)': 0.03}}
2024-04-25 08:36:05,080 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:05,081 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-04-25 08:36:05,231 - MainProcess - INFO - text_logger.py - 51 - Train epoch #17
2024-04-25 08:36:05,234 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.7991e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.5350e-01,
         0.0000e+00,  1.7855e-01,  1.2574e-03,  1.3368e-01,  0.0000e+00,
         1.3968e-01,  5.6514e-04,  0.0000e+00,  0.0000e+00,  9.8124e-02,
         2.2545e-04,  0.0000e+00,  0.0000e+00,  8.3203e-02,  6.2500e-05,
         0.0000e+00,  0.0000e+00,  7.6752e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  7.0627e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.0236e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.6986e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  5.6122e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  9.3345e-04,  0.0000e+00,  0.0000e+00])  tensor([1.4616e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3930e-01, 0.0000e+00,
        4.9965e-02, 7.0712e-03, 9.6386e-02, 0.0000e+00, 5.0532e-02, 3.7166e-03,
        0.0000e+00, 0.0000e+00, 4.1614e-02, 2.5866e-03, 0.0000e+00, 0.0000e+00,
        4.0820e-02, 1.3975e-03, 0.0000e+00, 0.0000e+00, 4.1001e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.0731e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9307e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1327e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.0653e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.7552e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:36:05,256 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.45629127799116986
2024-04-25 08:36:05,258 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-25 08:36:05,309 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #18: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.49, '(min, 1)': 0.13}}
2024-04-25 08:36:05,310 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:05,310 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-04-25 08:36:05,619 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #18: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.03, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.02, '(min, 0)': 0.44, '(min, 1)': 0.28, '(rev, 1)': 0.04, '(rev, 2)': 0.02}}
2024-04-25 08:36:05,620 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:05,620 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-04-25 08:36:05,750 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #18: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41509433962264153, 'length': 100, 'actions': {'(ado, 1)': 0.09, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.02, '(min, 0)': 0.48, '(min, 1)': 0.3, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-25 08:36:05,751 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:05,751 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-04-25 08:36:05,830 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #18: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 3, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.15}}
2024-04-25 08:36:05,830 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:05,831 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-04-25 08:36:06,371 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #18: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.46, '(min, 1)': 0.11}}
2024-04-25 08:36:06,371 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:06,371 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-04-25 08:36:06,807 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #18: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 2, 7, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.06521739130434782, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.24, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-25 08:36:06,807 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:06,808 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-04-25 08:36:08,745 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #18: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.26, '(rev, 1)': 0.03, '(rev, 2)': 0.01}}
2024-04-25 08:36:08,745 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:08,746 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-04-25 08:36:08,901 - MainProcess - INFO - text_logger.py - 51 - Train epoch #18
2024-04-25 08:36:08,904 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.9235e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7915e-01, 0.0000e+00,
        1.7294e-01, 1.2256e-03, 1.4055e-01, 0.0000e+00, 1.1973e-01, 5.8509e-04,
        0.0000e+00, 0.0000e+00, 1.2395e-01, 2.0944e-04, 0.0000e+00, 0.0000e+00,
        7.6187e-02, 1.0283e-04, 0.0000e+00, 0.0000e+00, 6.8480e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.2147e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7703e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1067e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.8828e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0870e-03, 0.0000e+00, 0.0000e+00])  tensor([1.9406e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6032e-01, 0.0000e+00,
        5.5797e-02, 6.5797e-03, 1.0801e-01, 0.0000e+00, 4.9980e-02, 3.4701e-03,
        0.0000e+00, 0.0000e+00, 6.4711e-02, 2.4346e-03, 0.0000e+00, 0.0000e+00,
        4.6433e-02, 1.6265e-03, 0.0000e+00, 0.0000e+00, 4.6390e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.4709e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.2355e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0970e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.6863e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.2116e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:36:08,925 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4553490437730493
2024-04-25 08:36:08,927 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-25 08:36:08,962 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #19: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 8)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/8', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 3)': 0.02, '(ado, 5)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.22}}
2024-04-25 08:36:08,962 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:08,963 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #19: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.56, '(min, 1)': 0.14, '(rev, 1)': 0.01}}
2024-04-25 08:36:08,963 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:08,963 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-04-25 08:36:08,964 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-04-25 08:36:08,978 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #19: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3023255813953488, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 8)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.32, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-04-25 08:36:08,978 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:08,979 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-04-25 08:36:08,980 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #19: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 3)': 0.01, '(ado, 6)': 0.03, '(min, 0)': 0.4, '(min, 1)': 0.28}}
2024-04-25 08:36:08,981 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:08,982 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-04-25 08:36:09,151 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #19: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 8)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.13}}
2024-04-25 08:36:09,152 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:09,152 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-04-25 08:36:10,685 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #19: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.27, '(min, 1)': 0.3}}
2024-04-25 08:36:10,685 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:10,686 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-04-25 08:36:12,440 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #19: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 5)': 0.01, '(ado, 7)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.29, '(rev, 5)': 0.01}}
2024-04-25 08:36:12,440 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:12,441 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-04-25 08:36:12,604 - MainProcess - INFO - text_logger.py - 51 - Train epoch #19
2024-04-25 08:36:12,607 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-4.6106e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1721e-01,
         0.0000e+00,  1.7649e-01,  1.2163e-04,  9.9133e-02,  0.0000e+00,
         1.5055e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2480e-01,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  9.3461e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  8.7925e-02,  1.0760e-04,  0.0000e+00,
         0.0000e+00,  7.7047e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.6330e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.9080e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  6.4165e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  1.3210e-03,  0.0000e+00,  0.0000e+00])  tensor([1.1902, 0.0000, 0.0000, 0.0000, 0.1058, 0.0000, 0.0392, 0.0020, 0.0738,
        0.0000, 0.0307, 0.0000, 0.0000, 0.0000, 0.0320, 0.0000, 0.0000, 0.0000,
        0.0346, 0.0000, 0.0000, 0.0000, 0.0382, 0.0017, 0.0000, 0.0000, 0.0371,
        0.0000, 0.0000, 0.0000, 0.0207, 0.0000, 0.0000, 0.0000, 0.0207, 0.0000,
        0.0000, 0.0000, 0.0094, 0.0000, 0.0000, 0.0000, 0.0044, 0.0000, 0.0000]) (500)
2024-04-25 08:36:12,625 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.454709135136324
2024-04-25 08:36:12,627 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.151160.15116
2024-04-25 08:36:12,635 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #20: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.31, '(min, 1)': 0.34}}
2024-04-25 08:36:12,635 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:12,636 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-04-25 08:36:12,650 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #20: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3191489361702128, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.02, '(min, 0)': 0.39, '(min, 1)': 0.34, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-25 08:36:12,650 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #20: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.19047619047619047, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 5)': 0.02, '(min, 0)': 0.36, '(min, 1)': 0.33, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-04-25 08:36:12,650 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:12,650 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:12,651 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-04-25 08:36:12,652 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-04-25 08:36:13,255 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #20: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.22}}
2024-04-25 08:36:13,256 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:13,256 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-04-25 08:36:13,591 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #20: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.27, '(rev, 1)': 0.01}}
2024-04-25 08:36:13,591 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:13,592 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-04-25 08:36:13,669 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #20: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 1, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.24324324324324326, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.51, '(min, 1)': 0.16, '(rev, 1)': 0.02, '(rev, 2)': 0.02, '(rev, 5)': 0.01}}
2024-04-25 08:36:13,669 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:13,670 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-04-25 08:36:15,010 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #20: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.08888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.22, '(rev, 4)': 0.01}}
2024-04-25 08:36:15,011 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:15,011 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-04-25 08:36:15,162 - MainProcess - INFO - text_logger.py - 51 - Train epoch #20
2024-04-25 08:36:15,165 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.0282,  0.0000,  0.0000,  0.0000,  0.1648,  0.0000,  0.1780,  0.0009,
         0.1290,  0.0000,  0.1231,  0.0005,  0.0000,  0.0000,  0.1083,  0.0003,
         0.0000,  0.0000,  0.0846,  0.0002,  0.0000,  0.0000,  0.0763,  0.0000,
         0.0000,  0.0000,  0.0675,  0.0000,  0.0000,  0.0000,  0.0325,  0.0000,
         0.0000,  0.0000,  0.0277,  0.0000,  0.0000,  0.0000,  0.0053,  0.0000,
         0.0000,  0.0000,  0.0009,  0.0000,  0.0000])  tensor([1.6133, 0.0000, 0.0000, 0.0000, 0.1692, 0.0000, 0.0548, 0.0050, 0.1076,
        0.0000, 0.0492, 0.0030, 0.0000, 0.0000, 0.0514, 0.0025, 0.0000, 0.0000,
        0.0462, 0.0021, 0.0000, 0.0000, 0.0442, 0.0000, 0.0000, 0.0000, 0.0424,
        0.0000, 0.0000, 0.0000, 0.0226, 0.0000, 0.0000, 0.0000, 0.0209, 0.0000,
        0.0000, 0.0000, 0.0089, 0.0000, 0.0000, 0.0000, 0.0037, 0.0000, 0.0000]) (500)
2024-04-25 08:36:15,185 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.45401014416144664
2024-04-25 08:36:15,187 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.121620.12162
2024-04-25 08:36:15,193 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #21: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.54, '(min, 1)': 0.06}}
2024-04-25 08:36:15,193 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:15,194 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-04-25 08:36:15,499 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #21: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5217391304347826, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(min, 0)': 0.4, '(min, 1)': 0.23, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 5)': 0.03}}
2024-04-25 08:36:15,499 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:15,500 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-04-25 08:36:16,122 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #21: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1891891891891892, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.41, '(min, 1)': 0.23, '(rev, 1)': 0.05, '(rev, 4)': 0.01}}
2024-04-25 08:36:16,122 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:16,123 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-04-25 08:36:16,344 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #21: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 3, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.20408163265306123, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.35, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-25 08:36:16,344 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:16,345 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-04-25 08:36:16,492 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #21: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.42857142857142855, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.24, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-25 08:36:16,492 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:16,493 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-04-25 08:36:16,742 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #21: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2682926829268293, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 8)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.15, '(rev, 1)': 0.01}}
2024-04-25 08:36:16,742 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:16,743 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-04-25 08:36:19,182 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #21: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 1, 1, 9, 1, 1),(min, 0)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 1, 1, 10, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.43902439024390244, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.41, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-04-25 08:36:19,182 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:19,182 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-04-25 08:36:19,332 - MainProcess - INFO - text_logger.py - 51 - Train epoch #21
2024-04-25 08:36:19,335 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.8018e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4530e-01, 0.0000e+00,
        1.4065e-01, 2.7679e-03, 2.1790e-01, 0.0000e+00, 7.2675e-02, 2.0853e-03,
        0.0000e+00, 0.0000e+00, 6.1899e-02, 1.4161e-03, 0.0000e+00, 0.0000e+00,
        4.3624e-02, 4.3635e-04, 0.0000e+00, 0.0000e+00, 3.8836e-02, 3.1539e-04,
        0.0000e+00, 0.0000e+00, 3.5302e-02, 1.7770e-04, 0.0000e+00, 0.0000e+00,
        1.8082e-02, 3.1000e-04, 0.0000e+00, 0.0000e+00, 1.4688e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.0309e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.0104e-04, 0.0000e+00, 0.0000e+00])  tensor([2.7306e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2768e-01, 0.0000e+00,
        7.4961e-02, 7.9999e-03, 1.3474e-01, 0.0000e+00, 7.4017e-02, 6.0368e-03,
        0.0000e+00, 0.0000e+00, 6.9627e-02, 5.2797e-03, 0.0000e+00, 0.0000e+00,
        5.3412e-02, 2.8535e-03, 0.0000e+00, 0.0000e+00, 4.9822e-02, 2.5392e-03,
        0.0000e+00, 0.0000e+00, 4.6564e-02, 1.7829e-03, 0.0000e+00, 0.0000e+00,
        2.5110e-02, 2.9522e-03, 0.0000e+00, 0.0000e+00, 2.1445e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.3779e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8020e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:36:19,365 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.45333620262625296
2024-04-25 08:36:19,368 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.134150.13415
2024-04-25 08:36:19,380 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #22: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.4782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(min, 0)': 0.21, '(min, 1)': 0.39, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 5)': 0.01}}
2024-04-25 08:36:19,380 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:19,380 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-04-25 08:36:19,394 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #22: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.018518518518518517, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.2, '(rev, 1)': 0.03}}
2024-04-25 08:36:19,394 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #22: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.54, '(min, 1)': 0.1}}
2024-04-25 08:36:19,395 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:19,395 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:19,395 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-04-25 08:36:19,395 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-04-25 08:36:19,409 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #22: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.45, '(min, 1)': 0.16}}
2024-04-25 08:36:19,409 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #22: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17777777777777778, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.38, '(rev, 1)': 0.05, '(rev, 5)': 0.01}}
2024-04-25 08:36:19,410 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:19,411 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-04-25 08:36:19,411 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-04-25 08:36:19,430 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #22: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.09523809523809523, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.27, '(rev, 1)': 0.02, '(rev, 2)': 0.02, '(rev, 4)': 0.01}}
2024-04-25 08:36:19,430 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:19,430 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-04-25 08:36:21,852 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #22: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.04081632653061224, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.26, '(rev, 1)': 0.03}}
2024-04-25 08:36:21,852 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:21,853 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-04-25 08:36:22,012 - MainProcess - INFO - text_logger.py - 51 - Train epoch #22
2024-04-25 08:36:22,016 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.4632e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1447e-01, 0.0000e+00,
        1.5425e-01, 2.1787e-03, 2.0707e-01, 0.0000e+00, 7.6371e-02, 1.3469e-03,
        0.0000e+00, 0.0000e+00, 6.3872e-02, 4.8771e-04, 0.0000e+00, 0.0000e+00,
        5.0829e-02, 2.3888e-04, 0.0000e+00, 0.0000e+00, 4.6539e-02, 1.6226e-04,
        0.0000e+00, 0.0000e+00, 3.9333e-02, 9.9755e-05, 0.0000e+00, 0.0000e+00,
        2.1156e-02, 9.9755e-05, 0.0000e+00, 0.0000e+00, 1.7088e-02, 9.9755e-05,
        0.0000e+00, 0.0000e+00, 3.6039e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.0032e-04, 0.0000e+00, 0.0000e+00])  tensor([2.3033e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3506e-01, 0.0000e+00,
        8.4181e-02, 6.8400e-03, 1.4124e-01, 0.0000e+00, 7.0722e-02, 4.6505e-03,
        0.0000e+00, 0.0000e+00, 6.2738e-02, 2.7259e-03, 0.0000e+00, 0.0000e+00,
        5.3606e-02, 2.0898e-03, 0.0000e+00, 0.0000e+00, 5.1064e-02, 1.8994e-03,
        0.0000e+00, 0.0000e+00, 4.4847e-02, 1.2911e-03, 0.0000e+00, 0.0000e+00,
        2.5339e-02, 1.2911e-03, 0.0000e+00, 0.0000e+00, 2.2429e-02, 1.2911e-03,
        0.0000e+00, 0.0000e+00, 7.8437e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2382e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:36:22,036 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4523939684081324
2024-04-25 08:36:22,039 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-25 08:36:22,062 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #23: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 5, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24489795918367346, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.4, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-25 08:36:22,062 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:22,063 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-04-25 08:36:22,090 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #23: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.54, '(min, 1)': 0.08}}
2024-04-25 08:36:22,090 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:22,092 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-04-25 08:36:22,254 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #23: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 1, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13043478260869565, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.25, '(rev, 1)': 0.05, '(rev, 4)': 0.01}}
2024-04-25 08:36:22,254 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:22,255 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-04-25 08:36:22,282 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #23: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.475, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.18, '(min, 1)': 0.46, '(rev, 1)': 0.12, '(rev, 2)': 0.06, '(rev, 3)': 0.03}}
2024-04-25 08:36:22,282 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:22,282 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-04-25 08:36:22,756 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #23: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 3, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6764705882352942, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.31, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.03}}
2024-04-25 08:36:22,756 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:22,757 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-04-25 08:36:23,322 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #23: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32558139534883723, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.18, '(rev, 4)': 0.01}}
2024-04-25 08:36:23,322 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:23,323 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-04-25 08:36:24,246 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #23: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.06666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.27, '(rev, 1)': 0.03}}
2024-04-25 08:36:24,247 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:24,247 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-04-25 08:36:24,397 - MainProcess - INFO - text_logger.py - 51 - Train epoch #23
2024-04-25 08:36:24,400 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.8448e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5889e-01, 0.0000e+00,
        1.3408e-01, 2.8890e-03, 2.3884e-01, 0.0000e+00, 5.6281e-02, 2.0893e-03,
        0.0000e+00, 0.0000e+00, 5.2573e-02, 1.4899e-03, 0.0000e+00, 0.0000e+00,
        4.2420e-02, 2.8371e-04, 0.0000e+00, 0.0000e+00, 3.8530e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.3171e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9449e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5104e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2930e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.1231e-04, 0.0000e+00, 0.0000e+00])  tensor([2.1605, 0.0000, 0.0000, 0.0000, 0.2294, 0.0000, 0.0795, 0.0076, 0.1406,
        0.0000, 0.0610, 0.0056, 0.0000, 0.0000, 0.0641, 0.0049, 0.0000, 0.0000,
        0.0564, 0.0025, 0.0000, 0.0000, 0.0531, 0.0000, 0.0000, 0.0000, 0.0468,
        0.0000, 0.0000, 0.0000, 0.0286, 0.0000, 0.0000, 0.0000, 0.0237, 0.0000,
        0.0000, 0.0000, 0.0079, 0.0000, 0.0000, 0.0000, 0.0031, 0.0000, 0.0000]) (500)
2024-04-25 08:36:24,420 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4517773155853606
2024-04-25 08:36:24,422 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.162790.16279
2024-04-25 08:36:24,943 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #24: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2549019607843137, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.15, '(rev, 1)': 0.02, '(rev, 2)': 0.01}}
2024-04-25 08:36:24,943 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:24,944 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-04-25 08:36:25,012 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #24: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.23076923076923078, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.26, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-25 08:36:25,012 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:25,013 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-04-25 08:36:25,190 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #24: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.31, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-25 08:36:25,191 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:25,191 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-04-25 08:36:25,429 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #24: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 3, 0, 0),(rev, 3)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5853658536585366, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.09, '(min, 1)': 0.55, '(rev, 1)': 0.08, '(rev, 3)': 0.05, '(rev, 4)': 0.01}}
2024-04-25 08:36:25,429 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:25,430 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-04-25 08:36:25,570 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #24: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.58, '(min, 1)': 0.04}}
2024-04-25 08:36:25,570 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:25,570 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-04-25 08:36:26,787 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #24: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5576923076923077, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.37, '(rev, 1)': 0.04, '(rev, 10)': 0.01, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-04-25 08:36:26,787 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:26,788 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-04-25 08:36:27,510 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #24: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.33, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-04-25 08:36:27,510 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:27,511 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-04-25 08:36:27,672 - MainProcess - INFO - text_logger.py - 51 - Train epoch #24
2024-04-25 08:36:27,675 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.5762e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8608e-01, 0.0000e+00,
        1.3146e-01, 3.3479e-03, 2.5035e-01, 0.0000e+00, 5.1753e-02, 2.2375e-03,
        0.0000e+00, 0.0000e+00, 4.8291e-02, 1.2717e-03, 0.0000e+00, 0.0000e+00,
        3.4475e-02, 6.0214e-04, 0.0000e+00, 0.0000e+00, 2.9547e-02, 2.6845e-04,
        0.0000e+00, 0.0000e+00, 2.8603e-02, 6.6120e-05, 0.0000e+00, 0.0000e+00,
        1.5746e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2549e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.7353e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.4919e-04, 6.0606e-05, 0.0000e+00])  tensor([2.1048e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2140e-01, 0.0000e+00,
        9.3938e-02, 8.0175e-03, 1.4063e-01, 0.0000e+00, 6.0955e-02, 5.8768e-03,
        0.0000e+00, 0.0000e+00, 6.4502e-02, 5.1054e-03, 0.0000e+00, 0.0000e+00,
        5.1423e-02, 3.5376e-03, 0.0000e+00, 0.0000e+00, 4.5621e-02, 2.1282e-03,
        0.0000e+00, 0.0000e+00, 4.5297e-02, 1.0444e-03, 0.0000e+00, 0.0000e+00,
        2.7113e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3462e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.6663e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9597e-03, 1.3552e-03, 0.0000e+00]) (500)
2024-04-25 08:36:27,695 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.45108998332802436
2024-04-25 08:36:27,699 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.127450.12745
2024-04-25 08:36:27,703 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #25: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(min, 0)': 0.08, '(min, 1)': 0.5, '(rev, 1)': 0.08, '(rev, 2)': 0.02}}
2024-04-25 08:36:27,703 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:27,704 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-04-25 08:36:27,719 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #25: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.11428571428571428, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.49, '(min, 1)': 0.14, '(rev, 1)': 0.04, '(rev, 2)': 0.02}}
2024-04-25 08:36:27,720 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:27,720 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-04-25 08:36:27,751 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #25: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 5, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.44, '(min, 1)': 0.18}}
2024-04-25 08:36:27,751 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:27,752 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-04-25 08:36:27,897 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #25: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.2653061224489796, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.29, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 5)': 0.01}}
2024-04-25 08:36:27,897 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:27,898 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-04-25 08:36:28,359 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #25: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.2}}
2024-04-25 08:36:28,359 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:28,359 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-04-25 08:36:30,055 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #25: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.08823529411764706, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.2, '(rev, 1)': 0.04, '(rev, 2)': 0.01}}
2024-04-25 08:36:30,055 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:30,056 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-04-25 08:36:31,202 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #25: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.04, '(ado, 6)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.24, '(rev, 1)': 0.1, '(rev, 2)': 0.04}}
2024-04-25 08:36:31,202 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:31,203 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-04-25 08:36:31,363 - MainProcess - INFO - text_logger.py - 51 - Train epoch #25
2024-04-25 08:36:31,366 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.2163e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7688e-01, 0.0000e+00,
        1.2395e-01, 2.9064e-03, 2.5882e-01, 0.0000e+00, 4.9168e-02, 1.4598e-03,
        0.0000e+00, 0.0000e+00, 4.5478e-02, 4.9162e-04, 0.0000e+00, 0.0000e+00,
        3.7302e-02, 2.8999e-04, 0.0000e+00, 0.0000e+00, 3.3436e-02, 6.4516e-05,
        0.0000e+00, 0.0000e+00, 3.0910e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8125e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6236e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.9369e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.4076e-04, 0.0000e+00, 0.0000e+00])  tensor([1.7014e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2795e-01, 0.0000e+00,
        8.1275e-02, 7.5326e-03, 1.4822e-01, 0.0000e+00, 6.3215e-02, 4.7677e-03,
        0.0000e+00, 0.0000e+00, 6.2690e-02, 2.8286e-03, 0.0000e+00, 0.0000e+00,
        5.2487e-02, 2.3002e-03, 0.0000e+00, 0.0000e+00, 4.7823e-02, 1.4426e-03,
        0.0000e+00, 0.0000e+00, 4.4558e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7178e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4837e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.8680e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8344e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:36:31,385 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4502620348241895
2024-04-25 08:36:31,387 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.057140.05714
2024-04-25 08:36:31,425 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #26: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 6)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.09, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-04-25 08:36:31,426 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #26: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46511627906976744, 'length': 100, 'actions': {'(ado, 1)': 0.09, '(ado, 2)': 0.01, '(ado, 3)': 0.04, '(min, 0)': 0.44, '(min, 1)': 0.24, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 6)': 0.01}}
2024-04-25 08:36:31,426 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:31,426 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-04-25 08:36:31,426 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-04-25 08:36:31,446 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #26: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 3, 0, 1),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 4, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(ado, 7)': 0.01, '(min, 0)': 0.52, '(min, 1)': 0.1}}
2024-04-25 08:36:31,446 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:31,449 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-04-25 08:36:31,513 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #26: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3953488372093023, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 9)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.2, '(rev, 1)': 0.07, '(rev, 3)': 0.01}}
2024-04-25 08:36:31,513 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:31,514 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-04-25 08:36:31,985 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #26: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.55, '(min, 1)': 0.07}}
2024-04-25 08:36:31,985 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:31,986 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-04-25 08:36:32,600 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #26: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.30612244897959184, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.21, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-04-25 08:36:32,601 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:32,601 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-04-25 08:36:35,317 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #26: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7659574468085106, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.46, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 7)': 0.01}}
2024-04-25 08:36:35,318 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:35,319 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-04-25 08:36:35,480 - MainProcess - INFO - text_logger.py - 51 - Train epoch #26
2024-04-25 08:36:35,483 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.4639e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8509e-01, 0.0000e+00,
        1.0326e-01, 4.2181e-03, 3.2732e-01, 0.0000e+00, 2.4460e-02, 2.5664e-03,
        0.0000e+00, 0.0000e+00, 1.5954e-02, 1.9792e-03, 0.0000e+00, 0.0000e+00,
        1.0588e-02, 6.1553e-04, 0.0000e+00, 0.0000e+00, 9.1967e-03, 4.0794e-04,
        0.0000e+00, 0.0000e+00, 6.7605e-03, 1.0387e-04, 0.0000e+00, 0.0000e+00,
        3.8038e-03, 1.2239e-04, 0.0000e+00, 0.0000e+00, 3.1235e-03, 6.6834e-05,
        0.0000e+00, 0.0000e+00, 3.2429e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.7736e-05, 0.0000e+00, 0.0000e+00])  tensor([1.8234e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4765e-01, 0.0000e+00,
        8.3586e-02, 8.8118e-03, 9.4388e-02, 0.0000e+00, 4.6317e-02, 6.2231e-03,
        0.0000e+00, 0.0000e+00, 3.9640e-02, 6.1664e-03, 0.0000e+00, 0.0000e+00,
        3.1976e-02, 3.3545e-03, 0.0000e+00, 0.0000e+00, 2.9514e-02, 2.7471e-03,
        0.0000e+00, 0.0000e+00, 2.4082e-02, 1.3410e-03, 0.0000e+00, 0.0000e+00,
        1.4588e-02, 1.6288e-03, 0.0000e+00, 0.0000e+00, 1.2543e-02, 1.0570e-03,
        0.0000e+00, 0.0000e+00, 2.6220e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.4380e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:36:35,498 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.44931980060606896
2024-04-25 08:36:35,501 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-25 08:36:35,511 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #27: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.44, '(min, 1)': 0.16}}
min, 0)': 0.58, '(min, 1)': 0.08, '(rev, 1)': 0.01, '(rev, 3)': 0.01}}
2024-04-25 08:36:35,511 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:35,511 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:35,512 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-04-25 08:36:35,512 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-04-25 08:36:35,542 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #27: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.28, '(min, 1)': 0.38, '(rev, 1)': 0.05, '(rev, 2)': 0.09, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-04-25 08:36:35,542 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:35,543 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-04-25 08:36:35,546 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #27: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24489795918367346, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.21, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-25 08:36:35,547 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:35,548 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-04-25 08:36:35,548 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #27: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.25}}
2024-04-25 08:36:35,548 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:35,550 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-04-25 08:36:36,507 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #27: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 1.1111111111111112, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.02, '(min, 0)': 0.11, '(min, 1)': 0.53, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.05, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-25 08:36:36,507 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:36,508 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-04-25 08:36:37,902 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #27: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5581395348837209, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.47, '(rev, 1)': 0.11, '(rev, 2)': 0.05, '(rev, 3)': 0.04, '(rev, 5)': 0.01}}
2024-04-25 08:36:37,902 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:37,902 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-04-25 08:36:38,061 - MainProcess - INFO - text_logger.py - 51 - Train epoch #27
2024-04-25 08:36:38,064 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.1840e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3622e-01, 0.0000e+00,
        1.0180e-01, 5.1427e-03, 2.8042e-01, 0.0000e+00, 3.8356e-02, 3.4036e-03,
        0.0000e+00, 0.0000e+00, 3.3745e-02, 1.6356e-03, 0.0000e+00, 0.0000e+00,
        2.7329e-02, 9.1489e-04, 0.0000e+00, 0.0000e+00, 2.3399e-02, 7.2711e-04,
        0.0000e+00, 0.0000e+00, 2.0532e-02, 3.0629e-04, 0.0000e+00, 0.0000e+00,
        1.2660e-02, 3.2787e-05, 0.0000e+00, 0.0000e+00, 1.0266e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.5739e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.4658e-04, 0.0000e+00, 0.0000e+00])  tensor([2.8414e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1567e-01, 0.0000e+00,
        9.0628e-02, 9.4945e-03, 1.3073e-01, 0.0000e+00, 5.6505e-02, 7.4274e-03,
        0.0000e+00, 0.0000e+00, 5.5996e-02, 5.7543e-03, 0.0000e+00, 0.0000e+00,
        4.7566e-02, 4.5518e-03, 0.0000e+00, 0.0000e+00, 4.2814e-02, 4.0686e-03,
        0.0000e+00, 0.0000e+00, 3.8844e-02, 2.7552e-03, 0.0000e+00, 0.0000e+00,
        2.5235e-02, 7.3314e-04, 0.0000e+00, 0.0000e+00, 2.1797e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.6515e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9495e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:36:38,090 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4483775663879484
2024-04-25 08:36:38,093 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-25 08:36:38,123 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #28: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 3, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.53, '(min, 1)': 0.06}}
2024-04-25 08:36:38,124 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:38,125 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-04-25 08:36:38,155 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #28: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.47, '(min, 1)': 0.11}}
2024-04-25 08:36:38,155 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:38,156 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-04-25 08:36:39,064 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #28: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.15789473684210525, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 6)': 0.01, '(min, 0)': 0.56, '(min, 1)': 0.13, '(rev, 1)': 0.03, '(rev, 3)': 0.01}}
2024-04-25 08:36:39,064 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:39,065 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-04-25 08:36:39,133 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #28: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3137254901960784, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.2, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-25 08:36:39,133 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:39,134 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-04-25 08:36:39,284 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #28: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3023255813953488, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 8)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.29, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 4)': 0.01}}
2024-04-25 08:36:39,284 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:39,284 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-04-25 08:36:39,332 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #28: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46938775510204084, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.33, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-25 08:36:39,332 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:39,333 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-04-25 08:36:40,521 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #28: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.11904761904761904, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.27, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-25 08:36:40,521 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:40,522 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-04-25 08:36:40,679 - MainProcess - INFO - text_logger.py - 51 - Train epoch #28
2024-04-25 08:36:40,682 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.2922e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.0455e-01,
         0.0000e+00,  1.4960e-01,  2.4424e-03,  2.1049e-01,  0.0000e+00,
         7.3082e-02,  1.5450e-03,  0.0000e+00,  0.0000e+00,  6.6095e-02,
         5.5574e-04,  0.0000e+00,  0.0000e+00,  5.1940e-02,  4.3512e-04,
         0.0000e+00,  0.0000e+00,  4.5993e-02,  9.1847e-05,  0.0000e+00,
         0.0000e+00,  4.2696e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.5036e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.0903e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.0616e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  4.8304e-04,  0.0000e+00,  0.0000e+00])  tensor([1.8604e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2621e-01, 0.0000e+00,
        8.7464e-02, 6.8842e-03, 1.3470e-01, 0.0000e+00, 5.7375e-02, 5.2099e-03,
        0.0000e+00, 0.0000e+00, 5.6781e-02, 2.9388e-03, 0.0000e+00, 0.0000e+00,
        4.8320e-02, 3.0446e-03, 0.0000e+00, 0.0000e+00, 4.4906e-02, 1.4662e-03,
        0.0000e+00, 0.0000e+00, 4.3466e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7660e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5715e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.7403e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7830e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:36:40,704 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4474353321698278
2024-04-25 08:36:40,706 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-25 08:36:40,710 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #29: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.53, '(min, 1)': 0.08}}
2024-04-25 08:36:40,710 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:40,711 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-04-25 08:36:40,757 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #29: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 4, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.55, '(min, 1)': 0.08}}
2024-04-25 08:36:40,757 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:40,758 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-04-25 08:36:41,782 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #29: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1276595744680851, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 5)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.14, '(rev, 1)': 0.05, '(rev, 3)': 0.01}}
2024-04-25 08:36:41,782 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:41,783 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-04-25 08:36:41,843 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #29: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 5, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17391304347826086, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.15, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-04-25 08:36:41,843 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:41,844 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-04-25 08:36:42,593 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #29: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 6, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 5, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.9024390243902439, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 3)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.46, '(rev, 1)': 0.12, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-25 08:36:42,594 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:42,594 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-04-25 08:36:43,219 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #29: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 4, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10256410256410256, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(ado, 5)': 0.02, '(min, 0)': 0.62, '(min, 1)': 0.13, '(rev, 1)': 0.02, '(rev, 2)': 0.02}}
2024-04-25 08:36:43,219 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:43,220 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-04-25 08:36:45,010 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #29: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2894736842105263, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.34, '(rev, 1)': 0.04, '(rev, 9)': 0.01}}
2024-04-25 08:36:45,010 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:45,011 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-04-25 08:36:45,180 - MainProcess - INFO - text_logger.py - 51 - Train epoch #29
2024-04-25 08:36:45,183 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.0570e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6026e-01, 0.0000e+00,
        1.3872e-01, 2.5162e-03, 2.5938e-01, 0.0000e+00, 5.5983e-02, 1.3172e-03,
        0.0000e+00, 0.0000e+00, 4.8970e-02, 8.0481e-04, 0.0000e+00, 0.0000e+00,
        3.6416e-02, 3.7067e-04, 0.0000e+00, 0.0000e+00, 3.1473e-02, 2.2070e-04,
        0.0000e+00, 0.0000e+00, 2.8553e-02, 6.8765e-05, 0.0000e+00, 0.0000e+00,
        1.7496e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4620e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.4258e-03, 5.2632e-05, 0.0000e+00, 0.0000e+00,
        3.5388e-04, 0.0000e+00, 0.0000e+00])  tensor([1.8385e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1610e-01, 0.0000e+00,
        9.3295e-02, 6.9465e-03, 1.3719e-01, 0.0000e+00, 5.8372e-02, 4.6119e-03,
        0.0000e+00, 0.0000e+00, 5.6103e-02, 3.7532e-03, 0.0000e+00, 0.0000e+00,
        4.5034e-02, 2.7978e-03, 0.0000e+00, 0.0000e+00, 4.1332e-02, 2.0358e-03,
        0.0000e+00, 0.0000e+00, 3.8711e-02, 1.0938e-03, 0.0000e+00, 0.0000e+00,
        2.5472e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2121e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.0205e-03, 1.1769e-03, 0.0000e+00, 0.0000e+00,
        2.3896e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:36:45,209 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4464930979517072
2024-04-25 08:36:45,211 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-25 08:36:45,243 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #30: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 1, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.21621621621621623, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.35, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-25 08:36:45,244 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:45,244 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-04-25 08:36:45,259 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #30: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.3157894736842105, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 2)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.09, '(rev, 1)': 0.03}}
2024-04-25 08:36:45,259 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #30: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40540540540540543, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(min, 0)': 0.37, '(min, 1)': 0.28, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.03}}
2024-04-25 08:36:45,260 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:45,260 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:45,260 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-04-25 08:36:45,260 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-04-25 08:36:45,276 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #30: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.6, '(min, 1)': 0.03, '(rev, 1)': 0.01}}
2024-04-25 08:36:45,276 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:45,276 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-04-25 08:36:45,628 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #30: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.4, '(rev, 1)': 0.04, '(rev, 2)': 0.06, '(rev, 3)': 0.03}}
2024-04-25 08:36:45,628 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:45,629 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-04-25 08:36:46,381 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #30: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.41, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 5)': 0.01}}
2024-04-25 08:36:46,381 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:46,382 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-04-25 08:36:48,706 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #30: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.07692307692307693, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.05, '(ado, 3)': 0.02, '(ado, 4)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.29, '(rev, 1)': 0.02, '(rev, 4)': 0.01}}
2024-04-25 08:36:48,707 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:48,707 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-04-25 08:36:48,860 - MainProcess - INFO - text_logger.py - 51 - Train epoch #30
2024-04-25 08:36:48,863 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.7532e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6311e-01, 0.0000e+00,
        1.2593e-01, 2.5290e-03, 2.6211e-01, 0.0000e+00, 5.5797e-02, 1.3070e-03,
        0.0000e+00, 0.0000e+00, 4.6264e-02, 5.6427e-04, 0.0000e+00, 0.0000e+00,
        3.9344e-02, 1.8476e-04, 0.0000e+00, 0.0000e+00, 3.5042e-02, 3.0303e-05,
        0.0000e+00, 0.0000e+00, 3.1175e-02, 3.0303e-05, 0.0000e+00, 0.0000e+00,
        1.9243e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4506e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.4759e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5609e-04, 0.0000e+00, 0.0000e+00])  tensor([1.9831e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2236e-01, 0.0000e+00,
        8.9290e-02, 7.0529e-03, 1.4228e-01, 0.0000e+00, 6.2259e-02, 4.8008e-03,
        0.0000e+00, 0.0000e+00, 5.4958e-02, 3.3656e-03, 0.0000e+00, 0.0000e+00,
        5.0090e-02, 1.8508e-03, 0.0000e+00, 0.0000e+00, 4.6462e-02, 6.7760e-04,
        0.0000e+00, 0.0000e+00, 4.2285e-02, 6.7760e-04, 0.0000e+00, 0.0000e+00,
        2.7780e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3807e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.1104e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.4065e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:36:48,882 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.44595626913899206
2024-04-25 08:36:48,884 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.202700.20270
2024-04-25 08:36:48,891 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #31: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 5, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 6, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.35, '(min, 1)': 0.25}}
2024-04-25 08:36:48,892 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:48,893 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-04-25 08:36:48,906 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #31: {'transition': '(exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 1, 5, 8, 1, 1),(min, 0)->(exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 1, 5, 9, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 8)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.2}}
2024-04-25 08:36:48,906 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #31: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.2, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-25 08:36:48,906 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:48,907 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-04-25 08:36:48,911 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-04-25 08:36:49,048 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #31: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.047619047619047616, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 4)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.17, '(rev, 1)': 0.04}}
2024-04-25 08:36:49,048 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:49,049 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-04-25 08:36:49,285 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #31: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0425531914893617, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.18, '(rev, 1)': 0.03}}
2024-04-25 08:36:49,285 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:49,286 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-04-25 08:36:49,296 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #31: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.22, '(rev, 1)': 0.03, '(rev, 3)': 0.01, '(rev, 7)': 0.01}}
2024-04-25 08:36:49,296 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:49,297 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-04-25 08:36:51,974 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #31: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.075, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.22, '(rev, 1)': 0.04}}
2024-04-25 08:36:51,974 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:51,975 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-04-25 08:36:52,134 - MainProcess - INFO - text_logger.py - 51 - Train epoch #31
2024-04-25 08:36:52,137 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-2.7033e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.3465e-01,
         0.0000e+00,  1.4433e-01,  1.7652e-03,  2.4880e-01,  0.0000e+00,
         6.2395e-02,  4.8541e-04,  0.0000e+00,  0.0000e+00,  5.2590e-02,
         2.1400e-04,  0.0000e+00,  0.0000e+00,  4.3628e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.8027e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  3.4583e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.0476e-02,  5.4054e-05,  0.0000e+00,  0.0000e+00,  1.5401e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.2866e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.2234e-04,  0.0000e+00,  0.0000e+00])  tensor([1.6936e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1740e-01, 0.0000e+00,
        8.8082e-02, 6.0241e-03, 1.4142e-01, 0.0000e+00, 5.9984e-02, 2.9068e-03,
        0.0000e+00, 0.0000e+00, 5.4355e-02, 2.3392e-03, 0.0000e+00, 0.0000e+00,
        4.9184e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5958e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.3724e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7722e-02, 1.2087e-03, 0.0000e+00, 0.0000e+00, 2.4159e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.9994e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.6278e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:36:52,157 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4450140349208715
2024-04-25 08:36:52,159 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-25 08:36:52,171 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #32: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 4)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.33, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 4)': 0.01}}
2024-04-25 08:36:52,171 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:52,172 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-04-25 08:36:52,181 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #32: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.06666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.29, '(rev, 1)': 0.04, '(rev, 2)': 0.02}}
2024-04-25 08:36:52,182 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #32: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.021739130434782608, 'length': 100, 'actions': {'(ado, 1)': 0.45, '(min, 0)': 0.41, '(min, 1)': 0.13, '(rev, 1)': 0.01}}
2024-04-25 08:36:52,182 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:52,182 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:52,183 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-04-25 08:36:52,183 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-04-25 08:36:52,184 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #32: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1590909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.31, '(min, 1)': 0.26, '(rev, 1)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-25 08:36:52,184 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:52,202 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-04-25 08:36:52,220 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #32: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.18604651162790697, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 8)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.3, '(rev, 1)': 0.1}}
2024-04-25 08:36:52,220 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:52,222 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-04-25 08:36:52,225 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #32: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.14583333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.16, '(rev, 1)': 0.07, '(rev, 2)': 0.01}}
2024-04-25 08:36:52,225 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:52,225 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-04-25 08:36:55,093 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #32: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.673469387755102, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.5, '(rev, 1)': 0.13, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-25 08:36:55,093 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:55,093 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-04-25 08:36:55,250 - MainProcess - INFO - text_logger.py - 51 - Train epoch #32
2024-04-25 08:36:55,253 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.7473e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2942e-01, 0.0000e+00,
        1.0267e-01, 3.3771e-03, 2.8620e-01, 0.0000e+00, 3.8527e-02, 2.6509e-03,
        0.0000e+00, 0.0000e+00, 3.4417e-02, 1.0354e-03, 0.0000e+00, 0.0000e+00,
        2.7638e-02, 4.6464e-04, 0.0000e+00, 0.0000e+00, 2.4567e-02, 1.5421e-04,
        0.0000e+00, 0.0000e+00, 2.1907e-02, 5.4143e-05, 0.0000e+00, 0.0000e+00,
        1.4664e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0558e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.5290e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6321e-04, 0.0000e+00, 0.0000e+00])  tensor([2.0453e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1956e-01, 0.0000e+00,
        8.7934e-02, 7.6739e-03, 1.3261e-01, 0.0000e+00, 5.7518e-02, 6.3132e-03,
        0.0000e+00, 0.0000e+00, 5.4034e-02, 4.0784e-03, 0.0000e+00, 0.0000e+00,
        4.5335e-02, 2.6953e-03, 0.0000e+00, 0.0000e+00, 4.0995e-02, 1.5475e-03,
        0.0000e+00, 0.0000e+00, 3.6991e-02, 8.5592e-04, 0.0000e+00, 0.0000e+00,
        2.5300e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9965e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.5251e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6437e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:36:55,272 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.44425263074227656
2024-04-25 08:36:55,274 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.090420.06868
2024-04-25 08:36:55,313 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #33: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 7)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.37, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-25 08:36:55,313 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:55,314 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-04-25 08:36:55,328 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #33: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.45, '(rev, 1)': 0.13, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-25 08:36:55,328 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:55,329 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-04-25 08:36:55,583 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #33: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.65, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.47, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-25 08:36:55,583 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:55,584 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-04-25 08:36:55,625 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #33: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 8, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3611111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.42, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.02}}
2024-04-25 08:36:55,626 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:55,626 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-04-25 08:36:55,879 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #33: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 8)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.41, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-25 08:36:55,879 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:55,880 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-04-25 08:36:55,928 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #33: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.9333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 3)': 0.03, '(min, 0)': 0.21, '(min, 1)': 0.46, '(rev, 1)': 0.11, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.03}}
2024-04-25 08:36:55,928 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:55,928 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-04-25 08:36:58,041 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #33: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46153846153846156, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.16, '(min, 1)': 0.49, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-25 08:36:58,042 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:58,042 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-04-25 08:36:58,195 - MainProcess - INFO - text_logger.py - 51 - Train epoch #33
2024-04-25 08:36:58,198 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.7745e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5310e-01, 0.0000e+00,
        5.4962e-02, 4.5035e-03, 3.5012e-01, 0.0000e+00, 9.8829e-03, 3.7582e-03,
        0.0000e+00, 0.0000e+00, 6.5385e-03, 2.2386e-03, 0.0000e+00, 0.0000e+00,
        4.1994e-03, 1.2557e-03, 0.0000e+00, 0.0000e+00, 3.5443e-03, 4.9375e-05,
        0.0000e+00, 0.0000e+00, 2.7762e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8191e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1763e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.9482e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.9291e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1101e-01, 0.0000e+00,
        5.9400e-02, 8.4329e-03, 6.8257e-02, 0.0000e+00, 2.8972e-02, 7.2873e-03,
        0.0000e+00, 0.0000e+00, 2.4829e-02, 5.7743e-03, 0.0000e+00, 0.0000e+00,
        2.0111e-02, 4.8777e-03, 0.0000e+00, 0.0000e+00, 1.8135e-02, 7.8461e-04,
        0.0000e+00, 0.0000e+00, 1.4630e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0142e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0861e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1016e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:36:58,217 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4438671598091802
2024-04-25 08:36:58,219 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.278380.08273
2024-04-25 08:36:58,226 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #34: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.4, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-25 08:36:58,226 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:58,227 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-04-25 08:36:58,257 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #34: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 2, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 1, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.14583333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.14, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-25 08:36:58,258 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:58,258 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #34: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.02, '(min, 0)': 0.02, '(min, 1)': 0.59, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-25 08:36:58,258 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:58,258 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-04-25 08:36:58,259 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-04-25 08:36:58,628 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #34: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.41, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-04-25 08:36:58,629 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:58,629 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-04-25 08:36:59,474 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #34: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8536585365853658, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 3)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.38, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.05, '(rev, 4)': 0.01}}
2024-04-25 08:36:59,474 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:59,475 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-04-25 08:36:59,973 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #34: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.39, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-04-25 08:36:59,973 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:36:59,974 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-04-25 08:37:00,715 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #34: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.42, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-25 08:37:00,715 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:00,715 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-04-25 08:37:00,868 - MainProcess - INFO - text_logger.py - 51 - Train epoch #34
2024-04-25 08:37:00,871 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.6787e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3925e-01, 0.0000e+00,
        5.7046e-02, 3.5841e-03, 3.5119e-01, 0.0000e+00, 1.1492e-02, 2.5135e-03,
        0.0000e+00, 0.0000e+00, 8.6446e-03, 1.7342e-03, 0.0000e+00, 0.0000e+00,
        6.5222e-03, 7.7687e-04, 0.0000e+00, 0.0000e+00, 5.6638e-03, 2.8676e-04,
        0.0000e+00, 0.0000e+00, 5.0297e-03, 2.0236e-04, 0.0000e+00, 0.0000e+00,
        3.2860e-03, 8.5497e-05, 0.0000e+00, 0.0000e+00, 2.3248e-03, 2.9412e-05,
        0.0000e+00, 0.0000e+00, 3.4415e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.0733e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3376e-01, 0.0000e+00,
        7.7735e-02, 7.7528e-03, 8.3435e-02, 0.0000e+00, 3.1336e-02, 6.2321e-03,
        0.0000e+00, 0.0000e+00, 2.8509e-02, 5.6695e-03, 0.0000e+00, 0.0000e+00,
        2.4309e-02, 3.7455e-03, 0.0000e+00, 0.0000e+00, 2.2033e-02, 2.0189e-03,
        0.0000e+00, 0.0000e+00, 2.0216e-02, 1.7100e-03, 0.0000e+00, 0.0000e+00,
        1.3457e-02, 1.1052e-03, 0.0000e+00, 0.0000e+00, 1.0048e-02, 6.5767e-04,
        0.0000e+00, 0.0000e+00, 2.5658e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:37:00,897 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4433968458809146
2024-04-25 08:37:00,900 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.235960.09013
2024-04-25 08:37:00,940 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #35: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36363636363636365, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.21, '(min, 1)': 0.38, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-25 08:37:00,940 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:00,941 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-04-25 08:37:01,276 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #35: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5853658536585366, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.5, '(min, 1)': 0.15, '(rev, 1)': 0.13, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 7)': 0.01}}
2024-04-25 08:37:01,276 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:01,277 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-04-25 08:37:01,341 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #35: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.875, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.13, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-25 08:37:01,341 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:01,342 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-04-25 08:37:02,069 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #35: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.022222222222222223, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.16, '(rev, 1)': 0.02}}
2024-04-25 08:37:02,070 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:02,070 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-04-25 08:37:02,693 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #35: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(ado, 3)': 0.02, '(min, 0)': 0.16, '(min, 1)': 0.43, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-25 08:37:02,694 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:02,694 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-04-25 08:37:02,727 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #35: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3611111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.43, '(min, 1)': 0.24, '(rev, 1)': 0.03, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-04-25 08:37:02,727 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:02,728 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-04-25 08:37:03,192 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #35: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0),(ado, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/3', 'revenue': 0.22727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.32, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-25 08:37:03,192 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:03,193 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-04-25 08:37:03,365 - MainProcess - INFO - text_logger.py - 51 - Train epoch #35
2024-04-25 08:37:03,367 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.5027e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6094e-01, 0.0000e+00,
        9.1682e-02, 3.1678e-03, 3.2056e-01, 0.0000e+00, 2.8251e-02, 1.7722e-03,
        0.0000e+00, 0.0000e+00, 2.3475e-02, 8.5122e-04, 0.0000e+00, 0.0000e+00,
        1.9432e-02, 4.5675e-04, 0.0000e+00, 0.0000e+00, 1.6489e-02, 2.1472e-04,
        0.0000e+00, 0.0000e+00, 1.4705e-02, 5.5787e-05, 0.0000e+00, 0.0000e+00,
        9.9476e-03, 3.2258e-05, 0.0000e+00, 0.0000e+00, 6.5854e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2015e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7739e-04, 0.0000e+00, 0.0000e+00])  tensor([1.9334e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9373e-01, 0.0000e+00,
        9.0088e-02, 7.5665e-03, 1.2169e-01, 0.0000e+00, 4.9270e-02, 5.4956e-03,
        0.0000e+00, 0.0000e+00, 4.5964e-02, 4.2107e-03, 0.0000e+00, 0.0000e+00,
        4.0440e-02, 3.1279e-03, 0.0000e+00, 0.0000e+00, 3.5775e-02, 2.2166e-03,
        0.0000e+00, 0.0000e+00, 3.2249e-02, 8.9196e-04, 0.0000e+00, 0.0000e+00,
        2.2950e-02, 7.2131e-04, 0.0000e+00, 0.0000e+00, 1.5986e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.6793e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6406e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:37:03,389 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.443403613880089
2024-04-25 08:37:03,391 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.474500.11086
2024-04-25 08:37:03,422 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #36: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3404255319148936, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.42, '(min, 1)': 0.13, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 4)': 0.01}}
2024-04-25 08:37:03,422 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:03,423 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-04-25 08:37:04,084 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #36: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.5, '(min, 1)': 0.12, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-25 08:37:04,084 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:04,085 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-04-25 08:37:04,600 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #36: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(min, 0)': 0.37, '(min, 1)': 0.19, '(rev, 1)': 0.12, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-25 08:37:04,601 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:04,601 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-04-25 08:37:05,104 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #36: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0975609756097561, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.5, '(min, 1)': 0.1, '(rev, 1)': 0.01, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-25 08:37:05,105 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:05,107 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-04-25 08:37:05,210 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #36: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.42, '(min, 1)': 0.17, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 6)': 0.01}}
2024-04-25 08:37:05,211 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:05,211 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-04-25 08:37:05,596 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #36: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3958333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 5)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.19, '(rev, 1)': 0.1, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-04-25 08:37:05,597 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:05,597 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-04-25 08:37:06,400 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #36: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 7, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.675, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.38, '(min, 1)': 0.25, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-04-25 08:37:06,401 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:06,401 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-04-25 08:37:06,547 - MainProcess - INFO - text_logger.py - 51 - Train epoch #36
2024-04-25 08:37:06,551 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.6275e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4567e-01, 0.0000e+00,
        5.9283e-02, 5.7920e-03, 3.7365e-01, 0.0000e+00, 5.6156e-03, 2.9363e-03,
        0.0000e+00, 0.0000e+00, 2.5923e-03, 8.3475e-04, 0.0000e+00, 0.0000e+00,
        1.0488e-03, 4.4797e-04, 0.0000e+00, 0.0000e+00, 6.9893e-04, 2.1204e-04,
        0.0000e+00, 0.0000e+00, 4.7149e-04, 5.5556e-05, 0.0000e+00, 0.0000e+00,
        4.3759e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5269e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.1984, 0.0000, 0.0000, 0.0000, 0.0729, 0.0000, 0.0638, 0.0097, 0.0418,
        0.0000, 0.0198, 0.0071, 0.0000, 0.0000, 0.0141, 0.0038, 0.0000, 0.0000,
        0.0097, 0.0029, 0.0000, 0.0000, 0.0085, 0.0023, 0.0000, 0.0000, 0.0061,
        0.0012, 0.0000, 0.0000, 0.0056, 0.0000, 0.0000, 0.0000, 0.0033, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-04-25 08:37:06,570 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4428993661694931
2024-04-25 08:37:06,572 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.218990.12143
2024-04-25 08:37:06,817 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #37: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 2, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.47, '(min, 1)': 0.07, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-25 08:37:06,817 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:06,818 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-04-25 08:37:07,036 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #37: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.05, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.44, '(min, 1)': 0.16, '(rev, 1)': 0.02}}
2024-04-25 08:37:07,037 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:07,037 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-04-25 08:37:07,296 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #37: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.30434782608695654, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.23, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-25 08:37:07,296 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:07,297 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-04-25 08:37:07,386 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #37: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.53, '(min, 1)': 0.08}}
2024-04-25 08:37:07,387 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:07,387 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-04-25 08:37:07,980 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #37: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7045454545454546, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.27, '(rev, 1)': 0.09, '(rev, 2)': 0.08, '(rev, 3)': 0.02}}
2024-04-25 08:37:07,980 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:07,981 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-04-25 08:37:08,383 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #37: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5909090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(min, 0)': 0.39, '(min, 1)': 0.23, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-25 08:37:08,383 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:08,383 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-04-25 08:37:09,241 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #37: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.46808510638297873, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.4, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-04-25 08:37:09,241 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:09,242 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-04-25 08:37:09,403 - MainProcess - INFO - text_logger.py - 51 - Train epoch #37
2024-04-25 08:37:09,407 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.0497e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5267e-01, 0.0000e+00,
        5.7198e-02, 5.0781e-03, 3.7242e-01, 0.0000e+00, 4.8975e-03, 2.8911e-03,
        0.0000e+00, 0.0000e+00, 1.6209e-03, 1.1614e-03, 0.0000e+00, 0.0000e+00,
        2.1440e-04, 7.0649e-04, 0.0000e+00, 0.0000e+00, 5.4444e-05, 3.3365e-04,
        0.0000e+00, 0.0000e+00, 2.7778e-05, 2.9238e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.1545e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2525e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0159e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5787e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.1285e-02, 0.0000e+00,
        7.2278e-02, 9.3626e-03, 4.3856e-02, 0.0000e+00, 1.7571e-02, 7.2379e-03,
        0.0000e+00, 0.0000e+00, 1.0143e-02, 4.5829e-03, 0.0000e+00, 0.0000e+00,
        2.4562e-03, 4.0358e-03, 0.0000e+00, 0.0000e+00, 8.6016e-04, 2.6658e-03,
        0.0000e+00, 0.0000e+00, 6.2113e-04, 2.5146e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.8434e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4082e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1721e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:37:09,431 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4420071319513725
2024-04-25 08:37:09,433 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.025000.02500
2024-04-25 08:37:09,467 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #38: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 3, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.56, '(min, 1)': 0.02}}
2024-04-25 08:37:09,467 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:09,468 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-04-25 08:37:09,472 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #38: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 6)': 0.01, '(min, 0)': 0.52, '(min, 1)': 0.06, '(rev, 1)': 0.09, '(rev, 2)': 0.05}}
2024-04-25 08:37:09,472 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:09,472 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-04-25 08:37:09,665 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #38: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35714285714285715, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(min, 0)': 0.45, '(min, 1)': 0.1, '(rev, 1)': 0.13, '(rev, 2)': 0.05}}
2024-04-25 08:37:09,665 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:09,666 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-04-25 08:37:09,755 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #38: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.52, '(min, 1)': 0.07}}
2024-04-25 08:37:09,755 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:09,756 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-04-25 08:37:11,230 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #38: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10869565217391304, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.16, '(rev, 1)': 0.04, '(rev, 2)': 0.01}}
2024-04-25 08:37:11,230 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:11,231 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-04-25 08:37:11,877 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #38: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.23, '(rev, 1)': 0.07, '(rev, 2)': 0.03}}
2024-04-25 08:37:11,877 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:11,878 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-04-25 08:37:11,896 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #38: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.2, '(rev, 1)': 0.08, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-04-25 08:37:11,896 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:11,896 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-04-25 08:37:12,054 - MainProcess - INFO - text_logger.py - 51 - Train epoch #38
2024-04-25 08:37:12,057 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.3554e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1297e-01, 0.0000e+00,
        7.1020e-02, 4.5371e-03, 3.5940e-01, 0.0000e+00, 1.3672e-02, 2.0646e-03,
        0.0000e+00, 0.0000e+00, 1.0424e-02, 5.5125e-04, 0.0000e+00, 0.0000e+00,
        7.5413e-03, 4.2356e-04, 0.0000e+00, 0.0000e+00, 6.1637e-03, 1.6311e-04,
        0.0000e+00, 0.0000e+00, 5.0178e-03, 1.0477e-04, 0.0000e+00, 0.0000e+00,
        3.2647e-03, 7.6197e-05, 0.0000e+00, 0.0000e+00, 2.2205e-03, 3.7736e-05,
        0.0000e+00, 0.0000e+00, 3.1624e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9412e-05, 0.0000e+00, 0.0000e+00])  tensor([1.2837e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3079e-01, 0.0000e+00,
        7.6764e-02, 8.9754e-03, 7.9060e-02, 0.0000e+00, 3.3122e-02, 6.0420e-03,
        0.0000e+00, 0.0000e+00, 3.0915e-02, 3.2128e-03, 0.0000e+00, 0.0000e+00,
        2.5148e-02, 3.0364e-03, 0.0000e+00, 0.0000e+00, 2.1439e-02, 1.6557e-03,
        0.0000e+00, 0.0000e+00, 1.8482e-02, 1.3611e-03, 0.0000e+00, 0.0000e+00,
        1.3349e-02, 1.2036e-03, 0.0000e+00, 0.0000e+00, 9.2802e-03, 8.4380e-04,
        0.0000e+00, 0.0000e+00, 2.3659e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.5767e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:37:12,082 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.44106489773325186
2024-04-25 08:37:12,084 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-25 08:37:12,147 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #39: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.44, '(min, 1)': 0.14, '(rev, 1)': 0.12, '(rev, 2)': 0.05}}
2024-04-25 08:37:12,147 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:12,148 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-04-25 08:37:12,383 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #39: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4318181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.49, '(min, 1)': 0.1, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 4)': 0.02}}
2024-04-25 08:37:12,383 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:12,384 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-04-25 08:37:12,536 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #39: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 4, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.58, '(min, 1)': 0.04}}
2024-04-25 08:37:12,536 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:12,537 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-04-25 08:37:14,157 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #39: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3023255813953488, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.42, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-25 08:37:14,157 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:14,158 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-04-25 08:37:14,435 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #39: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.51, '(min, 1)': 0.06}}
2024-04-25 08:37:14,435 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:14,436 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-04-25 08:37:14,528 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #39: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.1, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-25 08:37:14,528 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:14,530 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-04-25 08:37:14,683 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #39: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 4, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4883720930232558, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(min, 0)': 0.48, '(min, 1)': 0.11, '(rev, 1)': 0.12, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-25 08:37:14,683 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:14,684 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-04-25 08:37:14,858 - MainProcess - INFO - text_logger.py - 51 - Train epoch #39
2024-04-25 08:37:14,862 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.1386e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5382e-01, 0.0000e+00,
        4.7238e-02, 5.6896e-03, 3.8523e-01, 0.0000e+00, 3.1374e-03, 2.5391e-03,
        0.0000e+00, 0.0000e+00, 1.1484e-03, 6.3202e-04, 0.0000e+00, 0.0000e+00,
        1.9520e-04, 2.2575e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2219e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4483e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.4483e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([9.6098e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0373e-02, 0.0000e+00,
        5.2764e-02, 9.6935e-03, 2.7179e-02, 0.0000e+00, 1.2418e-02, 6.6354e-03,
        0.0000e+00, 0.0000e+00, 7.7827e-03, 3.3695e-03, 0.0000e+00, 0.0000e+00,
        3.1085e-03, 1.9123e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1419e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7106e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.7106e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:37:14,887 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4401226635151313
2024-04-25 08:37:14,890 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-25 08:37:15,342 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #40: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1282051282051282, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(min, 0)': 0.48, '(min, 1)': 0.11, '(rev, 1)': 0.04, '(rev, 2)': 0.03}}
2024-04-25 08:37:15,343 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:15,343 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-04-25 08:37:15,889 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #40: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.375, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 5)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.22, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-25 08:37:15,889 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:15,890 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-04-25 08:37:18,043 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #40: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.8541666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 7)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-04-25 08:37:18,044 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:18,045 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-04-25 08:37:18,822 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #40: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-04-25 08:37:18,823 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:18,823 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-04-25 08:37:19,398 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #40: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.41, '(min, 1)': 0.21, '(rev, 1)': 0.06, '(rev, 2)': 0.07, '(rev, 3)': 0.02}}
2024-04-25 08:37:19,398 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:19,399 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-04-25 08:37:19,552 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #40: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46808510638297873, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.28, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-25 08:37:19,552 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:37:19,553 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-04-25 08:38:18,027 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #40: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5434782608695652, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 7)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.19, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-04-25 08:38:18,028 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:18,028 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-04-25 08:38:18,137 - MainProcess - INFO - text_logger.py - 51 - Train epoch #40
2024-04-25 08:38:18,141 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-6.5838e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  5.0324e-01,
         0.0000e+00,  7.4070e-02,  4.4900e-03,  3.5479e-01,  0.0000e+00,
         1.5824e-02,  2.0706e-03,  0.0000e+00,  0.0000e+00,  1.3075e-02,
         8.2001e-04,  0.0000e+00,  0.0000e+00,  8.9763e-03,  3.6859e-04,
         0.0000e+00,  0.0000e+00,  7.8520e-03,  1.2269e-04,  0.0000e+00,
         0.0000e+00,  6.6181e-03,  7.9216e-05,  0.0000e+00,  0.0000e+00,
         4.2282e-03,  4.0000e-05,  0.0000e+00,  0.0000e+00,  2.8986e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.8957e-04,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  5.2303e-05,  0.0000e+00,  0.0000e+00])  tensor([1.6946e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4118e-01, 0.0000e+00,
        8.6325e-02, 8.8986e-03, 8.2653e-02, 0.0000e+00, 3.2707e-02, 6.0398e-03,
        0.0000e+00, 0.0000e+00, 3.1210e-02, 4.0749e-03, 0.0000e+00, 0.0000e+00,
        2.3238e-02, 2.7199e-03, 0.0000e+00, 0.0000e+00, 2.1577e-02, 1.5824e-03,
        0.0000e+00, 0.0000e+00, 1.9371e-02, 1.2513e-03, 0.0000e+00, 0.0000e+00,
        1.3257e-02, 8.9443e-04, 0.0000e+00, 0.0000e+00, 9.9011e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.6633e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.4177e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:38:18,165 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.440578074224547
2024-04-25 08:38:18,167 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.698820.15534
2024-04-25 08:38:18,190 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #41: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 6)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.16, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-25 08:38:18,190 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:18,191 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-04-25 08:38:18,191 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #41: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.023255813953488372, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 6)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.1, '(rev, 1)': 0.02}}
2024-04-25 08:38:18,195 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:18,200 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-04-25 08:38:19,210 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #41: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.52, '(min, 1)': 0.08, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-04-25 08:38:19,210 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:19,212 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-04-25 08:38:20,053 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #41: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5869565217391305, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(min, 0)': 0.29, '(min, 1)': 0.26, '(rev, 1)': 0.11, '(rev, 2)': 0.05}}
2024-04-25 08:38:20,053 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:20,054 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-04-25 08:38:20,121 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #41: {'transition': '(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 2, 5, 1, 1),(min, 0)->(exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 3, 5, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.41, '(min, 1)': 0.19, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-25 08:38:20,121 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:20,121 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-04-25 08:38:20,762 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #41: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 6, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40476190476190477, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.43, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-25 08:38:20,762 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:20,763 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-04-25 08:38:21,765 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #41: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6428571428571429, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(min, 0)': 0.27, '(min, 1)': 0.36, '(rev, 1)': 0.11, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-25 08:38:21,766 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:21,767 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-04-25 08:38:21,843 - MainProcess - INFO - text_logger.py - 51 - Train epoch #41
2024-04-25 08:38:21,847 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-2.4780e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.8062e-01,
         0.0000e+00,  8.2155e-02,  4.1523e-03,  3.3818e-01,  0.0000e+00,
         2.0960e-02,  1.6970e-03,  0.0000e+00,  0.0000e+00,  1.7971e-02,
         6.1111e-04,  0.0000e+00,  0.0000e+00,  1.3415e-02,  5.1597e-04,
         0.0000e+00,  0.0000e+00,  1.2301e-02,  3.4116e-04,  0.0000e+00,
         0.0000e+00,  1.0902e-02,  3.7958e-04,  0.0000e+00,  0.0000e+00,
         7.9294e-03,  1.3486e-04,  0.0000e+00,  0.0000e+00,  6.2985e-03,
         3.5714e-05,  0.0000e+00,  0.0000e+00,  1.2318e-03,  3.5714e-05,
         0.0000e+00,  0.0000e+00,  1.3438e-04,  0.0000e+00,  0.0000e+00])  tensor([1.8187e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7119e-01, 0.0000e+00,
        1.0330e-01, 8.6674e-03, 1.0216e-01, 0.0000e+00, 3.8422e-02, 5.4138e-03,
        0.0000e+00, 0.0000e+00, 3.5712e-02, 3.4326e-03, 0.0000e+00, 0.0000e+00,
        2.7495e-02, 3.1188e-03, 0.0000e+00, 0.0000e+00, 2.5936e-02, 2.4066e-03,
        0.0000e+00, 0.0000e+00, 2.3552e-02, 2.9703e-03, 0.0000e+00, 0.0000e+00,
        1.7384e-02, 1.5086e-03, 0.0000e+00, 0.0000e+00, 1.4009e-02, 7.9860e-04,
        0.0000e+00, 0.0000e+00, 4.6836e-03, 7.9860e-04, 0.0000e+00, 0.0000e+00,
        1.5078e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:38:21,872 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4405786971492836
2024-04-25 08:38:21,875 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.471430.17143
2024-04-25 08:38:21,922 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2692307692307692, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 7)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.18, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-25 08:38:21,922 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:21,923 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-04-25 08:38:22,878 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.48, '(min, 1)': 0.11}}
2024-04-25 08:38:22,879 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:22,880 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-04-25 08:38:23,311 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5294117647058824, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.17, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-04-25 08:38:23,311 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:23,313 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-04-25 08:38:24,257 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.045454545454545456, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.23, '(rev, 1)': 0.04}}
2024-04-25 08:38:24,258 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:24,258 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-04-25 08:38:25,122 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.36, '(min, 1)': 0.2, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-04-25 08:38:25,122 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:25,123 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-04-25 08:38:25,233 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7555555555555555, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(min, 0)': 0.37, '(min, 1)': 0.28, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.07, '(rev, 4)': 0.04}}
2024-04-25 08:38:25,233 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:25,234 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-04-25 08:38:25,252 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 8)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.31, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-04-25 08:38:25,252 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:25,253 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-04-25 08:38:25,415 - MainProcess - INFO - text_logger.py - 51 - Train epoch #42
2024-04-25 08:38:25,419 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.1348e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0159e-01, 0.0000e+00,
        6.9313e-02, 4.0843e-03, 3.4256e-01, 0.0000e+00, 1.8941e-02, 2.8893e-03,
        0.0000e+00, 0.0000e+00, 1.4575e-02, 2.1868e-03, 0.0000e+00, 0.0000e+00,
        1.0242e-02, 1.5799e-03, 0.0000e+00, 0.0000e+00, 9.8714e-03, 4.8663e-04,
        0.0000e+00, 0.0000e+00, 8.6144e-03, 3.6796e-04, 0.0000e+00, 0.0000e+00,
        6.2385e-03, 3.0907e-04, 0.0000e+00, 0.0000e+00, 4.9592e-03, 3.6364e-05,
        0.0000e+00, 0.0000e+00, 1.0056e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4532e-04, 0.0000e+00, 0.0000e+00])  tensor([2.0738e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6112e-01, 0.0000e+00,
        9.5430e-02, 8.2663e-03, 9.4860e-02, 0.0000e+00, 3.6711e-02, 6.6710e-03,
        0.0000e+00, 0.0000e+00, 3.2343e-02, 6.0066e-03, 0.0000e+00, 0.0000e+00,
        2.4618e-02, 5.4076e-03, 0.0000e+00, 0.0000e+00, 2.4410e-02, 2.8956e-03,
        0.0000e+00, 0.0000e+00, 2.1474e-02, 2.4863e-03, 0.0000e+00, 0.0000e+00,
        1.5873e-02, 2.2999e-03, 0.0000e+00, 0.0000e+00, 1.2975e-02, 8.1312e-04,
        0.0000e+00, 0.0000e+00, 4.2118e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4692e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:38:25,441 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43994757404227414
2024-04-25 08:38:25,444 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.155560.15556
2024-04-25 08:38:25,606 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #43: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 4, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 7)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.16, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-04-25 08:38:25,607 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:25,607 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-04-25 08:38:26,588 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #43: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 9, 3, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 9, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4594594594594595, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.21, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.04, '(rev, 5)': 0.01}}
2024-04-25 08:38:26,589 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:26,589 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-04-25 08:38:27,331 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #43: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 4, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 6)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.3}}
2024-04-25 08:38:27,331 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:27,333 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-04-25 08:38:28,023 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #43: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.23404255319148937, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.4, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-25 08:38:28,023 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:28,024 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-04-25 08:38:28,137 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #43: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 1),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 2, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.375, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.3, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-04-25 08:38:28,137 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:28,137 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-04-25 08:38:28,194 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #43: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 10)': 0.01, '(ado, 2)': 0.02, '(min, 0)': 0.45, '(min, 1)': 0.2, '(rev, 1)': 0.08, '(rev, 2)': 0.03}}
2024-04-25 08:38:28,194 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:28,195 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-04-25 08:38:28,460 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #43: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.08108108108108109, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(min, 0)': 0.43, '(min, 1)': 0.21, '(rev, 1)': 0.01, '(rev, 3)': 0.01}}
2024-04-25 08:38:28,460 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:28,461 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-04-25 08:38:28,542 - MainProcess - INFO - text_logger.py - 51 - Train epoch #43
2024-04-25 08:38:28,545 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.5734e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0649e-01, 0.0000e+00,
        7.2479e-02, 3.5302e-03, 3.4712e-01, 0.0000e+00, 1.7472e-02, 2.4893e-03,
        0.0000e+00, 0.0000e+00, 1.3313e-02, 1.6546e-03, 0.0000e+00, 0.0000e+00,
        8.9788e-03, 1.1303e-03, 0.0000e+00, 0.0000e+00, 8.2597e-03, 7.3222e-04,
        0.0000e+00, 0.0000e+00, 6.8963e-03, 5.7088e-04, 0.0000e+00, 0.0000e+00,
        4.1819e-03, 5.1313e-04, 0.0000e+00, 0.0000e+00, 3.2299e-03, 2.3399e-04,
        0.0000e+00, 0.0000e+00, 6.0997e-04, 3.6364e-05, 0.0000e+00, 0.0000e+00,
        8.2695e-05, 0.0000e+00, 0.0000e+00])  tensor([2.2182e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5520e-01, 0.0000e+00,
        9.5556e-02, 7.6240e-03, 9.0552e-02, 0.0000e+00, 3.5798e-02, 5.9175e-03,
        0.0000e+00, 0.0000e+00, 3.0487e-02, 5.0662e-03, 0.0000e+00, 0.0000e+00,
        2.1931e-02, 4.0308e-03, 0.0000e+00, 0.0000e+00, 2.2472e-02, 3.2606e-03,
        0.0000e+00, 0.0000e+00, 1.9894e-02, 2.8554e-03, 0.0000e+00, 0.0000e+00,
        1.3785e-02, 2.7135e-03, 0.0000e+00, 0.0000e+00, 1.1265e-02, 1.8800e-03,
        0.0000e+00, 0.0000e+00, 3.4288e-03, 8.1312e-04, 0.0000e+00, 0.0000e+00,
        1.0798e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:38:28,563 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4390864209052346
2024-04-25 08:38:28,565 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.040540.04054
2024-04-25 08:38:29,736 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.36, '(min, 1)': 0.27}}
2024-04-25 08:38:29,736 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:29,737 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-04-25 08:38:29,841 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 4)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.23, '(rev, 1)': 0.02, '(rev, 2)': 0.02, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-04-25 08:38:29,841 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:29,842 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-04-25 08:38:30,045 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.36, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 3)': 0.03, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.4, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-25 08:38:30,046 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:30,046 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-04-25 08:38:31,026 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.38, '(min, 1)': 0.2}}
2024-04-25 08:38:31,026 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:31,027 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-04-25 08:38:31,087 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #44: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.07692307692307693, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.31, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-04-25 08:38:31,089 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:31,089 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-04-25 08:38:31,469 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.29, '(rev, 1)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-04-25 08:38:31,469 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:31,470 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-04-25 08:38:31,764 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 5)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.22}}
2024-04-25 08:38:31,765 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:31,766 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-04-25 08:38:32,023 - MainProcess - INFO - text_logger.py - 51 - Train epoch #44
2024-04-25 08:38:32,027 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-7.1114e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.1395e-01,
         0.0000e+00,  1.7042e-01,  2.1033e-03,  2.4171e-01,  0.0000e+00,
         6.2073e-02,  1.4011e-03,  0.0000e+00,  0.0000e+00,  4.9834e-02,
         5.9143e-04,  0.0000e+00,  0.0000e+00,  3.8661e-02,  2.3694e-04,
         0.0000e+00,  0.0000e+00,  3.7497e-02,  5.2094e-04,  0.0000e+00,
         0.0000e+00,  3.4201e-02,  3.2258e-05,  0.0000e+00,  0.0000e+00,
         2.4427e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.8936e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.0899e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.0639e-04,  0.0000e+00,  0.0000e+00])  tensor([1.9727e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2199e-01, 0.0000e+00,
        1.2899e-01, 6.2317e-03, 1.3389e-01, 0.0000e+00, 5.1817e-02, 4.7689e-03,
        0.0000e+00, 0.0000e+00, 4.3491e-02, 3.4349e-03, 0.0000e+00, 0.0000e+00,
        3.5122e-02, 2.0167e-03, 0.0000e+00, 0.0000e+00, 3.5539e-02, 3.9136e-03,
        0.0000e+00, 0.0000e+00, 3.3385e-02, 7.2131e-04, 0.0000e+00, 0.0000e+00,
        2.5788e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1859e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.2711e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.1669e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:38:32,053 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.438144186687114
2024-04-25 08:38:32,057 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-25 08:38:33,673 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #45: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43137254901960786, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.32, '(rev, 1)': 0.03, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-04-25 08:38:33,673 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:33,674 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-04-25 08:38:34,001 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #45: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.3, '(min, 1)': 0.33}}
2024-04-25 08:38:34,001 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:34,002 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-04-25 08:38:34,072 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #45: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 7)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.1}}
2024-04-25 08:38:34,072 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:34,073 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-04-25 08:38:34,196 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #45: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7435897435897436, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.33, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 5)': 0.02}}
2024-04-25 08:38:34,196 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:34,197 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-04-25 08:38:34,862 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #45: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3673469387755102, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 9)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.42, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 5)': 0.02}}
2024-04-25 08:38:34,862 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:34,863 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-04-25 08:38:34,935 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #45: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.16326530612244897, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.14, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-04-25 08:38:34,936 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:34,936 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-04-25 08:38:35,454 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #45: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.52, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 6)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.3, '(rev, 1)': 0.05, '(rev, 5)': 0.01, '(rev, 6)': 0.02}}
2024-04-25 08:38:35,454 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:35,454 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-04-25 08:38:35,611 - MainProcess - INFO - text_logger.py - 51 - Train epoch #45
2024-04-25 08:38:35,614 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.3675e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3078e-01, 0.0000e+00,
        1.1235e-01, 3.0676e-03, 3.0306e-01, 0.0000e+00, 3.4429e-02, 2.0275e-03,
        0.0000e+00, 0.0000e+00, 2.8253e-02, 1.2080e-03, 0.0000e+00, 0.0000e+00,
        2.1168e-02, 6.7340e-04, 0.0000e+00, 0.0000e+00, 1.9589e-02, 6.9373e-04,
        0.0000e+00, 0.0000e+00, 1.7652e-02, 3.6722e-04, 0.0000e+00, 0.0000e+00,
        1.2531e-02, 1.0588e-04, 0.0000e+00, 0.0000e+00, 9.8324e-03, 3.6364e-05,
        0.0000e+00, 0.0000e+00, 1.8835e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.0031e-04, 0.0000e+00, 0.0000e+00])  tensor([2.4719e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1266e-01, 0.0000e+00,
        1.2858e-01, 7.3583e-03, 1.3013e-01, 0.0000e+00, 4.8757e-02, 5.7518e-03,
        0.0000e+00, 0.0000e+00, 4.3061e-02, 4.6920e-03, 0.0000e+00, 0.0000e+00,
        3.3662e-02, 3.3071e-03, 0.0000e+00, 0.0000e+00, 3.2548e-02, 3.5140e-03,
        0.0000e+00, 0.0000e+00, 2.9749e-02, 2.8631e-03, 0.0000e+00, 0.0000e+00,
        2.2139e-02, 1.3718e-03, 0.0000e+00, 0.0000e+00, 1.8016e-02, 8.1312e-04,
        0.0000e+00, 0.0000e+00, 5.8310e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.1417e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:38:35,634 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43720195246899346
2024-04-25 08:38:35,636 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-25 08:38:36,464 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #46: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.22, '(min, 1)': 0.37}}
2024-04-25 08:38:36,464 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:36,465 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-04-25 08:38:36,543 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #46: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.22, '(min, 1)': 0.38}}
2024-04-25 08:38:36,543 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:36,544 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-04-25 08:38:36,609 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #46: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3125, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 8)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.25, '(rev, 1)': 0.08, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-04-25 08:38:36,609 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:36,609 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-04-25 08:38:37,398 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #46: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 3, 1, 1),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 4, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.46, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.26, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.04, '(rev, 4)': 0.01}}
2024-04-25 08:38:37,398 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:37,399 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-04-25 08:38:38,149 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #46: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.48, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-04-25 08:38:38,149 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:38,149 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-04-25 08:38:39,163 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #46: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.09803921568627451, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.19, '(rev, 1)': 0.01, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-04-25 08:38:39,163 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:39,164 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-04-25 08:38:39,919 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #46: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.44680851063829785, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.34, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-04-25 08:38:39,919 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:39,920 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-04-25 08:38:40,077 - MainProcess - INFO - text_logger.py - 51 - Train epoch #46
2024-04-25 08:38:40,080 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.0413e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4966e-01, 0.0000e+00,
        9.3711e-02, 3.7625e-03, 3.2611e-01, 0.0000e+00, 3.0168e-02, 1.8121e-03,
        0.0000e+00, 0.0000e+00, 2.3568e-02, 1.3860e-03, 0.0000e+00, 0.0000e+00,
        1.6806e-02, 7.8657e-04, 0.0000e+00, 0.0000e+00, 1.6378e-02, 5.8606e-04,
        0.0000e+00, 0.0000e+00, 1.4641e-02, 3.4387e-04, 0.0000e+00, 0.0000e+00,
        1.0562e-02, 3.0613e-04, 0.0000e+00, 0.0000e+00, 7.7868e-03, 3.6364e-05,
        0.0000e+00, 0.0000e+00, 1.3372e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5569e-04, 0.0000e+00, 0.0000e+00])  tensor([2.2195e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9413e-01, 0.0000e+00,
        1.1056e-01, 8.3025e-03, 1.2154e-01, 0.0000e+00, 4.8304e-02, 5.4450e-03,
        0.0000e+00, 0.0000e+00, 4.0956e-02, 4.6998e-03, 0.0000e+00, 0.0000e+00,
        3.0773e-02, 3.6647e-03, 0.0000e+00, 0.0000e+00, 3.1686e-02, 3.1721e-03,
        0.0000e+00, 0.0000e+00, 2.8886e-02, 2.4388e-03, 0.0000e+00, 0.0000e+00,
        2.2189e-02, 2.2932e-03, 0.0000e+00, 0.0000e+00, 1.7071e-02, 8.1312e-04,
        0.0000e+00, 0.0000e+00, 4.9609e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.0261e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:38:40,100 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4362597182508729
2024-04-25 08:38:40,103 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-04-25 08:38:40,109 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #47: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.33, '(min, 1)': 0.29, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-04-25 08:38:40,109 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #47: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(ado, 8)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.19}}
2024-04-25 08:38:40,109 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:40,109 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:40,110 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-04-25 08:38:40,110 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-04-25 08:38:40,156 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #47: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2708333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.19, '(min, 1)': 0.42, '(rev, 1)': 0.03, '(rev, 10)': 0.01}}
2024-04-25 08:38:40,156 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:40,157 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-04-25 08:38:41,274 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #47: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 3, 0, 0),(rev, 3)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.27, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-04-25 08:38:41,275 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:41,275 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-04-25 08:38:42,003 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #47: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1875, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 3)': 0.03, '(ado, 8)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.24, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-25 08:38:42,003 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:42,004 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-04-25 08:38:42,030 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #47: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 3, 9, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.2}}
2024-04-25 08:38:42,031 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:42,031 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-04-25 08:38:44,277 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #47: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 2, 1, 1),(min, 0)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 3, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.19047619047619047, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.39, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-25 08:38:44,277 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:44,277 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-04-25 08:38:44,435 - MainProcess - INFO - text_logger.py - 51 - Train epoch #47
2024-04-25 08:38:44,438 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.3567e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.5587e-01,
         0.0000e+00,  1.5011e-01,  1.9760e-03,  2.6737e-01,  0.0000e+00,
         5.0904e-02,  1.4587e-03,  0.0000e+00,  0.0000e+00,  4.1269e-02,
         8.2454e-04,  0.0000e+00,  0.0000e+00,  3.1219e-02,  5.9187e-04,
         0.0000e+00,  0.0000e+00,  3.0360e-02,  2.3752e-04,  0.0000e+00,
         0.0000e+00,  2.8039e-02,  4.0816e-05,  0.0000e+00,  0.0000e+00,
         2.0783e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.5226e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.1162e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.0773e-04,  0.0000e+00,  0.0000e+00])  tensor([2.2636e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2690e-01, 0.0000e+00,
        1.3079e-01, 6.2641e-03, 1.4596e-01, 0.0000e+00, 5.4243e-02, 4.8474e-03,
        0.0000e+00, 0.0000e+00, 4.6247e-02, 3.7843e-03, 0.0000e+00, 0.0000e+00,
        3.7190e-02, 3.3883e-03, 0.0000e+00, 0.0000e+00, 3.7975e-02, 2.0146e-03,
        0.0000e+00, 0.0000e+00, 3.5814e-02, 9.1268e-04, 0.0000e+00, 0.0000e+00,
        2.8133e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2301e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.5571e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.0905e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-04-25 08:38:44,459 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43558831736608566
2024-04-25 08:38:44,461 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.135420.13542
2024-04-25 08:38:44,467 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #48: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5714285714285714, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(min, 0)': 0.3, '(min, 1)': 0.29, '(rev, 1)': 0.12, '(rev, 2)': 0.07, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-04-25 08:38:44,467 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:44,469 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729
2024-04-25 08:38:44,483 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #48: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.05263157894736842, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.37, '(min, 1)': 0.24, '(rev, 1)': 0.02, '(rev, 2)': 0.01}}
2024-04-25 08:38:44,483 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:44,484 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729
2024-04-25 08:38:44,514 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #48: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.24, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 5)': 0.01}}
2024-04-25 08:38:44,514 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #48: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 6, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.26, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-04-25 08:38:44,515 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:44,515 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-04-25 08:38:44,516 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729
2024-04-25 08:38:44,516 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729
2024-04-25 08:38:45,001 - Train Agent 3 - INFO - util.py - 54 - process shutting down
2024-04-25 08:38:45,001 - Train Agent 5 - INFO - util.py - 54 - process shutting down
2024-04-25 08:38:45,001 - Test Agent 1 - INFO - util.py - 54 - process shutting down
2024-04-25 08:38:45,001 - Train Agent 2 - INFO - util.py - 54 - process shutting down
2024-04-25 08:38:45,001 - Train Agent 1 - INFO - util.py - 54 - process shutting down
2024-04-25 08:38:45,001 - Test Agent 2 - INFO - util.py - 54 - process shutting down
2024-04-25 08:38:45,001 - Train Agent 4 - INFO - util.py - 54 - process shutting down
2024-04-25 08:38:45,110 - MainProcess - INFO - util.py - 54 - sending shutdown message to manager
2024-04-25 08:38:45,497 - MainProcess - INFO - util.py - 54 - process shutting down
