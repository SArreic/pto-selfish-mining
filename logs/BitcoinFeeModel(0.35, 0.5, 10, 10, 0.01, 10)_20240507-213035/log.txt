2024-05-07 21:30:41,782 - MainProcess - INFO - text_logger.py - 51 - Starting to train trainer:
instance(SynchronizedMultiProcessOrchestrator):
  Type: typing.Literal['single_process', 'multi_process', 'synced_multi_process'],
  agent: {'type': 'MCTSAgent', 'exploration_mechanism': {'type': 'EpsilonGreedyExploration', 'epsilon_schedule': {'type': 'ParameterSchedule', 'starting_parameter': 0.05, 'step_change': 0, 'end_parameter': 0}}, 'depth': 5, 'simulations': 25, 'ground_initial_state': False, 'value_clip': 0, 'nn_factor': 0.0001},
  algorithm: instance(MCTSAlgorithm):
    agent: {'type': 'MCTSAgent', 'exploration_mechanism': {'type': 'EpsilonGreedyExploration', 'epsilon_schedule': {'type': 'ParameterSchedule', 'starting_parameter': 0.05, 'step_change': 0, 'end_parameter': 0}}, 'depth': 5, 'simulations': 25, 'ground_initial_state': False, 'value_clip': 0, 'nn_factor': 0.0001},
    approximator: MCTSApproximator(
  (model): Sequential(
    (0): Linear(in_features=46, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=88, bias=True)
  )
),
    blockchain_model: BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01, 10),
    creation_args: {
      'batch_size': 100,
      'bind_all': False,
      'build_info': None,
      'bva_smart_init': 0.47111710906028753,
      'depth': 5,
      'dropout': 0,
      'epoch_shuffles': 2,
      'epsilon_step': 0,
      'evaluate_episode_length': 100,
      'ground_initial_state': False,
      'learning_rate': 0.0002,
      'length_factor': 10,
      'lower_priority': True,
      'lr_decay_epoch': 1000,
      'mc_simulations': 25,
      'nn_factor': 0.0001,
      'normalize_target_values': True,
      'num_of_episodes_for_average': 1000,
      'num_of_epochs': 5001,
      'number_of_evaluation_agents': 2,
      'number_of_training_agents': 5,
      'output_profile': False,
      'output_root': None,
      'prune_tree_rate': 250,
      'starting_epsilon': 0.05,
      'train_episode_length': 100,
      'use_base_approximation': True,
      'use_cached_values': False,
    },
    device: device(type='cpu'),
    loss_fn: MCTSLossFunction(
  (approximator): MCTSApproximator(
    (model): Sequential(
      (0): Linear(in_features=46, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=88, bias=True)
    )
  )
),
    lr_scheduler: instance(StepLR):
      base_lrs: [0.0002],
      gamma: 0.1,
      last_epoch: 0,
      optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0002
    lr: 0.0002
    weight_decay: 0
),
      step_size: 1000,
      verbose: False,
    optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0002
    lr: 0.0002
    weight_decay: 0
),
    simulator: instance(MDPBlockchainSimulator):
      action_space: instance(MultiDimensionalDiscreteSpace):
        dimension: 2,
        intervals: [
          instance(Interval):
            boundaries: (0, 3),
            enum: class(Action):
              Adopt: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Adopt',
                numerator: 1,
                real: 1,
                value: 1,
              Illegal: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Illegal',
                numerator: 0,
                real: 0,
                value: 0,
              Mine: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Mine',
                numerator: 3,
                real: 3,
                value: 3,
              Reveal: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Reveal',
                numerator: 2,
                real: 2,
                value: 2,
            size: 4
          instance(Interval):
            boundaries: (0, 10),
            enum: None,
            size: 11
        ],
        size: 44,
      check_valid_states: False,
      device: device(type='cpu'),
      expected_horizon: 10000,
      final_state: (
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Fork):
          denominator: 1,
          imag: 0,
          name: 'Irrelevant',
          numerator: 0,
          real: 0,
          value: 0
        -1,
        -1,
        -1,
        -1,
        -1,
      ),
      include_transition_info: True,
      initial_state: (
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Fork):
          denominator: 1,
          imag: 0,
          name: 'Irrelevant',
          numerator: 0,
          real: 0,
          value: 0
        0,
        0,
        0,
        0,
        0,
      ),
      num_of_actions: 44,
      num_of_states: 531232341494857729,
      state_space: instance(DefaultValueSpace):
        default_value: (
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Fork):
            denominator: 1,
            imag: 0,
            name: 'Irrelevant',
            numerator: 0,
            real: 0,
            value: 0
          -1,
          -1,
          -1,
          -1,
          -1,
        ),
        dimension: 46,
        size: 531232341494857729,
        underlying_space: instance(MultiDimensionalDiscreteSpace):
          dimension: 46,
          intervals: [
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 2),
              enum: class(Fork):
                Active: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Active',
                  numerator: 2,
                  real: 2,
                  value: 2,
                Irrelevant: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Irrelevant',
                  numerator: 0,
                  real: 0,
                  value: 0,
                Relevant: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Relevant',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 3
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
          ],
          size: 531232341494857728,
      state_space_dim: 46,
  approximator: MCTSApproximator(
  (model): Sequential(
    (0): Linear(in_features=46, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=88, bias=True)
  )
),
  batch_size: 100,
  bind_all: False,
  blockchain_model: BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01, 10),
  build_info: None,
  callback: instance(CompositionCallback):
    callbacks: (
      instance(CompositionCallback):
        callbacks: (
          instance(TextLoggingCallback):
            logger: instance(TextLogger):
              file_name: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                          10)_20240507-213035\\log.txt',
              logger: <Logger multiprocessing (INFO)>,
              output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                           10)_20240507-213035',
            logger_name: 'text',
            orchestrator: <Recursion on instance(SynchronizedMultiProcessOrchestrator) with id=2140044978496>,
            output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                         10)_20240507-213035'
          instance(TensorboardLoggingCallback):
            bind_all: False,
            logger: None,
            logger_name: 'tensorboard',
            max_num_of_agents: 5,
            max_number_of_actions: 3,
            num_of_q_values_in_approximator: 0,
            orchestrator: None,
            tensorboard_popen: None
          instance(BVACallback):
            agent: None,
            episode_values: deque([], maxlen=1000),
            episode_values_synchronizer: None,
            epoch_history: [],
            num_of_episodes_for_average: 1000,
            own_sync_manager: False,
            smart_init: 0.47111710906028753,
            sort_episodes: True,
            stop_goal: None,
            sync_dict: None,
            sync_manager: None
          instance(BVATextLoggingCallback):
            agent: None,
            bva_callback: instance(BVACallback):
              agent: None,
              episode_values: deque([], maxlen=1000),
              episode_values_synchronizer: None,
              epoch_history: [],
              num_of_episodes_for_average: 1000,
              own_sync_manager: False,
              smart_init: 0.47111710906028753,
              sort_episodes: True,
              stop_goal: None,
              sync_dict: None,
              sync_manager: None,
            logger: None,
            logger_name: 'text'
          instance(BVATensorboardLoggingCallback):
            bva_callback: instance(BVACallback):
              agent: None,
              episode_values: deque([], maxlen=1000),
              episode_values_synchronizer: None,
              epoch_history: [],
              num_of_episodes_for_average: 1000,
              own_sync_manager: False,
              smart_init: 0.47111710906028753,
              sort_episodes: True,
              stop_goal: None,
              sync_dict: None,
              sync_manager: None,
            logger: None,
            logger_name: 'tensorboard'
          instance(CheckpointCallback):
            bva_before: 0,
            bva_callback: instance(BVACallback):
              agent: None,
              episode_values: deque([], maxlen=1000),
              episode_values_synchronizer: None,
              epoch_history: [],
              num_of_episodes_for_average: 1000,
              own_sync_manager: False,
              smart_init: 0.47111710906028753,
              sort_episodes: True,
              stop_goal: None,
              sync_dict: None,
              sync_manager: None,
            latest_approximator: None,
            load_epoch: None,
            load_experiment: None,
            load_seed: True,
            nn_state_before: None,
            orchestrator: None,
            output_dir: None,
            own_sync_manager: False,
            random_seed_dict: None,
            save_rate: 100,
            sync_dict: None,
            sync_manager: None
          instance(PolicyRevenueCallback):
            agent: None,
            confidence: 0.99,
            dump_path: '',
            dump_trajectories: False,
            episode_values: None,
            episode_values_synchronizer: None,
            length_factor: 10,
            long_simulation_rate: 100,
            num_of_agents: 0,
            num_of_evaluation_agents: 0,
            orchestrator: None,
            own_sync_manager: False,
            policy_revenue: 0,
            policy_revenue_confidence_radius: 0,
            policy_test_revenue: 0,
            policy_test_revenue_confidence_radius: 0,
            repeats: 1,
            sync_dict: None,
            sync_manager: None,
            test_episode_values: None,
            test_episode_values_synchronizer: None
          instance(PolicyRevenueTextLoggingCallback):
            logger: None,
            logger_name: 'text',
            policy_revenue_callback: instance(PolicyRevenueCallback):
              agent: None,
              confidence: 0.99,
              dump_path: '',
              dump_trajectories: False,
              episode_values: None,
              episode_values_synchronizer: None,
              length_factor: 10,
              long_simulation_rate: 100,
              num_of_agents: 0,
              num_of_evaluation_agents: 0,
              orchestrator: None,
              own_sync_manager: False,
              policy_revenue: 0,
              policy_revenue_confidence_radius: 0,
              policy_test_revenue: 0,
              policy_test_revenue_confidence_radius: 0,
              repeats: 1,
              sync_dict: None,
              sync_manager: None,
              test_episode_values: None,
              test_episode_values_synchronizer: None
          instance(PolicyRevenueTensorboardLoggingCallback):
            logger: None,
            logger_name: 'tensorboard',
            policy_revenue_callback: instance(PolicyRevenueCallback):
              agent: None,
              confidence: 0.99,
              dump_path: '',
              dump_trajectories: False,
              episode_values: None,
              episode_values_synchronizer: None,
              length_factor: 10,
              long_simulation_rate: 100,
              num_of_agents: 0,
              num_of_evaluation_agents: 0,
              orchestrator: None,
              own_sync_manager: False,
              policy_revenue: 0,
              policy_revenue_confidence_radius: 0,
              policy_test_revenue: 0,
              policy_test_revenue_confidence_radius: 0,
              repeats: 1,
              sync_dict: None,
              sync_manager: None,
              test_episode_values: None,
              test_episode_values_synchronizer: None
        )
      instance(MCTSTensorboardLoggingCallback):
        agent: None,
        logger: None,
        logger_name: 'tensorboard',
        max_num_of_agents: 5,
        orchestrator: None
    ),
  creation_args: {
    'bva_smart_init': 0.47111710906028753,
    'depth': 5,
    'device': device(type='cpu')
    'dropout': 0,
    'epsilon_step': 0,
    'ground_initial_state': False,
    'length_factor': 10,
    'lr_decay_epoch': 1000,
    'mc_simulations': 25,
    'nn_factor': 0.0001,
    'normalize_target_values': True,
    'num_of_episodes_for_average': 1000,
    'prune_tree_rate': 250,
    'simulator': instance(MDPBlockchainSimulator):
      action_space: instance(MultiDimensionalDiscreteSpace):
        dimension: 2,
        intervals: [
          instance(Interval):
            boundaries: (0, 3),
            enum: class(Action):
              Adopt: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Adopt',
                numerator: 1,
                real: 1,
                value: 1,
              Illegal: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Illegal',
                numerator: 0,
                real: 0,
                value: 0,
              Mine: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Mine',
                numerator: 3,
                real: 3,
                value: 3,
              Reveal: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Reveal',
                numerator: 2,
                real: 2,
                value: 2,
            size: 4
          instance(Interval):
            boundaries: (0, 10),
            enum: None,
            size: 11
        ],
        size: 44,
      check_valid_states: False,
      device: device(type='cpu'),
      expected_horizon: 10000,
      final_state: (
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Fork):
          denominator: 1,
          imag: 0,
          name: 'Irrelevant',
          numerator: 0,
          real: 0,
          value: 0
        -1,
        -1,
        -1,
        -1,
        -1,
      ),
      include_transition_info: True,
      initial_state: (
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Fork):
          denominator: 1,
          imag: 0,
          name: 'Irrelevant',
          numerator: 0,
          real: 0,
          value: 0
        0,
        0,
        0,
        0,
        0,
      ),
      num_of_actions: 44,
      num_of_states: 531232341494857729,
      state_space: instance(DefaultValueSpace):
        default_value: (
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Fork):
            denominator: 1,
            imag: 0,
            name: 'Irrelevant',
            numerator: 0,
            real: 0,
            value: 0
          -1,
          -1,
          -1,
          -1,
          -1,
        ),
        dimension: 46,
        size: 531232341494857729,
        underlying_space: instance(MultiDimensionalDiscreteSpace):
          dimension: 46,
          intervals: [
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 2),
              enum: class(Fork):
                Active: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Active',
                  numerator: 2,
                  real: 2,
                  value: 2,
                Irrelevant: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Irrelevant',
                  numerator: 0,
                  real: 0,
                  value: 0,
                Relevant: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Relevant',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 3
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
          ],
          size: 531232341494857728,
      state_space_dim: 46
    'starting_epsilon': 0.05,
    'use_base_approximation': True,
    'use_cached_values': False,
  },
  episode_reset_rate: 10,
  episode_synchronizer: {'type': 'BufferSynchronizer', 'target_buffer': <reinforcement_learning.base.utility.dummy_buffer.DummyBuffer object at 0x000001F2449384F0>},
  epoch_length: 1000,
  epoch_size: 2000,
  evaluate_episode_length: 100,
  expected_horizon: 10000,
  experiment_name: 'BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                    10)_20240507-213035',
  learning_rate: 0.0002,
  loggers: {
    'tensorboard': instance(SynchronizedLogger):
      base_logger: instance(TensorboardLogger):
        flush_secs: 15,
        hparam_dict: {
        },
        hparam_domain_discrete: {
        },
        layout: {
        },
        metric_dict: {
        },
        output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                     10)_20240507-213035',
        started_logging: False,
        tensorboard_writer: instance(SummaryWriter):
          all_writers: {
            'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01, 10)_20240507-213035': instance(FileWriter):
              event_writer: instance(EventFileWriter)
          },
          default_bins: [-9.920775621859783e+19, -9.018886928963438e+19, -8.198988117239489e+19, -7.453625561126807e+19, -6.776023237388005e+19, -6.160021124898186e+19, -5.600019204452896e+19, -5.090926549502632e+19, -4.628115045002392e+19, -4.2073773136385384e+19, -3.824888466944125e+19, -3.477171333585568e+19, -3.1610648487141528e+19, -2.873695317012866e+19, -2.6124502881935143e+19, -2.3749548074486493e+19, -2.1590498249533174e+19, -1.962772568139379e+19, -1.7843386983085265e+19, -1.6221260893713875e+19, -1.4746600812467157e+19, -1.3406000738606506e+19, -1.2187273398733187e+19, -1.1079339453393805e+19, -1.0072126775812549e+19, -9.156478887102316e+18, -8.324071715547559e+18, -7.567337923225053e+18, -6.879398112022775e+18, -6.253998283657068e+18, -5.685452985142788e+18, -5.16859362285708e+18, -4.698721475324618e+18, -4.271564977567834e+18, -3.8832408886980306e+18, -3.530218989725482e+18, -3.2092899906595287e+18, -2.917536355145026e+18, -2.652305777404569e+18, -2.41118707036779e+18, -2.1919882457888998e+18, -1.992716587080818e+18, -1.8115605337098342e+18, -1.6468732124634854e+18, -1.4971574658758958e+18, -1.3610522417053596e+18, -1.237320219732145e+18, -1.1248365633928589e+18, -1.022578693993508e+18, -9.296169945395526e+17, -8.451063586723205e+17, -7.682785078839277e+17, -6.984350071672069e+17, -6.349409156065517e+17, -5.772190141877742e+17, -5.247445583525219e+17, -4.770405075932017e+17, -4.336731887210924e+17, -3.9424835338281126e+17, -3.584075939843738e+17, -3.2582508544033984e+17, -2.9620462312758163e+17, -2.6927693011598326e+17, -2.447972091963484e+17, -2.2254291745122582e+17, -2.02311743137478e+17, -1.8391976648861635e+17, -1.6719978771692394e+17, -1.5199980701538538e+17, -1.3818164274125942e+17, -1.2561967521932674e+17, -1.1419970474484248e+17, -1.0381791340440224e+17, -9.43799212767293e+16, -8.579992843339026e+16, -7.799993493944568e+16, -7.090903176313243e+16, -6.446275614830221e+16, -5.860250558936564e+16, -5.327500508124149e+16, -4.843182280112862e+16, -4.402892981920784e+16, -4.002629983564349e+16, -3.638754530513044e+16, -3.3079586641027668e+16, -3.0072351491843332e+16, -2.733850135622121e+16, -2.4853183051110188e+16, -2.2593802773736532e+16, -2.0539820703396844e+16, -1.867256427581531e+16, -1.6975058432559372e+16, -1.54318713023267e+16, -1.402897391120609e+16, -1.275361264655099e+16, -1.1594193315046354e+16, -1.054017574095123e+16, -9581977946319300.0, -8710889042108454.0, -7918990038280412.0, -7199081852982192.0, -6544619866347447.0, -5949654423952224.0, -5408776749047476.0, -4917069771861341.0, -4470063428964855.0, -4063694026331686.0, -3694267296665169.0, -3358424815150153.5, -3053113468318321.0, -2775557698471200.5, -2523234271337455.0, -2293849337579504.5, -2085317579617731.2, -1895743254197937.2, -1723402958361761.0, -1566729962147055.2, -1424299965588232.0, -1294818150534756.2, -1177107409577051.0, -1070097645070046.2, -972816040972769.2, -884378219066153.8, -803980199151048.8, -730891090137317.0, -664446445579379.0, -604042223253980.9, -549129293867255.25, -499208448970232.0, -453825862700210.9, -412568966091100.75, -375062696446455.2, -340966087678595.6, -309969170616905.06, -281790155106277.3, -256172868278433.9, -232884425707667.16, -211713114279697.4, -192466467526997.62, -174969515933634.2, -159063196303303.78, -144602905730276.16, -131457187027523.78, -119506533661385.25, -108642303328532.03, -98765730298665.47, -89787027544241.33, -81624570494764.84, -74204154995240.77, -67458322722946.15, -61325747929951.04, -55750679936319.125, -50682436305744.66, -46074942096131.5, -41886310996483.18, -38078464542257.43, -34616785947506.754, -31469805406824.32, -28608914006203.926, -26008103642003.566, -23643730583639.605, -21494300530581.457, -19540273209619.504, -17763884736017.73, -16148986123652.482, -14680896476047.71, -13346269523679.736, -12132972294254.305, -11029974812958.457, -10027249829962.232, -9115681663602.03, -8286983330547.298, -7533621209588.452, -6848746554171.319, -6226133231064.835, -5660121119149.85, -5145564653772.59, -4677786048884.172, -4252532771712.8833, -3865938883375.348, -3514489893977.589, -3194990812706.899, -2904537102460.817, -2640488274964.379, -2400443886331.2534, -2182221714846.594, -1983837922587.8125, -1803489020534.3748, -1639535473213.0679, -1490486793830.0615, -1354987994390.9648, -1231807267628.1497, -1119824788752.8633, -1018022535229.8757, -925475032027.1597, -841340938206.5087, -764855398369.5532, -695323089426.8665, -632111899478.9695, -574647181344.5177, -522406528495.01605, -474915025904.56, -431740932640.50903, -392491756945.9173, -356810688132.65204, -324373352847.8655, -294884866225.3322, -268077151113.93835, -243706501012.6712, -221551364556.97382, -201410331415.43073, -183100301286.7552, -166454819351.5956, -151322563046.9051, -137565966406.27734, -125059969460.25212, -113690881327.50192, -103355346661.36537, -93959406055.7867, -85417641868.89699, -77652401698.99725, -70593092453.63387, -64175538594.21259, -58341398722.011444, -53037635201.82858, -48216032001.662346, -43832756365.14758, -39847960331.95235, -36225418483.59304, -32932198621.448215, -29938362383.13474, -27216693075.577034, -24742448250.524574, -22493134773.204155, -20448304339.276505, -18589367581.160458, -16899425073.782234, -15363113703.438393, -13966467003.12581, -12696788184.659826, -11542534713.327114, -10493213375.75192, -9539284887.0472, -8672077170.042908, -7883706518.220825, -7167005925.655295, -6515459932.413904, -5923145393.103549, -5384677630.094135, -4895161481.903759, -4450146801.73069, -4045588001.5733542, -3677807274.1575947, -3343461158.3250856, -3039510143.9318957, -2763191039.938087, -2511991854.4891696, -2283628958.626518, -2076026326.0241067, -1887296660.021915, -1715724236.383559, -1559749305.8032353, -1417953914.3665774, -1289049013.0605247, -1171862739.1459315, -1065329762.8599375, -968481602.5999432, -880437820.5454028, -800398018.6776388, -727634562.434217, -661485965.8492881, -601350878.0448073, -546682616.4043702, -496984196.7312456, -451803815.2102232, -410730741.10020286, -373391582.8183662, -339446893.471242, -308588084.97385633, -280534622.70350575, -255031475.1850052, -231846795.62273198, -210769814.2024836, -191608922.0022578, -174189929.0929616, -158354480.99360144, -143958619.08509222, -130871471.89553836, -118974065.35958032, -108158241.2359821, -98325673.85089281, -89386976.22808437, -81260887.4800767, -73873534.072797, -67157758.24799727, -61052507.49817933, -55502279.543799385, -50456617.76709034, -45869652.51553667, -41699684.10503334, -37908803.731848486, -34462548.847134985, -31329589.861031804, -28481445.32821073, -25892223.025646117, -23538384.568769194, -21398531.426153813, -19453210.387412556, -17684736.715829596, -16077033.378026905, -14615484.889115367, -13286804.444650333, -12078913.131500302, -10980830.119545728, -9982572.835950661, -9075066.2145006, -8250060.195000546, -7500054.722727768, -6818231.566116152, -6198392.332832865, -5634902.1207571495, -5122638.291597408, -4656943.901452189, -4233585.364956535, -3848713.9681423046, -3498830.8801293676, -3180755.345572152, -2891595.768701956, -2628723.426092687, -2389748.56917517, -2172498.699250154, -1974998.81750014, -1795453.4704546726, -1632230.427686066, -1483845.8433509688, -1348950.7666826989, -1226318.8788024534, -1114835.3443658666, -1013486.6766962423, -921351.5242693111, -837592.2947902827, -761447.5407184388, -692225.0370167625, -629295.4881970568, -572086.8074518698, -520078.91586533614, -472799.0144230328, -429817.2858391207, -390742.98712647334, -355220.897387703, -322928.0885342754, -293570.989576614, -266882.7177969218, -242620.65254265617, -220564.22958423287, -200512.93598566623, -182284.48725969656, -165713.17023608775, -150648.33657826157, -136953.03325296505, -124502.75750269549, -113184.32500245044, -102894.84091131858, -93540.76446483507, -85037.05860439551, -77306.41691308682, -70278.56083007893, -63889.60075461721, -58081.45523147019, -52801.32293770016, -48001.20267063651, -43637.45697330591, -39670.415430278095, -36064.01402752554, -32785.46729775049, -29804.97027068226, -27095.427518802055, -24632.206835274592, -22392.915304795082, -20357.19573163189, -18506.54157421081, -16824.128703828006, -15294.66245802546, -13904.238598204962, -12640.216907459055, -11491.10627950823, -10446.46025409839, -9496.782049180354, -8633.438226527594, -7848.580205934176, -7135.072914485614, -6486.429922259648, -5896.754474781498, -5360.685886164998, -4873.350805604543, -4430.3189141859475, -4027.5626492599517, -3661.4205902363196, -3328.5641729421086, -3025.9674299473713, -2750.8794817703374, -2500.799528882125, -2273.454117165568, -2066.776470150516, -1878.8877001368326, -1708.0797273971205, -1552.7997521792004, -1411.6361383447274, -1283.3055803133884, -1166.6414366485349, -1060.5831242259408, -964.166476569037, -876.5149786991244, -796.8317988173858, -724.3925443794416, -658.5386767085832, -598.6715242805302, -544.2468402550275, -494.76985477729767, -449.79077707027056, -408.9007064275187, -371.72791493410784, -337.9344681219162, -307.2131528381056, -279.2846843982778, -253.89516763479799, -230.81378875890724, -209.830717053552, -190.7551973214109, -173.41381574673716, -157.64892340612468, -143.31720309647696, -130.28836645134268, -118.44396950122061, -107.67633591020055, -97.88757810018231, -88.98870736380209, -80.89882487618371, -73.54438625107609, -66.85853295552371, -60.78048450502155, -55.25498591365595, -50.23180537605086, -45.66527761459169, -41.513888740537894, -37.73989885503445, -34.30899895912222, -31.18999905374747, -28.35454459431588, -25.77685872210534, -23.43350792918667, -21.303189026533335, -19.366535478666666, -17.60594134424242, -16.005401222038564, -14.550364747307786, -13.22760431573435, -12.025094832485772, -10.931904393168884, -9.938094902880803, -9.034631729891638, -8.213301572628762, -7.466637793298873, -6.7878525393626115, -6.1707750357841915, -5.609795487076537, -5.099814079160488, -4.636194617418625, -4.214722379471477, -3.8315657995195243, -3.48324163592684, -3.1665833053880363, -2.8787120958073054, -2.6170109961884593, -2.379100905625872, -2.1628190051144287, -1.9661990955585713, -1.7874537232350647, -1.624957930213695, -1.47723448201245, -1.3429404381931362, -1.220854943811942, -1.109868130738129, -1.0089710279437536, -0.917246389039776, -0.8338603536725235, -0.7580548669750213, -0.6891407881591103, -0.6264916255991911, -0.56953784145381, -0.5177616740489182, -0.47069243095356195, -0.42790220995778355, -0.38900200905253046, -0.35363819004775493, -0.3214892636797772, -0.29226296698161564, -0.2656936063469233, -0.24153964213356663, -0.2195814928486969, -0.19961953895336082, -0.18147230813941892, -0.16497482558128992, -0.14997711416480902, -0.13634283105891729, -0.12394802823537933, -0.11268002566852665, -0.10243638697138786, -0.09312398815580714, -0.08465817105073375, -0.07696197368248522, -0.06996543062044111, -0.06360493692767373, -0.057822669934248845, -0.052566063576589855, -0.04778733052417259, -0.043443027749247805, -0.03949366159022527, -0.035903328718386605, -0.03263938974398782, -0.02967217249453438, -0.026974702267758523, -0.0245224566070532, -0.022293142370048362, -0.02026649306368033, -0.018424084603345752, -0.01674916782122341, -0.01522651620111219, -0.013842287455556535, -0.012583897686869577, -0.01143990698806325, -0.010399915443693864, -0.00945446858517624, -0.008594971441069308, -0.007813610400972098, -0.007103282182701907, -0.006457529257001733, -0.005870481142728848, -0.005336801038844407, -0.00485163730804037, -0.00441057937094579, -0.004009617609950718, -0.0036451069181370156, -0.003313733561942741, -0.0030124850563115826, -0.002738622778465075, -0.0024896570713318863, -0.0022633246103017147, -0.0020575678275470133, -0.001870516206860921, -0.0017004692789644735, -0.0015458811626949758, -0.001405346511540887, -0.0012775877377644426, -0.001161443397967675, -0.001055857634516068, -0.0009598705768327891, -0.0008726096153025355, -0.0007932814684568504, -0.0007211649713244094, -0.0006556045193858267, -0.0005960041085325697, -0.0005418219168477906, -0.0004925653789525368, -0.0004477867081386698, -0.0004070788255806089, -0.0003700716596187353, -0.00033642878147157755, -0.0003058443467923432, -0.0002780403152657665, -0.00025276392296887866, -0.0002297853845171624, -0.00020889580410651126, -0.00018990527646046477, -0.00017264116041860433, -0.00015694650947145847, -0.00014267864497405315, -0.00012970785906732103, -0.00011791623551574639, -0.00010719657774158762, -9.745143431053419e-05, -8.859221300957652e-05, -8.053837546325138e-05, -7.321670496659217e-05, -6.656064087872014e-05, -6.050967352610922e-05, -5.500879411464474e-05, -5.000799464967703e-05, -4.546181331788821e-05, -4.132892119808019e-05, -3.757174654370926e-05, -3.415613322155387e-05, -3.1051030201412604e-05, -2.822820927401146e-05, -2.5662008430919505e-05, -2.3329098573563184e-05, -2.1208271430511985e-05, -1.9280246755010893e-05, -1.7527497050009902e-05, -1.593408822728173e-05, -1.44855347520743e-05, -1.316866795643118e-05, -1.1971516324028345e-05, -1.0883196658207586e-05, -9.893815143825077e-06, -8.994377403477343e-06, -8.176706730433948e-06, -7.4333697549399525e-06, -6.757608868127229e-06, -6.143280789206572e-06, -5.584800717460519e-06, -5.077091561327744e-06, -4.615537783025222e-06, -4.1959434391138375e-06, -3.8144940355580335e-06, -3.467721850507303e-06, -3.1524744095520932e-06, -2.865885826865539e-06, -2.605350751695944e-06, -2.368500683359949e-06, -2.153182439418135e-06, -1.9574385812892137e-06, -1.7794896193538304e-06, -1.6177178357762093e-06, -1.470652577978372e-06, -1.3369568890712472e-06, -1.2154153537011338e-06, -1.1049230488192125e-06, -1.0044754989265568e-06, -9.131595444786879e-07, -8.301450404351707e-07, -7.546773094865188e-07, -6.860702813513807e-07, -6.237002557739824e-07, -5.670002325218022e-07, -5.15454756838002e-07, -4.6859523348909267e-07, -4.2599566680826603e-07, -3.8726878800751456e-07, -3.5206253455228594e-07, -3.200568495929872e-07, -2.909607723572611e-07, -2.645097930520555e-07, -2.4046344822914135e-07, -2.1860313475376482e-07, -1.9873012250342254e-07, -1.8066374773038411e-07, -1.6423977066398553e-07, -1.4930888242180502e-07, -1.3573534765618637e-07, -1.2339577059653305e-07, -1.1217797326957548e-07, -1.0197997569961407e-07, -9.270906881783097e-08, -8.42809716525736e-08, -7.661906513870326e-08, -6.965369558063933e-08, -6.332154143694484e-08, -5.756503766994985e-08, -5.2331852427227134e-08, -4.757441129747921e-08, -4.324946481589019e-08, -3.9317695287172896e-08, -3.574335935197536e-08, -3.249396304725032e-08, -2.95399664065912e-08, -2.6854514915082908e-08, -2.4413195377348097e-08, -2.219381397940736e-08, -2.017619452673396e-08, -1.83419950243036e-08, -1.667454093118509e-08, -1.5158673573804625e-08, -1.3780612339822385e-08, -1.2527829399838531e-08, -1.1388935818035027e-08, -1.0353578016395478e-08, -9.412343651268615e-09, -8.556676046607832e-09, -7.778796406007119e-09, -7.071633096370107e-09, -6.428757360336461e-09, -5.8443248730331455e-09, -5.313022611848313e-09, -4.830020556225739e-09, -4.390927778387036e-09, -3.991752525806396e-09, -3.628865932551268e-09, -3.2989690295920617e-09, -2.9990627541746013e-09, -2.7264206856132736e-09, -2.47856425964843e-09, -2.253240236044027e-09, -2.048400214585479e-09, -1.8621820132595262e-09, -1.6928927393268418e-09, -1.5389933993880379e-09, -1.3990849085345797e-09, -1.2718953713950723e-09, -1.1562685194500657e-09, -1.0511531995000597e-09, -9.55593817727327e-10, -8.68721652479388e-10, -7.897469567994436e-10, -7.179517789085851e-10, -6.52683435371441e-10, -5.933485776104008e-10, -5.394077978276371e-10, -4.903707252978519e-10, -4.4579156845259254e-10, -4.0526506222962957e-10, -3.684227838451178e-10, -3.349298034955616e-10, -3.0448163954141963e-10, -2.7680149049219964e-10, -2.516377186292724e-10, -2.287615623902476e-10, -2.079650567184069e-10, -1.89059142471279e-10, -1.718719477011627e-10, -1.5624722518287518e-10, -1.4204293198443196e-10, -1.291299381676654e-10, -1.173908528796958e-10, -1.067189571633598e-10, -9.701723378487254e-11, -8.819748525897503e-11, -8.017953205361366e-11, -7.289048368510333e-11, -6.626407607736665e-11, -6.02400691612424e-11, -5.4763699237493095e-11, -4.978518112499372e-11, -4.5259255568176104e-11, -4.1144777789251e-11, -3.7404343444773633e-11, -3.400394858615785e-11, -3.091268053287077e-11, -2.8102436848064334e-11, -2.5547669861876665e-11, -2.3225154419887876e-11, -2.111377674535261e-11, -1.91943424957751e-11, -1.7449402268886454e-11, -1.5863092971714956e-11, -1.4420993610649957e-11, -1.310999419149996e-11, -1.1918176537727236e-11, -1.0834705943388396e-11, -9.849732675807632e-12, -8.954302432552392e-12, -8.140274938683992e-12, -7.400249944258175e-12, -6.727499949325613e-12, -6.115909044841466e-12, -5.559917313492241e-12, -5.054470284992946e-12, -4.594972986357223e-12, -4.177248169415657e-12, -3.797498335832415e-12, -3.452271214393104e-12, -3.1384283767210032e-12, -2.8531167061100027e-12, -2.593742460100002e-12, -2.357947691000002e-12, -2.1435888100000016e-12, -1.9487171000000014e-12, -1.771561000000001e-12, -1.6105100000000008e-12, -1.4641000000000006e-12, -1.3310000000000005e-12, -1.2100000000000003e-12, -1.1000000000000002e-12, -1e-12, 0, 1e-12, 1.1000000000000002e-12, 1.2100000000000003e-12, 1.3310000000000005e-12, 1.4641000000000006e-12, 1.6105100000000008e-12, 1.771561000000001e-12, 1.9487171000000014e-12, 2.1435888100000016e-12, 2.357947691000002e-12, 2.593742460100002e-12, 2.8531167061100027e-12, 3.1384283767210032e-12, 3.452271214393104e-12, 3.797498335832415e-12, 4.177248169415657e-12, 4.594972986357223e-12, 5.054470284992946e-12, 5.559917313492241e-12, 6.115909044841466e-12, 6.727499949325613e-12, 7.400249944258175e-12, 8.140274938683992e-12, 8.954302432552392e-12, 9.849732675807632e-12, 1.0834705943388396e-11, 1.1918176537727236e-11, 1.310999419149996e-11, 1.4420993610649957e-11, 1.5863092971714956e-11, 1.7449402268886454e-11, 1.91943424957751e-11, 2.111377674535261e-11, 2.3225154419887876e-11, 2.5547669861876665e-11, 2.8102436848064334e-11, 3.091268053287077e-11, 3.400394858615785e-11, 3.7404343444773633e-11, 4.1144777789251e-11, 4.5259255568176104e-11, 4.978518112499372e-11, 5.4763699237493095e-11, 6.02400691612424e-11, 6.626407607736665e-11, 7.289048368510333e-11, 8.017953205361366e-11, 8.819748525897503e-11, 9.701723378487254e-11, 1.067189571633598e-10, 1.173908528796958e-10, 1.291299381676654e-10, 1.4204293198443196e-10, 1.5624722518287518e-10, 1.718719477011627e-10, 1.89059142471279e-10, 2.079650567184069e-10, 2.287615623902476e-10, 2.516377186292724e-10, 2.7680149049219964e-10, 3.0448163954141963e-10, 3.349298034955616e-10, 3.684227838451178e-10, 4.0526506222962957e-10, 4.4579156845259254e-10, 4.903707252978519e-10, 5.394077978276371e-10, 5.933485776104008e-10, 6.52683435371441e-10, 7.179517789085851e-10, 7.897469567994436e-10, 8.68721652479388e-10, 9.55593817727327e-10, 1.0511531995000597e-09, 1.1562685194500657e-09, 1.2718953713950723e-09, 1.3990849085345797e-09, 1.5389933993880379e-09, 1.6928927393268418e-09, 1.8621820132595262e-09, 2.048400214585479e-09, 2.253240236044027e-09, 2.47856425964843e-09, 2.7264206856132736e-09, 2.9990627541746013e-09, 3.2989690295920617e-09, 3.628865932551268e-09, 3.991752525806396e-09, 4.390927778387036e-09, 4.830020556225739e-09, 5.313022611848313e-09, 5.8443248730331455e-09, 6.428757360336461e-09, 7.071633096370107e-09, 7.778796406007119e-09, 8.556676046607832e-09, 9.412343651268615e-09, 1.0353578016395478e-08, 1.1388935818035027e-08, 1.2527829399838531e-08, 1.3780612339822385e-08, 1.5158673573804625e-08, 1.667454093118509e-08, 1.83419950243036e-08, 2.017619452673396e-08, 2.219381397940736e-08, 2.4413195377348097e-08, 2.6854514915082908e-08, 2.95399664065912e-08, 3.249396304725032e-08, 3.574335935197536e-08, 3.9317695287172896e-08, 4.324946481589019e-08, 4.757441129747921e-08, 5.2331852427227134e-08, 5.756503766994985e-08, 6.332154143694484e-08, 6.965369558063933e-08, 7.661906513870326e-08, 8.42809716525736e-08, 9.270906881783097e-08, 1.0197997569961407e-07, 1.1217797326957548e-07, 1.2339577059653305e-07, 1.3573534765618637e-07, 1.4930888242180502e-07, 1.6423977066398553e-07, 1.8066374773038411e-07, 1.9873012250342254e-07, 2.1860313475376482e-07, 2.4046344822914135e-07, 2.645097930520555e-07, 2.909607723572611e-07, 3.200568495929872e-07, 3.5206253455228594e-07, 3.8726878800751456e-07, 4.2599566680826603e-07, 4.6859523348909267e-07, 5.15454756838002e-07, 5.670002325218022e-07, 6.237002557739824e-07, 6.860702813513807e-07, 7.546773094865188e-07, 8.301450404351707e-07, 9.131595444786879e-07, 1.0044754989265568e-06, 1.1049230488192125e-06, 1.2154153537011338e-06, 1.3369568890712472e-06, 1.470652577978372e-06, 1.6177178357762093e-06, 1.7794896193538304e-06, 1.9574385812892137e-06, 2.153182439418135e-06, 2.368500683359949e-06, 2.605350751695944e-06, 2.865885826865539e-06, 3.1524744095520932e-06, 3.467721850507303e-06, 3.8144940355580335e-06, 4.1959434391138375e-06, 4.615537783025222e-06, 5.077091561327744e-06, 5.584800717460519e-06, 6.143280789206572e-06, 6.757608868127229e-06, 7.4333697549399525e-06, 8.176706730433948e-06, 8.994377403477343e-06, 9.893815143825077e-06, 1.0883196658207586e-05, 1.1971516324028345e-05, 1.316866795643118e-05, 1.44855347520743e-05, 1.593408822728173e-05, 1.7527497050009902e-05, 1.9280246755010893e-05, 2.1208271430511985e-05, 2.3329098573563184e-05, 2.5662008430919505e-05, 2.822820927401146e-05, 3.1051030201412604e-05, 3.415613322155387e-05, 3.757174654370926e-05, 4.132892119808019e-05, 4.546181331788821e-05, 5.000799464967703e-05, 5.500879411464474e-05, 6.050967352610922e-05, 6.656064087872014e-05, 7.321670496659217e-05, 8.053837546325138e-05, 8.859221300957652e-05, 9.745143431053419e-05, 0.00010719657774158762, 0.00011791623551574639, 0.00012970785906732103, 0.00014267864497405315, 0.00015694650947145847, 0.00017264116041860433, 0.00018990527646046477, 0.00020889580410651126, 0.0002297853845171624, 0.00025276392296887866, 0.0002780403152657665, 0.0003058443467923432, 0.00033642878147157755, 0.0003700716596187353, 0.0004070788255806089, 0.0004477867081386698, 0.0004925653789525368, 0.0005418219168477906, 0.0005960041085325697, 0.0006556045193858267, 0.0007211649713244094, 0.0007932814684568504, 0.0008726096153025355, 0.0009598705768327891, 0.001055857634516068, 0.001161443397967675, 0.0012775877377644426, 0.001405346511540887, 0.0015458811626949758, 0.0017004692789644735, 0.001870516206860921, 0.0020575678275470133, 0.0022633246103017147, 0.0024896570713318863, 0.002738622778465075, 0.0030124850563115826, 0.003313733561942741, 0.0036451069181370156, 0.004009617609950718, 0.00441057937094579, 0.00485163730804037, 0.005336801038844407, 0.005870481142728848, 0.006457529257001733, 0.007103282182701907, 0.007813610400972098, 0.008594971441069308, 0.00945446858517624, 0.010399915443693864, 0.01143990698806325, 0.012583897686869577, 0.013842287455556535, 0.01522651620111219, 0.01674916782122341, 0.018424084603345752, 0.02026649306368033, 0.022293142370048362, 0.0245224566070532, 0.026974702267758523, 0.02967217249453438, 0.03263938974398782, 0.035903328718386605, 0.03949366159022527, 0.043443027749247805, 0.04778733052417259, 0.052566063576589855, 0.057822669934248845, 0.06360493692767373, 0.06996543062044111, 0.07696197368248522, 0.08465817105073375, 0.09312398815580714, 0.10243638697138786, 0.11268002566852665, 0.12394802823537933, 0.13634283105891729, 0.14997711416480902, 0.16497482558128992, 0.18147230813941892, 0.19961953895336082, 0.2195814928486969, 0.24153964213356663, 0.2656936063469233, 0.29226296698161564, 0.3214892636797772, 0.35363819004775493, 0.38900200905253046, 0.42790220995778355, 0.47069243095356195, 0.5177616740489182, 0.56953784145381, 0.6264916255991911, 0.6891407881591103, 0.7580548669750213, 0.8338603536725235, 0.917246389039776, 1.0089710279437536, 1.109868130738129, 1.220854943811942, 1.3429404381931362, 1.47723448201245, 1.624957930213695, 1.7874537232350647, 1.9661990955585713, 2.1628190051144287, 2.379100905625872, 2.6170109961884593, 2.8787120958073054, 3.1665833053880363, 3.48324163592684, 3.8315657995195243, 4.214722379471477, 4.636194617418625, 5.099814079160488, 5.609795487076537, 6.1707750357841915, 6.7878525393626115, 7.466637793298873, 8.213301572628762, 9.034631729891638, 9.938094902880803, 10.931904393168884, 12.025094832485772, 13.22760431573435, 14.550364747307786, 16.005401222038564, 17.60594134424242, 19.366535478666666, 21.303189026533335, 23.43350792918667, 25.77685872210534, 28.35454459431588, 31.18999905374747, 34.30899895912222, 37.73989885503445, 41.513888740537894, 45.66527761459169, 50.23180537605086, 55.25498591365595, 60.78048450502155, 66.85853295552371, 73.54438625107609, 80.89882487618371, 88.98870736380209, 97.88757810018231, 107.67633591020055, 118.44396950122061, 130.28836645134268, 143.31720309647696, 157.64892340612468, 173.41381574673716, 190.7551973214109, 209.830717053552, 230.81378875890724, 253.89516763479799, 279.2846843982778, 307.2131528381056, 337.9344681219162, 371.72791493410784, 408.9007064275187, 449.79077707027056, 494.76985477729767, 544.2468402550275, 598.6715242805302, 658.5386767085832, 724.3925443794416, 796.8317988173858, 876.5149786991244, 964.166476569037, 1060.5831242259408, 1166.6414366485349, 1283.3055803133884, 1411.6361383447274, 1552.7997521792004, 1708.0797273971205, 1878.8877001368326, 2066.776470150516, 2273.454117165568, 2500.799528882125, 2750.8794817703374, 3025.9674299473713, 3328.5641729421086, 3661.4205902363196, 4027.5626492599517, 4430.3189141859475, 4873.350805604543, 5360.685886164998, 5896.754474781498, 6486.429922259648, 7135.072914485614, 7848.580205934176, 8633.438226527594, 9496.782049180354, 10446.46025409839, 11491.10627950823, 12640.216907459055, 13904.238598204962, 15294.66245802546, 16824.128703828006, 18506.54157421081, 20357.19573163189, 22392.915304795082, 24632.206835274592, 27095.427518802055, 29804.97027068226, 32785.46729775049, 36064.01402752554, 39670.415430278095, 43637.45697330591, 48001.20267063651, 52801.32293770016, 58081.45523147019, 63889.60075461721, 70278.56083007893, 77306.41691308682, 85037.05860439551, 93540.76446483507, 102894.84091131858, 113184.32500245044, 124502.75750269549, 136953.03325296505, 150648.33657826157, 165713.17023608775, 182284.48725969656, 200512.93598566623, 220564.22958423287, 242620.65254265617, 266882.7177969218, 293570.989576614, 322928.0885342754, 355220.897387703, 390742.98712647334, 429817.2858391207, 472799.0144230328, 520078.91586533614, 572086.8074518698, 629295.4881970568, 692225.0370167625, 761447.5407184388, 837592.2947902827, 921351.5242693111, 1013486.6766962423, 1114835.3443658666, 1226318.8788024534, 1348950.7666826989, 1483845.8433509688, 1632230.427686066, 1795453.4704546726, 1974998.81750014, 2172498.699250154, 2389748.56917517, 2628723.426092687, 2891595.768701956, 3180755.345572152, 3498830.8801293676, 3848713.9681423046, 4233585.364956535, 4656943.901452189, 5122638.291597408, 5634902.1207571495, 6198392.332832865, 6818231.566116152, 7500054.722727768, 8250060.195000546, 9075066.2145006, 9982572.835950661, 10980830.119545728, 12078913.131500302, 13286804.444650333, 14615484.889115367, 16077033.378026905, 17684736.715829596, 19453210.387412556, 21398531.426153813, 23538384.568769194, 25892223.025646117, 28481445.32821073, 31329589.861031804, 34462548.847134985, 37908803.731848486, 41699684.10503334, 45869652.51553667, 50456617.76709034, 55502279.543799385, 61052507.49817933, 67157758.24799727, 73873534.072797, 81260887.4800767, 89386976.22808437, 98325673.85089281, 108158241.2359821, 118974065.35958032, 130871471.89553836, 143958619.08509222, 158354480.99360144, 174189929.0929616, 191608922.0022578, 210769814.2024836, 231846795.62273198, 255031475.1850052, 280534622.70350575, 308588084.97385633, 339446893.471242, 373391582.8183662, 410730741.10020286, 451803815.2102232, 496984196.7312456, 546682616.4043702, 601350878.0448073, 661485965.8492881, 727634562.434217, 800398018.6776388, 880437820.5454028, 968481602.5999432, 1065329762.8599375, 1171862739.1459315, 1289049013.0605247, 1417953914.3665774, 1559749305.8032353, 1715724236.383559, 1887296660.021915, 2076026326.0241067, 2283628958.626518, 2511991854.4891696, 2763191039.938087, 3039510143.9318957, 3343461158.3250856, 3677807274.1575947, 4045588001.5733542, 4450146801.73069, 4895161481.903759, 5384677630.094135, 5923145393.103549, 6515459932.413904, 7167005925.655295, 7883706518.220825, 8672077170.042908, 9539284887.0472, 10493213375.75192, 11542534713.327114, 12696788184.659826, 13966467003.12581, 15363113703.438393, 16899425073.782234, 18589367581.160458, 20448304339.276505, 22493134773.204155, 24742448250.524574, 27216693075.577034, 29938362383.13474, 32932198621.448215, 36225418483.59304, 39847960331.95235, 43832756365.14758, 48216032001.662346, 53037635201.82858, 58341398722.011444, 64175538594.21259, 70593092453.63387, 77652401698.99725, 85417641868.89699, 93959406055.7867, 103355346661.36537, 113690881327.50192, 125059969460.25212, 137565966406.27734, 151322563046.9051, 166454819351.5956, 183100301286.7552, 201410331415.43073, 221551364556.97382, 243706501012.6712, 268077151113.93835, 294884866225.3322, 324373352847.8655, 356810688132.65204, 392491756945.9173, 431740932640.50903, 474915025904.56, 522406528495.01605, 574647181344.5177, 632111899478.9695, 695323089426.8665, 764855398369.5532, 841340938206.5087, 925475032027.1597, 1018022535229.8757, 1119824788752.8633, 1231807267628.1497, 1354987994390.9648, 1490486793830.0615, 1639535473213.0679, 1803489020534.3748, 1983837922587.8125, 2182221714846.594, 2400443886331.2534, 2640488274964.379, 2904537102460.817, 3194990812706.899, 3514489893977.589, 3865938883375.348, 4252532771712.8833, 4677786048884.172, 5145564653772.59, 5660121119149.85, 6226133231064.835, 6848746554171.319, 7533621209588.452, 8286983330547.298, 9115681663602.03, 10027249829962.232, 11029974812958.457, 12132972294254.305, 13346269523679.736, 14680896476047.71, 16148986123652.482, 17763884736017.73, 19540273209619.504, 21494300530581.457, 23643730583639.605, 26008103642003.566, 28608914006203.926, 31469805406824.32, 34616785947506.754, 38078464542257.43, 41886310996483.18, 46074942096131.5, 50682436305744.66, 55750679936319.125, 61325747929951.04, 67458322722946.15, 74204154995240.77, 81624570494764.84, 89787027544241.33, 98765730298665.47, 108642303328532.03, 119506533661385.25, 131457187027523.78, 144602905730276.16, 159063196303303.78, 174969515933634.2, 192466467526997.62, 211713114279697.4, 232884425707667.16, 256172868278433.9, 281790155106277.3, 309969170616905.06, 340966087678595.6, 375062696446455.2, 412568966091100.75, 453825862700210.9, 499208448970232.0, 549129293867255.25, 604042223253980.9, 664446445579379.0, 730891090137317.0, 803980199151048.8, 884378219066153.8, 972816040972769.2, 1070097645070046.2, 1177107409577051.0, 1294818150534756.2, 1424299965588232.0, 1566729962147055.2, 1723402958361761.0, 1895743254197937.2, 2085317579617731.2, 2293849337579504.5, 2523234271337455.0, 2775557698471200.5, 3053113468318321.0, 3358424815150153.5, 3694267296665169.0, 4063694026331686.0, 4470063428964855.0, 4917069771861341.0, 5408776749047476.0, 5949654423952224.0, 6544619866347447.0, 7199081852982192.0, 7918990038280412.0, 8710889042108454.0, 9581977946319300.0, 1.054017574095123e+16, 1.1594193315046354e+16, 1.275361264655099e+16, 1.402897391120609e+16, 1.54318713023267e+16, 1.6975058432559372e+16, 1.867256427581531e+16, 2.0539820703396844e+16, 2.2593802773736532e+16, 2.4853183051110188e+16, 2.733850135622121e+16, 3.0072351491843332e+16, 3.3079586641027668e+16, 3.638754530513044e+16, 4.002629983564349e+16, 4.402892981920784e+16, 4.843182280112862e+16, 5.327500508124149e+16, 5.860250558936564e+16, 6.446275614830221e+16, 7.090903176313243e+16, 7.799993493944568e+16, 8.579992843339026e+16, 9.43799212767293e+16, 1.0381791340440224e+17, 1.1419970474484248e+17, 1.2561967521932674e+17, 1.3818164274125942e+17, 1.5199980701538538e+17, 1.6719978771692394e+17, 1.8391976648861635e+17, 2.02311743137478e+17, 2.2254291745122582e+17, 2.447972091963484e+17, 2.6927693011598326e+17, 2.9620462312758163e+17, 3.2582508544033984e+17, 3.584075939843738e+17, 3.9424835338281126e+17, 4.336731887210924e+17, 4.770405075932017e+17, 5.247445583525219e+17, 5.772190141877742e+17, 6.349409156065517e+17, 6.984350071672069e+17, 7.682785078839277e+17, 8.451063586723205e+17, 9.296169945395526e+17, 1.022578693993508e+18, 1.1248365633928589e+18, 1.237320219732145e+18, 1.3610522417053596e+18, 1.4971574658758958e+18, 1.6468732124634854e+18, 1.8115605337098342e+18, 1.992716587080818e+18, 2.1919882457888998e+18, 2.41118707036779e+18, 2.652305777404569e+18, 2.917536355145026e+18, 3.2092899906595287e+18, 3.530218989725482e+18, 3.8832408886980306e+18, 4.271564977567834e+18, 4.698721475324618e+18, 5.16859362285708e+18, 5.685452985142788e+18, 6.253998283657068e+18, 6.879398112022775e+18, 7.567337923225053e+18, 8.324071715547559e+18, 9.156478887102316e+18, 1.0072126775812549e+19, 1.1079339453393805e+19, 1.2187273398733187e+19, 1.3406000738606506e+19, 1.4746600812467157e+19, 1.6221260893713875e+19, 1.7843386983085265e+19, 1.962772568139379e+19, 2.1590498249533174e+19, 2.3749548074486493e+19, 2.6124502881935143e+19, 2.873695317012866e+19, 3.1610648487141528e+19, 3.477171333585568e+19, 3.824888466944125e+19, 4.2073773136385384e+19, 4.628115045002392e+19, 5.090926549502632e+19, 5.600019204452896e+19, 6.160021124898186e+19, 6.776023237388005e+19, 7.453625561126807e+19, 8.198988117239489e+19, 9.018886928963438e+19, 9.920775621859783e+19],
          file_writer: instance(FileWriter):
            event_writer: instance(EventFileWriter),
          filename_suffix: '',
          flush_secs: 15,
          log_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                    10)_20240507-213035',
          max_queue: 10,
          purge_step: None,
      buffer_synchronizer: {'type': 'BufferSynchronizer', 'target_buffer': <reinforcement_learning.base.utility.deque_buffer_wrapper.DequeBufferWrapper object at 0x000001F24494C9D0>},
      output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                   10)_20240507-213035',
      own_sync_manager: False,
      sync_manager: instance(SyncManager):
        address: '\\\\.\\pipe\\pyc-44012-0-hn1bcjv1',
        shutdown: <Finalize object, callback=_finalize_manager, args=(<SpawnProcess name='SyncManager-1' pid=44012 parent=3216 started>, '\\\\.\\pipe\\pyc-44012-0-hn1bcjv1', b'\x9b(\x8c\xba\x87\x1dK\xc7\xfb\x81B\xcb\x02C\xb1fVK\xcc\xa8a\xbc\x96 \xa7C\xd6\xa5/\xb2\xebp', <multiprocessing.managers.State object at 0x000001F2449EEF40>, <function Client at 0x000001F24409E160>), exitpriority=0>,
      writing_buffer: deque([], maxlen=5000)
    'text': instance(TextLogger):
      file_name: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                  10)_20240507-213035\\log.txt',
      logger: <Logger multiprocessing (INFO)>,
      output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                   10)_20240507-213035'
  },
  loss_fn: MCTSLossFunction(
  (approximator): MCTSApproximator(
    (model): Sequential(
      (0): Linear(in_features=46, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=88, bias=True)
    )
  )
),
  lower_priority: True,
  lr_scheduler: instance(StepLR):
    base_lrs: [0.0002],
    gamma: 0.1,
    last_epoch: 0,
    optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0002
    lr: 0.0002
    weight_decay: 0
),
    step_size: 1000,
    verbose: False,
  num_of_epochs: 5001,
  number_of_evaluation_agents: 2,
  number_of_training_agents: 5,
  optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0002
    lr: 0.0002
    weight_decay: 0
),
  original_affinity: None,
  output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
               10)_20240507-213035',
  output_profile: False,
  output_root: 'logs/',
  processes: [],
  random_seed: 0,
  replay_buffer: {'type': 'ShuffleReplayBuffer', 'batch_size': 100, 'buffer_size': 0},
  replay_buffer_agent_queue: {'type': 'SequentialReplayBuffer', 'batch_size': 100, 'buffer_size': 100},
  replay_buffer_queue: None,
  replay_buffer_size: 1000,
  replay_buffer_synchronizer: {'type': 'BufferSynchronizer', 'target_buffer': {'type': 'ShuffleReplayBuffer', 'batch_size': 100, 'buffer_size': 0}},
  sync_dict: <DictProxy object, typeid 'dict' at 0x1f2449eefa0>,
  sync_manager: instance(SyncManager):
    address: '\\\\.\\pipe\\pyc-44012-0-hn1bcjv1',
    shutdown: <Finalize object, callback=_finalize_manager, args=(<SpawnProcess name='SyncManager-1' pid=44012 parent=3216 started>, '\\\\.\\pipe\\pyc-44012-0-hn1bcjv1', b'\x9b(\x8c\xba\x87\x1dK\xc7\xfb\x81B\xcb\x02C\xb1fVK\xcc\xa8a\xbc\x96 \xa7C\xd6\xa5/\xb2\xebp', <multiprocessing.managers.State object at 0x000001F2449EEF40>, <function Client at 0x000001F24409E160>), exitpriority=0>,
  train_episode_length: 100,
  weight_decay: 0

2024-05-07 21:31:01,491 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #0: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 6, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 6, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.05128205128205128, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.31, '(rev, 2)': 0.01}}
2024-05-07 21:31:01,491 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:01,493 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-07 21:31:01,497 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #0: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, rel, 1, 2, 10, 0, 1),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, nob, not, irr, 1, 0, 9, 0, 1)', 'reward_ratio': '0/1', 'revenue': 0.11764705882352941, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.32, '(min, 1)': 0.34, '(rev, 1)': 0.04}}
2024-05-07 21:31:01,498 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:01,498 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-07 21:31:01,506 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #0: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.025, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.26, '(rev, 1)': 0.01}}
2024-05-07 21:31:01,506 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:01,507 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-07 21:31:01,538 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #0: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 5, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.42, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:31:01,538 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:01,539 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-07 21:31:01,539 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #0: {'transition': '(exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, rel, 1, 6, 10, 1, 1),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, nob, not, irr, 1, 0, 9, 0, 1)', 'reward_ratio': '0/1', 'revenue': 0.11627906976744186, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 10)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.44, '(rev, 1)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:31:01,539 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:01,540 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-07 21:31:01,540 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #0: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.029411764705882353, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(min, 0)': 0.42, '(min, 1)': 0.24, '(rev, 1)': 0.01}}
2024-05-07 21:31:01,541 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:01,542 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-07 21:31:03,757 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #0: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.02631578947368421, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.36, '(rev, 1)': 0.01}}
2024-05-07 21:31:03,758 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:03,758 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-07 21:31:23,400 - MainProcess - INFO - text_logger.py - 51 - Train epoch #0
2024-05-07 21:31:23,418 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.0509,  0.0000,  0.0000,  0.0000,  0.1385,  0.0000,  0.1335,  0.0083,
         0.1518,  0.0000,  0.1096,  0.0032,  0.0000,  0.0000,  0.0756,  0.0021,
         0.0000,  0.0000,  0.0836,  0.0000,  0.0000,  0.0000,  0.0665,  0.0003,
         0.0000,  0.0000,  0.0628,  0.0000,  0.0000,  0.0000,  0.0472,  0.0000,
         0.0000,  0.0000,  0.0551,  0.0000,  0.0000,  0.0000,  0.0454,  0.0000,
         0.0000,  0.0000,  0.0165,  0.0000,  0.0000])  tensor([0.6359, 0.0000, 0.0000, 0.0000, 0.1162, 0.0000, 0.0713, 0.0498, 0.1125,
        0.0000, 0.0601, 0.0275, 0.0000, 0.0000, 0.0446, 0.0208, 0.0000, 0.0000,
        0.0502, 0.0000, 0.0000, 0.0000, 0.0443, 0.0072, 0.0000, 0.0000, 0.0450,
        0.0000, 0.0000, 0.0000, 0.0380, 0.0000, 0.0000, 0.0000, 0.0471, 0.0000,
        0.0000, 0.0000, 0.0498, 0.0000, 0.0000, 0.0000, 0.0397, 0.0000, 0.0000]) (500)
2024-05-07 21:31:23,573 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4703219336656964
2024-05-07 21:31:23,609 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.073530.04412
2024-05-07 21:31:23,609 - MainProcess - INFO - text_logger.py - 51 - Simulated Policy Revenue 0.017740.01269
2024-05-07 21:31:23,633 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #1: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 4, 0, 0),(ado, 4)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/4', 'revenue': 0.05263157894736842, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.01, '(ado, 4)': 0.03, '(ado, 7)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.36, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-05-07 21:31:23,633 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #1: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 5, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.21}}
2024-05-07 21:31:23,633 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:23,634 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:23,635 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-07 21:31:23,635 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-07 21:31:23,650 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #1: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.32, '(min, 1)': 0.32}}
2024-05-07 21:31:23,650 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:23,650 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-07 21:31:23,667 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #1: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.32, '(min, 1)': 0.29}}
2024-05-07 21:31:23,667 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:23,671 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #1: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.14893617021276595, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.34, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:31:23,671 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:23,671 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-07 21:31:23,671 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-07 21:31:24,073 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #1: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.02, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.33}}
2024-05-07 21:31:24,074 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:24,075 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-07 21:31:26,885 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #1: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, nob, not, irr, 1, 0, 9, 0, 1),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, rel, 1, 0, 10, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.022222222222222223, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 10)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.31, '(rev, 1)': 0.01}}
2024-05-07 21:31:26,885 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:26,886 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-07 21:31:27,038 - MainProcess - INFO - text_logger.py - 51 - Train epoch #1
2024-05-07 21:31:27,040 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.2491,  0.0000,  0.0000,  0.0000,  0.1124,  0.0000,  0.1309,  0.0014,
         0.1275,  0.0000,  0.1132,  0.0005,  0.0000,  0.0000,  0.0836,  0.0008,
         0.0000,  0.0000,  0.0929,  0.0004,  0.0000,  0.0000,  0.0774,  0.0000,
         0.0000,  0.0000,  0.0719,  0.0000,  0.0000,  0.0000,  0.0549,  0.0000,
         0.0000,  0.0000,  0.0623,  0.0000,  0.0000,  0.0000,  0.0508,  0.0000,
         0.0000,  0.0000,  0.0191,  0.0000,  0.0000])  tensor([0.6798, 0.0000, 0.0000, 0.0000, 0.0901, 0.0000, 0.0566, 0.0215, 0.0906,
        0.0000, 0.0469, 0.0118, 0.0000, 0.0000, 0.0367, 0.0122, 0.0000, 0.0000,
        0.0422, 0.0084, 0.0000, 0.0000, 0.0388, 0.0000, 0.0000, 0.0000, 0.0406,
        0.0000, 0.0000, 0.0000, 0.0358, 0.0000, 0.0000, 0.0000, 0.0455, 0.0000,
        0.0000, 0.0000, 0.0499, 0.0000, 0.0000, 0.0000, 0.0421, 0.0000, 0.0000]) (500)
2024-05-07 21:31:27,062 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46937969944757585
2024-05-07 21:31:27,064 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:31:27,070 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #2: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.57, '(min, 1)': 0.03}}
2024-05-07 21:31:27,070 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:27,071 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-05-07 21:31:27,086 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #2: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 3)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.22}}
2024-05-07 21:31:27,086 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:27,086 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-05-07 21:31:27,101 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #2: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.41, '(min, 1)': 0.2}}
2024-05-07 21:31:27,102 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:27,102 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-05-07 21:31:27,121 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #2: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.41, '(min, 1)': 0.27}}
2024-05-07 21:31:27,121 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:27,121 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-05-07 21:31:27,133 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #2: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 5, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 4)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.21, '(rev, 1)': 0.04, '(rev, 2)': 0.02}}
2024-05-07 21:31:27,134 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:27,134 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-05-07 21:31:29,241 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #2: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.36585365853658536, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.45, '(rev, 1)': 0.01, '(rev, 2)': 0.02}}
2024-05-07 21:31:29,241 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:29,242 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-05-07 21:31:31,514 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #2: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.29}}
2024-05-07 21:31:31,514 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:31,515 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-05-07 21:31:31,678 - MainProcess - INFO - text_logger.py - 51 - Train epoch #2
2024-05-07 21:31:31,680 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.2749,  0.0000,  0.0000,  0.0000,  0.1084,  0.0000,  0.1138,  0.0048,
         0.1192,  0.0000,  0.1043,  0.0024,  0.0000,  0.0000,  0.0860,  0.0000,
         0.0000,  0.0000,  0.0872,  0.0000,  0.0000,  0.0000,  0.0770,  0.0000,
         0.0000,  0.0000,  0.0825,  0.0000,  0.0000,  0.0000,  0.0593,  0.0000,
         0.0000,  0.0000,  0.0723,  0.0000,  0.0000,  0.0000,  0.0616,  0.0000,
         0.0000,  0.0000,  0.0212,  0.0000,  0.0000])  tensor([0.7598, 0.0000, 0.0000, 0.0000, 0.1003, 0.0000, 0.0513, 0.0379, 0.0988,
        0.0000, 0.0411, 0.0236, 0.0000, 0.0000, 0.0345, 0.0000, 0.0000, 0.0000,
        0.0360, 0.0000, 0.0000, 0.0000, 0.0336, 0.0000, 0.0000, 0.0000, 0.0381,
        0.0000, 0.0000, 0.0000, 0.0305, 0.0000, 0.0000, 0.0000, 0.0403, 0.0000,
        0.0000, 0.0000, 0.0503, 0.0000, 0.0000, 0.0000, 0.0408, 0.0000, 0.0000]) (500)
2024-05-07 21:31:31,703 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46843746522945523
2024-05-07 21:31:31,707 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:31:31,740 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #3: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 7)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.29}}
2024-05-07 21:31:31,740 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #3: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 0, 8, 0, 1),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 1, 8, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.02, '(min, 0)': 0.45, '(min, 1)': 0.26}}
2024-05-07 21:31:31,740 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:31,740 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:31,741 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-05-07 21:31:31,741 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-05-07 21:31:31,755 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #3: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.32, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(ado, 8)': 0.02, '(min, 0)': 0.47, '(min, 1)': 0.25, '(rev, 1)': 0.02, '(rev, 2)': 0.02}}
2024-05-07 21:31:31,755 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:31,756 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-05-07 21:31:31,776 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #3: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.51, '(min, 1)': 0.11}}
2024-05-07 21:31:31,776 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:31,777 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-05-07 21:31:31,789 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #3: {'transition': '(exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 2, 9, 1, 1),(min, 0)->(exi, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 3, 9, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.29, '(min, 1)': 0.3}}
2024-05-07 21:31:31,789 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:31,790 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-05-07 21:31:31,793 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #3: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.29}}
2024-05-07 21:31:31,793 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:31,794 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-05-07 21:31:33,751 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #3: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.43, '(min, 1)': 0.21}}
2024-05-07 21:31:33,752 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:33,752 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-05-07 21:31:33,918 - MainProcess - INFO - text_logger.py - 51 - Train epoch #3
2024-05-07 21:31:33,921 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.4370,  0.0000,  0.0000,  0.0000,  0.0995,  0.0000,  0.1134,  0.0012,
         0.1097,  0.0000,  0.1071,  0.0009,  0.0000,  0.0000,  0.0948,  0.0006,
         0.0000,  0.0000,  0.0875,  0.0000,  0.0000,  0.0000,  0.0875,  0.0000,
         0.0000,  0.0000,  0.0897,  0.0000,  0.0000,  0.0000,  0.0554,  0.0000,
         0.0000,  0.0000,  0.0753,  0.0000,  0.0000,  0.0000,  0.0595,  0.0000,
         0.0000,  0.0000,  0.0181,  0.0000,  0.0000])  tensor([0.7811, 0.0000, 0.0000, 0.0000, 0.0834, 0.0000, 0.0437, 0.0196, 0.0840,
        0.0000, 0.0341, 0.0141, 0.0000, 0.0000, 0.0304, 0.0089, 0.0000, 0.0000,
        0.0297, 0.0000, 0.0000, 0.0000, 0.0321, 0.0000, 0.0000, 0.0000, 0.0368,
        0.0000, 0.0000, 0.0000, 0.0260, 0.0000, 0.0000, 0.0000, 0.0410, 0.0000,
        0.0000, 0.0000, 0.0460, 0.0000, 0.0000, 0.0000, 0.0339, 0.0000, 0.0000]) (500)
2024-05-07 21:31:33,943 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46749523101133467
2024-05-07 21:31:33,946 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:31:34,123 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #4: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.21, '(min, 1)': 0.39}}
2024-05-07 21:31:34,123 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:34,124 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-05-07 21:31:34,217 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #4: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.29, '(min, 1)': 0.33}}
2024-05-07 21:31:34,218 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:34,218 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-05-07 21:31:34,355 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #4: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 4, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.44, '(min, 1)': 0.19}}
2024-05-07 21:31:34,356 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:34,356 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-05-07 21:31:35,174 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #4: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 4)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.32}}
2024-05-07 21:31:35,174 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:35,175 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-05-07 21:31:35,757 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #4: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 6, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.020833333333333332, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.27, '(rev, 1)': 0.01}}
2024-05-07 21:31:35,758 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:35,758 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-05-07 21:31:35,928 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #4: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 1, 1, 10, 1, 1),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 0, 9, 0, 1)', 'reward_ratio': '0/1', 'revenue': 0.20454545454545456, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 10)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.27, '(rev, 1)': 0.01, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:31:35,929 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:35,929 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-05-07 21:31:36,035 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #4: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.23}}
2024-05-07 21:31:36,035 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:36,036 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-05-07 21:31:36,201 - MainProcess - INFO - text_logger.py - 51 - Train epoch #4
2024-05-07 21:31:36,203 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.7685e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1046e-01,
         0.0000e+00,  1.2044e-01,  1.1654e-03,  1.1943e-01,  0.0000e+00,
         1.1254e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.5067e-02,
         2.4242e-04,  0.0000e+00,  0.0000e+00,  8.1553e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  8.9473e-02,  1.4815e-04,  0.0000e+00,
         0.0000e+00,  8.9990e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         4.7644e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  7.4368e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.8004e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  9.4771e-03,  0.0000e+00,  0.0000e+00])  tensor([0.6829, 0.0000, 0.0000, 0.0000, 0.0853, 0.0000, 0.0451, 0.0184, 0.0836,
        0.0000, 0.0378, 0.0000, 0.0000, 0.0000, 0.0326, 0.0054, 0.0000, 0.0000,
        0.0307, 0.0000, 0.0000, 0.0000, 0.0358, 0.0033, 0.0000, 0.0000, 0.0405,
        0.0000, 0.0000, 0.0000, 0.0244, 0.0000, 0.0000, 0.0000, 0.0409, 0.0000,
        0.0000, 0.0000, 0.0403, 0.0000, 0.0000, 0.0000, 0.0219, 0.0000, 0.0000]) (500)
2024-05-07 21:31:36,224 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4665529967932141
2024-05-07 21:31:36,226 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:31:36,467 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #5: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.24390243902439024, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.46, '(min, 1)': 0.22, '(rev, 10)': 0.01}}
2024-05-07 21:31:36,468 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:36,468 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-05-07 21:31:36,583 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #5: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.34, '(min, 1)': 0.29}}
2024-05-07 21:31:36,583 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:36,584 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-05-07 21:31:38,256 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #5: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, nob, not, nob, not, rel, 1, 1, 8, 0, 1),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, nob, not, nob, not, irr, 1, 2, 8, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.22641509433962265, 'length': 100, 'actions': {'(ado, 1)': 0.06, '(ado, 2)': 0.03, '(ado, 4)': 0.02, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.42, '(rev, 1)': 0.04, '(rev, 4)': 0.02}}
2024-05-07 21:31:38,257 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:38,257 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-05-07 21:31:38,654 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #5: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 4, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 10)': 0.01, '(ado, 3)': 0.02, '(ado, 9)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.25}}
2024-05-07 21:31:38,654 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:38,655 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-05-07 21:31:39,160 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #5: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.31}}
2024-05-07 21:31:39,160 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:39,161 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-05-07 21:31:40,195 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #5: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.03508771929824561, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 7)': 0.01, '(ado, 9)': 0.02, '(min, 0)': 0.32, '(min, 1)': 0.38, '(rev, 1)': 0.02}}
2024-05-07 21:31:40,195 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:40,196 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-05-07 21:31:40,450 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #5: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, rel, 1, 0, 10, 0, 1),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, nob, not, irr, 1, 0, 9, 0, 1)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.35, '(min, 1)': 0.29}}
2024-05-07 21:31:40,450 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:40,451 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-05-07 21:31:40,607 - MainProcess - INFO - text_logger.py - 51 - Train epoch #5
2024-05-07 21:31:40,610 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.3213e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2581e-01,
         0.0000e+00,  1.3036e-01,  3.2301e-03,  1.2873e-01,  0.0000e+00,
         1.1640e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.9801e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  7.7022e-02,  2.5714e-04,
         0.0000e+00,  0.0000e+00,  8.6918e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  9.1935e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.5495e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.1368e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.6515e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.1547e-03,  0.0000e+00,  0.0000e+00])  tensor([0.7028, 0.0000, 0.0000, 0.0000, 0.1011, 0.0000, 0.0541, 0.0293, 0.0961,
        0.0000, 0.0464, 0.0000, 0.0000, 0.0000, 0.0419, 0.0000, 0.0000, 0.0000,
        0.0373, 0.0041, 0.0000, 0.0000, 0.0441, 0.0000, 0.0000, 0.0000, 0.0523,
        0.0000, 0.0000, 0.0000, 0.0254, 0.0000, 0.0000, 0.0000, 0.0467, 0.0000,
        0.0000, 0.0000, 0.0384, 0.0000, 0.0000, 0.0000, 0.0140, 0.0000, 0.0000]) (500)
2024-05-07 21:31:40,630 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46585466501411793
2024-05-07 21:31:40,632 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.121950.12195
2024-05-07 21:31:40,637 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.44, '(min, 1)': 0.16}}
2024-05-07 21:31:40,637 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:40,638 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-05-07 21:31:40,653 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.26, '(rev, 1)': 0.01}}
2024-05-07 21:31:40,655 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:40,655 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-05-07 21:31:40,876 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 4, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.038461538461538464, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.27, '(rev, 2)': 0.01}}
2024-05-07 21:31:40,876 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:40,877 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-05-07 21:31:41,677 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 2, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.29}}
2024-05-07 21:31:41,677 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:41,678 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-05-07 21:31:42,579 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #6: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 4)': 0.01, '(ado, 6)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.37}}
2024-05-07 21:31:42,580 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:42,580 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-05-07 21:31:42,787 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.38, '(rev, 6)': 0.01}}
2024-05-07 21:31:42,787 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:42,787 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-05-07 21:31:44,454 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2653061224489796, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.37, '(rev, 1)': 0.03}}
2024-05-07 21:31:44,454 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:44,454 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-05-07 21:31:44,615 - MainProcess - INFO - text_logger.py - 51 - Train epoch #6
2024-05-07 21:31:44,618 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.1305e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2509e-01,
         0.0000e+00,  1.3462e-01,  1.4188e-03,  1.2737e-01,  0.0000e+00,
         1.1998e-01,  2.6667e-04,  0.0000e+00,  0.0000e+00,  1.0545e-01,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  7.6159e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  9.0372e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  9.2950e-02,  7.4074e-05,  0.0000e+00,  0.0000e+00,
         3.2772e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.2706e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8623e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  2.1467e-03,  0.0000e+00,  0.0000e+00])  tensor([0.8490, 0.0000, 0.0000, 0.0000, 0.0861, 0.0000, 0.0498, 0.0183, 0.0814,
        0.0000, 0.0433, 0.0060, 0.0000, 0.0000, 0.0401, 0.0000, 0.0000, 0.0000,
        0.0340, 0.0000, 0.0000, 0.0000, 0.0427, 0.0000, 0.0000, 0.0000, 0.0522,
        0.0017, 0.0000, 0.0000, 0.0216, 0.0000, 0.0000, 0.0000, 0.0457, 0.0000,
        0.0000, 0.0000, 0.0330, 0.0000, 0.0000, 0.0000, 0.0074, 0.0000, 0.0000]) (500)
2024-05-07 21:31:44,644 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46515687524044175
2024-05-07 21:31:44,647 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.122220.12222
2024-05-07 21:31:44,679 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #7: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 5, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.21}}
2024-05-07 21:31:44,679 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:44,680 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-05-07 21:31:44,694 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #7: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5116279069767442, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 7)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.37, '(rev, 1)': 0.03, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:31:44,695 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:44,695 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-05-07 21:31:45,116 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #7: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.28, '(min, 1)': 0.33}}
2024-05-07 21:31:45,116 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:45,117 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-05-07 21:31:45,156 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #7: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.020833333333333332, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 4)': 0.02, '(ado, 5)': 0.01, '(ado, 7)': 0.02, '(min, 0)': 0.3, '(min, 1)': 0.45, '(rev, 1)': 0.01}}
2024-05-07 21:31:45,156 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:45,156 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-05-07 21:31:46,659 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #7: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 5, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.36}}
2024-05-07 21:31:46,659 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:46,660 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-05-07 21:31:46,849 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #7: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(ado, 4)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.16}}
2024-05-07 21:31:46,849 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:46,850 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-05-07 21:31:47,224 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #7: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.09302325581395349, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.42, '(rev, 2)': 0.02}}
2024-05-07 21:31:47,225 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:47,226 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-05-07 21:31:47,389 - MainProcess - INFO - text_logger.py - 51 - Train epoch #7
2024-05-07 21:31:47,392 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.2760,  0.0000,  0.0000,  0.0000,  0.1087,  0.0000,  0.1350,  0.0004,
         0.1081,  0.0000,  0.1192,  0.0005,  0.0000,  0.0000,  0.1132,  0.0000,
         0.0000,  0.0000,  0.0839,  0.0000,  0.0000,  0.0000,  0.0997,  0.0000,
         0.0000,  0.0000,  0.1038,  0.0000,  0.0000,  0.0000,  0.0356,  0.0000,
         0.0000,  0.0000,  0.0653,  0.0000,  0.0000,  0.0000,  0.0253,  0.0000,
         0.0000,  0.0000,  0.0012,  0.0000,  0.0000])  tensor([0.7433, 0.0000, 0.0000, 0.0000, 0.0722, 0.0000, 0.0370, 0.0097, 0.0669,
        0.0000, 0.0313, 0.0067, 0.0000, 0.0000, 0.0301, 0.0000, 0.0000, 0.0000,
        0.0256, 0.0000, 0.0000, 0.0000, 0.0320, 0.0000, 0.0000, 0.0000, 0.0400,
        0.0000, 0.0000, 0.0000, 0.0171, 0.0000, 0.0000, 0.0000, 0.0390, 0.0000,
        0.0000, 0.0000, 0.0277, 0.0000, 0.0000, 0.0000, 0.0047, 0.0000, 0.0000]) (500)
2024-05-07 21:31:47,428 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4647262689292979
2024-05-07 21:31:47,432 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.255810.25581
2024-05-07 21:31:47,483 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #8: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.44, '(min, 0)': 0.41, '(min, 1)': 0.15}}
2024-05-07 21:31:47,483 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #8: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 3, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.02, '(min, 0)': 0.42, '(min, 1)': 0.31}}
2024-05-07 21:31:47,484 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:47,484 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:47,484 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-05-07 21:31:47,485 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-05-07 21:31:47,504 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #8: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.46, '(min, 1)': 0.16}}
2024-05-07 21:31:47,504 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:47,505 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-05-07 21:31:47,839 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #8: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.38636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.43, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:31:47,839 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:47,840 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-05-07 21:31:49,803 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #8: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(ado, 9)': 0.02, '(min, 0)': 0.25, '(min, 1)': 0.44}}
2024-05-07 21:31:49,804 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:49,804 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-05-07 21:31:50,313 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #8: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.31}}
2024-05-07 21:31:50,313 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:50,314 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-05-07 21:31:50,358 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #8: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.34, '(rev, 1)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:31:50,358 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:50,358 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-05-07 21:31:50,510 - MainProcess - INFO - text_logger.py - 51 - Train epoch #8
2024-05-07 21:31:50,513 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.2338e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4610e-01,
         0.0000e+00,  1.4827e-01,  2.2367e-03,  1.4067e-01,  0.0000e+00,
         1.2631e-01,  1.6514e-04,  0.0000e+00,  0.0000e+00,  1.1219e-01,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  7.5760e-02,  1.3118e-04,
         0.0000e+00,  0.0000e+00,  8.3356e-02,  7.1429e-05,  0.0000e+00,
         0.0000e+00,  8.3329e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.6762e-02,  6.6667e-05,  0.0000e+00,  0.0000e+00,  4.2627e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1608e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.4037e-04,  0.0000e+00,  0.0000e+00])  tensor([0.9523, 0.0000, 0.0000, 0.0000, 0.1022, 0.0000, 0.0551, 0.0203, 0.0916,
        0.0000, 0.0482, 0.0037, 0.0000, 0.0000, 0.0473, 0.0000, 0.0000, 0.0000,
        0.0381, 0.0021, 0.0000, 0.0000, 0.0474, 0.0016, 0.0000, 0.0000, 0.0520,
        0.0000, 0.0000, 0.0000, 0.0198, 0.0015, 0.0000, 0.0000, 0.0387, 0.0000,
        0.0000, 0.0000, 0.0183, 0.0000, 0.0000, 0.0000, 0.0024, 0.0000, 0.0000]) (500)
2024-05-07 21:31:50,532 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46378403471117735
2024-05-07 21:31:50,534 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:31:50,542 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #9: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 4)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.28}}
2024-05-07 21:31:50,543 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:50,543 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-05-07 21:31:50,544 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-05-07 21:31:50,557 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #9: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.47, '(min, 0)': 0.44, '(min, 1)': 0.09}}
2024-05-07 21:31:50,557 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:50,558 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-05-07 21:31:50,849 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #9: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.04081632653061224, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.28, '(rev, 1)': 0.02}}
2024-05-07 21:31:50,849 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:50,850 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-05-07 21:31:52,619 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #9: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.19047619047619047, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.31, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:31:52,619 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:52,620 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-05-07 21:31:53,377 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #9: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 2, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 5)': 0.02, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.3}}
2024-05-07 21:31:53,377 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:53,377 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-05-07 21:31:54,542 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #9: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.38, '(min, 1)': 0.36, '(rev, 1)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:31:54,542 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:54,543 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-05-07 21:31:54,704 - MainProcess - INFO - text_logger.py - 51 - Train epoch #9
2024-05-07 21:31:54,707 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.0845e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3351e-01, 0.0000e+00,
        1.5016e-01, 1.7154e-03, 1.2747e-01, 0.0000e+00, 1.2825e-01, 1.2903e-04,
        0.0000e+00, 0.0000e+00, 1.1680e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.0408e-02, 1.1765e-04, 0.0000e+00, 0.0000e+00, 9.0740e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.8899e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9282e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2512e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.5814e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.1614e-04, 0.0000e+00, 0.0000e+00])  tensor([0.7108, 0.0000, 0.0000, 0.0000, 0.0945, 0.0000, 0.0492, 0.0171, 0.0830,
        0.0000, 0.0425, 0.0029, 0.0000, 0.0000, 0.0429, 0.0000, 0.0000, 0.0000,
        0.0355, 0.0019, 0.0000, 0.0000, 0.0438, 0.0000, 0.0000, 0.0000, 0.0495,
        0.0000, 0.0000, 0.0000, 0.0190, 0.0000, 0.0000, 0.0000, 0.0377, 0.0000,
        0.0000, 0.0000, 0.0156, 0.0000, 0.0000, 0.0000, 0.0025, 0.0000, 0.0000]) (500)
2024-05-07 21:31:54,726 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4628418004930568
2024-05-07 21:31:54,729 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:31:54,766 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.027777777777777776, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.41, '(min, 1)': 0.23, '(rev, 1)': 0.01}}
2024-05-07 21:31:54,766 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.52, '(min, 1)': 0.17}}
2024-05-07 21:31:54,766 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:54,766 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:54,767 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-05-07 21:31:54,767 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-05-07 21:31:54,781 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #10: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 5, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.08695652173913043, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.54, '(min, 1)': 0.23, '(rev, 4)': 0.01}}
2024-05-07 21:31:54,781 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:54,782 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-05-07 21:31:54,828 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.15789473684210525, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(ado, 5)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.35, '(rev, 2)': 0.03}}
2024-05-07 21:31:54,828 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:54,829 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-05-07 21:31:55,405 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3684210526315789, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.42, '(rev, 1)': 0.01, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:31:55,405 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:55,406 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-05-07 21:31:55,627 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.48, '(min, 1)': 0.15}}
2024-05-07 21:31:55,627 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:55,628 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-05-07 21:31:58,225 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.11627906976744186, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.33, '(rev, 5)': 0.01}}
2024-05-07 21:31:58,226 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:58,226 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-05-07 21:31:58,387 - MainProcess - INFO - text_logger.py - 51 - Train epoch #10
2024-05-07 21:31:58,390 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.6141e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4978e-01,
         0.0000e+00,  1.6110e-01,  8.4094e-04,  1.3691e-01,  0.0000e+00,
         1.2972e-01,  7.2803e-04,  0.0000e+00,  0.0000e+00,  1.1509e-01,
         2.5941e-04,  0.0000e+00,  0.0000e+00,  7.5663e-02,  6.6667e-05,
         0.0000e+00,  0.0000e+00,  7.9413e-02,  6.6667e-05,  0.0000e+00,
         0.0000e+00,  7.7207e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.6002e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.7472e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  9.0707e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.2120e-04,  0.0000e+00,  0.0000e+00])  tensor([1.0480, 0.0000, 0.0000, 0.0000, 0.1091, 0.0000, 0.0564, 0.0095, 0.0934,
        0.0000, 0.0495, 0.0065, 0.0000, 0.0000, 0.0509, 0.0031, 0.0000, 0.0000,
        0.0395, 0.0015, 0.0000, 0.0000, 0.0457, 0.0015, 0.0000, 0.0000, 0.0489,
        0.0000, 0.0000, 0.0000, 0.0187, 0.0000, 0.0000, 0.0000, 0.0314, 0.0000,
        0.0000, 0.0000, 0.0139, 0.0000, 0.0000, 0.0000, 0.0031, 0.0000, 0.0000]) (500)
2024-05-07 21:31:58,414 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4619273440527139
2024-05-07 21:31:58,417 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.013890.01389
2024-05-07 21:31:58,435 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #11: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.49, '(min, 1)': 0.11}}
2024-05-07 21:31:58,435 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:58,436 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-05-07 21:31:58,454 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #11: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 5, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8043478260869565, 'length': 100, 'actions': {'(ado, 1)': 0.05, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.48, '(rev, 1)': 0.04, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.03}}
2024-05-07 21:31:58,454 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:58,455 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-05-07 21:31:58,465 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #11: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 4, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.39, '(min, 1)': 0.26}}
2024-05-07 21:31:58,465 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:58,466 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-05-07 21:31:58,757 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #11: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 4, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 9)': 0.02, '(min, 0)': 0.37, '(min, 1)': 0.3}}
2024-05-07 21:31:58,757 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:58,758 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-05-07 21:31:59,143 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #11: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.37}}
2024-05-07 21:31:59,144 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:31:59,144 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-05-07 21:32:00,037 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #11: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.18181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.42, '(min, 1)': 0.28, '(rev, 8)': 0.01}}
2024-05-07 21:32:00,037 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:00,038 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-05-07 21:32:00,768 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #11: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 6, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 5, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0425531914893617, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 3)': 0.01, '(ado, 5)': 0.02, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.27, '(rev, 2)': 0.01}}
2024-05-07 21:32:00,768 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:00,768 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-05-07 21:32:00,932 - MainProcess - INFO - text_logger.py - 51 - Train epoch #11
2024-05-07 21:32:00,935 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.2525e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7271e-01, 0.0000e+00,
        1.6679e-01, 3.3844e-03, 1.4920e-01, 0.0000e+00, 1.2736e-01, 1.9751e-03,
        0.0000e+00, 0.0000e+00, 1.1377e-01, 1.6745e-03, 0.0000e+00, 0.0000e+00,
        7.0703e-02, 9.9183e-04, 0.0000e+00, 0.0000e+00, 7.5141e-02, 5.7477e-04,
        0.0000e+00, 0.0000e+00, 6.5990e-02, 8.3464e-05, 0.0000e+00, 0.0000e+00,
        2.1871e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3034e-02, 6.2500e-05,
        0.0000e+00, 0.0000e+00, 4.3102e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.6525e-04, 0.0000e+00, 0.0000e+00])  tensor([1.4961e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2454e-01, 0.0000e+00,
        5.9621e-02, 1.6888e-02, 9.3327e-02, 0.0000e+00, 5.2142e-02, 8.7547e-03,
        0.0000e+00, 0.0000e+00, 5.3971e-02, 7.0405e-03, 0.0000e+00, 0.0000e+00,
        3.9460e-02, 4.5704e-03, 0.0000e+00, 0.0000e+00, 4.7493e-02, 3.5879e-03,
        0.0000e+00, 0.0000e+00, 4.8140e-02, 1.0814e-03, 0.0000e+00, 0.0000e+00,
        1.8439e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4696e-02, 1.3975e-03,
        0.0000e+00, 0.0000e+00, 9.5567e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3669e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:32:00,953 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46098510983459334
2024-05-07 21:32:00,955 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:32:01,012 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #12: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.39, '(min, 1)': 0.18}}
2024-05-07 21:32:01,012 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:01,012 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-05-07 21:32:01,487 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #12: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.55, '(min, 1)': 0.14}}
2024-05-07 21:32:01,487 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:01,487 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-05-07 21:32:02,391 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #12: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.04878048780487805, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 8)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.17, '(rev, 2)': 0.01}}
2024-05-07 21:32:02,391 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:02,392 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-05-07 21:32:02,397 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #12: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17391304347826086, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.28, '(rev, 1)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:32:02,397 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:02,397 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-05-07 21:32:02,474 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #12: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.46, '(min, 1)': 0.16}}
2024-05-07 21:32:02,474 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:02,474 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-05-07 21:32:02,749 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #12: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.23}}
2024-05-07 21:32:02,749 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:02,750 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-05-07 21:32:03,360 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #12: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 6)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.2}}
2024-05-07 21:32:03,360 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:03,361 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-05-07 21:32:03,521 - MainProcess - INFO - text_logger.py - 51 - Train epoch #12
2024-05-07 21:32:03,524 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-4.5656e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1426e-01,
         0.0000e+00,  1.5901e-01,  2.1495e-04,  1.0502e-01,  0.0000e+00,
         1.3796e-01,  7.1429e-05,  0.0000e+00,  0.0000e+00,  1.3043e-01,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  8.9096e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  9.1562e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  9.2157e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.0433e-02,  6.6667e-05,  0.0000e+00,  0.0000e+00,  4.0114e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  8.2744e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  1.3347e-03,  0.0000e+00,  0.0000e+00])  tensor([0.7962, 0.0000, 0.0000, 0.0000, 0.0875, 0.0000, 0.0399, 0.0048, 0.0737,
        0.0000, 0.0332, 0.0016, 0.0000, 0.0000, 0.0359, 0.0000, 0.0000, 0.0000,
        0.0312, 0.0000, 0.0000, 0.0000, 0.0367, 0.0000, 0.0000, 0.0000, 0.0414,
        0.0000, 0.0000, 0.0000, 0.0162, 0.0015, 0.0000, 0.0000, 0.0262, 0.0000,
        0.0000, 0.0000, 0.0113, 0.0000, 0.0000, 0.0000, 0.0044, 0.0000, 0.0000]) (500)
2024-05-07 21:32:03,545 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4600428756164728
2024-05-07 21:32:03,547 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:32:03,858 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #13: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 0, 8, 0, 0),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 1, 8, 1, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.45, '(min, 1)': 0.16}}
2024-05-07 21:32:03,858 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:03,859 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-05-07 21:32:05,090 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #13: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.18}}
2024-05-07 21:32:05,090 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:05,091 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-05-07 21:32:05,794 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #13: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.28}}
2024-05-07 21:32:05,795 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:05,795 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-05-07 21:32:05,895 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #13: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 3, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36585365853658536, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 7)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.24, '(rev, 5)': 0.01}}
2024-05-07 21:32:05,895 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:05,896 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-05-07 21:32:05,901 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #13: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 1, 1, 9, 1, 1),(min, 0)->(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 2, 9, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.36}}
2024-05-07 21:32:05,902 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:05,902 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-05-07 21:32:06,331 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #13: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 3, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.29}}
2024-05-07 21:32:06,332 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:06,332 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-05-07 21:32:07,156 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #13: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2982456140350877, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 4)': 0.02, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.38, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:32:07,157 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:07,157 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-05-07 21:32:07,316 - MainProcess - INFO - text_logger.py - 51 - Train epoch #13
2024-05-07 21:32:07,319 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([9.0063e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5436e-01, 0.0000e+00,
        1.8150e-01, 6.1104e-04, 1.4030e-01, 0.0000e+00, 1.3727e-01, 6.0606e-05,
        0.0000e+00, 0.0000e+00, 1.1722e-01, 4.3478e-05, 0.0000e+00, 0.0000e+00,
        7.4198e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7105e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.3506e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5802e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4387e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2449e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.9423e-04, 0.0000e+00, 0.0000e+00])  tensor([1.1919e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0242e-01, 0.0000e+00,
        4.7654e-02, 6.4607e-03, 7.9749e-02, 0.0000e+00, 3.9105e-02, 1.3552e-03,
        0.0000e+00, 0.0000e+00, 4.2390e-02, 9.7220e-04, 0.0000e+00, 0.0000e+00,
        3.2807e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9199e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.6444e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7838e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2314e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.5063e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3684e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:32:07,339 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4594664950568888
2024-05-07 21:32:07,341 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.182930.18293
2024-05-07 21:32:08,136 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #14: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 4)': 0.01, '(ado, 5)': 0.03, '(min, 0)': 0.53, '(min, 1)': 0.13}}
2024-05-07 21:32:08,136 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:08,137 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-05-07 21:32:08,142 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #14: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.61, '(min, 1)': 0.02}}
2024-05-07 21:32:08,142 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:08,143 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-05-07 21:32:08,248 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #14: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 5, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 8)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.34, '(rev, 3)': 0.01}}
2024-05-07 21:32:08,248 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:08,249 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-05-07 21:32:08,253 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #14: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 6)': 0.02, '(min, 0)': 0.53, '(min, 1)': 0.16}}
2024-05-07 21:32:08,253 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:08,254 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-05-07 21:32:08,894 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #14: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2127659574468085, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.19, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:32:08,895 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:08,895 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-05-07 21:32:10,154 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #14: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 0, 9, 0, 1),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 1, 9, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.31}}
2024-05-07 21:32:10,154 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:10,155 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-05-07 21:32:10,585 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #14: {'transition': '(exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 1, 3, 8, 1, 1),(min, 0)->(exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 1, 3, 9, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.38636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.08, '(ado, 3)': 0.02, '(ado, 4)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.32, '(rev, 1)': 0.03, '(rev, 10)': 0.01, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:32:10,585 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:10,586 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-05-07 21:32:10,741 - MainProcess - INFO - text_logger.py - 51 - Train epoch #14
2024-05-07 21:32:10,744 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-4.8173e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2343e-01,
         0.0000e+00,  1.5561e-01,  1.0693e-03,  1.0808e-01,  0.0000e+00,
         1.3823e-01,  6.1929e-04,  0.0000e+00,  0.0000e+00,  1.3190e-01,
         2.6391e-04,  0.0000e+00,  0.0000e+00,  9.1785e-02,  1.0833e-04,
         0.0000e+00,  0.0000e+00,  9.0953e-02,  7.6923e-05,  0.0000e+00,
         0.0000e+00,  8.7833e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.8796e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.3285e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  6.7302e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  1.1562e-03,  6.4516e-05,  0.0000e+00])  tensor([1.1898, 0.0000, 0.0000, 0.0000, 0.1192, 0.0000, 0.0486, 0.0080, 0.0882,
        0.0000, 0.0428, 0.0040, 0.0000, 0.0000, 0.0467, 0.0025, 0.0000, 0.0000,
        0.0406, 0.0018, 0.0000, 0.0000, 0.0470, 0.0017, 0.0000, 0.0000, 0.0534,
        0.0000, 0.0000, 0.0000, 0.0200, 0.0000, 0.0000, 0.0000, 0.0256, 0.0000,
        0.0000, 0.0000, 0.0104, 0.0000, 0.0000, 0.0000, 0.0042, 0.0014, 0.0000]) (500)
2024-05-07 21:32:10,765 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.45880686953442046
2024-05-07 21:32:10,768 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.141300.14130
2024-05-07 21:32:10,787 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #15: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 6, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.44, '(min, 1)': 0.15}}
2024-05-07 21:32:10,788 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:10,788 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-05-07 21:32:10,834 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #15: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 6, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.34, '(min, 1)': 0.24}}
2024-05-07 21:32:10,834 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:10,835 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-05-07 21:32:10,868 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #15: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 1, 7, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 2, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.27}}
2024-05-07 21:32:10,869 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:10,869 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-05-07 21:32:11,377 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #15: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 4, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.23, '(rev, 10)': 0.01}}
2024-05-07 21:32:11,377 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:11,377 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-05-07 21:32:12,879 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #15: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.17}}
2024-05-07 21:32:12,880 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:12,880 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-05-07 21:32:13,024 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #15: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 2, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.038461538461538464, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.34, '(rev, 2)': 0.01}}
2024-05-07 21:32:13,025 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:13,025 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-05-07 21:32:14,701 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #15: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 3, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.06382978723404255, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 8)': 0.02, '(min, 0)': 0.4, '(min, 1)': 0.33, '(rev, 3)': 0.01}}
2024-05-07 21:32:14,701 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:14,701 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-05-07 21:32:14,852 - MainProcess - INFO - text_logger.py - 51 - Train epoch #15
2024-05-07 21:32:14,855 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.1737e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5253e-01, 0.0000e+00,
        1.9077e-01, 0.0000e+00, 1.3914e-01, 0.0000e+00, 1.4270e-01, 4.4444e-05,
        0.0000e+00, 0.0000e+00, 1.1073e-01, 6.0606e-05, 0.0000e+00, 0.0000e+00,
        7.7842e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0702e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.4214e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8052e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0754e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.2048e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8350e-04, 6.6667e-05, 0.0000e+00])  tensor([0.9119, 0.0000, 0.0000, 0.0000, 0.0906, 0.0000, 0.0489, 0.0000, 0.0682,
        0.0000, 0.0330, 0.0010, 0.0000, 0.0000, 0.0336, 0.0014, 0.0000, 0.0000,
        0.0304, 0.0000, 0.0000, 0.0000, 0.0315, 0.0000, 0.0000, 0.0000, 0.0325,
        0.0000, 0.0000, 0.0000, 0.0194, 0.0000, 0.0000, 0.0000, 0.0219, 0.0000,
        0.0000, 0.0000, 0.0063, 0.0000, 0.0000, 0.0000, 0.0017, 0.0015, 0.0000]) (500)
2024-05-07 21:32:14,875 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4578646353162999
2024-05-07 21:32:14,877 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:32:14,883 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #16: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.11904761904761904, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.54, '(min, 1)': 0.22, '(rev, 5)': 0.01}}
2024-05-07 21:32:14,883 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #16: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.12195121951219512, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.28, '(rev, 5)': 0.01}}
2024-05-07 21:32:14,883 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:14,883 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:14,884 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #16: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.37, '(min, 1)': 0.25}}
2024-05-07 21:32:14,884 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:14,884 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-05-07 21:32:14,884 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-05-07 21:32:14,885 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-05-07 21:32:14,931 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #16: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.21, '(rev, 1)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:32:14,931 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:14,932 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-05-07 21:32:15,562 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #16: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 5, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.25, '(rev, 1)': 0.01, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-05-07 21:32:15,562 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:15,563 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-05-07 21:32:16,518 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #16: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 2, 7, 0, 0),(ado, 5)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 2, 0, 0)', 'reward_ratio': '0/5', 'revenue': 0.17777777777777778, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 5)': 0.02, '(min, 0)': 0.35, '(min, 1)': 0.31, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-05-07 21:32:16,518 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:16,519 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-05-07 21:32:16,959 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #16: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.15}}
2024-05-07 21:32:16,959 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:16,960 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-05-07 21:32:17,114 - MainProcess - INFO - text_logger.py - 51 - Train epoch #16
2024-05-07 21:32:17,117 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.7100e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.3308e-01,
         0.0000e+00,  1.6258e-01,  8.4530e-04,  1.1135e-01,  0.0000e+00,
         1.3481e-01,  5.3282e-04,  0.0000e+00,  0.0000e+00,  1.4233e-01,
         3.1351e-04,  0.0000e+00,  0.0000e+00,  8.8484e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  8.8593e-02,  1.4039e-04,  0.0000e+00,
         0.0000e+00,  7.4482e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.0433e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7011e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.4145e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.0313e-04,  0.0000e+00,  0.0000e+00])  tensor([1.2383, 0.0000, 0.0000, 0.0000, 0.1239, 0.0000, 0.0480, 0.0062, 0.0889,
        0.0000, 0.0424, 0.0038, 0.0000, 0.0000, 0.0532, 0.0029, 0.0000, 0.0000,
        0.0396, 0.0000, 0.0000, 0.0000, 0.0466, 0.0022, 0.0000, 0.0000, 0.0448,
        0.0000, 0.0000, 0.0000, 0.0205, 0.0000, 0.0000, 0.0000, 0.0238, 0.0000,
        0.0000, 0.0000, 0.0086, 0.0000, 0.0000, 0.0000, 0.0031, 0.0000, 0.0000]) (500)
2024-05-07 21:32:17,138 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4572335122092904
2024-05-07 21:32:17,141 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.155560.15556
2024-05-07 21:32:17,201 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #17: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.36, '(min, 1)': 0.26}}
2024-05-07 21:32:17,201 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:17,201 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-05-07 21:32:17,327 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #17: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.2}}
2024-05-07 21:32:17,327 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:17,329 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-05-07 21:32:17,357 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #17: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.2}}
2024-05-07 21:32:17,357 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:17,358 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-05-07 21:32:19,028 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #17: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 1, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4634146341463415, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.34, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:32:19,028 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:19,029 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-05-07 21:32:19,382 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #17: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 2)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.33}}
2024-05-07 21:32:19,382 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:19,383 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-05-07 21:32:19,495 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #17: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 5, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.29, '(rev, 1)': 0.02, '(rev, 3)': 0.02}}
2024-05-07 21:32:19,495 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:19,496 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-05-07 21:32:20,054 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #17: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.34, '(rev, 2)': 0.03}}
2024-05-07 21:32:20,055 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:20,055 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-05-07 21:32:20,206 - MainProcess - INFO - text_logger.py - 51 - Train epoch #17
2024-05-07 21:32:20,210 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.7991e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.5350e-01,
         0.0000e+00,  1.7855e-01,  1.2574e-03,  1.3368e-01,  0.0000e+00,
         1.3968e-01,  5.6514e-04,  0.0000e+00,  0.0000e+00,  9.8124e-02,
         2.2545e-04,  0.0000e+00,  0.0000e+00,  8.3203e-02,  6.2500e-05,
         0.0000e+00,  0.0000e+00,  7.6752e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  7.0627e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.0236e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.6986e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  5.6122e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  9.3345e-04,  0.0000e+00,  0.0000e+00])  tensor([1.4616e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3930e-01, 0.0000e+00,
        4.9965e-02, 7.0712e-03, 9.6386e-02, 0.0000e+00, 5.0532e-02, 3.7166e-03,
        0.0000e+00, 0.0000e+00, 4.1614e-02, 2.5866e-03, 0.0000e+00, 0.0000e+00,
        4.0820e-02, 1.3975e-03, 0.0000e+00, 0.0000e+00, 4.1001e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.0731e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9307e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1327e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.0653e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.7552e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:32:20,230 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.45629127799116986
2024-05-07 21:32:20,232 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:32:20,285 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #18: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.49, '(min, 1)': 0.13}}
2024-05-07 21:32:20,286 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:20,286 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-05-07 21:32:20,833 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #18: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.03, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.02, '(min, 0)': 0.44, '(min, 1)': 0.28, '(rev, 1)': 0.04, '(rev, 2)': 0.02}}
2024-05-07 21:32:20,834 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:20,834 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-05-07 21:32:21,003 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #18: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41509433962264153, 'length': 100, 'actions': {'(ado, 1)': 0.09, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.02, '(min, 0)': 0.48, '(min, 1)': 0.3, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:32:21,003 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:21,003 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-05-07 21:32:21,422 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #18: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 3, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.15}}
2024-05-07 21:32:21,422 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:21,423 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-05-07 21:32:21,609 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #18: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.46, '(min, 1)': 0.11}}
2024-05-07 21:32:21,609 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:21,610 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-05-07 21:32:22,135 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #18: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 2, 7, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.06521739130434782, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.24, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:32:22,135 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:22,135 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-05-07 21:32:23,922 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #18: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.26, '(rev, 1)': 0.03, '(rev, 2)': 0.01}}
2024-05-07 21:32:23,922 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:23,923 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-05-07 21:32:24,085 - MainProcess - INFO - text_logger.py - 51 - Train epoch #18
2024-05-07 21:32:24,088 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.9235e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7915e-01, 0.0000e+00,
        1.7294e-01, 1.2256e-03, 1.4055e-01, 0.0000e+00, 1.1973e-01, 5.8509e-04,
        0.0000e+00, 0.0000e+00, 1.2395e-01, 2.0944e-04, 0.0000e+00, 0.0000e+00,
        7.6187e-02, 1.0283e-04, 0.0000e+00, 0.0000e+00, 6.8480e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.2147e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7703e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1067e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.8828e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0870e-03, 0.0000e+00, 0.0000e+00])  tensor([1.9406e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6032e-01, 0.0000e+00,
        5.5797e-02, 6.5797e-03, 1.0801e-01, 0.0000e+00, 4.9980e-02, 3.4701e-03,
        0.0000e+00, 0.0000e+00, 6.4711e-02, 2.4346e-03, 0.0000e+00, 0.0000e+00,
        4.6433e-02, 1.6265e-03, 0.0000e+00, 0.0000e+00, 4.6390e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.4709e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.2355e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0970e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.6863e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.2116e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:32:24,108 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4553490437730493
2024-05-07 21:32:24,110 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:32:24,119 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #19: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 8)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/8', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 3)': 0.02, '(ado, 5)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.22}}
2024-05-07 21:32:24,119 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:24,120 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-05-07 21:32:24,120 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #19: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 3)': 0.01, '(ado, 6)': 0.03, '(min, 0)': 0.4, '(min, 1)': 0.28}}
2024-05-07 21:32:24,120 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:24,121 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-05-07 21:32:24,133 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #19: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.56, '(min, 1)': 0.14, '(rev, 1)': 0.01}}
2024-05-07 21:32:24,133 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:24,134 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-05-07 21:32:24,163 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #19: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3023255813953488, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 8)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.32, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-05-07 21:32:24,163 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:24,164 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-05-07 21:32:24,424 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #19: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 8)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.13}}
2024-05-07 21:32:24,424 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:24,425 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-05-07 21:32:25,908 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #19: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.27, '(min, 1)': 0.3}}
2024-05-07 21:32:25,908 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:25,908 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-05-07 21:32:27,554 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #19: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 5)': 0.01, '(ado, 7)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.29, '(rev, 5)': 0.01}}
2024-05-07 21:32:27,554 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:27,555 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-05-07 21:32:27,708 - MainProcess - INFO - text_logger.py - 51 - Train epoch #19
2024-05-07 21:32:27,711 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-4.6106e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1721e-01,
         0.0000e+00,  1.7649e-01,  1.2163e-04,  9.9133e-02,  0.0000e+00,
         1.5055e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2480e-01,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  9.3461e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  8.7925e-02,  1.0760e-04,  0.0000e+00,
         0.0000e+00,  7.7047e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.6330e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.9080e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  6.4165e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  1.3210e-03,  0.0000e+00,  0.0000e+00])  tensor([1.1902, 0.0000, 0.0000, 0.0000, 0.1058, 0.0000, 0.0392, 0.0020, 0.0738,
        0.0000, 0.0307, 0.0000, 0.0000, 0.0000, 0.0320, 0.0000, 0.0000, 0.0000,
        0.0346, 0.0000, 0.0000, 0.0000, 0.0382, 0.0017, 0.0000, 0.0000, 0.0371,
        0.0000, 0.0000, 0.0000, 0.0207, 0.0000, 0.0000, 0.0000, 0.0207, 0.0000,
        0.0000, 0.0000, 0.0094, 0.0000, 0.0000, 0.0000, 0.0044, 0.0000, 0.0000]) (500)
2024-05-07 21:32:27,733 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.454709135136324
2024-05-07 21:32:27,735 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.151160.15116
2024-05-07 21:32:27,740 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #20: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.31, '(min, 1)': 0.34}}
2024-05-07 21:32:27,740 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:27,741 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-05-07 21:32:27,747 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #20: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3191489361702128, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.02, '(min, 0)': 0.39, '(min, 1)': 0.34, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:32:27,748 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:27,748 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-05-07 21:32:27,771 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #20: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.19047619047619047, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 5)': 0.02, '(min, 0)': 0.36, '(min, 1)': 0.33, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:32:27,772 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:27,772 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-05-07 21:32:28,535 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #20: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.22}}
2024-05-07 21:32:28,535 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:28,535 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-05-07 21:32:28,727 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #20: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.27, '(rev, 1)': 0.01}}
2024-05-07 21:32:28,727 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:28,727 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-05-07 21:32:28,915 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #20: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 1, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.24324324324324326, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.51, '(min, 1)': 0.16, '(rev, 1)': 0.02, '(rev, 2)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:32:28,915 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:28,916 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-05-07 21:32:30,126 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #20: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.08888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.22, '(rev, 4)': 0.01}}
2024-05-07 21:32:30,127 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:30,127 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-05-07 21:32:30,279 - MainProcess - INFO - text_logger.py - 51 - Train epoch #20
2024-05-07 21:32:30,283 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.0282,  0.0000,  0.0000,  0.0000,  0.1648,  0.0000,  0.1780,  0.0009,
         0.1290,  0.0000,  0.1231,  0.0005,  0.0000,  0.0000,  0.1083,  0.0003,
         0.0000,  0.0000,  0.0846,  0.0002,  0.0000,  0.0000,  0.0763,  0.0000,
         0.0000,  0.0000,  0.0675,  0.0000,  0.0000,  0.0000,  0.0325,  0.0000,
         0.0000,  0.0000,  0.0277,  0.0000,  0.0000,  0.0000,  0.0053,  0.0000,
         0.0000,  0.0000,  0.0009,  0.0000,  0.0000])  tensor([1.6133, 0.0000, 0.0000, 0.0000, 0.1692, 0.0000, 0.0548, 0.0050, 0.1076,
        0.0000, 0.0492, 0.0030, 0.0000, 0.0000, 0.0514, 0.0025, 0.0000, 0.0000,
        0.0462, 0.0021, 0.0000, 0.0000, 0.0442, 0.0000, 0.0000, 0.0000, 0.0424,
        0.0000, 0.0000, 0.0000, 0.0226, 0.0000, 0.0000, 0.0000, 0.0209, 0.0000,
        0.0000, 0.0000, 0.0089, 0.0000, 0.0000, 0.0000, 0.0037, 0.0000, 0.0000]) (500)
2024-05-07 21:32:30,299 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.45401014416144664
2024-05-07 21:32:30,302 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.121620.12162
2024-05-07 21:32:30,311 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #21: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.54, '(min, 1)': 0.06}}
2024-05-07 21:32:30,311 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:30,312 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-05-07 21:32:30,606 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #21: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5217391304347826, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(min, 0)': 0.4, '(min, 1)': 0.23, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 5)': 0.03}}
2024-05-07 21:32:30,606 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:30,607 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-05-07 21:32:31,418 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #21: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1891891891891892, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.41, '(min, 1)': 0.23, '(rev, 1)': 0.05, '(rev, 4)': 0.01}}
2024-05-07 21:32:31,418 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:31,419 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-05-07 21:32:31,423 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #21: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 3, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.20408163265306123, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.35, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:32:31,424 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:31,424 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-05-07 21:32:31,719 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #21: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.42857142857142855, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.24, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:32:31,719 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:31,720 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-05-07 21:32:32,016 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #21: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2682926829268293, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 8)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.15, '(rev, 1)': 0.01}}
2024-05-07 21:32:32,016 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:32,017 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-05-07 21:32:34,485 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #21: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 1, 1, 9, 1, 1),(min, 0)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 1, 1, 10, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.43902439024390244, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.41, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:32:34,485 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:34,485 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-05-07 21:32:34,643 - MainProcess - INFO - text_logger.py - 51 - Train epoch #21
2024-05-07 21:32:34,647 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.8018e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4530e-01, 0.0000e+00,
        1.4065e-01, 2.7679e-03, 2.1790e-01, 0.0000e+00, 7.2675e-02, 2.0853e-03,
        0.0000e+00, 0.0000e+00, 6.1899e-02, 1.4161e-03, 0.0000e+00, 0.0000e+00,
        4.3624e-02, 4.3635e-04, 0.0000e+00, 0.0000e+00, 3.8836e-02, 3.1539e-04,
        0.0000e+00, 0.0000e+00, 3.5302e-02, 1.7770e-04, 0.0000e+00, 0.0000e+00,
        1.8082e-02, 3.1000e-04, 0.0000e+00, 0.0000e+00, 1.4688e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.0309e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.0104e-04, 0.0000e+00, 0.0000e+00])  tensor([2.7306e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2768e-01, 0.0000e+00,
        7.4961e-02, 7.9999e-03, 1.3474e-01, 0.0000e+00, 7.4017e-02, 6.0368e-03,
        0.0000e+00, 0.0000e+00, 6.9627e-02, 5.2797e-03, 0.0000e+00, 0.0000e+00,
        5.3412e-02, 2.8535e-03, 0.0000e+00, 0.0000e+00, 4.9822e-02, 2.5392e-03,
        0.0000e+00, 0.0000e+00, 4.6564e-02, 1.7829e-03, 0.0000e+00, 0.0000e+00,
        2.5110e-02, 2.9522e-03, 0.0000e+00, 0.0000e+00, 2.1445e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.3779e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8020e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:32:34,664 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.45333620262625296
2024-05-07 21:32:34,667 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.134150.13415
2024-05-07 21:32:34,674 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #22: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.4782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(min, 0)': 0.21, '(min, 1)': 0.39, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 5)': 0.01}}
2024-05-07 21:32:34,674 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #22: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17777777777777778, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.38, '(rev, 1)': 0.05, '(rev, 5)': 0.01}}
2024-05-07 21:32:34,674 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:34,674 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #22: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.018518518518518517, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.2, '(rev, 1)': 0.03}}
2024-05-07 21:32:34,674 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:34,674 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:34,674 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-05-07 21:32:34,674 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-05-07 21:32:34,674 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-05-07 21:32:34,707 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #22: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.54, '(min, 1)': 0.1}}
2024-05-07 21:32:34,707 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:34,708 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-05-07 21:32:34,721 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #22: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.09523809523809523, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.27, '(rev, 1)': 0.02, '(rev, 2)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:32:34,721 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:34,722 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-05-07 21:32:34,738 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #22: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.45, '(min, 1)': 0.16}}
2024-05-07 21:32:34,738 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:34,739 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-05-07 21:32:37,198 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #22: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.04081632653061224, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.26, '(rev, 1)': 0.03}}
2024-05-07 21:32:37,199 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:37,199 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-05-07 21:32:37,359 - MainProcess - INFO - text_logger.py - 51 - Train epoch #22
2024-05-07 21:32:37,362 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.4632e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1447e-01, 0.0000e+00,
        1.5425e-01, 2.1787e-03, 2.0707e-01, 0.0000e+00, 7.6371e-02, 1.3469e-03,
        0.0000e+00, 0.0000e+00, 6.3872e-02, 4.8771e-04, 0.0000e+00, 0.0000e+00,
        5.0829e-02, 2.3888e-04, 0.0000e+00, 0.0000e+00, 4.6539e-02, 1.6226e-04,
        0.0000e+00, 0.0000e+00, 3.9333e-02, 9.9755e-05, 0.0000e+00, 0.0000e+00,
        2.1156e-02, 9.9755e-05, 0.0000e+00, 0.0000e+00, 1.7088e-02, 9.9755e-05,
        0.0000e+00, 0.0000e+00, 3.6039e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.0032e-04, 0.0000e+00, 0.0000e+00])  tensor([2.3033e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3506e-01, 0.0000e+00,
        8.4181e-02, 6.8400e-03, 1.4124e-01, 0.0000e+00, 7.0722e-02, 4.6505e-03,
        0.0000e+00, 0.0000e+00, 6.2738e-02, 2.7259e-03, 0.0000e+00, 0.0000e+00,
        5.3606e-02, 2.0898e-03, 0.0000e+00, 0.0000e+00, 5.1064e-02, 1.8994e-03,
        0.0000e+00, 0.0000e+00, 4.4847e-02, 1.2911e-03, 0.0000e+00, 0.0000e+00,
        2.5339e-02, 1.2911e-03, 0.0000e+00, 0.0000e+00, 2.2429e-02, 1.2911e-03,
        0.0000e+00, 0.0000e+00, 7.8437e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2382e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:32:37,383 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4523939684081324
2024-05-07 21:32:37,385 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:32:37,391 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #23: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.54, '(min, 1)': 0.08}}
2024-05-07 21:32:37,392 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:37,392 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-05-07 21:32:37,427 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #23: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 5, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24489795918367346, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.4, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:32:37,427 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:37,428 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-05-07 21:32:37,504 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #23: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 1, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13043478260869565, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.25, '(rev, 1)': 0.05, '(rev, 4)': 0.01}}
2024-05-07 21:32:37,504 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:37,505 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-05-07 21:32:37,562 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #23: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.475, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.18, '(min, 1)': 0.46, '(rev, 1)': 0.12, '(rev, 2)': 0.06, '(rev, 3)': 0.03}}
2024-05-07 21:32:37,562 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:37,563 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-05-07 21:32:38,173 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #23: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 3, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6764705882352942, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.31, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.03}}
2024-05-07 21:32:38,173 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:38,173 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-05-07 21:32:38,695 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #23: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32558139534883723, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.18, '(rev, 4)': 0.01}}
2024-05-07 21:32:38,696 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:38,696 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-05-07 21:32:39,632 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #23: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.06666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.27, '(rev, 1)': 0.03}}
2024-05-07 21:32:39,632 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:39,633 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-05-07 21:32:39,790 - MainProcess - INFO - text_logger.py - 51 - Train epoch #23
2024-05-07 21:32:39,793 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.8448e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5889e-01, 0.0000e+00,
        1.3408e-01, 2.8890e-03, 2.3884e-01, 0.0000e+00, 5.6281e-02, 2.0893e-03,
        0.0000e+00, 0.0000e+00, 5.2573e-02, 1.4899e-03, 0.0000e+00, 0.0000e+00,
        4.2420e-02, 2.8371e-04, 0.0000e+00, 0.0000e+00, 3.8530e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.3171e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9449e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5104e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2930e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.1231e-04, 0.0000e+00, 0.0000e+00])  tensor([2.1605, 0.0000, 0.0000, 0.0000, 0.2294, 0.0000, 0.0795, 0.0076, 0.1406,
        0.0000, 0.0610, 0.0056, 0.0000, 0.0000, 0.0641, 0.0049, 0.0000, 0.0000,
        0.0564, 0.0025, 0.0000, 0.0000, 0.0531, 0.0000, 0.0000, 0.0000, 0.0468,
        0.0000, 0.0000, 0.0000, 0.0286, 0.0000, 0.0000, 0.0000, 0.0237, 0.0000,
        0.0000, 0.0000, 0.0079, 0.0000, 0.0000, 0.0000, 0.0031, 0.0000, 0.0000]) (500)
2024-05-07 21:32:39,816 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4517773155853606
2024-05-07 21:32:39,819 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.162790.16279
2024-05-07 21:32:40,315 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #24: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2549019607843137, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.15, '(rev, 1)': 0.02, '(rev, 2)': 0.01}}
2024-05-07 21:32:40,315 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:40,316 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-05-07 21:32:40,346 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #24: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.23076923076923078, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.26, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-07 21:32:40,347 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:40,347 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-05-07 21:32:40,436 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #24: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.31, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:32:40,436 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:40,437 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-05-07 21:32:40,672 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #24: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 3, 0, 0),(rev, 3)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5853658536585366, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.09, '(min, 1)': 0.55, '(rev, 1)': 0.08, '(rev, 3)': 0.05, '(rev, 4)': 0.01}}
2024-05-07 21:32:40,672 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:40,672 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-05-07 21:32:40,961 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #24: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.58, '(min, 1)': 0.04}}
2024-05-07 21:32:40,961 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:40,962 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-05-07 21:32:42,291 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #24: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5576923076923077, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.37, '(rev, 1)': 0.04, '(rev, 10)': 0.01, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-07 21:32:42,291 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:42,292 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-05-07 21:32:42,912 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #24: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.33, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-05-07 21:32:42,912 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:42,913 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-05-07 21:32:43,074 - MainProcess - INFO - text_logger.py - 51 - Train epoch #24
2024-05-07 21:32:43,077 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.5762e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8608e-01, 0.0000e+00,
        1.3146e-01, 3.3479e-03, 2.5035e-01, 0.0000e+00, 5.1753e-02, 2.2375e-03,
        0.0000e+00, 0.0000e+00, 4.8291e-02, 1.2717e-03, 0.0000e+00, 0.0000e+00,
        3.4475e-02, 6.0214e-04, 0.0000e+00, 0.0000e+00, 2.9547e-02, 2.6845e-04,
        0.0000e+00, 0.0000e+00, 2.8603e-02, 6.6120e-05, 0.0000e+00, 0.0000e+00,
        1.5746e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2549e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.7353e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.4919e-04, 6.0606e-05, 0.0000e+00])  tensor([2.1048e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2140e-01, 0.0000e+00,
        9.3938e-02, 8.0175e-03, 1.4063e-01, 0.0000e+00, 6.0955e-02, 5.8768e-03,
        0.0000e+00, 0.0000e+00, 6.4502e-02, 5.1054e-03, 0.0000e+00, 0.0000e+00,
        5.1423e-02, 3.5376e-03, 0.0000e+00, 0.0000e+00, 4.5621e-02, 2.1282e-03,
        0.0000e+00, 0.0000e+00, 4.5297e-02, 1.0444e-03, 0.0000e+00, 0.0000e+00,
        2.7113e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3462e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.6663e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9597e-03, 1.3552e-03, 0.0000e+00]) (500)
2024-05-07 21:32:43,096 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.45108998332802436
2024-05-07 21:32:43,099 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.127450.12745
2024-05-07 21:32:43,154 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #25: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(min, 0)': 0.08, '(min, 1)': 0.5, '(rev, 1)': 0.08, '(rev, 2)': 0.02}}
2024-05-07 21:32:43,154 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:43,154 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-05-07 21:32:43,156 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #25: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.11428571428571428, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.49, '(min, 1)': 0.14, '(rev, 1)': 0.04, '(rev, 2)': 0.02}}
2024-05-07 21:32:43,156 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:43,164 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-05-07 21:32:43,262 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #25: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.2653061224489796, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.29, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:32:43,262 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:43,263 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-05-07 21:32:43,289 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #25: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 5, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.44, '(min, 1)': 0.18}}
2024-05-07 21:32:43,289 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:43,290 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-05-07 21:32:43,732 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #25: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.2}}
2024-05-07 21:32:43,732 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:43,732 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-05-07 21:32:45,584 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #25: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.08823529411764706, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.2, '(rev, 1)': 0.04, '(rev, 2)': 0.01}}
2024-05-07 21:32:45,584 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:45,584 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-05-07 21:32:46,567 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #25: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.04, '(ado, 6)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.24, '(rev, 1)': 0.1, '(rev, 2)': 0.04}}
2024-05-07 21:32:46,567 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:46,568 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-05-07 21:32:46,726 - MainProcess - INFO - text_logger.py - 51 - Train epoch #25
2024-05-07 21:32:46,729 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.2163e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7688e-01, 0.0000e+00,
        1.2395e-01, 2.9064e-03, 2.5882e-01, 0.0000e+00, 4.9168e-02, 1.4598e-03,
        0.0000e+00, 0.0000e+00, 4.5478e-02, 4.9162e-04, 0.0000e+00, 0.0000e+00,
        3.7302e-02, 2.8999e-04, 0.0000e+00, 0.0000e+00, 3.3436e-02, 6.4516e-05,
        0.0000e+00, 0.0000e+00, 3.0910e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8125e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6236e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.9369e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.4076e-04, 0.0000e+00, 0.0000e+00])  tensor([1.7014e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2795e-01, 0.0000e+00,
        8.1275e-02, 7.5326e-03, 1.4822e-01, 0.0000e+00, 6.3215e-02, 4.7677e-03,
        0.0000e+00, 0.0000e+00, 6.2690e-02, 2.8286e-03, 0.0000e+00, 0.0000e+00,
        5.2487e-02, 2.3002e-03, 0.0000e+00, 0.0000e+00, 4.7823e-02, 1.4426e-03,
        0.0000e+00, 0.0000e+00, 4.4558e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7178e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4837e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.8680e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8344e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:32:46,746 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4502620348241895
2024-05-07 21:32:46,748 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.057140.05714
2024-05-07 21:32:46,773 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #26: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 6)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.09, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-07 21:32:46,774 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:46,774 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-05-07 21:32:46,776 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #26: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46511627906976744, 'length': 100, 'actions': {'(ado, 1)': 0.09, '(ado, 2)': 0.01, '(ado, 3)': 0.04, '(min, 0)': 0.44, '(min, 1)': 0.24, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 6)': 0.01}}
2024-05-07 21:32:46,776 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:46,777 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-05-07 21:32:46,804 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #26: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 3, 0, 1),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 4, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(ado, 7)': 0.01, '(min, 0)': 0.52, '(min, 1)': 0.1}}
2024-05-07 21:32:46,804 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:46,806 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-05-07 21:32:46,963 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #26: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3953488372093023, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 9)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.2, '(rev, 1)': 0.07, '(rev, 3)': 0.01}}
2024-05-07 21:32:46,963 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:46,964 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-05-07 21:32:47,592 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #26: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.55, '(min, 1)': 0.07}}
2024-05-07 21:32:47,592 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:47,593 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-05-07 21:32:48,071 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #26: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.30612244897959184, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.21, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-05-07 21:32:48,071 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:48,071 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-05-07 21:32:50,637 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #26: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7659574468085106, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.46, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 7)': 0.01}}
2024-05-07 21:32:50,637 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:50,638 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-05-07 21:32:50,800 - MainProcess - INFO - text_logger.py - 51 - Train epoch #26
2024-05-07 21:32:50,803 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.4639e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8509e-01, 0.0000e+00,
        1.0326e-01, 4.2181e-03, 3.2732e-01, 0.0000e+00, 2.4460e-02, 2.5664e-03,
        0.0000e+00, 0.0000e+00, 1.5954e-02, 1.9792e-03, 0.0000e+00, 0.0000e+00,
        1.0588e-02, 6.1553e-04, 0.0000e+00, 0.0000e+00, 9.1967e-03, 4.0794e-04,
        0.0000e+00, 0.0000e+00, 6.7605e-03, 1.0387e-04, 0.0000e+00, 0.0000e+00,
        3.8038e-03, 1.2239e-04, 0.0000e+00, 0.0000e+00, 3.1235e-03, 6.6834e-05,
        0.0000e+00, 0.0000e+00, 3.2429e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.7736e-05, 0.0000e+00, 0.0000e+00])  tensor([1.8234e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4765e-01, 0.0000e+00,
        8.3586e-02, 8.8118e-03, 9.4388e-02, 0.0000e+00, 4.6317e-02, 6.2231e-03,
        0.0000e+00, 0.0000e+00, 3.9640e-02, 6.1664e-03, 0.0000e+00, 0.0000e+00,
        3.1976e-02, 3.3545e-03, 0.0000e+00, 0.0000e+00, 2.9514e-02, 2.7471e-03,
        0.0000e+00, 0.0000e+00, 2.4082e-02, 1.3410e-03, 0.0000e+00, 0.0000e+00,
        1.4588e-02, 1.6288e-03, 0.0000e+00, 0.0000e+00, 1.2543e-02, 1.0570e-03,
        0.0000e+00, 0.0000e+00, 2.6220e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.4380e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:32:50,825 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.44931980060606896
2024-05-07 21:32:50,827 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:32:50,862 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #27: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.28, '(min, 1)': 0.38, '(rev, 1)': 0.05, '(rev, 2)': 0.09, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:32:50,863 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:50,864 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-05-07 21:32:50,878 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #27: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.07894736842105263, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 4)': 0.01, '(min, 0)': 0.58, '(min, 1)': 0.08, '(rev, 1)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:32:50,878 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #27: {'tran2024-05-07 21:32:50,879 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
t, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.44, '(min, 1)': 0.16}}
2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:32:50,880 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:50,880 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-05-07 21:32:50,908 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:50,909 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-05-07 21:32:51,066 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #27: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.25}}
2024-05-07 21:32:51,067 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:51,068 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-05-07 21:32:51,888 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #27: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 1.1111111111111112, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.02, '(min, 0)': 0.11, '(min, 1)': 0.53, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.05, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:32:51,888 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:51,889 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-05-07 21:32:53,334 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #27: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5581395348837209, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.47, '(rev, 1)': 0.11, '(rev, 2)': 0.05, '(rev, 3)': 0.04, '(rev, 5)': 0.01}}
2024-05-07 21:32:53,334 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:53,335 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-05-07 21:32:53,487 - MainProcess - INFO - text_logger.py - 51 - Train epoch #27
2024-05-07 21:32:53,490 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.1840e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3622e-01, 0.0000e+00,
        1.0180e-01, 5.1427e-03, 2.8042e-01, 0.0000e+00, 3.8356e-02, 3.4036e-03,
        0.0000e+00, 0.0000e+00, 3.3745e-02, 1.6356e-03, 0.0000e+00, 0.0000e+00,
        2.7329e-02, 9.1489e-04, 0.0000e+00, 0.0000e+00, 2.3399e-02, 7.2711e-04,
        0.0000e+00, 0.0000e+00, 2.0532e-02, 3.0629e-04, 0.0000e+00, 0.0000e+00,
        1.2660e-02, 3.2787e-05, 0.0000e+00, 0.0000e+00, 1.0266e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.5739e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.4658e-04, 0.0000e+00, 0.0000e+00])  tensor([2.8414e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1567e-01, 0.0000e+00,
        9.0628e-02, 9.4945e-03, 1.3073e-01, 0.0000e+00, 5.6505e-02, 7.4274e-03,
        0.0000e+00, 0.0000e+00, 5.5996e-02, 5.7543e-03, 0.0000e+00, 0.0000e+00,
        4.7566e-02, 4.5518e-03, 0.0000e+00, 0.0000e+00, 4.2814e-02, 4.0686e-03,
        0.0000e+00, 0.0000e+00, 3.8844e-02, 2.7552e-03, 0.0000e+00, 0.0000e+00,
        2.5235e-02, 7.3314e-04, 0.0000e+00, 0.0000e+00, 2.1797e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.6515e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9495e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:32:53,516 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4483775663879484
2024-05-07 21:32:53,518 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:32:53,534 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #28: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 3, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.53, '(min, 1)': 0.06}}
2024-05-07 21:32:53,534 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:53,535 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-05-07 21:32:53,550 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #28: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.47, '(min, 1)': 0.11}}
2024-05-07 21:32:53,550 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:53,551 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-05-07 21:32:54,529 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #28: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3137254901960784, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.2, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:32:54,529 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:54,529 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-05-07 21:32:54,589 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #28: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.15789473684210525, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 6)': 0.01, '(min, 0)': 0.56, '(min, 1)': 0.13, '(rev, 1)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:32:54,589 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:54,589 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-05-07 21:32:54,649 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #28: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3023255813953488, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 8)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.29, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 4)': 0.01}}
2024-05-07 21:32:54,649 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:54,649 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-05-07 21:32:54,824 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #28: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46938775510204084, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.33, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:32:54,824 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:54,825 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-05-07 21:32:56,058 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #28: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.11904761904761904, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.27, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:32:56,058 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:56,059 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-05-07 21:32:56,209 - MainProcess - INFO - text_logger.py - 51 - Train epoch #28
2024-05-07 21:32:56,211 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.2922e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.0455e-01,
         0.0000e+00,  1.4960e-01,  2.4424e-03,  2.1049e-01,  0.0000e+00,
         7.3082e-02,  1.5450e-03,  0.0000e+00,  0.0000e+00,  6.6095e-02,
         5.5574e-04,  0.0000e+00,  0.0000e+00,  5.1940e-02,  4.3512e-04,
         0.0000e+00,  0.0000e+00,  4.5993e-02,  9.1847e-05,  0.0000e+00,
         0.0000e+00,  4.2696e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.5036e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.0903e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.0616e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  4.8304e-04,  0.0000e+00,  0.0000e+00])  tensor([1.8604e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2621e-01, 0.0000e+00,
        8.7464e-02, 6.8842e-03, 1.3470e-01, 0.0000e+00, 5.7375e-02, 5.2099e-03,
        0.0000e+00, 0.0000e+00, 5.6781e-02, 2.9388e-03, 0.0000e+00, 0.0000e+00,
        4.8320e-02, 3.0446e-03, 0.0000e+00, 0.0000e+00, 4.4906e-02, 1.4662e-03,
        0.0000e+00, 0.0000e+00, 4.3466e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7660e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5715e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.7403e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7830e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:32:56,232 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4474353321698278
2024-05-07 21:32:56,236 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:32:56,257 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #29: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 4, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.55, '(min, 1)': 0.08}}
2024-05-07 21:32:56,258 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:56,258 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:56,258 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-05-07 21:32:56,258 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-05-07 21:32:57,113 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #29: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1276595744680851, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 5)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.14, '(rev, 1)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:32:57,113 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:57,114 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-05-07 21:32:57,376 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #29: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 5, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17391304347826086, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.15, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-07 21:32:57,376 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:57,377 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-05-07 21:32:58,232 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #29: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 6, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 5, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.9024390243902439, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 3)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.46, '(rev, 1)': 0.12, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:32:58,233 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:58,233 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-05-07 21:32:58,592 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #29: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 4, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10256410256410256, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(ado, 5)': 0.02, '(min, 0)': 0.62, '(min, 1)': 0.13, '(rev, 1)': 0.02, '(rev, 2)': 0.02}}
2024-05-07 21:32:58,592 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:32:58,593 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-05-07 21:33:00,611 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #29: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2894736842105263, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.34, '(rev, 1)': 0.04, '(rev, 9)': 0.01}}
2024-05-07 21:33:00,611 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:00,612 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-05-07 21:33:00,764 - MainProcess - INFO - text_logger.py - 51 - Train epoch #29
2024-05-07 21:33:00,767 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.0570e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6026e-01, 0.0000e+00,
        1.3872e-01, 2.5162e-03, 2.5938e-01, 0.0000e+00, 5.5983e-02, 1.3172e-03,
        0.0000e+00, 0.0000e+00, 4.8970e-02, 8.0481e-04, 0.0000e+00, 0.0000e+00,
        3.6416e-02, 3.7067e-04, 0.0000e+00, 0.0000e+00, 3.1473e-02, 2.2070e-04,
        0.0000e+00, 0.0000e+00, 2.8553e-02, 6.8765e-05, 0.0000e+00, 0.0000e+00,
        1.7496e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4620e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.4258e-03, 5.2632e-05, 0.0000e+00, 0.0000e+00,
        3.5388e-04, 0.0000e+00, 0.0000e+00])  tensor([1.8385e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1610e-01, 0.0000e+00,
        9.3295e-02, 6.9465e-03, 1.3719e-01, 0.0000e+00, 5.8372e-02, 4.6119e-03,
        0.0000e+00, 0.0000e+00, 5.6103e-02, 3.7532e-03, 0.0000e+00, 0.0000e+00,
        4.5034e-02, 2.7978e-03, 0.0000e+00, 0.0000e+00, 4.1332e-02, 2.0358e-03,
        0.0000e+00, 0.0000e+00, 3.8711e-02, 1.0938e-03, 0.0000e+00, 0.0000e+00,
        2.5472e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2121e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.0205e-03, 1.1769e-03, 0.0000e+00, 0.0000e+00,
        2.3896e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:33:00,792 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4464930979517072
2024-05-07 21:33:00,795 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:33:00,811 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #30: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.3157894736842105, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 2)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.09, '(rev, 1)': 0.03}}
2024-05-07 21:33:00,811 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:00,812 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-05-07 21:33:00,843 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #30: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40540540540540543, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(min, 0)': 0.37, '(min, 1)': 0.28, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.03}}
2024-05-07 21:33:00,843 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:00,844 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-05-07 21:33:00,859 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #30: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 1, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.21621621621621623, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.35, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:33:00,859 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:00,861 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-05-07 21:33:00,891 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #30: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.6, '(min, 1)': 0.03, '(rev, 1)': 0.01}}
2024-05-07 21:33:00,891 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:00,892 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-05-07 21:33:01,169 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #30: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.4, '(rev, 1)': 0.04, '(rev, 2)': 0.06, '(rev, 3)': 0.03}}
2024-05-07 21:33:01,170 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:01,170 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-05-07 21:33:01,650 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #30: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.41, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 5)': 0.01}}
2024-05-07 21:33:01,651 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:01,651 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-05-07 21:33:04,158 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #30: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.07692307692307693, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.05, '(ado, 3)': 0.02, '(ado, 4)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.29, '(rev, 1)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:33:04,158 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:04,159 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-05-07 21:33:04,310 - MainProcess - INFO - text_logger.py - 51 - Train epoch #30
2024-05-07 21:33:04,313 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.7532e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6311e-01, 0.0000e+00,
        1.2593e-01, 2.5290e-03, 2.6211e-01, 0.0000e+00, 5.5797e-02, 1.3070e-03,
        0.0000e+00, 0.0000e+00, 4.6264e-02, 5.6427e-04, 0.0000e+00, 0.0000e+00,
        3.9344e-02, 1.8476e-04, 0.0000e+00, 0.0000e+00, 3.5042e-02, 3.0303e-05,
        0.0000e+00, 0.0000e+00, 3.1175e-02, 3.0303e-05, 0.0000e+00, 0.0000e+00,
        1.9243e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4506e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.4759e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5609e-04, 0.0000e+00, 0.0000e+00])  tensor([1.9831e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2236e-01, 0.0000e+00,
        8.9290e-02, 7.0529e-03, 1.4228e-01, 0.0000e+00, 6.2259e-02, 4.8008e-03,
        0.0000e+00, 0.0000e+00, 5.4958e-02, 3.3656e-03, 0.0000e+00, 0.0000e+00,
        5.0090e-02, 1.8508e-03, 0.0000e+00, 0.0000e+00, 4.6462e-02, 6.7760e-04,
        0.0000e+00, 0.0000e+00, 4.2285e-02, 6.7760e-04, 0.0000e+00, 0.0000e+00,
        2.7780e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3807e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.1104e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.4065e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:33:04,332 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.44595626913899206
2024-05-07 21:33:04,335 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.202700.20270
2024-05-07 21:33:04,356 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #31: {'transition': '(exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 1, 5, 8, 1, 1),(min, 0)->(exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 1, 5, 9, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 8)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.2}}
2024-05-07 21:33:04,356 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:04,357 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-05-07 21:33:04,372 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #31: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 5, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 6, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.35, '(min, 1)': 0.25}}
2024-05-07 21:33:04,372 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:04,372 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #31: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.047619047619047616, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 4)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.17, '(rev, 1)': 0.04}}
2024-05-07 21:33:04,373 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:04,373 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-05-07 21:33:04,373 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-05-07 21:33:04,402 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #31: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.2, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:33:04,403 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:04,403 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-05-07 21:33:04,762 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #31: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.22, '(rev, 1)': 0.03, '(rev, 3)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:33:04,762 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:04,763 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-05-07 21:33:04,885 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #31: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0425531914893617, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.18, '(rev, 1)': 0.03}}
2024-05-07 21:33:04,886 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:04,886 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-05-07 21:33:07,309 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #31: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.075, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.22, '(rev, 1)': 0.04}}
2024-05-07 21:33:07,310 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:07,310 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-05-07 21:33:07,466 - MainProcess - INFO - text_logger.py - 51 - Train epoch #31
2024-05-07 21:33:07,469 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-2.7033e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.3465e-01,
         0.0000e+00,  1.4433e-01,  1.7652e-03,  2.4880e-01,  0.0000e+00,
         6.2395e-02,  4.8541e-04,  0.0000e+00,  0.0000e+00,  5.2590e-02,
         2.1400e-04,  0.0000e+00,  0.0000e+00,  4.3628e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.8027e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  3.4583e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.0476e-02,  5.4054e-05,  0.0000e+00,  0.0000e+00,  1.5401e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.2866e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.2234e-04,  0.0000e+00,  0.0000e+00])  tensor([1.6936e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1740e-01, 0.0000e+00,
        8.8082e-02, 6.0241e-03, 1.4142e-01, 0.0000e+00, 5.9984e-02, 2.9068e-03,
        0.0000e+00, 0.0000e+00, 5.4355e-02, 2.3392e-03, 0.0000e+00, 0.0000e+00,
        4.9184e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5958e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.3724e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7722e-02, 1.2087e-03, 0.0000e+00, 0.0000e+00, 2.4159e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.9994e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.6278e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:33:07,488 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4450140349208715
2024-05-07 21:33:07,490 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:33:07,498 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #32: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.021739130434782608, 'length': 100, 'actions': {'(ado, 1)': 0.45, '(min, 0)': 0.41, '(min, 1)': 0.13, '(rev, 1)': 0.01}}
2024-05-07 21:33:07,498 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
nsition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.14583333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.16, '(rev, 1)': 0.07, '(rev, 2)': 0.01}}
2024-05-07 21:33:07,499 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:07,499 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-05-07 21:33:07,499 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-05-07 21:33:07,530 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #32: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1590909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.31, '(min, 1)': 0.26, '(rev, 1)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:33:07,530 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:07,531 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-05-07 21:33:07,558 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #32: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.18604651162790697, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 8)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.3, '(rev, 1)': 0.1}}
2024-05-07 21:33:07,558 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:07,559 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-05-07 21:33:07,596 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #32: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.06666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.29, '(rev, 1)': 0.04, '(rev, 2)': 0.02}}
2024-05-07 21:33:07,596 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:07,596 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-05-07 21:33:07,747 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #32: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 4)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.33, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 4)': 0.01}}
2024-05-07 21:33:07,747 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:07,748 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-05-07 21:33:10,468 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #32: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.673469387755102, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.5, '(rev, 1)': 0.13, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:33:10,468 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:10,469 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-05-07 21:33:10,623 - MainProcess - INFO - text_logger.py - 51 - Train epoch #32
2024-05-07 21:33:10,626 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.7473e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2942e-01, 0.0000e+00,
        1.0267e-01, 3.3771e-03, 2.8620e-01, 0.0000e+00, 3.8527e-02, 2.6509e-03,
        0.0000e+00, 0.0000e+00, 3.4417e-02, 1.0354e-03, 0.0000e+00, 0.0000e+00,
        2.7638e-02, 4.6464e-04, 0.0000e+00, 0.0000e+00, 2.4567e-02, 1.5421e-04,
        0.0000e+00, 0.0000e+00, 2.1907e-02, 5.4143e-05, 0.0000e+00, 0.0000e+00,
        1.4664e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0558e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.5290e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6321e-04, 0.0000e+00, 0.0000e+00])  tensor([2.0453e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1956e-01, 0.0000e+00,
        8.7934e-02, 7.6739e-03, 1.3261e-01, 0.0000e+00, 5.7518e-02, 6.3132e-03,
        0.0000e+00, 0.0000e+00, 5.4034e-02, 4.0784e-03, 0.0000e+00, 0.0000e+00,
        4.5335e-02, 2.6953e-03, 0.0000e+00, 0.0000e+00, 4.0995e-02, 1.5475e-03,
        0.0000e+00, 0.0000e+00, 3.6991e-02, 8.5592e-04, 0.0000e+00, 0.0000e+00,
        2.5300e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9965e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.5251e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6437e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:33:10,643 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.44425263074227656
2024-05-07 21:33:10,646 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.090420.06868
2024-05-07 21:33:10,655 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #33: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 7)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.37, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:33:10,656 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:10,657 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-05-07 21:33:10,702 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #33: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.45, '(rev, 1)': 0.13, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:33:10,702 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:10,703 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-05-07 21:33:10,970 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #33: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 8, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3611111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.42, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.02}}
2024-05-07 21:33:10,970 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:10,971 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-05-07 21:33:11,148 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #33: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.65, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.47, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:33:11,148 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:11,149 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-05-07 21:33:11,168 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #33: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 8)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.41, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:33:11,168 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:11,169 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-05-07 21:33:11,171 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #33: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.9333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 3)': 0.03, '(min, 0)': 0.21, '(min, 1)': 0.46, '(rev, 1)': 0.11, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.03}}
2024-05-07 21:33:11,172 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:11,172 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-05-07 21:33:13,470 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #33: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46153846153846156, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.16, '(min, 1)': 0.49, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:33:13,470 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:13,471 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-05-07 21:33:13,629 - MainProcess - INFO - text_logger.py - 51 - Train epoch #33
2024-05-07 21:33:13,632 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.7745e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5310e-01, 0.0000e+00,
        5.4962e-02, 4.5035e-03, 3.5012e-01, 0.0000e+00, 9.8829e-03, 3.7582e-03,
        0.0000e+00, 0.0000e+00, 6.5385e-03, 2.2386e-03, 0.0000e+00, 0.0000e+00,
        4.1994e-03, 1.2557e-03, 0.0000e+00, 0.0000e+00, 3.5443e-03, 4.9375e-05,
        0.0000e+00, 0.0000e+00, 2.7762e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8191e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1763e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.9482e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.9291e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1101e-01, 0.0000e+00,
        5.9400e-02, 8.4329e-03, 6.8257e-02, 0.0000e+00, 2.8972e-02, 7.2873e-03,
        0.0000e+00, 0.0000e+00, 2.4829e-02, 5.7743e-03, 0.0000e+00, 0.0000e+00,
        2.0111e-02, 4.8777e-03, 0.0000e+00, 0.0000e+00, 1.8135e-02, 7.8461e-04,
        0.0000e+00, 0.0000e+00, 1.4630e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0142e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0861e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1016e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:33:13,655 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4438671598091802
2024-05-07 21:33:13,657 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.278380.08273
2024-05-07 21:33:13,661 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #34: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.4, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:33:13,661 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:13,662 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-05-07 21:33:13,709 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #34: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.02, '(min, 0)': 0.02, '(min, 1)': 0.59, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:33:13,710 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:13,710 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-05-07 21:33:13,718 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #34: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 2, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 1, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.14583333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.14, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:33:13,718 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:13,719 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-05-07 21:33:14,386 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #34: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.41, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-05-07 21:33:14,386 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:14,387 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-05-07 21:33:14,770 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #34: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8536585365853658, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 3)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.38, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.05, '(rev, 4)': 0.01}}
2024-05-07 21:33:14,770 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:14,771 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-05-07 21:33:15,356 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #34: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.39, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:33:15,356 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:15,357 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-05-07 21:33:16,130 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #34: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.42, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:33:16,130 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:16,131 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-05-07 21:33:16,292 - MainProcess - INFO - text_logger.py - 51 - Train epoch #34
2024-05-07 21:33:16,295 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.6787e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3925e-01, 0.0000e+00,
        5.7046e-02, 3.5841e-03, 3.5119e-01, 0.0000e+00, 1.1492e-02, 2.5135e-03,
        0.0000e+00, 0.0000e+00, 8.6446e-03, 1.7342e-03, 0.0000e+00, 0.0000e+00,
        6.5222e-03, 7.7687e-04, 0.0000e+00, 0.0000e+00, 5.6638e-03, 2.8676e-04,
        0.0000e+00, 0.0000e+00, 5.0297e-03, 2.0236e-04, 0.0000e+00, 0.0000e+00,
        3.2860e-03, 8.5497e-05, 0.0000e+00, 0.0000e+00, 2.3248e-03, 2.9412e-05,
        0.0000e+00, 0.0000e+00, 3.4415e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.0733e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3376e-01, 0.0000e+00,
        7.7735e-02, 7.7528e-03, 8.3435e-02, 0.0000e+00, 3.1336e-02, 6.2321e-03,
        0.0000e+00, 0.0000e+00, 2.8509e-02, 5.6695e-03, 0.0000e+00, 0.0000e+00,
        2.4309e-02, 3.7455e-03, 0.0000e+00, 0.0000e+00, 2.2033e-02, 2.0189e-03,
        0.0000e+00, 0.0000e+00, 2.0216e-02, 1.7100e-03, 0.0000e+00, 0.0000e+00,
        1.3457e-02, 1.1052e-03, 0.0000e+00, 0.0000e+00, 1.0048e-02, 6.5767e-04,
        0.0000e+00, 0.0000e+00, 2.5658e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:33:16,322 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4433968458809146
2024-05-07 21:33:16,325 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.235960.09013
2024-05-07 21:33:16,467 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #35: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36363636363636365, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.21, '(min, 1)': 0.38, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:33:16,468 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:16,468 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-05-07 21:33:16,638 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #35: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5853658536585366, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.5, '(min, 1)': 0.15, '(rev, 1)': 0.13, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 7)': 0.01}}
2024-05-07 21:33:16,639 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:16,639 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-05-07 21:33:16,864 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #35: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.875, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.13, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:33:16,864 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:16,865 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-05-07 21:33:17,863 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #35: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.022222222222222223, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.16, '(rev, 1)': 0.02}}
2024-05-07 21:33:17,864 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:17,864 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-05-07 21:33:18,085 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #35: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(ado, 3)': 0.02, '(min, 0)': 0.16, '(min, 1)': 0.43, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:33:18,086 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:18,087 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-05-07 21:33:18,094 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #35: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3611111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.43, '(min, 1)': 0.24, '(rev, 1)': 0.03, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:33:18,094 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:18,095 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-05-07 21:33:18,642 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #35: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0),(ado, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/3', 'revenue': 0.22727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.32, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:33:18,642 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:18,643 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-05-07 21:33:18,794 - MainProcess - INFO - text_logger.py - 51 - Train epoch #35
2024-05-07 21:33:18,797 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.5027e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6094e-01, 0.0000e+00,
        9.1682e-02, 3.1678e-03, 3.2056e-01, 0.0000e+00, 2.8251e-02, 1.7722e-03,
        0.0000e+00, 0.0000e+00, 2.3475e-02, 8.5122e-04, 0.0000e+00, 0.0000e+00,
        1.9432e-02, 4.5675e-04, 0.0000e+00, 0.0000e+00, 1.6489e-02, 2.1472e-04,
        0.0000e+00, 0.0000e+00, 1.4705e-02, 5.5787e-05, 0.0000e+00, 0.0000e+00,
        9.9476e-03, 3.2258e-05, 0.0000e+00, 0.0000e+00, 6.5854e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2015e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7739e-04, 0.0000e+00, 0.0000e+00])  tensor([1.9334e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9373e-01, 0.0000e+00,
        9.0088e-02, 7.5665e-03, 1.2169e-01, 0.0000e+00, 4.9270e-02, 5.4956e-03,
        0.0000e+00, 0.0000e+00, 4.5964e-02, 4.2107e-03, 0.0000e+00, 0.0000e+00,
        4.0440e-02, 3.1279e-03, 0.0000e+00, 0.0000e+00, 3.5775e-02, 2.2166e-03,
        0.0000e+00, 0.0000e+00, 3.2249e-02, 8.9196e-04, 0.0000e+00, 0.0000e+00,
        2.2950e-02, 7.2131e-04, 0.0000e+00, 0.0000e+00, 1.5986e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.6793e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6406e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:33:18,817 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.443403613880089
2024-05-07 21:33:18,820 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.474500.11086
2024-05-07 21:33:19,041 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #36: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3404255319148936, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.42, '(min, 1)': 0.13, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 4)': 0.01}}
2024-05-07 21:33:19,042 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:19,042 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-05-07 21:33:19,707 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #36: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.5, '(min, 1)': 0.12, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:33:19,708 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:19,708 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-05-07 21:33:20,280 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #36: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0975609756097561, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.5, '(min, 1)': 0.1, '(rev, 1)': 0.01, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:33:20,280 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:20,281 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-05-07 21:33:20,321 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #36: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(min, 0)': 0.37, '(min, 1)': 0.19, '(rev, 1)': 0.12, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:33:20,321 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:20,322 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-05-07 21:33:20,570 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #36: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.42, '(min, 1)': 0.17, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 6)': 0.01}}
2024-05-07 21:33:20,570 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:20,571 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-05-07 21:33:20,803 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #36: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3958333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 5)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.19, '(rev, 1)': 0.1, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-05-07 21:33:20,803 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:20,804 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-05-07 21:33:21,555 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #36: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 7, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.675, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.38, '(min, 1)': 0.25, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-05-07 21:33:21,555 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:21,556 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-05-07 21:33:21,714 - MainProcess - INFO - text_logger.py - 51 - Train epoch #36
2024-05-07 21:33:21,717 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.6275e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4567e-01, 0.0000e+00,
        5.9283e-02, 5.7920e-03, 3.7365e-01, 0.0000e+00, 5.6156e-03, 2.9363e-03,
        0.0000e+00, 0.0000e+00, 2.5923e-03, 8.3475e-04, 0.0000e+00, 0.0000e+00,
        1.0488e-03, 4.4797e-04, 0.0000e+00, 0.0000e+00, 6.9893e-04, 2.1204e-04,
        0.0000e+00, 0.0000e+00, 4.7149e-04, 5.5556e-05, 0.0000e+00, 0.0000e+00,
        4.3759e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5269e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.1984, 0.0000, 0.0000, 0.0000, 0.0729, 0.0000, 0.0638, 0.0097, 0.0418,
        0.0000, 0.0198, 0.0071, 0.0000, 0.0000, 0.0141, 0.0038, 0.0000, 0.0000,
        0.0097, 0.0029, 0.0000, 0.0000, 0.0085, 0.0023, 0.0000, 0.0000, 0.0061,
        0.0012, 0.0000, 0.0000, 0.0056, 0.0000, 0.0000, 0.0000, 0.0033, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-05-07 21:33:21,739 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4428993661694931
2024-05-07 21:33:21,742 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.218990.12143
2024-05-07 21:33:22,172 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #37: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 2, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.47, '(min, 1)': 0.07, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:33:22,172 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:22,172 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-05-07 21:33:22,476 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #37: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.05, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.44, '(min, 1)': 0.16, '(rev, 1)': 0.02}}
2024-05-07 21:33:22,476 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:22,477 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-05-07 21:33:22,615 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #37: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.53, '(min, 1)': 0.08}}
2024-05-07 21:33:22,615 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:22,616 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-05-07 21:33:23,042 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #37: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.30434782608695654, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.23, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:33:23,042 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:23,042 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-05-07 21:33:23,336 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #37: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7045454545454546, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.27, '(rev, 1)': 0.09, '(rev, 2)': 0.08, '(rev, 3)': 0.02}}
2024-05-07 21:33:23,336 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:23,337 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-05-07 21:33:23,609 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #37: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5909090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(min, 0)': 0.39, '(min, 1)': 0.23, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:33:23,610 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:23,611 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-05-07 21:33:24,457 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #37: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.46808510638297873, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.4, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:33:24,457 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:24,458 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-05-07 21:33:24,624 - MainProcess - INFO - text_logger.py - 51 - Train epoch #37
2024-05-07 21:33:24,627 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.0497e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5267e-01, 0.0000e+00,
        5.7198e-02, 5.0781e-03, 3.7242e-01, 0.0000e+00, 4.8975e-03, 2.8911e-03,
        0.0000e+00, 0.0000e+00, 1.6209e-03, 1.1614e-03, 0.0000e+00, 0.0000e+00,
        2.1440e-04, 7.0649e-04, 0.0000e+00, 0.0000e+00, 5.4444e-05, 3.3365e-04,
        0.0000e+00, 0.0000e+00, 2.7778e-05, 2.9238e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.1545e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2525e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0159e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5787e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.1285e-02, 0.0000e+00,
        7.2278e-02, 9.3626e-03, 4.3856e-02, 0.0000e+00, 1.7571e-02, 7.2379e-03,
        0.0000e+00, 0.0000e+00, 1.0143e-02, 4.5829e-03, 0.0000e+00, 0.0000e+00,
        2.4562e-03, 4.0358e-03, 0.0000e+00, 0.0000e+00, 8.6016e-04, 2.6658e-03,
        0.0000e+00, 0.0000e+00, 6.2113e-04, 2.5146e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.8434e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4082e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1721e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:33:24,655 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4420071319513725
2024-05-07 21:33:24,657 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.025000.02500
2024-05-07 21:33:24,735 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #38: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 6)': 0.01, '(min, 0)': 0.52, '(min, 1)': 0.06, '(rev, 1)': 0.09, '(rev, 2)': 0.05}}
2024-05-07 21:33:24,736 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:24,736 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-05-07 21:33:24,857 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #38: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 3, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.56, '(min, 1)': 0.02}}
2024-05-07 21:33:24,857 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:24,858 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-05-07 21:33:24,956 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #38: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.52, '(min, 1)': 0.07}}
2024-05-07 21:33:24,956 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:24,957 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-05-07 21:33:25,470 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #38: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35714285714285715, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(min, 0)': 0.45, '(min, 1)': 0.1, '(rev, 1)': 0.13, '(rev, 2)': 0.05}}
2024-05-07 21:33:25,470 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:25,471 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-05-07 21:33:26,390 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #38: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10869565217391304, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.16, '(rev, 1)': 0.04, '(rev, 2)': 0.01}}
2024-05-07 21:33:26,390 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:26,391 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-05-07 21:33:27,014 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #38: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.23, '(rev, 1)': 0.07, '(rev, 2)': 0.03}}
2024-05-07 21:33:27,014 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:27,015 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-05-07 21:33:27,053 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #38: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.2, '(rev, 1)': 0.08, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:33:27,053 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:27,053 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-05-07 21:33:27,209 - MainProcess - INFO - text_logger.py - 51 - Train epoch #38
2024-05-07 21:33:27,213 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.3554e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1297e-01, 0.0000e+00,
        7.1020e-02, 4.5371e-03, 3.5940e-01, 0.0000e+00, 1.3672e-02, 2.0646e-03,
        0.0000e+00, 0.0000e+00, 1.0424e-02, 5.5125e-04, 0.0000e+00, 0.0000e+00,
        7.5413e-03, 4.2356e-04, 0.0000e+00, 0.0000e+00, 6.1637e-03, 1.6311e-04,
        0.0000e+00, 0.0000e+00, 5.0178e-03, 1.0477e-04, 0.0000e+00, 0.0000e+00,
        3.2647e-03, 7.6197e-05, 0.0000e+00, 0.0000e+00, 2.2205e-03, 3.7736e-05,
        0.0000e+00, 0.0000e+00, 3.1624e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9412e-05, 0.0000e+00, 0.0000e+00])  tensor([1.2837e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3079e-01, 0.0000e+00,
        7.6764e-02, 8.9754e-03, 7.9060e-02, 0.0000e+00, 3.3122e-02, 6.0420e-03,
        0.0000e+00, 0.0000e+00, 3.0915e-02, 3.2128e-03, 0.0000e+00, 0.0000e+00,
        2.5148e-02, 3.0364e-03, 0.0000e+00, 0.0000e+00, 2.1439e-02, 1.6557e-03,
        0.0000e+00, 0.0000e+00, 1.8482e-02, 1.3611e-03, 0.0000e+00, 0.0000e+00,
        1.3349e-02, 1.2036e-03, 0.0000e+00, 0.0000e+00, 9.2802e-03, 8.4380e-04,
        0.0000e+00, 0.0000e+00, 2.3659e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.5767e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:33:27,241 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.44106489773325186
2024-05-07 21:33:27,243 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:33:27,286 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #39: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.44, '(min, 1)': 0.14, '(rev, 1)': 0.12, '(rev, 2)': 0.05}}
2024-05-07 21:33:27,286 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:27,287 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-05-07 21:33:27,587 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #39: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 4, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.58, '(min, 1)': 0.04}}
2024-05-07 21:33:27,587 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:27,588 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-05-07 21:33:28,152 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #39: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4318181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.49, '(min, 1)': 0.1, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 4)': 0.02}}
2024-05-07 21:33:28,152 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:28,153 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-05-07 21:33:29,276 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #39: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3023255813953488, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.42, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-07 21:33:29,276 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:29,276 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-05-07 21:33:29,521 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #39: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.1, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-07 21:33:29,522 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:29,522 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-05-07 21:33:29,604 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #39: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 4, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4883720930232558, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(min, 0)': 0.48, '(min, 1)': 0.11, '(rev, 1)': 0.12, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:33:29,604 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:29,604 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-05-07 21:33:29,646 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #39: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.51, '(min, 1)': 0.06}}
2024-05-07 21:33:29,646 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:29,647 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-05-07 21:33:29,754 - MainProcess - INFO - text_logger.py - 51 - Train epoch #39
2024-05-07 21:33:29,757 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.1386e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5382e-01, 0.0000e+00,
        4.7238e-02, 5.6896e-03, 3.8523e-01, 0.0000e+00, 3.1374e-03, 2.5391e-03,
        0.0000e+00, 0.0000e+00, 1.1484e-03, 6.3202e-04, 0.0000e+00, 0.0000e+00,
        1.9520e-04, 2.2575e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2219e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4483e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.4483e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([9.6098e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0373e-02, 0.0000e+00,
        5.2764e-02, 9.6935e-03, 2.7179e-02, 0.0000e+00, 1.2418e-02, 6.6354e-03,
        0.0000e+00, 0.0000e+00, 7.7827e-03, 3.3695e-03, 0.0000e+00, 0.0000e+00,
        3.1085e-03, 1.9123e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1419e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7106e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.7106e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:33:29,777 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4401226635151313
2024-05-07 21:33:29,780 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:33:29,970 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #40: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1282051282051282, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(min, 0)': 0.48, '(min, 1)': 0.11, '(rev, 1)': 0.04, '(rev, 2)': 0.03}}
2024-05-07 21:33:29,970 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:29,971 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-05-07 21:33:31,025 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #40: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.375, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 5)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.22, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:33:31,026 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:31,026 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-05-07 21:33:31,614 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #40: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.8541666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 7)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-05-07 21:33:31,614 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:31,615 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-05-07 21:33:32,084 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #40: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-05-07 21:33:32,084 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:32,085 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-05-07 21:33:32,393 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #40: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.41, '(min, 1)': 0.21, '(rev, 1)': 0.06, '(rev, 2)': 0.07, '(rev, 3)': 0.02}}
2024-05-07 21:33:32,393 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:32,393 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-05-07 21:33:32,545 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #40: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46808510638297873, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.28, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:33:32,545 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:32,546 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-05-07 21:33:33,520 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #40: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5434782608695652, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 7)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.19, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-05-07 21:33:33,520 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:33,521 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-05-07 21:33:33,592 - MainProcess - INFO - text_logger.py - 51 - Train epoch #40
2024-05-07 21:33:33,595 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-6.5838e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  5.0324e-01,
         0.0000e+00,  7.4070e-02,  4.4900e-03,  3.5479e-01,  0.0000e+00,
         1.5824e-02,  2.0706e-03,  0.0000e+00,  0.0000e+00,  1.3075e-02,
         8.2001e-04,  0.0000e+00,  0.0000e+00,  8.9763e-03,  3.6859e-04,
         0.0000e+00,  0.0000e+00,  7.8520e-03,  1.2269e-04,  0.0000e+00,
         0.0000e+00,  6.6181e-03,  7.9216e-05,  0.0000e+00,  0.0000e+00,
         4.2282e-03,  4.0000e-05,  0.0000e+00,  0.0000e+00,  2.8986e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.8957e-04,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  5.2303e-05,  0.0000e+00,  0.0000e+00])  tensor([1.6946e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4118e-01, 0.0000e+00,
        8.6325e-02, 8.8986e-03, 8.2653e-02, 0.0000e+00, 3.2707e-02, 6.0398e-03,
        0.0000e+00, 0.0000e+00, 3.1210e-02, 4.0749e-03, 0.0000e+00, 0.0000e+00,
        2.3238e-02, 2.7199e-03, 0.0000e+00, 0.0000e+00, 2.1577e-02, 1.5824e-03,
        0.0000e+00, 0.0000e+00, 1.9371e-02, 1.2513e-03, 0.0000e+00, 0.0000e+00,
        1.3257e-02, 8.9443e-04, 0.0000e+00, 0.0000e+00, 9.9011e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.6633e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.4177e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:33:33,613 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.440578074224547
2024-05-07 21:33:33,616 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.698820.15534
2024-05-07 21:33:33,671 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #41: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.023255813953488372, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 6)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.1, '(rev, 1)': 0.02}}
2024-05-07 21:33:33,671 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:33,672 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-05-07 21:33:33,976 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #41: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 6)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.16, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:33:33,976 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:33,977 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-05-07 21:33:34,251 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #41: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.52, '(min, 1)': 0.08, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:33:34,251 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:34,252 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-05-07 21:33:35,093 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #41: {'transition': '(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 2, 5, 1, 1),(min, 0)->(exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 3, 5, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.41, '(min, 1)': 0.19, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:33:35,093 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:35,094 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-05-07 21:33:35,110 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #41: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5869565217391305, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(min, 0)': 0.29, '(min, 1)': 0.26, '(rev, 1)': 0.11, '(rev, 2)': 0.05}}
2024-05-07 21:33:35,110 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:35,111 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-05-07 21:33:35,442 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #41: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 6, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40476190476190477, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.43, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:33:35,442 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:35,442 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-05-07 21:33:36,388 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #41: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6428571428571429, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(min, 0)': 0.27, '(min, 1)': 0.36, '(rev, 1)': 0.11, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:33:36,388 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:36,389 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-05-07 21:33:36,460 - MainProcess - INFO - text_logger.py - 51 - Train epoch #41
2024-05-07 21:33:36,463 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-2.4780e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.8062e-01,
         0.0000e+00,  8.2155e-02,  4.1523e-03,  3.3818e-01,  0.0000e+00,
         2.0960e-02,  1.6970e-03,  0.0000e+00,  0.0000e+00,  1.7971e-02,
         6.1111e-04,  0.0000e+00,  0.0000e+00,  1.3415e-02,  5.1597e-04,
         0.0000e+00,  0.0000e+00,  1.2301e-02,  3.4116e-04,  0.0000e+00,
         0.0000e+00,  1.0902e-02,  3.7958e-04,  0.0000e+00,  0.0000e+00,
         7.9294e-03,  1.3486e-04,  0.0000e+00,  0.0000e+00,  6.2985e-03,
         3.5714e-05,  0.0000e+00,  0.0000e+00,  1.2318e-03,  3.5714e-05,
         0.0000e+00,  0.0000e+00,  1.3438e-04,  0.0000e+00,  0.0000e+00])  tensor([1.8187e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7119e-01, 0.0000e+00,
        1.0330e-01, 8.6674e-03, 1.0216e-01, 0.0000e+00, 3.8422e-02, 5.4138e-03,
        0.0000e+00, 0.0000e+00, 3.5712e-02, 3.4326e-03, 0.0000e+00, 0.0000e+00,
        2.7495e-02, 3.1188e-03, 0.0000e+00, 0.0000e+00, 2.5936e-02, 2.4066e-03,
        0.0000e+00, 0.0000e+00, 2.3552e-02, 2.9703e-03, 0.0000e+00, 0.0000e+00,
        1.7384e-02, 1.5086e-03, 0.0000e+00, 0.0000e+00, 1.4009e-02, 7.9860e-04,
        0.0000e+00, 0.0000e+00, 4.6836e-03, 7.9860e-04, 0.0000e+00, 0.0000e+00,
        1.5078e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:33:36,483 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4405786971492836
2024-05-07 21:33:36,485 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.471430.17143
2024-05-07 21:33:36,507 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2692307692307692, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 7)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.18, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:33:36,508 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:36,508 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-05-07 21:33:36,709 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.48, '(min, 1)': 0.11}}
2024-05-07 21:33:36,709 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:36,710 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-05-07 21:33:37,432 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5294117647058824, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.17, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:33:37,432 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:37,433 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-05-07 21:33:37,824 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.045454545454545456, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.23, '(rev, 1)': 0.04}}
2024-05-07 21:33:37,824 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:37,825 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-05-07 21:33:38,563 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 8)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.31, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-05-07 21:33:38,564 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:38,564 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-05-07 21:33:38,758 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7555555555555555, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(min, 0)': 0.37, '(min, 1)': 0.28, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.07, '(rev, 4)': 0.04}}
2024-05-07 21:33:38,759 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:38,759 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-05-07 21:33:38,922 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.36, '(min, 1)': 0.2, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:33:38,922 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:38,923 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-05-07 21:33:38,989 - MainProcess - INFO - text_logger.py - 51 - Train epoch #42
2024-05-07 21:33:38,993 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.1348e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0159e-01, 0.0000e+00,
        6.9313e-02, 4.0843e-03, 3.4256e-01, 0.0000e+00, 1.8941e-02, 2.8893e-03,
        0.0000e+00, 0.0000e+00, 1.4575e-02, 2.1868e-03, 0.0000e+00, 0.0000e+00,
        1.0242e-02, 1.5799e-03, 0.0000e+00, 0.0000e+00, 9.8714e-03, 4.8663e-04,
        0.0000e+00, 0.0000e+00, 8.6144e-03, 3.6796e-04, 0.0000e+00, 0.0000e+00,
        6.2385e-03, 3.0907e-04, 0.0000e+00, 0.0000e+00, 4.9592e-03, 3.6364e-05,
        0.0000e+00, 0.0000e+00, 1.0056e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4532e-04, 0.0000e+00, 0.0000e+00])  tensor([2.0738e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6112e-01, 0.0000e+00,
        9.5430e-02, 8.2663e-03, 9.4860e-02, 0.0000e+00, 3.6711e-02, 6.6710e-03,
        0.0000e+00, 0.0000e+00, 3.2343e-02, 6.0066e-03, 0.0000e+00, 0.0000e+00,
        2.4618e-02, 5.4076e-03, 0.0000e+00, 0.0000e+00, 2.4410e-02, 2.8956e-03,
        0.0000e+00, 0.0000e+00, 2.1474e-02, 2.4863e-03, 0.0000e+00, 0.0000e+00,
        1.5873e-02, 2.2999e-03, 0.0000e+00, 0.0000e+00, 1.2975e-02, 8.1312e-04,
        0.0000e+00, 0.0000e+00, 4.2118e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4692e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:33:39,016 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43994757404227414
2024-05-07 21:33:39,019 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.155560.15556
2024-05-07 21:33:39,512 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #43: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 4, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 7)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.16, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:33:39,513 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:39,513 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-05-07 21:33:40,636 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #43: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 9, 3, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 9, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4594594594594595, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.21, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.04, '(rev, 5)': 0.01}}
2024-05-07 21:33:40,636 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:40,637 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-05-07 21:33:40,766 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #43: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 4, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 6)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.3}}
2024-05-07 21:33:40,767 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:40,768 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-05-07 21:33:41,357 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #43: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.23404255319148937, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.4, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:33:41,357 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:41,358 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-05-07 21:33:41,715 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #43: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 10)': 0.01, '(ado, 2)': 0.02, '(min, 0)': 0.45, '(min, 1)': 0.2, '(rev, 1)': 0.08, '(rev, 2)': 0.03}}
2024-05-07 21:33:41,715 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:41,716 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-05-07 21:33:41,765 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #43: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 1),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 2, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.375, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.3, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:33:41,765 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:41,765 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-05-07 21:33:42,386 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #43: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.08108108108108109, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(min, 0)': 0.43, '(min, 1)': 0.21, '(rev, 1)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:33:42,387 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:42,387 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-05-07 21:33:42,456 - MainProcess - INFO - text_logger.py - 51 - Train epoch #43
2024-05-07 21:33:42,459 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.5734e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0649e-01, 0.0000e+00,
        7.2479e-02, 3.5302e-03, 3.4712e-01, 0.0000e+00, 1.7472e-02, 2.4893e-03,
        0.0000e+00, 0.0000e+00, 1.3313e-02, 1.6546e-03, 0.0000e+00, 0.0000e+00,
        8.9788e-03, 1.1303e-03, 0.0000e+00, 0.0000e+00, 8.2597e-03, 7.3222e-04,
        0.0000e+00, 0.0000e+00, 6.8963e-03, 5.7088e-04, 0.0000e+00, 0.0000e+00,
        4.1819e-03, 5.1313e-04, 0.0000e+00, 0.0000e+00, 3.2299e-03, 2.3399e-04,
        0.0000e+00, 0.0000e+00, 6.0997e-04, 3.6364e-05, 0.0000e+00, 0.0000e+00,
        8.2695e-05, 0.0000e+00, 0.0000e+00])  tensor([2.2182e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5520e-01, 0.0000e+00,
        9.5556e-02, 7.6240e-03, 9.0552e-02, 0.0000e+00, 3.5798e-02, 5.9175e-03,
        0.0000e+00, 0.0000e+00, 3.0487e-02, 5.0662e-03, 0.0000e+00, 0.0000e+00,
        2.1931e-02, 4.0308e-03, 0.0000e+00, 0.0000e+00, 2.2472e-02, 3.2606e-03,
        0.0000e+00, 0.0000e+00, 1.9894e-02, 2.8554e-03, 0.0000e+00, 0.0000e+00,
        1.3785e-02, 2.7135e-03, 0.0000e+00, 0.0000e+00, 1.1265e-02, 1.8800e-03,
        0.0000e+00, 0.0000e+00, 3.4288e-03, 8.1312e-04, 0.0000e+00, 0.0000e+00,
        1.0798e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:33:42,480 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4390864209052346
2024-05-07 21:33:42,483 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.040540.04054
2024-05-07 21:33:43,149 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.36, '(min, 1)': 0.27}}
2024-05-07 21:33:43,149 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:43,150 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-05-07 21:33:43,928 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 4)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.23, '(rev, 1)': 0.02, '(rev, 2)': 0.02, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:33:43,929 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:43,929 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-05-07 21:33:43,988 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.36, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 3)': 0.03, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.4, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:33:43,988 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:43,989 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-05-07 21:33:44,288 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #44: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.07692307692307693, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.31, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:33:44,288 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:44,289 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-05-07 21:33:44,768 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.29, '(rev, 1)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:33:44,768 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:44,769 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-05-07 21:33:44,869 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.38, '(min, 1)': 0.2}}
2024-05-07 21:33:44,869 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:44,870 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-05-07 21:33:45,086 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 5)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.22}}
2024-05-07 21:33:45,086 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:45,086 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-05-07 21:33:45,245 - MainProcess - INFO - text_logger.py - 51 - Train epoch #44
2024-05-07 21:33:45,248 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-7.1114e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.1395e-01,
         0.0000e+00,  1.7042e-01,  2.1033e-03,  2.4171e-01,  0.0000e+00,
         6.2073e-02,  1.4011e-03,  0.0000e+00,  0.0000e+00,  4.9834e-02,
         5.9143e-04,  0.0000e+00,  0.0000e+00,  3.8661e-02,  2.3694e-04,
         0.0000e+00,  0.0000e+00,  3.7497e-02,  5.2094e-04,  0.0000e+00,
         0.0000e+00,  3.4201e-02,  3.2258e-05,  0.0000e+00,  0.0000e+00,
         2.4427e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.8936e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.0899e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.0639e-04,  0.0000e+00,  0.0000e+00])  tensor([1.9727e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2199e-01, 0.0000e+00,
        1.2899e-01, 6.2317e-03, 1.3389e-01, 0.0000e+00, 5.1817e-02, 4.7689e-03,
        0.0000e+00, 0.0000e+00, 4.3491e-02, 3.4349e-03, 0.0000e+00, 0.0000e+00,
        3.5122e-02, 2.0167e-03, 0.0000e+00, 0.0000e+00, 3.5539e-02, 3.9136e-03,
        0.0000e+00, 0.0000e+00, 3.3385e-02, 7.2131e-04, 0.0000e+00, 0.0000e+00,
        2.5788e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1859e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.2711e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.1669e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:33:45,269 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.438144186687114
2024-05-07 21:33:45,271 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:33:47,038 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #45: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 7)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.1}}
2024-05-07 21:33:47,039 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:47,039 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-05-07 21:33:47,292 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #45: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43137254901960786, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.32, '(rev, 1)': 0.03, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-07 21:33:47,292 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:47,293 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-05-07 21:33:47,356 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #45: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.3, '(min, 1)': 0.33}}
2024-05-07 21:33:47,356 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:47,357 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-05-07 21:33:47,579 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #45: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7435897435897436, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.33, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 5)': 0.02}}
2024-05-07 21:33:47,579 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:47,580 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-05-07 21:33:47,992 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #45: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3673469387755102, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 9)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.42, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 5)': 0.02}}
2024-05-07 21:33:47,993 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:47,993 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-05-07 21:33:47,998 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #45: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.16326530612244897, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.14, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:33:47,998 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:47,999 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-05-07 21:33:48,361 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #45: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.52, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 6)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.3, '(rev, 1)': 0.05, '(rev, 5)': 0.01, '(rev, 6)': 0.02}}
2024-05-07 21:33:48,362 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:48,362 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-05-07 21:33:48,514 - MainProcess - INFO - text_logger.py - 51 - Train epoch #45
2024-05-07 21:33:48,517 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.3675e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3078e-01, 0.0000e+00,
        1.1235e-01, 3.0676e-03, 3.0306e-01, 0.0000e+00, 3.4429e-02, 2.0275e-03,
        0.0000e+00, 0.0000e+00, 2.8253e-02, 1.2080e-03, 0.0000e+00, 0.0000e+00,
        2.1168e-02, 6.7340e-04, 0.0000e+00, 0.0000e+00, 1.9589e-02, 6.9373e-04,
        0.0000e+00, 0.0000e+00, 1.7652e-02, 3.6722e-04, 0.0000e+00, 0.0000e+00,
        1.2531e-02, 1.0588e-04, 0.0000e+00, 0.0000e+00, 9.8324e-03, 3.6364e-05,
        0.0000e+00, 0.0000e+00, 1.8835e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.0031e-04, 0.0000e+00, 0.0000e+00])  tensor([2.4719e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1266e-01, 0.0000e+00,
        1.2858e-01, 7.3583e-03, 1.3013e-01, 0.0000e+00, 4.8757e-02, 5.7518e-03,
        0.0000e+00, 0.0000e+00, 4.3061e-02, 4.6920e-03, 0.0000e+00, 0.0000e+00,
        3.3662e-02, 3.3071e-03, 0.0000e+00, 0.0000e+00, 3.2548e-02, 3.5140e-03,
        0.0000e+00, 0.0000e+00, 2.9749e-02, 2.8631e-03, 0.0000e+00, 0.0000e+00,
        2.2139e-02, 1.3718e-03, 0.0000e+00, 0.0000e+00, 1.8016e-02, 8.1312e-04,
        0.0000e+00, 0.0000e+00, 5.8310e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.1417e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:33:48,537 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43720195246899346
2024-05-07 21:33:48,540 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:33:49,625 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #46: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.22, '(min, 1)': 0.38}}
2024-05-07 21:33:49,625 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:49,626 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-05-07 21:33:49,769 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #46: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.22, '(min, 1)': 0.37}}
2024-05-07 21:33:49,769 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:49,770 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-05-07 21:33:50,202 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #46: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3125, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 8)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.25, '(rev, 1)': 0.08, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:33:50,202 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:50,202 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-05-07 21:33:50,863 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #46: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 3, 1, 1),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 4, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.46, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.26, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.04, '(rev, 4)': 0.01}}
2024-05-07 21:33:50,863 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:50,864 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-05-07 21:33:51,104 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #46: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.48, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-05-07 21:33:51,104 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:51,105 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-05-07 21:33:52,311 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #46: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.09803921568627451, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.19, '(rev, 1)': 0.01, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:33:52,311 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:52,311 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-05-07 21:33:52,892 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #46: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.44680851063829785, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.34, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-05-07 21:33:52,892 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:52,893 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-05-07 21:33:53,047 - MainProcess - INFO - text_logger.py - 51 - Train epoch #46
2024-05-07 21:33:53,050 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.0413e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4966e-01, 0.0000e+00,
        9.3711e-02, 3.7625e-03, 3.2611e-01, 0.0000e+00, 3.0168e-02, 1.8121e-03,
        0.0000e+00, 0.0000e+00, 2.3568e-02, 1.3860e-03, 0.0000e+00, 0.0000e+00,
        1.6806e-02, 7.8657e-04, 0.0000e+00, 0.0000e+00, 1.6378e-02, 5.8606e-04,
        0.0000e+00, 0.0000e+00, 1.4641e-02, 3.4387e-04, 0.0000e+00, 0.0000e+00,
        1.0562e-02, 3.0613e-04, 0.0000e+00, 0.0000e+00, 7.7868e-03, 3.6364e-05,
        0.0000e+00, 0.0000e+00, 1.3372e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5569e-04, 0.0000e+00, 0.0000e+00])  tensor([2.2195e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9413e-01, 0.0000e+00,
        1.1056e-01, 8.3025e-03, 1.2154e-01, 0.0000e+00, 4.8304e-02, 5.4450e-03,
        0.0000e+00, 0.0000e+00, 4.0956e-02, 4.6998e-03, 0.0000e+00, 0.0000e+00,
        3.0773e-02, 3.6647e-03, 0.0000e+00, 0.0000e+00, 3.1686e-02, 3.1721e-03,
        0.0000e+00, 0.0000e+00, 2.8886e-02, 2.4388e-03, 0.0000e+00, 0.0000e+00,
        2.2189e-02, 2.2932e-03, 0.0000e+00, 0.0000e+00, 1.7071e-02, 8.1312e-04,
        0.0000e+00, 0.0000e+00, 4.9609e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.0261e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:33:53,067 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4362597182508729
2024-05-07 21:33:53,069 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:33:53,125 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #47: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2708333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.19, '(min, 1)': 0.42, '(rev, 1)': 0.03, '(rev, 10)': 0.01}}
2024-05-07 21:33:53,125 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:53,126 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-05-07 21:33:53,155 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #47: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(ado, 8)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.19}}
2024-05-07 21:33:53,155 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:53,156 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-05-07 21:33:53,494 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #47: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.33, '(min, 1)': 0.29, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-05-07 21:33:53,495 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:53,495 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-05-07 21:33:54,237 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #47: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 3, 0, 0),(rev, 3)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.27, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:33:54,237 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:54,238 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-05-07 21:33:55,260 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #47: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1875, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 3)': 0.03, '(ado, 8)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.24, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:33:55,260 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:55,261 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-05-07 21:33:55,541 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #47: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 3, 9, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.2}}
2024-05-07 21:33:55,541 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:55,542 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-05-07 21:33:57,286 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #47: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 2, 1, 1),(min, 0)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 3, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.19047619047619047, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.39, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:33:57,286 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:57,287 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-05-07 21:33:57,437 - MainProcess - INFO - text_logger.py - 51 - Train epoch #47
2024-05-07 21:33:57,441 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.3567e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.5587e-01,
         0.0000e+00,  1.5011e-01,  1.9760e-03,  2.6737e-01,  0.0000e+00,
         5.0904e-02,  1.4587e-03,  0.0000e+00,  0.0000e+00,  4.1269e-02,
         8.2454e-04,  0.0000e+00,  0.0000e+00,  3.1219e-02,  5.9187e-04,
         0.0000e+00,  0.0000e+00,  3.0360e-02,  2.3752e-04,  0.0000e+00,
         0.0000e+00,  2.8039e-02,  4.0816e-05,  0.0000e+00,  0.0000e+00,
         2.0783e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.5226e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.1162e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.0773e-04,  0.0000e+00,  0.0000e+00])  tensor([2.2636e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2690e-01, 0.0000e+00,
        1.3079e-01, 6.2641e-03, 1.4596e-01, 0.0000e+00, 5.4243e-02, 4.8474e-03,
        0.0000e+00, 0.0000e+00, 4.6247e-02, 3.7843e-03, 0.0000e+00, 0.0000e+00,
        3.7190e-02, 3.3883e-03, 0.0000e+00, 0.0000e+00, 3.7975e-02, 2.0146e-03,
        0.0000e+00, 0.0000e+00, 3.5814e-02, 9.1268e-04, 0.0000e+00, 0.0000e+00,
        2.8133e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2301e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.5571e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.0905e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:33:57,461 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43558831736608566
2024-05-07 21:33:57,463 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.135420.13542
2024-05-07 21:33:57,470 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #48: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 6, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.26, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:33:57,470 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:57,471 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729
2024-05-07 21:33:57,486 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #48: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5714285714285714, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(min, 0)': 0.3, '(min, 1)': 0.29, '(rev, 1)': 0.12, '(rev, 2)': 0.07, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-05-07 21:33:57,487 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:57,487 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729
2024-05-07 21:33:57,502 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #48: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.24, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:33:57,503 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:57,503 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729
2024-05-07 21:33:57,526 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #48: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.05263157894736842, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.37, '(min, 1)': 0.24, '(rev, 1)': 0.02, '(rev, 2)': 0.01}}
2024-05-07 21:33:57,526 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:57,527 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729
2024-05-07 21:33:59,266 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #48: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 2, 0, 1),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 1, 0, 1)', 'reward_ratio': '0/1', 'revenue': 0.23404255319148937, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.03, '(ado, 5)': 0.02, '(min, 0)': 0.39, '(min, 1)': 0.29, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:33:59,267 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:59,267 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729
2024-05-07 21:33:59,495 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #48: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.4074074074074074, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.15, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:33:59,496 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:33:59,496 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729
2024-05-07 21:34:01,123 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #48: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 8)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.35, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:34:01,123 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:01,124 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729
2024-05-07 21:34:01,287 - MainProcess - INFO - text_logger.py - 51 - Train epoch #48
2024-05-07 21:34:01,290 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.8644e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8341e-01, 0.0000e+00,
        8.0020e-02, 3.8365e-03, 3.5160e-01, 0.0000e+00, 1.9837e-02, 2.8473e-03,
        0.0000e+00, 0.0000e+00, 1.4915e-02, 1.9913e-03, 0.0000e+00, 0.0000e+00,
        1.0716e-02, 9.7278e-04, 0.0000e+00, 0.0000e+00, 9.4654e-03, 5.9830e-04,
        0.0000e+00, 0.0000e+00, 8.0379e-03, 2.0826e-04, 0.0000e+00, 0.0000e+00,
        6.4292e-03, 7.4773e-05, 0.0000e+00, 0.0000e+00, 4.4028e-03, 7.4773e-05,
        0.0000e+00, 0.0000e+00, 5.6576e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.0909e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5989e-01, 0.0000e+00,
        1.0039e-01, 8.4677e-03, 1.0190e-01, 0.0000e+00, 3.8609e-02, 6.9654e-03,
        0.0000e+00, 0.0000e+00, 3.3519e-02, 5.7357e-03, 0.0000e+00, 0.0000e+00,
        2.6686e-02, 4.0771e-03, 0.0000e+00, 0.0000e+00, 2.5305e-02, 3.3263e-03,
        0.0000e+00, 0.0000e+00, 2.2419e-02, 2.2779e-03, 0.0000e+00, 0.0000e+00,
        1.8722e-02, 1.1811e-03, 0.0000e+00, 0.0000e+00, 1.3333e-02, 1.1811e-03,
        0.0000e+00, 0.0000e+00, 3.5065e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:34:01,313 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4350987147269124
2024-05-07 21:34:01,315 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.226320.17368
2024-05-07 21:34:01,334 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #49: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4523809523809524, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.02, '(min, 0)': 0.31, '(min, 1)': 0.32, '(rev, 1)': 0.04, '(rev, 3)': 0.02}}
2024-05-07 21:34:01,334 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:01,335 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43558831736608566
2024-05-07 21:34:01,350 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #49: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.48, '(min, 1)': 0.12}}
2024-05-07 21:34:01,351 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:01,351 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43558831736608566
2024-05-07 21:34:01,378 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #49: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.02, '(min, 0)': 0.14, '(min, 1)': 0.43, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:34:01,378 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:01,379 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43558831736608566
2024-05-07 21:34:01,381 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #49: {'transition': '(exi, wit, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 4, 9, 1, 1),(min, 0)->(exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 5, 9, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.2}}
2024-05-07 21:34:01,381 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:01,382 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43558831736608566
2024-05-07 21:34:02,162 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #49: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.28, '(min, 1)': 0.33, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:34:02,162 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:02,163 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43558831736608566
2024-05-07 21:34:02,427 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #49: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.34, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:34:02,427 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:02,427 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43558831736608566
2024-05-07 21:34:03,818 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #49: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.275, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.04, '(min, 0)': 0.26, '(min, 1)': 0.35, '(rev, 1)': 0.1, '(rev, 2)': 0.04}}
2024-05-07 21:34:03,818 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:03,819 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43558831736608566
2024-05-07 21:34:03,973 - MainProcess - INFO - text_logger.py - 51 - Train epoch #49
2024-05-07 21:34:03,976 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.7844e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2157e-01, 0.0000e+00,
        5.4320e-02, 4.9637e-03, 3.7244e-01, 0.0000e+00, 1.1496e-02, 3.3140e-03,
        0.0000e+00, 0.0000e+00, 7.9989e-03, 1.8463e-03, 0.0000e+00, 0.0000e+00,
        5.7487e-03, 4.6123e-04, 0.0000e+00, 0.0000e+00, 4.7484e-03, 1.0131e-04,
        0.0000e+00, 0.0000e+00, 4.6222e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4616e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4700e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.0578e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.1250e-05, 0.0000e+00, 0.0000e+00])  tensor([1.5525e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2212e-01, 0.0000e+00,
        7.0607e-02, 9.3715e-03, 7.6340e-02, 0.0000e+00, 3.1169e-02, 7.2097e-03,
        0.0000e+00, 0.0000e+00, 2.5902e-02, 5.9269e-03, 0.0000e+00, 0.0000e+00,
        2.1061e-02, 2.7484e-03, 0.0000e+00, 0.0000e+00, 1.8780e-02, 1.3064e-03,
        0.0000e+00, 0.0000e+00, 1.8274e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4250e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0725e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.9071e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.9877e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:34:03,996 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43415648050879185
2024-05-07 21:34:03,998 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:34:04,036 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #50: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32558139534883723, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.33, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-07 21:34:04,037 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:04,038 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4350987147269124
2024-05-07 21:34:04,142 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #50: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0967741935483871, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.56, '(min, 1)': 0.11, '(rev, 1)': 0.03, '(rev, 2)': 0.02}}
2024-05-07 21:34:04,142 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:04,143 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4350987147269124
2024-05-07 21:34:04,981 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #50: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.13157894736842105, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.19, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:34:04,981 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:04,982 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4350987147269124
2024-05-07 21:34:05,276 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #50: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.06521739130434782, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.28, '(rev, 1)': 0.03, '(rev, 2)': 0.03}}
2024-05-07 21:34:05,276 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:05,277 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4350987147269124
2024-05-07 21:34:05,342 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #50: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43243243243243246, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.2, '(min, 1)': 0.41, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-07 21:34:05,342 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:05,343 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4350987147269124
2024-05-07 21:34:05,671 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #50: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.03, '(min, 0)': 0.24, '(min, 1)': 0.41, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-07 21:34:05,671 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:05,673 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4350987147269124
2024-05-07 21:34:06,828 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #50: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.23684210526315788, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.42, '(min, 1)': 0.28, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:34:06,828 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:06,829 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4350987147269124
2024-05-07 21:34:06,982 - MainProcess - INFO - text_logger.py - 51 - Train epoch #50
2024-05-07 21:34:06,985 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.7318e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7669e-01, 0.0000e+00,
        8.8320e-02, 3.9829e-03, 3.5464e-01, 0.0000e+00, 2.0432e-02, 2.9770e-03,
        0.0000e+00, 0.0000e+00, 1.4041e-02, 2.1318e-03, 0.0000e+00, 0.0000e+00,
        9.8043e-03, 6.4910e-04, 0.0000e+00, 0.0000e+00, 8.2357e-03, 2.2072e-04,
        0.0000e+00, 0.0000e+00, 8.2472e-03, 2.7397e-05, 0.0000e+00, 0.0000e+00,
        5.6174e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6024e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.8572e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.8686e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6113e-01, 0.0000e+00,
        1.1699e-01, 8.5795e-03, 1.0229e-01, 0.0000e+00, 4.0138e-02, 6.7260e-03,
        0.0000e+00, 0.0000e+00, 3.1683e-02, 6.2419e-03, 0.0000e+00, 0.0000e+00,
        2.4432e-02, 3.1691e-03, 0.0000e+00, 0.0000e+00, 2.1624e-02, 1.7611e-03,
        0.0000e+00, 0.0000e+00, 2.2469e-02, 6.1262e-04, 0.0000e+00, 0.0000e+00,
        1.6901e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1979e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.8873e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:34:07,006 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4334425994315881
2024-05-07 21:34:07,008 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.114180.01740
2024-05-07 21:34:07,045 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #51: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.09090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.28, '(rev, 1)': 0.05, '(rev, 2)': 0.02}}
2024-05-07 21:34:07,046 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:07,046 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43415648050879185
2024-05-07 21:34:07,757 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #51: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(min, 0)': 0.12, '(min, 1)': 0.44, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:34:07,757 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:07,758 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43415648050879185
2024-05-07 21:34:07,889 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #51: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5098039215686274, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 8)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.3, '(rev, 1)': 0.05, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-05-07 21:34:07,889 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:07,890 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43415648050879185
2024-05-07 21:34:08,329 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #51: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7021276595744681, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(min, 0)': 0.34, '(min, 1)': 0.36, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 6)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:34:08,329 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:08,330 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43415648050879185
2024-05-07 21:34:09,005 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #51: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.57, '(min, 1)': 0.1}}
2024-05-07 21:34:09,005 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:09,006 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43415648050879185
2024-05-07 21:34:09,786 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #51: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.42, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 5)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.25, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:34:09,786 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:09,786 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43415648050879185
2024-05-07 21:34:09,976 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #51: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.39215686274509803, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.02, '(min, 0)': 0.2, '(min, 1)': 0.41, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:34:09,976 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:09,976 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43415648050879185
2024-05-07 21:34:10,141 - MainProcess - INFO - text_logger.py - 51 - Train epoch #51
2024-05-07 21:34:10,144 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.0092e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4926e-01, 0.0000e+00,
        9.5926e-02, 4.5311e-03, 3.2863e-01, 0.0000e+00, 2.7861e-02, 2.2772e-03,
        0.0000e+00, 0.0000e+00, 2.2054e-02, 1.1543e-03, 0.0000e+00, 0.0000e+00,
        1.7267e-02, 8.6356e-04, 0.0000e+00, 0.0000e+00, 1.5041e-02, 3.5569e-04,
        0.0000e+00, 0.0000e+00, 1.3989e-02, 6.0400e-04, 0.0000e+00, 0.0000e+00,
        1.1777e-02, 3.8462e-05, 0.0000e+00, 0.0000e+00, 7.0973e-03, 6.0606e-05,
        0.0000e+00, 0.0000e+00, 9.9993e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.0914e-04, 0.0000e+00, 0.0000e+00])  tensor([2.7567e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9100e-01, 0.0000e+00,
        1.0712e-01, 9.3869e-03, 1.2441e-01, 0.0000e+00, 4.7908e-02, 6.2216e-03,
        0.0000e+00, 0.0000e+00, 4.1487e-02, 4.5771e-03, 0.0000e+00, 0.0000e+00,
        3.4284e-02, 4.0533e-03, 0.0000e+00, 0.0000e+00, 3.1003e-02, 2.4089e-03,
        0.0000e+00, 0.0000e+00, 2.9316e-02, 4.1196e-03, 0.0000e+00, 0.0000e+00,
        2.5103e-02, 8.6003e-04, 0.0000e+00, 0.0000e+00, 1.7098e-02, 1.3552e-03,
        0.0000e+00, 0.0000e+00, 4.3303e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7938e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:34:10,164 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4330101691350361
2024-05-07 21:34:10,166 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.254900.25490
2024-05-07 21:34:10,189 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #52: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3617021276595745, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.25, '(min, 1)': 0.3, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 4)': 0.01}}
2024-05-07 21:34:10,189 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:10,190 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4334425994315881
2024-05-07 21:34:10,695 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #52: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5217391304347826, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.51, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 7)': 0.01}}
2024-05-07 21:34:10,695 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:10,696 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4334425994315881
2024-05-07 21:34:11,228 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #52: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2608695652173913, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.15, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:34:11,229 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:11,229 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4334425994315881
2024-05-07 21:34:11,363 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #52: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8095238095238095, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(min, 0)': 0.42, '(min, 1)': 0.19, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:34:11,363 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:11,364 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4334425994315881
2024-05-07 21:34:11,842 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #52: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5416666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(min, 0)': 0.34, '(min, 1)': 0.21, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:34:11,842 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:11,843 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4334425994315881
2024-05-07 21:34:12,652 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #52: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.27, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:34:12,652 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:12,653 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4334425994315881
2024-05-07 21:34:12,834 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #52: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6585365853658537, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(min, 0)': 0.27, '(min, 1)': 0.4, '(rev, 1)': 0.11, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:34:12,834 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:12,835 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4334425994315881
2024-05-07 21:34:12,992 - MainProcess - INFO - text_logger.py - 51 - Train epoch #52
2024-05-07 21:34:12,995 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.9688e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1647e-01, 0.0000e+00,
        6.1197e-02, 5.3188e-03, 3.7817e-01, 0.0000e+00, 1.1213e-02, 3.0371e-03,
        0.0000e+00, 0.0000e+00, 6.8769e-03, 1.7143e-03, 0.0000e+00, 0.0000e+00,
        4.2821e-03, 9.0427e-04, 0.0000e+00, 0.0000e+00, 3.3658e-03, 3.1769e-04,
        0.0000e+00, 0.0000e+00, 3.1542e-03, 2.5696e-04, 0.0000e+00, 0.0000e+00,
        2.2226e-03, 1.5060e-04, 0.0000e+00, 0.0000e+00, 1.1751e-03, 2.7778e-05,
        0.0000e+00, 0.0000e+00, 1.1316e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4483e-05, 0.0000e+00, 0.0000e+00])  tensor([1.6400e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1254e-01, 0.0000e+00,
        7.9106e-02, 9.7767e-03, 6.7764e-02, 0.0000e+00, 2.9021e-02, 7.0918e-03,
        0.0000e+00, 0.0000e+00, 2.2897e-02, 5.3889e-03, 0.0000e+00, 0.0000e+00,
        1.7412e-02, 3.8467e-03, 0.0000e+00, 0.0000e+00, 1.4939e-02, 2.1409e-03,
        0.0000e+00, 0.0000e+00, 1.4528e-02, 1.9138e-03, 0.0000e+00, 0.0000e+00,
        1.0967e-02, 1.7986e-03, 0.0000e+00, 0.0000e+00, 7.1421e-03, 6.2113e-04,
        0.0000e+00, 0.0000e+00, 1.5088e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.7106e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:34:13,012 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.433419125393106
2024-05-07 21:34:13,014 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.675600.13393
2024-05-07 21:34:13,984 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #53: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.43902439024390244, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.49, '(rev, 1)': 0.12, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-05-07 21:34:13,984 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:13,985 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4330101691350361
2024-05-07 21:34:14,044 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #53: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 7, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 7, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.9285714285714286, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.02, '(min, 0)': 0.21, '(min, 1)': 0.45, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 6)': 0.01}}
2024-05-07 21:34:14,044 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:14,045 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4330101691350361
2024-05-07 21:34:15,922 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #53: {'transition': '(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 2, 4, 1, 1),(min, 0)->(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 2, 5, 1, 1)', 'reward_ratio': '0/0', 'revenue': 1.3095238095238095, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.51, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 4)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:34:15,922 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:15,923 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4330101691350361
2024-05-07 21:34:16,102 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #53: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.25, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:34:16,102 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:16,103 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4330101691350361
2024-05-07 21:34:16,284 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #53: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.4444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.34, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:34:16,284 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:16,285 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4330101691350361
2024-05-07 21:34:16,651 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #53: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2708333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.38, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:34:16,651 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:16,652 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4330101691350361
2024-05-07 21:34:18,170 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #53: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6585365853658537, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.42, '(rev, 1)': 0.06, '(rev, 3)': 0.04, '(rev, 4)': 0.02}}
2024-05-07 21:34:18,170 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:18,171 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4330101691350361
2024-05-07 21:34:18,260 - MainProcess - INFO - text_logger.py - 51 - Train epoch #53
2024-05-07 21:34:18,263 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.7046e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2815e-01, 0.0000e+00,
        5.5707e-02, 4.8250e-03, 3.6947e-01, 0.0000e+00, 9.7838e-03, 3.8373e-03,
        0.0000e+00, 0.0000e+00, 6.6349e-03, 2.0325e-03, 0.0000e+00, 0.0000e+00,
        4.7114e-03, 1.2539e-03, 0.0000e+00, 0.0000e+00, 3.6491e-03, 7.4801e-04,
        0.0000e+00, 0.0000e+00, 3.6980e-03, 4.4119e-04, 0.0000e+00, 0.0000e+00,
        2.6908e-03, 1.0643e-04, 0.0000e+00, 0.0000e+00, 1.7137e-03, 2.2841e-04,
        0.0000e+00, 0.0000e+00, 2.7813e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2787e-05, 0.0000e+00, 0.0000e+00])  tensor([3.0576e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2294e-01, 0.0000e+00,
        9.3034e-02, 9.3650e-03, 7.5776e-02, 0.0000e+00, 2.8158e-02, 7.9409e-03,
        0.0000e+00, 0.0000e+00, 2.2937e-02, 5.9631e-03, 0.0000e+00, 0.0000e+00,
        1.8234e-02, 4.4760e-03, 0.0000e+00, 0.0000e+00, 1.5299e-02, 3.4627e-03,
        0.0000e+00, 0.0000e+00, 1.5729e-02, 2.6425e-03, 0.0000e+00, 0.0000e+00,
        1.2306e-02, 1.3748e-03, 0.0000e+00, 0.0000e+00, 8.1597e-03, 2.5782e-03,
        0.0000e+00, 0.0000e+00, 2.2356e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.3314e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:34:18,285 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4335798722047957
2024-05-07 21:34:18,287 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.551490.10705
2024-05-07 21:34:18,322 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #54: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6363636363636364, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 5)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.36, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.03, '(rev, 4)': 0.02, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:34:18,322 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:18,323 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.433419125393106
2024-05-07 21:34:18,337 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #54: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4523809523809524, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.18, '(min, 1)': 0.49, '(rev, 1)': 0.03, '(rev, 2)': 0.03, '(rev, 4)': 0.02, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:34:18,337 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:18,338 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.433419125393106
2024-05-07 21:34:18,846 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #54: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.15555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 7)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.39, '(rev, 1)': 0.06, '(rev, 3)': 0.01}}
2024-05-07 21:34:18,846 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:18,846 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.433419125393106
2024-05-07 21:34:19,352 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #54: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 9, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 8, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.47368421052631576, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(min, 0)': 0.21, '(min, 1)': 0.43, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:34:19,352 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:19,353 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.433419125393106
2024-05-07 21:34:19,482 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #54: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.38636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(min, 0)': 0.48, '(min, 1)': 0.13, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.05}}
2024-05-07 21:34:19,482 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:19,482 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.433419125393106
2024-05-07 21:34:19,591 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #54: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 4)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.29, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:34:19,591 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:19,592 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.433419125393106
2024-05-07 21:34:21,044 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #54: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.15384615384615385, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.05, '(ado, 5)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.42, '(rev, 1)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:34:21,044 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:21,045 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.433419125393106
2024-05-07 21:34:21,116 - MainProcess - INFO - text_logger.py - 51 - Train epoch #54
2024-05-07 21:34:21,119 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.3155e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0670e-01, 0.0000e+00,
        6.4310e-02, 5.0441e-03, 3.8153e-01, 0.0000e+00, 1.1692e-02, 3.5197e-03,
        0.0000e+00, 0.0000e+00, 7.0833e-03, 2.1090e-03, 0.0000e+00, 0.0000e+00,
        4.6380e-03, 1.3144e-03, 0.0000e+00, 0.0000e+00, 3.4514e-03, 6.2476e-04,
        0.0000e+00, 0.0000e+00, 3.1840e-03, 4.6936e-04, 0.0000e+00, 0.0000e+00,
        2.2642e-03, 2.5836e-04, 0.0000e+00, 0.0000e+00, 1.5286e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.2337e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.7310e-05, 0.0000e+00, 0.0000e+00])  tensor([1.9280e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1308e-01, 0.0000e+00,
        8.2645e-02, 9.5476e-03, 7.1158e-02, 0.0000e+00, 2.8564e-02, 7.5056e-03,
        0.0000e+00, 0.0000e+00, 2.2691e-02, 5.7452e-03, 0.0000e+00, 0.0000e+00,
        1.8018e-02, 4.8627e-03, 0.0000e+00, 0.0000e+00, 1.5290e-02, 3.0530e-03,
        0.0000e+00, 0.0000e+00, 1.4599e-02, 2.9039e-03, 0.0000e+00, 0.0000e+00,
        1.0953e-02, 2.3999e-03, 0.0000e+00, 0.0000e+00, 7.8551e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.0605e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.2786e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:34:21,138 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43326516835104767
2024-05-07 21:34:21,140 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.313770.15992
2024-05-07 21:34:21,425 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #55: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.26666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.02, '(min, 0)': 0.15, '(min, 1)': 0.41, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:34:21,425 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:21,426 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4335798722047957
2024-05-07 21:34:22,098 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #55: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 4)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.26, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 6)': 0.01}}
2024-05-07 21:34:22,098 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:22,099 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4335798722047957
2024-05-07 21:34:22,515 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #55: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 3, 0, 0),(rev, 4)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '4/4', 'revenue': 0.723404255319149, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(min, 0)': 0.36, '(min, 1)': 0.29, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.07, '(rev, 4)': 0.05}}
2024-05-07 21:34:22,515 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:22,516 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4335798722047957
2024-05-07 21:34:22,641 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #55: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.2, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 6)': 0.01}}
2024-05-07 21:34:22,641 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:22,642 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4335798722047957
2024-05-07 21:34:22,853 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #55: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 5, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 4, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.37209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(min, 0)': 0.38, '(min, 1)': 0.29, '(rev, 1)': 0.02, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:34:22,854 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:22,854 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4335798722047957
2024-05-07 21:34:22,897 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #55: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 1),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 2, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.7111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.06, '(min, 1)': 0.57, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:34:22,897 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:22,897 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4335798722047957
2024-05-07 21:34:24,699 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #55: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24390243902439024, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 7)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.38, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:34:24,699 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:24,700 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4335798722047957
2024-05-07 21:34:24,779 - MainProcess - INFO - text_logger.py - 51 - Train epoch #55
2024-05-07 21:34:24,782 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.1923e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9486e-01, 0.0000e+00,
        7.6800e-02, 4.1114e-03, 3.6307e-01, 0.0000e+00, 1.6038e-02, 2.4869e-03,
        0.0000e+00, 0.0000e+00, 1.1245e-02, 1.3042e-03, 0.0000e+00, 0.0000e+00,
        8.1422e-03, 9.8946e-04, 0.0000e+00, 0.0000e+00, 6.3933e-03, 5.7649e-04,
        0.0000e+00, 0.0000e+00, 5.5593e-03, 2.0258e-04, 0.0000e+00, 0.0000e+00,
        4.7936e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5853e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.5348e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8769e-04, 0.0000e+00, 0.0000e+00])  tensor([2.0153e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4004e-01, 0.0000e+00,
        9.0705e-02, 9.0911e-03, 9.0018e-02, 0.0000e+00, 3.5382e-02, 6.4220e-03,
        0.0000e+00, 0.0000e+00, 2.9216e-02, 4.6350e-03, 0.0000e+00, 0.0000e+00,
        2.4816e-02, 4.1828e-03, 0.0000e+00, 0.0000e+00, 2.0835e-02, 3.3317e-03,
        0.0000e+00, 0.0000e+00, 1.8836e-02, 1.8521e-03, 0.0000e+00, 0.0000e+00,
        1.6716e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.7176e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.5301e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7275e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:34:24,812 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43329024082727063
2024-05-07 21:34:24,815 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.483650.23975
2024-05-07 21:34:25,068 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #56: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.41, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.03}}
2024-05-07 21:34:25,068 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:25,068 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43326516835104767
2024-05-07 21:34:25,545 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #56: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.29545454545454547, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.28, '(rev, 1)': 0.11, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:34:25,546 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:25,547 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43326516835104767
2024-05-07 21:34:25,633 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #56: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4523809523809524, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.2, '(rev, 1)': 0.14, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:34:25,633 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:25,634 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43326516835104767
2024-05-07 21:34:25,913 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #56: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36363636363636365, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.42, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:34:25,913 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:25,914 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43326516835104767
2024-05-07 21:34:26,601 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #56: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 5)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.28, '(rev, 1)': 0.08, '(rev, 4)': 0.01}}
2024-05-07 21:34:26,601 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:26,606 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43326516835104767
2024-05-07 21:34:26,820 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #56: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3902439024390244, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.43, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:34:26,820 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:26,820 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43326516835104767
2024-05-07 21:34:28,021 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #56: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(min, 0)': 0.4, '(min, 1)': 0.22, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 4)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:34:28,021 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:28,022 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43326516835104767
2024-05-07 21:34:28,101 - MainProcess - INFO - text_logger.py - 51 - Train epoch #56
2024-05-07 21:34:28,104 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-8.4694e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  5.0568e-01,
         0.0000e+00,  7.1448e-02,  4.5858e-03,  3.8496e-01,  0.0000e+00,
         1.0374e-02,  3.0817e-03,  0.0000e+00,  0.0000e+00,  6.1425e-03,
         1.5045e-03,  0.0000e+00,  0.0000e+00,  3.9272e-03,  5.1647e-04,
         0.0000e+00,  0.0000e+00,  2.6775e-03,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  2.1462e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         1.6636e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1145e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4439e-04,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.0769e-05,  0.0000e+00,  0.0000e+00])  tensor([1.4802e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0299e-01, 0.0000e+00,
        7.5939e-02, 9.5103e-03, 6.2443e-02, 0.0000e+00, 2.6818e-02, 7.5404e-03,
        0.0000e+00, 0.0000e+00, 2.0626e-02, 5.1342e-03, 0.0000e+00, 0.0000e+00,
        1.6469e-02, 3.4787e-03, 0.0000e+00, 0.0000e+00, 1.2604e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1259e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.1846e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2273e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.6556e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.8802e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:34:28,122 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43304346115460457
2024-05-07 21:34:28,125 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.347730.05227
2024-05-07 21:34:28,152 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #57: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36363636363636365, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.14, '(min, 1)': 0.47, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 7)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:34:28,152 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:28,153 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43329024082727063
2024-05-07 21:34:28,384 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #57: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40476190476190477, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.26, '(min, 1)': 0.34, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:34:28,384 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:28,385 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43329024082727063
2024-05-07 21:34:29,230 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #57: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7027027027027027, 'length': 100, 'actions': {'(ado, 1)': 0.09, '(ado, 2)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.31, '(rev, 1)': 0.12, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-05-07 21:34:29,230 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:29,231 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43329024082727063
2024-05-07 21:34:29,690 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #57: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3617021276595745, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.28, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:34:29,691 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:29,691 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43329024082727063
2024-05-07 21:34:29,833 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #57: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3617021276595745, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.47, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 7)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:34:29,833 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:29,833 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43329024082727063
2024-05-07 21:34:30,363 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #57: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.22, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 5)': 0.02}}
2024-05-07 21:34:30,363 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:30,364 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43329024082727063
2024-05-07 21:34:30,458 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #57: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2653061224489796, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.03, '(min, 0)': 0.46, '(min, 1)': 0.11, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:34:30,458 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:30,459 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43329024082727063
2024-05-07 21:34:30,527 - MainProcess - INFO - text_logger.py - 51 - Train epoch #57
2024-05-07 21:34:30,530 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0844e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4038e-01, 0.0000e+00,
        5.2713e-02, 5.0531e-03, 3.8055e-01, 0.0000e+00, 5.4900e-03, 3.7189e-03,
        0.0000e+00, 0.0000e+00, 2.5312e-03, 2.2204e-03, 0.0000e+00, 0.0000e+00,
        1.0874e-03, 1.8590e-03, 0.0000e+00, 0.0000e+00, 4.3162e-04, 1.5009e-03,
        0.0000e+00, 0.0000e+00, 1.4820e-04, 9.3969e-04, 0.0000e+00, 0.0000e+00,
        7.0523e-05, 7.4857e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5111e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.6849e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.4061e-02, 0.0000e+00,
        8.3042e-02, 9.7892e-03, 3.8066e-02, 0.0000e+00, 1.5235e-02, 7.8811e-03,
        0.0000e+00, 0.0000e+00, 1.0235e-02, 5.8614e-03, 0.0000e+00, 0.0000e+00,
        6.2598e-03, 5.3358e-03, 0.0000e+00, 0.0000e+00, 3.6088e-03, 4.8574e-03,
        0.0000e+00, 0.0000e+00, 1.6558e-03, 3.7375e-03, 0.0000e+00, 0.0000e+00,
        1.1167e-03, 3.4112e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5325e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:34:30,553 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43277129496369493
2024-05-07 21:34:30,556 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.335030.06973
2024-05-07 21:34:30,784 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #58: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1590909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.03, '(ado, 3)': 0.02, '(min, 0)': 0.37, '(min, 1)': 0.23, '(rev, 1)': 0.09, '(rev, 2)': 0.01}}
2024-05-07 21:34:30,785 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:30,785 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43304346115460457
2024-05-07 21:34:32,211 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #58: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6363636363636364, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 3)': 0.01, '(min, 0)': 0.12, '(min, 1)': 0.47, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:34:32,212 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:32,212 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43304346115460457
2024-05-07 21:34:33,121 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #58: {'transition': '(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 2, 6, 1, 1),(min, 0)->(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 1, 2, 7, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.3170731707317073, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.17, '(min, 1)': 0.49, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:34:33,121 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:33,122 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43304346115460457
2024-05-07 21:34:33,184 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #58: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5306122448979592, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.03, '(ado, 4)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.41, '(rev, 1)': 0.06, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:34:33,184 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:33,185 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43304346115460457
2024-05-07 21:34:33,471 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #58: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.42, '(min, 1)': 0.23, '(rev, 1)': 0.03, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-05-07 21:34:33,471 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:33,472 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43304346115460457
2024-05-07 21:34:33,609 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #58: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6428571428571429, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.26, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:34:33,609 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:33,610 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43304346115460457
2024-05-07 21:34:33,621 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #58: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.425, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 4)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.27, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:34:33,622 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:33,622 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43304346115460457
2024-05-07 21:34:33,794 - MainProcess - INFO - text_logger.py - 51 - Train epoch #58
2024-05-07 21:34:33,798 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.5619e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9517e-01, 0.0000e+00,
        7.2724e-02, 5.0066e-03, 3.7806e-01, 0.0000e+00, 1.4500e-02, 3.9404e-03,
        0.0000e+00, 0.0000e+00, 8.8893e-03, 1.8587e-03, 0.0000e+00, 0.0000e+00,
        5.7673e-03, 9.6552e-04, 0.0000e+00, 0.0000e+00, 4.4258e-03, 5.8635e-04,
        0.0000e+00, 0.0000e+00, 3.6978e-03, 2.5196e-04, 0.0000e+00, 0.0000e+00,
        2.4382e-03, 3.4483e-05, 0.0000e+00, 0.0000e+00, 1.4715e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.7171e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.1746e-05, 0.0000e+00, 0.0000e+00])  tensor([1.9504e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2343e-01, 0.0000e+00,
        8.6693e-02, 9.9874e-03, 7.5393e-02, 0.0000e+00, 3.3923e-02, 8.5943e-03,
        0.0000e+00, 0.0000e+00, 2.5429e-02, 5.4450e-03, 0.0000e+00, 0.0000e+00,
        1.9350e-02, 4.0087e-03, 0.0000e+00, 0.0000e+00, 1.7197e-02, 2.9857e-03,
        0.0000e+00, 0.0000e+00, 1.5656e-02, 2.3442e-03, 0.0000e+00, 0.0000e+00,
        1.1920e-02, 7.7106e-04, 0.0000e+00, 0.0000e+00, 7.4987e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.7502e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.0986e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:34:33,820 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4331082815247951
2024-05-07 21:34:33,823 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.639610.00325
2024-05-07 21:34:33,873 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #59: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.4791666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.44, '(rev, 1)': 0.05, '(rev, 2)': 0.08, '(rev, 3)': 0.04}}
2024-05-07 21:34:33,873 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:33,874 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43277129496369493
2024-05-07 21:34:35,550 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #59: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6511627906976745, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(min, 0)': 0.31, '(min, 1)': 0.34, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.03, '(rev, 7)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:34:35,550 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:35,551 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43277129496369493
2024-05-07 21:34:35,812 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #59: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.18, '(min, 1)': 0.41, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:34:35,812 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:35,813 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43277129496369493
2024-05-07 21:34:36,074 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #59: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.27450980392156865, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.31, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-05-07 21:34:36,075 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:36,075 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43277129496369493
2024-05-07 21:34:36,283 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #59: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5348837209302325, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(min, 0)': 0.22, '(min, 1)': 0.4, '(rev, 1)': 0.13, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:34:36,283 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:36,284 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43277129496369493
2024-05-07 21:34:36,711 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #59: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.39215686274509803, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.21, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 5)': 0.01}}
2024-05-07 21:34:36,712 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:36,712 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43277129496369493
2024-05-07 21:34:37,435 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #59: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.08695652173913043, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 2)': 0.02, '(min, 0)': 0.22, '(min, 1)': 0.33, '(rev, 1)': 0.05}}
2024-05-07 21:34:37,435 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:37,436 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43277129496369493
2024-05-07 21:34:37,593 - MainProcess - INFO - text_logger.py - 51 - Train epoch #59
2024-05-07 21:34:37,596 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.6486e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.9808e-01,
         0.0000e+00,  7.5711e-02,  5.4752e-03,  3.5751e-01,  0.0000e+00,
         1.6264e-02,  2.9164e-03,  0.0000e+00,  0.0000e+00,  1.1456e-02,
         9.4398e-04,  0.0000e+00,  0.0000e+00,  8.6552e-03,  2.9231e-04,
         0.0000e+00,  0.0000e+00,  7.3292e-03,  4.8529e-05,  0.0000e+00,
         0.0000e+00,  6.1485e-03,  2.3529e-05,  0.0000e+00,  0.0000e+00,
         5.3694e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.2389e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.7568e-04,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.8966e-05,  0.0000e+00,  0.0000e+00])  tensor([1.6221e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5121e-01, 0.0000e+00,
        9.5577e-02, 1.0378e-02, 9.8408e-02, 0.0000e+00, 4.0650e-02, 7.9513e-03,
        0.0000e+00, 0.0000e+00, 3.1706e-02, 4.4535e-03, 0.0000e+00, 0.0000e+00,
        2.4913e-02, 2.5209e-03, 0.0000e+00, 0.0000e+00, 2.1744e-02, 7.6690e-04,
        0.0000e+00, 0.0000e+00, 1.9012e-02, 5.2613e-04, 0.0000e+00, 0.0000e+00,
        1.7314e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0698e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.9692e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0893e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:34:37,617 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4333520938183025
2024-05-07 21:34:37,619 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.593020.05814
2024-05-07 21:34:37,641 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #60: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(min, 0)': 0.22, '(min, 1)': 0.43, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:34:37,641 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:37,642 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331082815247951
2024-05-07 21:34:37,982 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #60: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32558139534883723, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.25, '(rev, 1)': 0.08, '(rev, 2)': 0.07}}
2024-05-07 21:34:37,982 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:37,982 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331082815247951
2024-05-07 21:34:38,309 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #60: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.34, '(min, 1)': 0.21, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-05-07 21:34:38,310 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:38,310 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331082815247951
2024-05-07 21:34:38,521 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #60: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.41, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03}}
2024-05-07 21:34:38,521 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:38,522 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331082815247951
2024-05-07 21:34:38,904 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #60: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.42857142857142855, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(min, 0)': 0.47, '(min, 1)': 0.13, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-07 21:34:38,905 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:38,905 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331082815247951
2024-05-07 21:34:39,668 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #60: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.39, '(min, 1)': 0.24, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:34:39,668 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:39,669 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331082815247951
2024-05-07 21:34:41,097 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #60: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.18421052631578946, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(min, 0)': 0.37, '(min, 1)': 0.25, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:34:41,097 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:41,097 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331082815247951
2024-05-07 21:34:41,253 - MainProcess - INFO - text_logger.py - 51 - Train epoch #60
2024-05-07 21:34:41,256 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.2521e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0984e-01, 0.0000e+00,
        6.0588e-02, 5.9973e-03, 3.9417e-01, 0.0000e+00, 9.2310e-03, 4.0167e-03,
        0.0000e+00, 0.0000e+00, 4.5869e-03, 1.7681e-03, 0.0000e+00, 0.0000e+00,
        2.5643e-03, 8.5119e-04, 0.0000e+00, 0.0000e+00, 1.8348e-03, 4.9869e-04,
        0.0000e+00, 0.0000e+00, 1.5833e-03, 3.5480e-04, 0.0000e+00, 0.0000e+00,
        1.2319e-03, 1.5487e-04, 0.0000e+00, 0.0000e+00, 5.9611e-04, 2.6316e-05,
        0.0000e+00, 0.0000e+00, 6.3492e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5714e-05, 0.0000e+00, 0.0000e+00])  tensor([1.6832e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.4960e-02, 0.0000e+00,
        7.2058e-02, 1.0735e-02, 5.6777e-02, 0.0000e+00, 2.7297e-02, 9.1146e-03,
        0.0000e+00, 0.0000e+00, 1.9800e-02, 5.7591e-03, 0.0000e+00, 0.0000e+00,
        1.4333e-02, 3.8367e-03, 0.0000e+00, 0.0000e+00, 1.0950e-02, 2.7191e-03,
        0.0000e+00, 0.0000e+00, 9.8622e-03, 2.6243e-03, 0.0000e+00, 0.0000e+00,
        8.4485e-03, 1.5674e-03, 0.0000e+00, 0.0000e+00, 4.4561e-03, 5.8844e-04,
        0.0000e+00, 0.0000e+00, 1.0107e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.9860e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:34:41,278 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43316401242410213
2024-05-07 21:34:41,281 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.377080.05150
2024-05-07 21:34:41,284 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #61: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(min, 0)': 0.32, '(min, 1)': 0.28, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.03}}
2024-05-07 21:34:41,284 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:41,285 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4333520938183025
2024-05-07 21:34:41,289 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #61: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.9230769230769231, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(min, 0)': 0.35, '(min, 1)': 0.3, '(rev, 1)': 0.15, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:34:41,290 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:41,291 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4333520938183025
2024-05-07 21:34:41,303 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #61: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.43, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-07 21:34:41,303 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:41,304 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #61: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.19, '(rev, 1)': 0.05, '(rev, 2)': 0.04}}
2024-05-07 21:34:41,304 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
ation 0.4333520938183025
2024-05-07 21:34:41,304 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4333520938183025
2024-05-07 21:34:41,430 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #61: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 3)': 0.02, '(min, 0)': 0.47, '(min, 1)': 0.15, '(rev, 1)': 0.02, '(rev, 2)': 0.01}}
2024-05-07 21:34:41,430 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:41,431 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4333520938183025
2024-05-07 21:34:42,333 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #61: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3191489361702128, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(min, 0)': 0.2, '(min, 1)': 0.4, '(rev, 1)': 0.05, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:34:42,333 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:42,334 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4333520938183025
2024-05-07 21:34:44,046 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #61: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.24, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(ado, 3)': 0.03, '(ado, 5)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.21, '(rev, 1)': 0.05, '(rev, 2)': 0.01}}
2024-05-07 21:34:44,046 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:44,047 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4333520938183025
2024-05-07 21:34:44,211 - MainProcess - INFO - text_logger.py - 51 - Train epoch #61
2024-05-07 21:34:44,214 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-5.4623e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.5976e-01,
         0.0000e+00,  9.7643e-02,  4.9134e-03,  3.3965e-01,  0.0000e+00,
         2.8841e-02,  3.2865e-03,  0.0000e+00,  0.0000e+00,  1.8407e-02,
         1.0259e-03,  0.0000e+00,  0.0000e+00,  1.2855e-02,  1.9904e-04,
         0.0000e+00,  0.0000e+00,  1.0970e-02,  1.4304e-04,  0.0000e+00,
         0.0000e+00,  9.5333e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         7.5044e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.7146e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.8013e-04,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.8622e-05,  0.0000e+00,  0.0000e+00])  tensor([1.5781e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7973e-01, 0.0000e+00,
        1.1772e-01, 1.0322e-02, 1.1733e-01, 0.0000e+00, 5.5604e-02, 9.2139e-03,
        0.0000e+00, 0.0000e+00, 3.8275e-02, 4.7951e-03, 0.0000e+00, 0.0000e+00,
        2.8720e-02, 2.0159e-03, 0.0000e+00, 0.0000e+00, 2.6522e-02, 2.0098e-03,
        0.0000e+00, 0.0000e+00, 2.3822e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.0100e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2938e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.9799e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0859e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:34:44,248 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4331448551290584
2024-05-07 21:34:44,251 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.461540.46154
2024-05-07 21:34:44,258 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #62: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.4, '(min, 1)': 0.17}}
2024-05-07 21:34:44,258 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:44,260 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43316401242410213
2024-05-07 21:34:44,290 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #62: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3023255813953488, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(min, 0)': 0.14, '(min, 1)': 0.48, '(rev, 1)': 0.11, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:34:44,290 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #62: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.08333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.01, '(min, 0)': 0.58, '(min, 1)': 0.07, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:34:44,290 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:44,291 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:44,291 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43316401242410213
2024-05-07 21:34:44,291 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43316401242410213
2024-05-07 21:34:44,307 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #62: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35714285714285715, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.02, '(ado, 3)': 0.03, '(min, 0)': 0.27, '(min, 1)': 0.35, '(rev, 1)': 0.15, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:34:44,307 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:44,308 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43316401242410213
2024-05-07 21:34:44,699 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #62: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.26, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.35, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:34:44,699 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:44,700 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43316401242410213
2024-05-07 21:34:45,608 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #62: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 8)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.29, '(rev, 1)': 0.11, '(rev, 3)': 0.02}}
2024-05-07 21:34:45,608 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:45,609 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43316401242410213
2024-05-07 21:34:46,486 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #62: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.31, '(min, 1)': 0.29, '(rev, 1)': 0.16, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:34:46,486 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:46,487 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43316401242410213
2024-05-07 21:34:46,655 - MainProcess - INFO - text_logger.py - 51 - Train epoch #62
2024-05-07 21:34:46,658 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.5594e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8152e-01, 0.0000e+00,
        7.7883e-02, 6.6277e-03, 3.7524e-01, 0.0000e+00, 1.5282e-02, 5.5533e-03,
        0.0000e+00, 0.0000e+00, 9.6708e-03, 1.6858e-03, 0.0000e+00, 0.0000e+00,
        6.6060e-03, 3.6947e-04, 0.0000e+00, 0.0000e+00, 6.0992e-03, 1.6840e-04,
        0.0000e+00, 0.0000e+00, 5.3566e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.4257e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0082e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.7358e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2258e-05, 0.0000e+00, 0.0000e+00])  tensor([1.5064e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3636e-01, 0.0000e+00,
        9.5828e-02, 1.1598e-02, 9.2634e-02, 0.0000e+00, 3.8923e-02, 1.1292e-02,
        0.0000e+00, 0.0000e+00, 2.9359e-02, 6.1333e-03, 0.0000e+00, 0.0000e+00,
        2.2207e-02, 2.4944e-03, 0.0000e+00, 0.0000e+00, 2.0934e-02, 2.0867e-03,
        0.0000e+00, 0.0000e+00, 1.8526e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6100e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1119e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.9609e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.2131e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:34:46,676 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43228595424427124
2024-05-07 21:34:46,679 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.041670.04167
2024-05-07 21:34:46,703 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #63: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0),(ado, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/3', 'revenue': 0.26666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.18, '(rev, 1)': 0.11, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-05-07 21:34:46,704 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:46,704 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331448551290584
2024-05-07 21:34:47,325 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #63: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4489795918367347, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 4)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.15, '(rev, 1)': 0.06, '(rev, 2)': 0.04}}
2024-05-07 21:34:47,325 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:47,326 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331448551290584
2024-05-07 21:34:47,557 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #63: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40425531914893614, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.47, '(min, 1)': 0.15, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:34:47,557 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:47,558 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331448551290584
2024-05-07 21:34:47,619 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #63: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 1, 0, 1),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 2, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.46938775510204084, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.21, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:34:47,619 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:47,620 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331448551290584
2024-05-07 21:34:47,928 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #63: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6136363636363636, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.37, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:34:47,929 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:47,930 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331448551290584
2024-05-07 21:34:48,114 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #63: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22916666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.05, '(min, 0)': 0.46, '(min, 1)': 0.11, '(rev, 1)': 0.07, '(rev, 2)': 0.04}}
2024-05-07 21:34:48,114 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:48,115 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331448551290584
2024-05-07 21:34:48,969 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #63: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3125, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(min, 0)': 0.35, '(min, 1)': 0.22, '(rev, 1)': 0.03, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-07 21:34:48,969 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:48,970 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331448551290584
2024-05-07 21:34:49,136 - MainProcess - INFO - text_logger.py - 51 - Train epoch #63
2024-05-07 21:34:49,139 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.4918e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3037e-01, 0.0000e+00,
        5.1452e-02, 6.4486e-03, 3.9650e-01, 0.0000e+00, 5.2904e-03, 4.5945e-03,
        0.0000e+00, 0.0000e+00, 2.0778e-03, 1.5239e-03, 0.0000e+00, 0.0000e+00,
        7.8588e-04, 2.7694e-04, 0.0000e+00, 0.0000e+00, 3.7702e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.4144e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.6667e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.1477, 0.0000, 0.0000, 0.0000, 0.0673, 0.0000, 0.0612, 0.0117, 0.0303,
        0.0000, 0.0176, 0.0108, 0.0000, 0.0000, 0.0106, 0.0059, 0.0000, 0.0000,
        0.0061, 0.0025, 0.0000, 0.0000, 0.0045, 0.0000, 0.0000, 0.0000, 0.0038,
        0.0000, 0.0000, 0.0000, 0.0015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-05-07 21:34:49,158 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43226208737308947
2024-05-07 21:34:49,161 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.459180.01020
2024-05-07 21:34:49,184 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #64: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.15555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.1, '(min, 1)': 0.48, '(rev, 1)': 0.09, '(rev, 2)': 0.02}}
2024-05-07 21:34:49,184 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:49,185 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43228595424427124
2024-05-07 21:34:50,518 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #64: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.02, '(min, 0)': 0.03, '(min, 1)': 0.53, '(rev, 1)': 0.08, '(rev, 2)': 0.03}}
2024-05-07 21:34:50,518 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:50,519 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43228595424427124
2024-05-07 21:34:50,673 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #64: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(min, 0)': 0.18, '(min, 1)': 0.41, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.06}}
2024-05-07 21:34:50,673 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:50,673 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43228595424427124
2024-05-07 21:34:50,731 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #64: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8157894736842105, 'length': 100, 'actions': {'(ado, 1)': 0.09, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.15, '(min, 1)': 0.49, '(rev, 1)': 0.17, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-05-07 21:34:50,731 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:50,732 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43228595424427124
2024-05-07 21:34:50,975 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #64: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3611111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(min, 0)': 0.39, '(min, 1)': 0.26, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:34:50,975 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:50,976 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43228595424427124
2024-05-07 21:34:51,128 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #64: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4878048780487805, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.14, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 7)': 0.01}}
2024-05-07 21:34:51,129 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:51,129 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43228595424427124
2024-05-07 21:34:53,534 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #64: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4146341463414634, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.28, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:34:53,534 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:53,535 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43228595424427124
2024-05-07 21:34:53,700 - MainProcess - INFO - text_logger.py - 51 - Train epoch #64
2024-05-07 21:34:53,703 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.4939e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9517e-01, 0.0000e+00,
        7.1044e-02, 5.3553e-03, 3.8347e-01, 0.0000e+00, 1.2661e-02, 5.4033e-03,
        0.0000e+00, 0.0000e+00, 7.1581e-03, 1.7150e-03, 0.0000e+00, 0.0000e+00,
        4.4814e-03, 6.2033e-04, 0.0000e+00, 0.0000e+00, 3.9262e-03, 2.7066e-04,
        0.0000e+00, 0.0000e+00, 3.5127e-03, 1.1174e-04, 0.0000e+00, 0.0000e+00,
        2.9530e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8993e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.5342e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.1150e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2350e-01, 0.0000e+00,
        9.6430e-02, 1.0935e-02, 8.2323e-02, 0.0000e+00, 3.7387e-02, 1.1890e-02,
        0.0000e+00, 0.0000e+00, 2.4543e-02, 6.0097e-03, 0.0000e+00, 0.0000e+00,
        1.8012e-02, 3.5734e-03, 0.0000e+00, 0.0000e+00, 1.6431e-02, 2.3057e-03,
        0.0000e+00, 0.0000e+00, 1.5180e-02, 1.2769e-03, 0.0000e+00, 0.0000e+00,
        1.3162e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.7691e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.1843e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:34:53,724 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43249654692190653
2024-05-07 21:34:53,726 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.588350.10054
2024-05-07 21:34:53,731 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #65: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.17391304347826086, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.4, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:34:53,731 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:53,732 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43226208737308947
2024-05-07 21:34:53,746 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #65: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 5, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 5, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5517241379310345, 'length': 100, 'actions': {'(ado, 1)': 0.07, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.47, '(rev, 1)': 0.12, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 6)': 0.01}}
2024-05-07 21:34:53,746 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:53,747 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43226208737308947
2024-05-07 21:34:53,862 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #65: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 2, 0, 1),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 3, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.19230769230769232, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.04, '(ado, 8)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.46, '(rev, 1)': 0.06, '(rev, 2)': 0.04}}
2024-05-07 21:34:53,863 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:53,863 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43226208737308947
2024-05-07 21:34:53,966 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #65: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 7)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.28, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:34:53,966 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:53,967 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43226208737308947
2024-05-07 21:34:54,277 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #65: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.18181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.03, '(ado, 4)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.22, '(min, 1)': 0.41, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:34:54,277 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:54,279 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43226208737308947
2024-05-07 21:34:54,965 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #65: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10526315789473684, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.35, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:34:54,965 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:54,966 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43226208737308947
2024-05-07 21:34:56,339 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #65: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5945945945945946, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.02, '(min, 0)': 0.44, '(min, 1)': 0.19, '(rev, 1)': 0.14, '(rev, 2)': 0.05, '(rev, 3)': 0.04, '(rev, 6)': 0.01}}
2024-05-07 21:34:56,339 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:56,340 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43226208737308947
2024-05-07 21:34:56,507 - MainProcess - INFO - text_logger.py - 51 - Train epoch #65
2024-05-07 21:34:56,511 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.5621e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7693e-01, 0.0000e+00,
        8.5262e-02, 5.4491e-03, 3.7158e-01, 0.0000e+00, 1.6683e-02, 6.6789e-03,
        0.0000e+00, 0.0000e+00, 9.8635e-03, 2.6669e-03, 0.0000e+00, 0.0000e+00,
        6.6180e-03, 8.7762e-04, 0.0000e+00, 0.0000e+00, 5.7335e-03, 4.9350e-04,
        0.0000e+00, 0.0000e+00, 4.8993e-03, 3.3674e-04, 0.0000e+00, 0.0000e+00,
        3.3800e-03, 2.1674e-04, 0.0000e+00, 0.0000e+00, 2.0927e-03, 4.2553e-05,
        0.0000e+00, 0.0000e+00, 1.9242e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.9437e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3930e-01, 0.0000e+00,
        1.0697e-01, 1.0892e-02, 9.3586e-02, 0.0000e+00, 4.2538e-02, 1.2931e-02,
        0.0000e+00, 0.0000e+00, 2.8320e-02, 7.3146e-03, 0.0000e+00, 0.0000e+00,
        2.0220e-02, 3.8689e-03, 0.0000e+00, 0.0000e+00, 1.9097e-02, 2.9193e-03,
        0.0000e+00, 0.0000e+00, 1.7409e-02, 2.5205e-03, 0.0000e+00, 0.0000e+00,
        1.3279e-02, 2.3301e-03, 0.0000e+00, 0.0000e+00, 8.9086e-03, 9.5152e-04,
        0.0000e+00, 0.0000e+00, 1.9578e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:34:56,530 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4319040203061252
2024-05-07 21:34:56,532 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.174850.06959
2024-05-07 21:34:56,538 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #66: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.03, '(min, 0)': 0.22, '(min, 1)': 0.38, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.05}}
2024-05-07 21:34:56,538 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:56,539 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43249654692190653
2024-05-07 21:34:56,570 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #66: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 3)': 0.01, '(min, 0)': 0.1, '(min, 1)': 0.46, '(rev, 1)': 0.09, '(rev, 2)': 0.05}}
2024-05-07 21:34:56,571 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:56,571 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43249654692190653
2024-05-07 21:34:56,954 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #66: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5609756097560976, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.03, '(min, 0)': 0.4, '(min, 1)': 0.24, '(rev, 1)': 0.13, '(rev, 2)': 0.02, '(rev, 3)': 0.06}}
2024-05-07 21:34:56,954 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:56,954 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43249654692190653
2024-05-07 21:34:56,989 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #66: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.27, '(rev, 1)': 0.11, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:34:56,990 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:56,990 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43249654692190653
2024-05-07 21:34:57,349 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #66: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.14893617021276595, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.47, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:34:57,350 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:57,350 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43249654692190653
2024-05-07 21:34:57,581 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #66: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3584905660377358, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.56, '(min, 1)': 0.02, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:34:57,581 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:34:57,582 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43249654692190653
2024-05-07 21:35:00,161 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #66: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 6, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.725, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.18, '(min, 1)': 0.47, '(rev, 1)': 0.14, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-07 21:35:00,162 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:00,162 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43249654692190653
2024-05-07 21:35:00,338 - MainProcess - INFO - text_logger.py - 51 - Train epoch #66
2024-05-07 21:35:00,341 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([9.0636e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1289e-01, 0.0000e+00,
        5.7769e-02, 6.1697e-03, 3.9390e-01, 0.0000e+00, 8.0397e-03, 6.1704e-03,
        0.0000e+00, 0.0000e+00, 3.9249e-03, 2.2736e-03, 0.0000e+00, 0.0000e+00,
        2.3498e-03, 7.9026e-04, 0.0000e+00, 0.0000e+00, 1.5911e-03, 3.3914e-04,
        0.0000e+00, 0.0000e+00, 1.4686e-03, 1.8765e-04, 0.0000e+00, 0.0000e+00,
        1.1227e-03, 6.0181e-05, 0.0000e+00, 0.0000e+00, 7.8604e-04, 3.0769e-05,
        0.0000e+00, 0.0000e+00, 1.1217e-04, 3.0769e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.9742e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.3073e-02, 0.0000e+00,
        7.0567e-02, 1.1112e-02, 5.7506e-02, 0.0000e+00, 2.8101e-02, 1.2143e-02,
        0.0000e+00, 0.0000e+00, 1.7499e-02, 6.8300e-03, 0.0000e+00, 0.0000e+00,
        1.3187e-02, 3.8153e-03, 0.0000e+00, 0.0000e+00, 1.0268e-02, 2.3186e-03,
        0.0000e+00, 0.0000e+00, 9.6187e-03, 1.7279e-03, 0.0000e+00, 0.0000e+00,
        8.0800e-03, 9.5083e-04, 0.0000e+00, 0.0000e+00, 5.5454e-03, 6.8802e-04,
        0.0000e+00, 0.0000e+00, 1.4859e-03, 6.8802e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:35:00,361 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43172936756313324
2024-05-07 21:35:00,363 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.383790.02530
2024-05-07 21:35:00,384 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #67: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6097560975609756, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(min, 0)': 0.22, '(min, 1)': 0.42, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.03, '(rev, 5)': 0.01}}
2024-05-07 21:35:00,384 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #67: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.41, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:35:00,384 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:00,385 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:00,385 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319040203061252
2024-05-07 21:35:00,385 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319040203061252
2024-05-07 21:35:00,417 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #67: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4883720930232558, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.03, '(min, 0)': 0.22, '(min, 1)': 0.39, '(rev, 1)': 0.11, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-05-07 21:35:00,418 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:00,418 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319040203061252
2024-05-07 21:35:00,723 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #67: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.30434782608695654, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.15, '(rev, 1)': 0.09, '(rev, 2)': 0.06}}
2024-05-07 21:35:00,723 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:00,724 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319040203061252
2024-05-07 21:35:00,805 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #67: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.8222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.1, '(min, 1)': 0.49, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:35:00,805 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:00,806 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319040203061252
2024-05-07 21:35:00,932 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #67: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.8809523809523809, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(min, 0)': 0.31, '(min, 1)': 0.34, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:35:00,932 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:00,932 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319040203061252
2024-05-07 21:35:03,719 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #67: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.47058823529411764, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.03, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.12, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:35:03,719 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:03,720 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319040203061252
2024-05-07 21:35:03,886 - MainProcess - INFO - text_logger.py - 51 - Train epoch #67
2024-05-07 21:35:03,888 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0560e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3522e-01, 0.0000e+00,
        4.0954e-02, 5.8785e-03, 4.0462e-01, 0.0000e+00, 2.2134e-03, 5.0837e-03,
        0.0000e+00, 0.0000e+00, 8.5810e-04, 1.8770e-03, 0.0000e+00, 0.0000e+00,
        2.7785e-04, 1.3600e-03, 0.0000e+00, 0.0000e+00, 1.8071e-04, 5.5199e-04,
        0.0000e+00, 0.0000e+00, 1.4897e-04, 4.6099e-04, 0.0000e+00, 0.0000e+00,
        6.8966e-05, 2.1333e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2258e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.4701e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3840e-02, 0.0000e+00,
        5.0122e-02, 1.0648e-02, 2.4064e-02, 0.0000e+00, 1.1470e-02, 1.1231e-02,
        0.0000e+00, 0.0000e+00, 6.2351e-03, 6.1312e-03, 0.0000e+00, 0.0000e+00,
        3.6828e-03, 5.1645e-03, 0.0000e+00, 0.0000e+00, 2.4620e-03, 2.9947e-03,
        0.0000e+00, 0.0000e+00, 2.3595e-03, 2.6805e-03, 0.0000e+00, 0.0000e+00,
        1.5421e-03, 1.8322e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2131e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:35:03,911 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4322191116647958
2024-05-07 21:35:03,914 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.715990.10623
2024-05-07 21:35:03,933 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #68: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.09, '(min, 1)': 0.46, '(rev, 1)': 0.1, '(rev, 2)': 0.02}}
2024-05-07 21:35:03,934 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:03,934 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #68: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(min, 0)': 0.51, '(min, 1)': 0.09, '(rev, 1)': 0.06, '(rev, 2)': 0.06, '(rev, 3)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:35:03,934 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #68: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.17, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:35:03,934 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:03,934 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #68: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.07, '(min, 1)': 0.54, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:35:03,934 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43172936756313324
2024-05-07 21:35:03,934 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:03,935 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43172936756313324
, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.574468085106383, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.23, '(min, 1)': 0.33, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 4)': 0.01}}
2024-05-07 21:35:03,935 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43172936756313324
2024-05-07 21:35:03,935 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43172936756313324
2024-05-07 21:35:03,939 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:03,943 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43172936756313324
2024-05-07 21:35:03,958 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #68: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 2, 0, 0),(rev, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.5625, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 3)': 0.02, '(min, 0)': 0.14, '(min, 1)': 0.48, '(rev, 1)': 0.1, '(rev, 2)': 0.08, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:35:03,958 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:03,959 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43172936756313324
2024-05-07 21:35:07,280 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #68: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.7142857142857143, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.4, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:35:07,281 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:07,281 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43172936756313324
2024-05-07 21:35:07,459 - MainProcess - INFO - text_logger.py - 51 - Train epoch #68
2024-05-07 21:35:07,462 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.8827e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2709e-01, 0.0000e+00,
        5.1183e-02, 6.2517e-03, 4.0236e-01, 0.0000e+00, 3.2930e-03, 4.5905e-03,
        0.0000e+00, 0.0000e+00, 1.1483e-03, 1.6880e-03, 0.0000e+00, 0.0000e+00,
        2.3332e-04, 1.0456e-03, 0.0000e+00, 0.0000e+00, 8.8440e-05, 4.2456e-04,
        0.0000e+00, 0.0000e+00, 3.3898e-05, 2.7008e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.9254e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7408e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2908e-02, 0.0000e+00,
        7.0644e-02, 1.0794e-02, 2.5846e-02, 0.0000e+00, 1.0973e-02, 1.0902e-02,
        0.0000e+00, 0.0000e+00, 6.3269e-03, 6.0251e-03, 0.0000e+00, 0.0000e+00,
        2.2974e-03, 4.6528e-03, 0.0000e+00, 0.0000e+00, 1.1488e-03, 2.7476e-03,
        0.0000e+00, 0.0000e+00, 7.5799e-04, 2.1364e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.3712e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:35:07,486 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4321774324883033
2024-05-07 21:35:07,489 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.450280.12419
2024-05-07 21:35:07,508 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #69: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.41, '(min, 1)': 0.22, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-05-07 21:35:07,508 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:07,509 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4322191116647958
2024-05-07 21:35:07,524 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #69: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.14583333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.27, '(min, 1)': 0.31, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-05-07 21:35:07,524 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #69: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(min, 0)': 0.16, '(min, 1)': 0.43, '(rev, 1)': 0.13, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 5)': 0.02}}
2024-05-07 21:35:07,525 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:07,525 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:07,526 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4322191116647958
2024-05-07 21:35:07,526 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4322191116647958
2024-05-07 21:35:07,544 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #69: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(min, 0)': 0.39, '(min, 1)': 0.16, '(rev, 1)': 0.09, '(rev, 2)': 0.02}}
2024-05-07 21:35:07,544 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:07,545 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #69: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.717391304347826, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.17, '(min, 1)': 0.43, '(rev, 1)': 0.08, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-05-07 21:35:07,545 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:07,547 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4322191116647958
2024-05-07 21:35:07,547 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4322191116647958
2024-05-07 21:35:07,560 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #69: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(min, 0)': 0.35, '(min, 1)': 0.24, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:35:07,561 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:07,561 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4322191116647958
2024-05-07 21:35:09,745 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #69: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.07, '(min, 0)': 0.24, '(min, 1)': 0.33, '(rev, 1)': 0.09, '(rev, 2)': 0.01}}
2024-05-07 21:35:09,745 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:09,746 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4322191116647958
2024-05-07 21:35:09,924 - MainProcess - INFO - text_logger.py - 51 - Train epoch #69
2024-05-07 21:35:09,927 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.4583e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3718e-01, 0.0000e+00,
        4.1492e-02, 6.0478e-03, 4.0824e-01, 0.0000e+00, 2.2865e-03, 2.8400e-03,
        0.0000e+00, 0.0000e+00, 4.5949e-04, 8.3019e-04, 0.0000e+00, 0.0000e+00,
        1.3350e-04, 1.7108e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0128e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3114e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.3114e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3114e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5049e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9417e-02, 0.0000e+00,
        4.6503e-02, 1.0797e-02, 1.3820e-02, 0.0000e+00, 9.2200e-03, 8.6238e-03,
        0.0000e+00, 0.0000e+00, 4.2385e-03, 4.3473e-03, 0.0000e+00, 0.0000e+00,
        1.8739e-03, 1.7234e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3166e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1579e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.1579e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1579e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:35:09,947 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4319735821085666
2024-05-07 21:35:09,949 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.369190.14192
2024-05-07 21:35:10,001 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #70: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.26666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(min, 0)': 0.32, '(min, 1)': 0.23, '(rev, 1)': 0.07, '(rev, 2)': 0.05}}
2024-05-07 21:35:10,001 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:10,002 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321774324883033
2024-05-07 21:35:10,043 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #70: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.29, '(min, 1)': 0.32, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:35:10,043 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:10,043 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321774324883033
2024-05-07 21:35:10,063 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #70: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.06, '(min, 0)': 0.33, '(min, 1)': 0.26, '(rev, 1)': 0.11, '(rev, 2)': 0.06}}
2024-05-07 21:35:10,063 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:10,064 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321774324883033
2024-05-07 21:35:10,068 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #70: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.4888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(min, 0)': 0.3, '(min, 1)': 0.29, '(rev, 1)': 0.11, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-05-07 21:35:10,068 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:10,070 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321774324883033
2024-05-07 21:35:10,578 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #70: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5813953488372093, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.27, '(min, 1)': 0.32, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:35:10,578 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:10,579 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321774324883033
2024-05-07 21:35:11,048 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #70: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 3, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:35:11,048 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:11,049 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321774324883033
2024-05-07 21:35:12,575 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #70: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.03, '(min, 0)': 0.24, '(min, 1)': 0.38, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 6)': 0.01}}
2024-05-07 21:35:12,575 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:12,576 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321774324883033
2024-05-07 21:35:12,759 - MainProcess - INFO - text_logger.py - 51 - Train epoch #70
2024-05-07 21:35:12,762 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.2711e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  5.1596e-01,
         0.0000e+00,  6.5149e-02,  5.5637e-03,  3.9351e-01,  0.0000e+00,
         7.0318e-03,  3.0848e-03,  0.0000e+00,  0.0000e+00,  3.0964e-03,
         9.7623e-04,  0.0000e+00,  0.0000e+00,  1.7377e-03,  3.9413e-04,
         0.0000e+00,  0.0000e+00,  1.0720e-03,  1.9025e-04,  0.0000e+00,
         0.0000e+00,  1.0464e-03,  4.0000e-05,  0.0000e+00,  0.0000e+00,
         5.3636e-04,  4.0000e-05,  0.0000e+00,  0.0000e+00,  4.7389e-04,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0021e-04,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00])  tensor([1.4442e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.6017e-02, 0.0000e+00,
        9.6620e-02, 1.0307e-02, 5.6611e-02, 0.0000e+00, 2.3570e-02, 8.7641e-03,
        0.0000e+00, 0.0000e+00, 1.4525e-02, 4.5599e-03, 0.0000e+00, 0.0000e+00,
        1.0047e-02, 2.9542e-03, 0.0000e+00, 0.0000e+00, 7.4624e-03, 1.7851e-03,
        0.0000e+00, 0.0000e+00, 7.2308e-03, 8.9443e-04, 0.0000e+00, 0.0000e+00,
        4.5200e-03, 8.9443e-04, 0.0000e+00, 0.0000e+00, 4.0395e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.3259e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:35:12,786 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4318384185975168
2024-05-07 21:35:12,788 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.403540.08535
2024-05-07 21:35:12,837 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #71: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2553191489361702, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.02, '(min, 0)': 0.09, '(min, 1)': 0.48, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:35:12,837 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:12,838 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319735821085666
2024-05-07 21:35:12,974 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #71: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:35:12,975 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:12,975 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319735821085666
2024-05-07 21:35:13,196 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #71: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5434782608695652, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.04, '(min, 0)': 0.23, '(min, 1)': 0.38, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:35:13,196 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:13,197 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319735821085666
2024-05-07 21:35:13,209 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #71: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43478260869565216, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-05-07 21:35:13,209 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:13,210 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319735821085666
2024-05-07 21:35:13,396 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #71: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3023255813953488, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.34, '(min, 1)': 0.25, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:35:13,396 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:13,397 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319735821085666
2024-05-07 21:35:14,549 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #71: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46296296296296297, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.13, '(rev, 1)': 0.04, '(rev, 2)': 0.07}}
2024-05-07 21:35:14,549 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:14,550 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319735821085666
2024-05-07 21:35:16,339 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #71: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.2, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:35:16,340 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:16,340 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319735821085666
2024-05-07 21:35:16,515 - MainProcess - INFO - text_logger.py - 51 - Train epoch #71
2024-05-07 21:35:16,518 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.3312e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2493e-01, 0.0000e+00,
        4.7920e-02, 5.8275e-03, 4.0741e-01, 0.0000e+00, 3.5264e-03, 4.4477e-03,
        0.0000e+00, 0.0000e+00, 1.3589e-03, 1.9544e-03, 0.0000e+00, 0.0000e+00,
        7.7924e-04, 5.3234e-04, 0.0000e+00, 0.0000e+00, 3.0187e-04, 1.6261e-04,
        0.0000e+00, 0.0000e+00, 2.2550e-04, 5.7700e-05, 0.0000e+00, 0.0000e+00,
        2.2550e-04, 5.7700e-05, 0.0000e+00, 0.0000e+00, 1.4550e-04, 5.7700e-05,
        0.0000e+00, 0.0000e+00, 8.0000e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.6320e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6109e-02, 0.0000e+00,
        5.9366e-02, 1.1019e-02, 2.8960e-02, 0.0000e+00, 1.3942e-02, 1.1044e-02,
        0.0000e+00, 0.0000e+00, 7.7537e-03, 6.5602e-03, 0.0000e+00, 0.0000e+00,
        6.4892e-03, 3.2114e-03, 0.0000e+00, 0.0000e+00, 3.1439e-03, 1.6559e-03,
        0.0000e+00, 0.0000e+00, 2.9087e-03, 9.1257e-04, 0.0000e+00, 0.0000e+00,
        2.9087e-03, 9.1257e-04, 0.0000e+00, 0.0000e+00, 2.2987e-03, 9.1257e-04,
        0.0000e+00, 0.0000e+00, 1.7889e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:35:16,539 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43193966264026573
2024-05-07 21:35:16,542 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.521740.02174
2024-05-07 21:35:16,548 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #72: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.48, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.04, '(rev, 4)': 0.01}}
2024-05-07 21:35:16,548 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:16,549 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318384185975168
2024-05-07 21:35:16,578 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #72: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.7045454545454546, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.28, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.03, '(rev, 5)': 0.01}}
2024-05-07 21:35:16,578 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:16,579 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #72: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.08, '(rev, 1)': 0.11, '(rev, 2)': 0.07}}
2024-05-07 21:35:16,579 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #72: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.27, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-05-07 21:35:16,579 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:16,580 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:16,580 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318384185975168
2024-05-07 21:35:16,580 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318384185975168
2024-05-07 21:35:16,580 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #72: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5918367346938775, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.2, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:35:16,581 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:16,581 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318384185975168
2024-05-07 21:35:16,582 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318384185975168
2024-05-07 21:35:18,053 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #72: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(min, 0)': 0.33, '(min, 1)': 0.26, '(rev, 1)': 0.08, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-05-07 21:35:18,053 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:18,054 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318384185975168
2024-05-07 21:35:19,056 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #72: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.18, '(rev, 1)': 0.06, '(rev, 2)': 0.09, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:35:19,056 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:19,057 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318384185975168
2024-05-07 21:35:19,253 - MainProcess - INFO - text_logger.py - 51 - Train epoch #72
2024-05-07 21:35:19,256 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.6049e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3233e-01, 0.0000e+00,
        4.7311e-02, 7.6463e-03, 4.0276e-01, 0.0000e+00, 2.3659e-03, 4.6951e-03,
        0.0000e+00, 0.0000e+00, 7.4133e-04, 1.5187e-03, 0.0000e+00, 0.0000e+00,
        2.4170e-04, 2.7119e-04, 0.0000e+00, 0.0000e+00, 3.9216e-05, 7.9278e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.3138e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8011e-02, 0.0000e+00,
        5.8219e-02, 1.3136e-02, 1.9054e-02, 0.0000e+00, 9.1446e-03, 1.1828e-02,
        0.0000e+00, 0.0000e+00, 4.8661e-03, 6.1003e-03, 0.0000e+00, 0.0000e+00,
        2.5156e-03, 2.6081e-03, 0.0000e+00, 0.0000e+00, 8.7689e-04, 1.2528e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:35:19,279 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43210197387669064
2024-05-07 21:35:19,281 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.552270.15227
2024-05-07 21:35:19,357 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #73: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.35, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:35:19,358 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:19,358 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43193966264026573
2024-05-07 21:35:19,384 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #73: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.27906976744186046, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 4)': 0.01, '(min, 0)': 0.15, '(min, 1)': 0.45, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:35:19,385 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:19,386 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43193966264026573
2024-05-07 21:35:19,405 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #73: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.5333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.39, '(min, 1)': 0.25, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:35:19,405 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:19,405 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43193966264026573
2024-05-07 21:35:19,605 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #73: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6744186046511628, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.02, '(min, 0)': 0.25, '(min, 1)': 0.42, '(rev, 1)': 0.1, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:35:19,605 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:19,606 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43193966264026573
2024-05-07 21:35:20,339 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #73: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7346938775510204, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(ado, 9)': 0.01, '(min, 0)': 0.12, '(min, 1)': 0.53, '(rev, 1)': 0.05, '(rev, 2)': 0.06, '(rev, 4)': 0.01}}
2024-05-07 21:35:20,339 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:20,340 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43193966264026573
2024-05-07 21:35:20,844 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #73: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 1, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6585365853658537, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.47, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:35:20,844 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:20,845 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43193966264026573
2024-05-07 21:35:21,668 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #73: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.48, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:35:21,668 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:21,669 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43193966264026573
2024-05-07 21:35:21,869 - MainProcess - INFO - text_logger.py - 51 - Train epoch #73
2024-05-07 21:35:21,872 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.7098e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0185e-01, 0.0000e+00,
        6.7076e-02, 8.2400e-03, 4.0219e-01, 0.0000e+00, 4.4519e-03, 7.8142e-03,
        0.0000e+00, 0.0000e+00, 1.6032e-03, 3.4520e-03, 0.0000e+00, 0.0000e+00,
        6.8056e-04, 1.2108e-03, 0.0000e+00, 0.0000e+00, 2.8567e-04, 4.9294e-04,
        0.0000e+00, 0.0000e+00, 2.1292e-04, 1.2603e-04, 0.0000e+00, 0.0000e+00,
        7.6923e-05, 3.7037e-05, 0.0000e+00, 0.0000e+00, 7.6923e-05, 8.7037e-05,
        0.0000e+00, 0.0000e+00, 3.8462e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.0125e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.7161e-02, 0.0000e+00,
        1.0425e-01, 1.3766e-02, 4.5395e-02, 0.0000e+00, 1.3889e-02, 1.6117e-02,
        0.0000e+00, 0.0000e+00, 7.6909e-03, 9.5549e-03, 0.0000e+00, 0.0000e+00,
        5.0662e-03, 4.7954e-03, 0.0000e+00, 0.0000e+00, 3.2133e-03, 2.8638e-03,
        0.0000e+00, 0.0000e+00, 3.0059e-03, 1.4138e-03, 0.0000e+00, 0.0000e+00,
        1.7201e-03, 8.2817e-04, 0.0000e+00, 0.0000e+00, 1.7201e-03, 1.3900e-03,
        0.0000e+00, 0.0000e+00, 8.6003e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:35:21,887 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43197214275934526
2024-05-07 21:35:21,889 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.406200.12713
2024-05-07 21:35:21,919 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #74: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.45652173913043476, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(min, 0)': 0.04, '(min, 1)': 0.55, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-05-07 21:35:21,919 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:21,919 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210197387669064
2024-05-07 21:35:21,974 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #74: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.13, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:35:21,974 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:21,975 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210197387669064
2024-05-07 21:35:22,381 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #74: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8478260869565217, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.06, '(min, 0)': 0.19, '(min, 1)': 0.42, '(rev, 1)': 0.1, '(rev, 2)': 0.08}}
2024-05-07 21:35:22,382 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:22,382 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210197387669064
2024-05-07 21:35:22,967 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #74: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4883720930232558, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.15, '(min, 1)': 0.49, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:35:22,967 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:22,968 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210197387669064
2024-05-07 21:35:24,707 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #74: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.28, '(rev, 1)': 0.04, '(rev, 2)': 0.02}}
2024-05-07 21:35:24,707 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:24,713 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210197387669064
2024-05-07 21:35:24,829 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #74: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17073170731707318, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.49, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-05-07 21:35:24,829 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:24,830 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210197387669064
2024-05-07 21:35:24,966 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #74: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7555555555555555, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.29, '(min, 1)': 0.35, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-05-07 21:35:24,966 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:24,967 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210197387669064
2024-05-07 21:35:25,178 - MainProcess - INFO - text_logger.py - 51 - Train epoch #74
2024-05-07 21:35:25,181 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.1799e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0907e-01, 0.0000e+00,
        7.1241e-02, 8.2611e-03, 3.9056e-01, 0.0000e+00, 5.8473e-03, 5.4103e-03,
        0.0000e+00, 0.0000e+00, 2.5680e-03, 2.1349e-03, 0.0000e+00, 0.0000e+00,
        1.6287e-03, 5.2272e-04, 0.0000e+00, 0.0000e+00, 1.0689e-03, 7.0846e-05,
        0.0000e+00, 0.0000e+00, 8.1960e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.4111e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8455e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.8986e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7026e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0226e-01, 0.0000e+00,
        1.2582e-01, 1.3770e-02, 6.1084e-02, 0.0000e+00, 1.8554e-02, 1.2957e-02,
        0.0000e+00, 0.0000e+00, 1.1174e-02, 7.4809e-03, 0.0000e+00, 0.0000e+00,
        8.3295e-03, 3.0012e-03, 0.0000e+00, 0.0000e+00, 6.5926e-03, 1.1195e-03,
        0.0000e+00, 0.0000e+00, 5.7203e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.9429e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1743e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0898e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:35:25,204 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43155480691520837
2024-05-07 21:35:25,207 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.262450.09172
2024-05-07 21:35:25,494 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #75: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.15, '(min, 1)': 0.45, '(rev, 1)': 0.09, '(rev, 2)': 0.06}}
2024-05-07 21:35:25,494 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:25,495 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43197214275934526
2024-05-07 21:35:26,042 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #75: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7391304347826086, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.53, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-05-07 21:35:26,042 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:26,043 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43197214275934526
2024-05-07 21:35:26,053 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #75: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.36, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:35:26,053 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:26,054 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43197214275934526
2024-05-07 21:35:26,897 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #75: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.68, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(min, 0)': 0.18, '(min, 1)': 0.42, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-07 21:35:26,897 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:26,898 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43197214275934526
2024-05-07 21:35:27,402 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #75: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2978723404255319, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(min, 0)': 0.26, '(min, 1)': 0.32, '(rev, 1)': 0.04, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:35:27,402 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:27,403 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43197214275934526
2024-05-07 21:35:27,645 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #75: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.24561403508771928, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.03, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.08, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:35:27,645 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:27,646 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43197214275934526
2024-05-07 21:35:27,767 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #75: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.32, '(rev, 1)': 0.02, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-07 21:35:27,767 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:27,767 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43197214275934526
2024-05-07 21:35:27,952 - MainProcess - INFO - text_logger.py - 51 - Train epoch #75
2024-05-07 21:35:27,955 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.2526e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1725e-01, 0.0000e+00,
        4.8838e-02, 6.5418e-03, 4.1385e-01, 0.0000e+00, 3.1914e-03, 4.7114e-03,
        0.0000e+00, 0.0000e+00, 1.5224e-03, 2.1542e-03, 0.0000e+00, 0.0000e+00,
        7.5135e-04, 4.9101e-04, 0.0000e+00, 0.0000e+00, 3.9993e-04, 4.0816e-05,
        0.0000e+00, 0.0000e+00, 2.1302e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.2553e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.6439e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5298e-02, 0.0000e+00,
        6.3091e-02, 1.2653e-02, 2.4353e-02, 0.0000e+00, 1.0429e-02, 1.2741e-02,
        0.0000e+00, 0.0000e+00, 6.8038e-03, 7.9512e-03, 0.0000e+00, 0.0000e+00,
        4.3630e-03, 3.1002e-03, 0.0000e+00, 0.0000e+00, 3.1069e-03, 9.1268e-04,
        0.0000e+00, 0.0000e+00, 2.1491e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.5152e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:35:27,973 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4315973171669582
2024-05-07 21:35:27,975 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.492370.24676
2024-05-07 21:35:28,631 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #76: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.14583333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.05, '(min, 0)': 0.13, '(min, 1)': 0.42, '(rev, 1)': 0.06, '(rev, 2)': 0.03}}
2024-05-07 21:35:28,632 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:28,632 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43155480691520837
2024-05-07 21:35:28,655 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #76: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(min, 0)': 0.18, '(min, 1)': 0.41, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 5)': 0.01}}
2024-05-07 21:35:28,656 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:28,656 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43155480691520837
2024-05-07 21:35:29,046 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #76: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6444444444444445, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(min, 0)': 0.26, '(min, 1)': 0.36, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:35:29,046 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:29,047 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43155480691520837
2024-05-07 21:35:29,302 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #76: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(min, 0)': 0.13, '(min, 1)': 0.46, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-07 21:35:29,302 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:29,303 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43155480691520837
2024-05-07 21:35:29,819 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #76: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 3, 0, 0),(rev, 4)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '4/4', 'revenue': 0.4772727272727273, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.28, '(min, 1)': 0.33, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:35:29,819 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:29,820 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43155480691520837
2024-05-07 21:35:29,899 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #76: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(min, 0)': 0.46, '(min, 1)': 0.11, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:35:29,899 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:29,899 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43155480691520837
2024-05-07 21:35:31,527 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #76: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.09, '(min, 1)': 0.49, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:35:31,527 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:31,528 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43155480691520837
2024-05-07 21:35:31,736 - MainProcess - INFO - text_logger.py - 51 - Train epoch #76
2024-05-07 21:35:31,739 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.6600e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2699e-01, 0.0000e+00,
        5.0214e-02, 6.5798e-03, 4.0120e-01, 0.0000e+00, 2.3768e-03, 6.5598e-03,
        0.0000e+00, 0.0000e+00, 5.7227e-04, 2.9863e-03, 0.0000e+00, 0.0000e+00,
        2.8318e-04, 1.1428e-03, 0.0000e+00, 0.0000e+00, 3.7736e-05, 6.2918e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4586e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.1808e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7614e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7365e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.0620e-02, 0.0000e+00,
        6.3120e-02, 1.2451e-02, 2.3568e-02, 0.0000e+00, 8.0800e-03, 1.6006e-02,
        0.0000e+00, 0.0000e+00, 3.5804e-03, 8.8042e-03, 0.0000e+00, 0.0000e+00,
        2.4214e-03, 4.7382e-03, 0.0000e+00, 0.0000e+00, 8.4380e-04, 3.3711e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9770e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.3406e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0711e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:35:31,761 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.431299527393282
2024-05-07 21:35:31,764 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.322220.03333
2024-05-07 21:35:31,893 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #77: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 7, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 7, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(min, 0)': 0.34, '(min, 1)': 0.27, '(rev, 1)': 0.12, '(rev, 2)': 0.02}}
2024-05-07 21:35:31,893 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:31,893 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315973171669582
2024-05-07 21:35:32,070 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #77: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8372093023255814, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.34, '(min, 1)': 0.29, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 3)': 0.03}}
2024-05-07 21:35:32,070 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:32,070 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315973171669582
2024-05-07 21:35:32,106 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #77: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40816326530612246, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.01, '(min, 0)': 0.18, '(min, 1)': 0.43, '(rev, 1)': 0.04, '(rev, 2)': 0.08}}
2024-05-07 21:35:32,107 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:32,108 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315973171669582
2024-05-07 21:35:32,460 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #77: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.16, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-05-07 21:35:32,460 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:32,461 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315973171669582
2024-05-07 21:35:32,649 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #77: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 1, 1, 1),(min, 0)->(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 2, 1, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.17777777777777778, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.03, '(min, 0)': 0.04, '(min, 1)': 0.52, '(rev, 1)': 0.08, '(rev, 2)': 0.02}}
2024-05-07 21:35:32,649 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:32,650 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315973171669582
2024-05-07 21:35:33,124 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #77: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6444444444444445, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 3)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.41, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.02, '(rev, 5)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:35:33,124 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:33,125 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315973171669582
2024-05-07 21:35:34,471 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #77: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3953488372093023, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.04, '(min, 0)': 0.3, '(min, 1)': 0.32, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:35:34,471 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:34,472 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315973171669582
2024-05-07 21:35:34,668 - MainProcess - INFO - text_logger.py - 51 - Train epoch #77
2024-05-07 21:35:34,671 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.9062e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1326e-01, 0.0000e+00,
        4.4297e-02, 8.0292e-03, 4.1886e-01, 0.0000e+00, 1.8459e-03, 7.6687e-03,
        0.0000e+00, 0.0000e+00, 1.7739e-04, 4.1579e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 9.8894e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1623e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7415e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.9827e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0303e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.0482e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6354e-02, 0.0000e+00,
        4.8532e-02, 1.3875e-02, 1.7972e-02, 0.0000e+00, 7.0985e-03, 1.9734e-02,
        0.0000e+00, 0.0000e+00, 2.0983e-03, 1.0608e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.0168e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4834e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5910e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.1591e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7760e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:35:34,691 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4314099008849121
2024-05-07 21:35:34,693 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.526300.11814
2024-05-07 21:35:34,696 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #78: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5625, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.32, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:35:34,696 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:34,697 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431299527393282
2024-05-07 21:35:34,731 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #78: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.16, '(min, 1)': 0.41, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 4)': 0.01}}
2024-05-07 21:35:34,732 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:34,732 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431299527393282
2024-05-07 21:35:35,128 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #78: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.05, '(min, 0)': 0.1, '(min, 1)': 0.46, '(rev, 1)': 0.09, '(rev, 2)': 0.02}}
2024-05-07 21:35:35,128 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:35,130 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431299527393282
2024-05-07 21:35:35,822 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #78: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46938775510204084, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.03, '(min, 0)': 0.18, '(min, 1)': 0.41, '(rev, 1)': 0.02, '(rev, 2)': 0.06}}
2024-05-07 21:35:35,822 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:35,823 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431299527393282
2024-05-07 21:35:35,848 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #78: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7674418604651163, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.41, '(rev, 1)': 0.11, '(rev, 2)': 0.07, '(rev, 4)': 0.01}}
2024-05-07 21:35:35,848 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:35,849 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431299527393282
2024-05-07 21:35:36,607 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #78: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(min, 0)': 0.48, '(min, 1)': 0.18, '(rev, 1)': 0.08, '(rev, 2)': 0.08, '(rev, 3)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:35:36,607 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:36,607 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431299527393282
2024-05-07 21:35:38,129 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #78: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5217391304347826, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.08, '(min, 1)': 0.53, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:35:38,129 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:38,130 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431299527393282
2024-05-07 21:35:38,333 - MainProcess - INFO - text_logger.py - 51 - Train epoch #78
2024-05-07 21:35:38,336 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.1697e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2973e-01, 0.0000e+00,
        5.0194e-02, 6.9670e-03, 4.0072e-01, 0.0000e+00, 2.2460e-03, 5.4403e-03,
        0.0000e+00, 0.0000e+00, 7.2327e-04, 2.2451e-03, 0.0000e+00, 0.0000e+00,
        3.6806e-04, 6.9591e-04, 0.0000e+00, 0.0000e+00, 1.6476e-04, 2.4191e-04,
        0.0000e+00, 0.0000e+00, 8.7996e-05, 9.5868e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.0000e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.6056e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5706e-02, 0.0000e+00,
        7.4104e-02, 1.2512e-02, 3.0796e-02, 0.0000e+00, 9.0852e-03, 1.5274e-02,
        0.0000e+00, 0.0000e+00, 4.6151e-03, 8.2853e-03, 0.0000e+00, 0.0000e+00,
        3.3525e-03, 3.7614e-03, 0.0000e+00, 0.0000e+00, 1.8730e-03, 2.1042e-03,
        0.0000e+00, 0.0000e+00, 1.3982e-03, 1.2395e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.7889e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:35:38,359 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43210177519392323
2024-05-07 21:35:38,362 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.817050.04961
2024-05-07 21:35:38,365 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #79: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7291666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.09, '(min, 1)': 0.5, '(rev, 1)': 0.08, '(rev, 2)': 0.09, '(rev, 3)': 0.01}}
2024-05-07 21:35:38,365 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:38,366 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4314099008849121
2024-05-07 21:35:38,380 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #79: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(min, 0)': 0.18, '(min, 1)': 0.41, '(rev, 1)': 0.08, '(rev, 2)': 0.05}}
2024-05-07 21:35:38,380 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:38,381 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4314099008849121
2024-05-07 21:35:38,411 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #79: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(min, 0)': 0.04, '(min, 1)': 0.51, '(rev, 1)': 0.1, '(rev, 2)': 0.04}}
2024-05-07 21:35:38,411 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:38,412 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4314099008849121
2024-05-07 21:35:39,024 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #79: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.5333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.22, '(rev, 1)': 0.11, '(rev, 2)': 0.09}}
2024-05-07 21:35:39,025 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:39,025 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4314099008849121
2024-05-07 21:35:39,600 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #79: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 2, 1, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.425, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(min, 0)': 0.25, '(min, 1)': 0.36, '(rev, 1)': 0.13, '(rev, 2)': 0.05}}
2024-05-07 21:35:39,600 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:39,601 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4314099008849121
2024-05-07 21:35:41,490 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #79: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5957446808510638, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.04, '(ado, 4)': 0.01, '(min, 0)': 0.18, '(min, 1)': 0.43, '(rev, 1)': 0.1, '(rev, 2)': 0.07}}
2024-05-07 21:35:41,491 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:41,491 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4314099008849121
2024-05-07 21:35:41,509 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #79: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.48936170212765956, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.46, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:35:41,509 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:41,510 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4314099008849121
2024-05-07 21:35:41,691 - MainProcess - INFO - text_logger.py - 51 - Train epoch #79
2024-05-07 21:35:41,694 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.4353e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1683e-01, 0.0000e+00,
        4.2944e-02, 7.1793e-03, 4.2783e-01, 0.0000e+00, 1.1143e-03, 3.1274e-03,
        0.0000e+00, 0.0000e+00, 1.5710e-04, 6.9480e-04, 0.0000e+00, 0.0000e+00,
        4.0816e-05, 8.3370e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.2742e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8011e-02, 0.0000e+00,
        4.6847e-02, 1.1908e-02, 1.1392e-02, 0.0000e+00, 5.9475e-03, 9.2649e-03,
        0.0000e+00, 0.0000e+00, 2.1209e-03, 4.7944e-03, 0.0000e+00, 0.0000e+00,
        9.1268e-04, 1.3172e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:35:41,715 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4321822360112636
2024-05-07 21:35:41,717 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.511350.02199
2024-05-07 21:35:41,722 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #80: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 9, 5, 0, 0),(rev, 6)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '6/6', 'revenue': 0.5813953488372093, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.03, '(min, 0)': 0.15, '(min, 1)': 0.51, '(rev, 1)': 0.1, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:35:41,722 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:41,723 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210177519392323
2024-05-07 21:35:41,789 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #80: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8043478260869565, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(min, 0)': 0.38, '(min, 1)': 0.22, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:35:41,789 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:41,790 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210177519392323
2024-05-07 21:35:42,112 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #80: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.42, '(min, 1)': 0.16, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:35:42,112 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:42,113 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210177519392323
2024-05-07 21:35:42,222 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #80: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4318181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.21, '(min, 1)': 0.41, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.02}}
2024-05-07 21:35:42,223 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:42,223 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210177519392323
2024-05-07 21:35:42,882 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #80: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.43, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:35:42,883 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:42,883 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210177519392323
2024-05-07 21:35:43,937 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #80: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3404255319148936, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.06, '(min, 0)': 0.08, '(min, 1)': 0.51, '(rev, 1)': 0.09, '(rev, 2)': 0.07}}
2024-05-07 21:35:43,937 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:43,938 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210177519392323
2024-05-07 21:35:44,641 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #80: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(min, 0)': 0.45, '(min, 1)': 0.13, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:35:44,642 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:44,642 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210177519392323
2024-05-07 21:35:44,714 - MainProcess - INFO - text_logger.py - 51 - Train epoch #80
2024-05-07 21:35:44,717 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.2698e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2971e-01, 0.0000e+00,
        5.0744e-02, 6.8435e-03, 3.9641e-01, 0.0000e+00, 2.4503e-03, 6.1745e-03,
        0.0000e+00, 0.0000e+00, 4.7945e-04, 4.0000e-03, 0.0000e+00, 0.0000e+00,
        1.6053e-04, 1.1412e-03, 0.0000e+00, 0.0000e+00, 7.5565e-05, 7.6743e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.1656e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.6444e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6993e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.2982e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5352e-02, 0.0000e+00,
        7.0629e-02, 1.2045e-02, 2.6752e-02, 0.0000e+00, 7.6390e-03, 1.5282e-02,
        0.0000e+00, 0.0000e+00, 2.8879e-03, 1.1403e-02, 0.0000e+00, 0.0000e+00,
        1.6301e-03, 4.4150e-03, 0.0000e+00, 0.0000e+00, 1.1999e-03, 3.5105e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7779e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.1020e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0736e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:35:44,737 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4321719462375876
2024-05-07 21:35:44,740 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.465970.11181
2024-05-07 21:35:44,760 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #81: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.48936170212765956, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(min, 0)': 0.12, '(min, 1)': 0.51, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:35:44,760 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:44,761 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321822360112636
2024-05-07 21:35:44,974 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #81: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(min, 0)': 0.13, '(min, 1)': 0.46, '(rev, 1)': 0.09, '(rev, 2)': 0.08, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:35:44,974 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:44,975 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321822360112636
2024-05-07 21:35:45,142 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #81: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(min, 0)': 0.52, '(min, 1)': 0.07, '(rev, 1)': 0.09, '(rev, 2)': 0.06}}
2024-05-07 21:35:45,142 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:45,143 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321822360112636
2024-05-07 21:35:45,414 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #81: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.3191489361702128, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.03, '(min, 0)': 0.13, '(min, 1)': 0.46, '(rev, 1)': 0.05, '(rev, 2)': 0.07}}
2024-05-07 21:35:45,414 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:45,415 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321822360112636
2024-05-07 21:35:46,126 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #81: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.52, '(min, 1)': 0.07, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-07 21:35:46,126 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:46,127 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321822360112636
2024-05-07 21:35:47,191 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #81: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.21, '(rev, 1)': 0.06, '(rev, 2)': 0.05}}
2024-05-07 21:35:47,191 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:47,192 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321822360112636
2024-05-07 21:35:47,643 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #81: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(min, 0)': 0.36, '(min, 1)': 0.25, '(rev, 1)': 0.08, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-05-07 21:35:47,643 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:47,645 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321822360112636
2024-05-07 21:35:47,855 - MainProcess - INFO - text_logger.py - 51 - Train epoch #81
2024-05-07 21:35:47,858 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.8111e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0588e-01, 0.0000e+00,
        4.6375e-02, 7.6501e-03, 4.2980e-01, 0.0000e+00, 2.4208e-03, 4.5294e-03,
        0.0000e+00, 0.0000e+00, 9.1783e-04, 1.3893e-03, 0.0000e+00, 0.0000e+00,
        5.1472e-04, 2.2558e-04, 0.0000e+00, 0.0000e+00, 1.8986e-04, 7.0667e-05,
        0.0000e+00, 0.0000e+00, 4.0816e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.6993e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6959e-02, 0.0000e+00,
        5.7200e-02, 1.2982e-02, 2.0109e-02, 0.0000e+00, 8.6151e-03, 1.2487e-02,
        0.0000e+00, 0.0000e+00, 4.9533e-03, 6.6518e-03, 0.0000e+00, 0.0000e+00,
        3.6517e-03, 2.0597e-03, 0.0000e+00, 0.0000e+00, 2.2805e-03, 1.1296e-03,
        0.0000e+00, 0.0000e+00, 9.1268e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:35:47,877 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43209927723685826
2024-05-07 21:35:47,880 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.434780.04348
2024-05-07 21:35:47,901 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #82: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.03, '(min, 0)': 0.04, '(min, 1)': 0.53, '(rev, 1)': 0.09, '(rev, 2)': 0.06}}
2024-05-07 21:35:47,901 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:47,902 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321719462375876
2024-05-07 21:35:47,933 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #82: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.02, '(min, 0)': 0.08, '(min, 1)': 0.5, '(rev, 1)': 0.05, '(rev, 2)': 0.06}}
'(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:35:47,933 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:47,933 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:47,934 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321719462375876
2024-05-07 21:35:47,934 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321719462375876
2024-05-07 21:35:48,234 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #82: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(min, 0)': 0.24, '(min, 1)': 0.38, '(rev, 1)': 0.12, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-05-07 21:35:48,235 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:48,235 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321719462375876
2024-05-07 21:35:48,849 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #82: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.21, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:35:48,850 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:48,850 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321719462375876
2024-05-07 21:35:49,992 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #82: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5531914893617021, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.05, '(min, 1)': 0.56, '(rev, 1)': 0.07, '(rev, 2)': 0.11}}
2024-05-07 21:35:49,993 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:49,993 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321719462375876
2024-05-07 21:35:50,485 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #82: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7045454545454546, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.45, '(min, 1)': 0.14, '(rev, 1)': 0.12, '(rev, 2)': 0.03, '(rev, 3)': 0.03}}
2024-05-07 21:35:50,485 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:50,486 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321719462375876
2024-05-07 21:35:50,561 - MainProcess - INFO - text_logger.py - 51 - Train epoch #82
2024-05-07 21:35:50,564 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.6678e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3643e-01, 0.0000e+00,
        4.9837e-02, 8.0855e-03, 3.9309e-01, 0.0000e+00, 1.7817e-03, 5.7171e-03,
        0.0000e+00, 0.0000e+00, 5.6448e-04, 3.2547e-03, 0.0000e+00, 0.0000e+00,
        2.1278e-04, 5.5775e-04, 0.0000e+00, 0.0000e+00, 6.9151e-05, 1.7603e-04,
        0.0000e+00, 0.0000e+00, 3.6364e-05, 1.2633e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.3333e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3333e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5134e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6575e-02, 0.0000e+00,
        6.1671e-02, 1.3420e-02, 2.8095e-02, 0.0000e+00, 7.3558e-03, 1.3511e-02,
        0.0000e+00, 0.0000e+00, 4.1012e-03, 1.0553e-02, 0.0000e+00, 0.0000e+00,
        2.2306e-03, 3.3600e-03, 0.0000e+00, 0.0000e+00, 1.0937e-03, 1.6141e-03,
        0.0000e+00, 0.0000e+00, 8.1312e-04, 1.4149e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.4536e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.4536e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:35:50,594 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4323398493428483
2024-05-07 21:35:50,597 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.591400.11314
2024-05-07 21:35:50,608 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #83: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22916666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.05, '(min, 0)': 0.04, '(min, 1)': 0.53, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:35:50,608 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:50,608 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #83: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.09, '(min, 1)': 0.46, '(rev, 1)': 0.1, '(rev, 2)': 0.05}}
2024-05-07 21:35:50,609 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:50,609 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43209927723685826
2024-05-07 21:35:50,609 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43209927723685826
2024-05-07 21:35:50,639 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #83: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.22727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.06, '(min, 0)': 0.2, '(min, 1)': 0.38, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:35:50,639 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:50,640 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43209927723685826
2024-05-07 21:35:51,264 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #83: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.625, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.23, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:35:51,264 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:51,265 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43209927723685826
2024-05-07 21:35:51,960 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #83: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.16666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.39, '(rev, 1)': 0.05, '(rev, 2)': 0.03}}
2024-05-07 21:35:51,960 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:51,961 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43209927723685826
2024-05-07 21:35:53,067 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #83: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(min, 0)': 0.14, '(min, 1)': 0.47, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:35:53,067 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:53,068 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43209927723685826
2024-05-07 21:35:53,561 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #83: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 1.2708333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(min, 0)': 0.13, '(min, 1)': 0.46, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 4)': 0.01}}
2024-05-07 21:35:53,561 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:53,562 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43209927723685826
2024-05-07 21:35:53,759 - MainProcess - INFO - text_logger.py - 51 - Train epoch #83
2024-05-07 21:35:53,762 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.4308e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9760e-01, 0.0000e+00,
        4.7119e-02, 5.6586e-03, 4.4373e-01, 0.0000e+00, 1.5622e-03, 2.7793e-03,
        0.0000e+00, 0.0000e+00, 1.5951e-04, 9.7299e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.1381e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.0418, 0.0000, 0.0000, 0.0000, 0.0536, 0.0000, 0.0590, 0.0110, 0.0198,
        0.0000, 0.0067, 0.0085, 0.0000, 0.0000, 0.0022, 0.0053, 0.0000, 0.0000,
        0.0000, 0.0029, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-05-07 21:35:53,787 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43195558613922047
2024-05-07 21:35:53,790 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.278990.11232
2024-05-07 21:35:53,823 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #84: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(min, 1)': 0.57, '(rev, 1)': 0.09, '(rev, 2)': 0.05}}
2024-05-07 21:35:53,823 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:53,824 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323398493428483
2024-05-07 21:35:53,839 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #84: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6170212765957447, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.44, '(rev, 1)': 0.08, '(rev, 2)': 0.08}}
2024-05-07 21:35:53,839 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
sition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.03, '(min, 0)': 0.18, '(min, 1)': 0.4, '(rev, 1)': 0.07, '(rev, 2)': 0.07}}
2024-05-07 21:35:53,840 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:53,840 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323398493428483
2024-05-07 21:35:53,840 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323398493428483
2024-05-07 21:35:54,179 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #84: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5116279069767442, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.45, '(min, 1)': 0.16, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:35:54,179 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:54,180 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323398493428483
2024-05-07 21:35:54,693 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #84: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6818181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(min, 0)': 0.23, '(min, 1)': 0.35, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:35:54,694 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:54,694 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323398493428483
2024-05-07 21:35:55,501 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #84: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.16, '(min, 1)': 0.46, '(rev, 1)': 0.09, '(rev, 2)': 0.09, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:35:55,501 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:55,502 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323398493428483
2024-05-07 21:35:55,910 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #84: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.06, '(min, 0)': 0.15, '(min, 1)': 0.41, '(rev, 1)': 0.14, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:35:55,911 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:55,911 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323398493428483
2024-05-07 21:35:56,115 - MainProcess - INFO - text_logger.py - 51 - Train epoch #84
2024-05-07 21:35:56,118 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.8999e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4546e-01, 0.0000e+00,
        5.0490e-02, 7.2953e-03, 3.8893e-01, 0.0000e+00, 1.2570e-03, 3.9870e-03,
        0.0000e+00, 0.0000e+00, 1.2489e-04, 1.8685e-03, 0.0000e+00, 0.0000e+00,
        4.0816e-05, 2.8420e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4607e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2787e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.0000e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.2632e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6476e-02, 0.0000e+00,
        7.2800e-02, 1.2740e-02, 3.1949e-02, 0.0000e+00, 5.9603e-03, 1.1274e-02,
        0.0000e+00, 0.0000e+00, 1.6356e-03, 8.2457e-03, 0.0000e+00, 0.0000e+00,
        9.1268e-04, 2.2844e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6492e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3314e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.7889e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:35:56,137 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43231739232514044
2024-05-07 21:35:56,139 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.652020.02980
2024-05-07 21:35:56,175 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #85: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10638297872340426, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.06, '(min, 0)': 0.03, '(min, 1)': 0.53, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-05-07 21:35:56,175 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:56,176 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195558613922047
2024-05-07 21:35:56,429 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #85: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.20930232558139536, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(min, 0)': 0.44, '(min, 1)': 0.12, '(rev, 1)': 0.09, '(rev, 2)': 0.03}}
2024-05-07 21:35:56,429 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:56,431 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195558613922047
2024-05-07 21:35:56,533 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #85: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.574468085106383, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(min, 0)': 0.38, '(min, 1)': 0.2, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:35:56,533 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:56,534 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195558613922047
2024-05-07 21:35:57,002 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #85: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1702127659574468, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.04, '(min, 0)': 0.48, '(min, 1)': 0.07, '(rev, 1)': 0.06, '(rev, 2)': 0.04}}
2024-05-07 21:35:57,002 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:57,003 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195558613922047
2024-05-07 21:35:57,067 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #85: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3617021276595745, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.03, '(min, 1)': 0.58, '(rev, 1)': 0.04, '(rev, 2)': 0.08}}
2024-05-07 21:35:57,067 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:57,068 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195558613922047
2024-05-07 21:35:58,224 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #85: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.03, '(min, 0)': 0.18, '(min, 1)': 0.39, '(rev, 1)': 0.12, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-05-07 21:35:58,224 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:58,225 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195558613922047
2024-05-07 21:35:58,311 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #85: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4883720930232558, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.15, '(min, 1)': 0.46, '(rev, 1)': 0.12, '(rev, 2)': 0.08}}
2024-05-07 21:35:58,311 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:58,312 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195558613922047
2024-05-07 21:35:58,513 - MainProcess - INFO - text_logger.py - 51 - Train epoch #85
2024-05-07 21:35:58,516 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.2710e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9280e-01, 0.0000e+00,
        4.6705e-02, 7.3843e-03, 4.4701e-01, 0.0000e+00, 1.4496e-03, 3.1359e-03,
        0.0000e+00, 0.0000e+00, 2.5874e-04, 8.7702e-04, 0.0000e+00, 0.0000e+00,
        1.1489e-04, 2.3190e-04, 0.0000e+00, 0.0000e+00, 3.2787e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.0472e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1576e-02, 0.0000e+00,
        5.7067e-02, 1.3315e-02, 1.9874e-02, 0.0000e+00, 6.3801e-03, 9.8495e-03,
        0.0000e+00, 0.0000e+00, 2.4346e-03, 5.4536e-03, 0.0000e+00, 0.0000e+00,
        1.5024e-03, 2.4424e-03, 0.0000e+00, 0.0000e+00, 7.3314e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:35:58,548 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43195446178206814
2024-05-07 21:35:58,551 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.289650.11944
2024-05-07 21:35:59,025 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #86: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3829787234042553, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.05, '(min, 0)': 0.24, '(min, 1)': 0.36, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 8)': 0.01}}
2024-05-07 21:35:59,025 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:59,026 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43231739232514044
2024-05-07 21:35:59,457 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #86: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5454545454545454, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(min, 0)': 0.17, '(min, 1)': 0.44, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 4)': 0.03}}
2024-05-07 21:35:59,457 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:59,457 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43231739232514044
2024-05-07 21:35:59,477 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #86: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.21739130434782608, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.06, '(ado, 3)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.5, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:35:59,477 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:59,478 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43231739232514044
2024-05-07 21:35:59,701 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #86: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6818181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.18, '(rev, 1)': 0.11, '(rev, 2)': 0.05, '(rev, 3)': 0.03}}
2024-05-07 21:35:59,701 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:35:59,702 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43231739232514044
2024-05-07 21:36:00,046 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #86: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(min, 0)': 0.43, '(min, 1)': 0.14, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:36:00,047 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:00,047 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43231739232514044
2024-05-07 21:36:01,681 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #86: {'transition': '(exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 1, 5, 7, 1, 1),(min, 1)->(exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 1, 5, 8, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.38, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:36:01,681 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:01,682 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43231739232514044
2024-05-07 21:36:02,152 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #86: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.26, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:36:02,152 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:02,153 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43231739232514044
2024-05-07 21:36:02,349 - MainProcess - INFO - text_logger.py - 51 - Train epoch #86
2024-05-07 21:36:02,352 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.3707e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2186e-01, 0.0000e+00,
        6.5090e-02, 7.0690e-03, 3.8736e-01, 0.0000e+00, 3.2494e-03, 7.5197e-03,
        0.0000e+00, 0.0000e+00, 1.1676e-03, 4.8299e-03, 0.0000e+00, 0.0000e+00,
        5.4724e-04, 8.4363e-04, 0.0000e+00, 0.0000e+00, 2.2377e-04, 2.0774e-04,
        0.0000e+00, 0.0000e+00, 3.9216e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.8513e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8407e-02, 0.0000e+00,
        8.0764e-02, 1.3712e-02, 4.0253e-02, 0.0000e+00, 1.0590e-02, 2.0367e-02,
        0.0000e+00, 0.0000e+00, 5.6348e-03, 1.4540e-02, 0.0000e+00, 0.0000e+00,
        3.9306e-03, 4.1079e-03, 0.0000e+00, 0.0000e+00, 2.2525e-03, 1.7610e-03,
        0.0000e+00, 0.0000e+00, 8.7689e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:36:02,370 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43189101544273545
2024-05-07 21:36:02,373 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.439390.10606
2024-05-07 21:36:02,381 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #87: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.44680851063829785, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(min, 0)': 0.24, '(min, 1)': 0.36, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-05-07 21:36:02,381 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:02,382 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195446178206814
2024-05-07 21:36:02,413 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #87: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.03, '(min, 0)': 0.45, '(min, 1)': 0.11, '(rev, 1)': 0.1, '(rev, 2)': 0.05}}
2024-05-07 21:36:02,414 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:02,414 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195446178206814
2024-05-07 21:36:02,428 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #87: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4878048780487805, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.04, '(min, 0)': 0.18, '(min, 1)': 0.42, '(rev, 1)': 0.15, '(rev, 2)': 0.05, '(rev, 3)': 0.03}}
2024-05-07 21:36:02,429 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:02,429 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195446178206814
2024-05-07 21:36:02,448 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #87: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5681818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(min, 0)': 0.05, '(min, 1)': 0.54, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:36:02,449 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:02,449 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195446178206814
2024-05-07 21:36:02,544 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #87: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.575, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.09, '(min, 1)': 0.52, '(rev, 1)': 0.13, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-05-07 21:36:02,544 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:02,545 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195446178206814
2024-05-07 21:36:04,317 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #87: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.08, '(min, 1)': 0.49, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-07 21:36:04,317 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:04,318 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195446178206814
2024-05-07 21:36:05,129 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #87: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(min, 0)': 0.06, '(min, 1)': 0.51, '(rev, 1)': 0.1, '(rev, 2)': 0.07}}
2024-05-07 21:36:05,130 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:05,130 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195446178206814
2024-05-07 21:36:05,332 - MainProcess - INFO - text_logger.py - 51 - Train epoch #87
2024-05-07 21:36:05,335 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.2795e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8964e-01, 0.0000e+00,
        5.6258e-02, 1.0032e-02, 4.2756e-01, 0.0000e+00, 1.6630e-03, 8.6526e-03,
        0.0000e+00, 0.0000e+00, 3.2772e-04, 4.7710e-03, 0.0000e+00, 0.0000e+00,
        9.4246e-05, 7.9547e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0172e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5016, 0.0000, 0.0000, 0.0000, 0.0604, 0.0000, 0.0679, 0.0164, 0.0330,
        0.0000, 0.0068, 0.0203, 0.0000, 0.0000, 0.0032, 0.0138, 0.0000, 0.0000,
        0.0016, 0.0040, 0.0000, 0.0000, 0.0000, 0.0017, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-05-07 21:36:05,351 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4315710034468371
2024-05-07 21:36:05,354 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.311110.02222
2024-05-07 21:36:05,364 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #88: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.11, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 4)': 0.01}}
2024-05-07 21:36:05,364 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:05,365 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43189101544273545
2024-05-07 21:36:05,396 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #88: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4166666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(min, 0)': 0.09, '(min, 1)': 0.5, '(rev, 1)': 0.06, '(rev, 2)': 0.09}}
2024-05-07 21:36:05,396 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #88: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.06, '(min, 1)': 0.53, '(rev, 1)': 0.1, '(rev, 2)': 0.09}}
2024-05-07 21:36:05,396 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:05,396 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:05,397 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43189101544273545
2024-05-07 21:36:05,397 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43189101544273545
2024-05-07 21:36:05,551 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #88: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.03, '(ado, 5)': 0.01, '(min, 0)': 0.06, '(min, 1)': 0.55, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-05-07 21:36:05,552 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:05,552 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43189101544273545
2024-05-07 21:36:05,878 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #88: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 2, 1, 0, 1, 0)', 'reward_ratio': '0/0', 'revenue': 0.6875, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.26, '(min, 1)': 0.34, '(rev, 1)': 0.05, '(rev, 2)': 0.09, '(rev, 3)': 0.01}}
2024-05-07 21:36:05,878 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:05,879 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43189101544273545
2024-05-07 21:36:06,644 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #88: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(min, 1)': 0.57, '(rev, 1)': 0.11, '(rev, 2)': 0.07}}
2024-05-07 21:36:06,644 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:06,645 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43189101544273545
2024-05-07 21:36:07,607 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #88: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3695652173913043, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.04, '(min, 0)': 0.23, '(min, 1)': 0.38, '(rev, 1)': 0.04, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:36:07,607 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:07,608 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43189101544273545
2024-05-07 21:36:07,821 - MainProcess - INFO - text_logger.py - 51 - Train epoch #88
2024-05-07 21:36:07,825 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.6435e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3186e-01, 0.0000e+00,
        4.6263e-02, 8.3972e-03, 4.0595e-01, 0.0000e+00, 1.0414e-03, 4.6626e-03,
        0.0000e+00, 0.0000e+00, 1.3783e-04, 1.3975e-03, 0.0000e+00, 0.0000e+00,
        6.5045e-05, 2.0074e-04, 0.0000e+00, 0.0000e+00, 3.2258e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.1857e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9963e-02, 0.0000e+00,
        6.2525e-02, 1.4038e-02, 2.9993e-02, 0.0000e+00, 5.2306e-03, 1.1483e-02,
        0.0000e+00, 0.0000e+00, 1.5431e-03, 6.8082e-03, 0.0000e+00, 0.0000e+00,
        1.0275e-03, 2.2054e-03, 0.0000e+00, 0.0000e+00, 7.2131e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:36:07,845 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43149543589538314
2024-05-07 21:36:07,847 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.433330.05556
2024-05-07 21:36:07,858 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #89: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3488372093023256, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.09, '(min, 1)': 0.49, '(rev, 1)': 0.1, '(rev, 2)': 0.05}}
2024-05-07 21:36:07,858 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:07,859 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315710034468371
2024-05-07 21:36:07,916 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #89: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.3673469387755102, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(min, 0)': 0.22, '(min, 1)': 0.35, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-07 21:36:07,916 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:07,917 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315710034468371
2024-05-07 21:36:07,975 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #89: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(min, 0)': 0.26, '(min, 1)': 0.34, '(rev, 1)': 0.07, '(rev, 2)': 0.09, '(rev, 3)': 0.01}}
2024-05-07 21:36:07,975 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:07,976 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315710034468371
2024-05-07 21:36:08,235 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #89: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46511627906976744, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.12, '(min, 1)': 0.48, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:36:08,236 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:08,237 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315710034468371
2024-05-07 21:36:09,207 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #89: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.44680851063829785, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(min, 0)': 0.06, '(min, 1)': 0.53, '(rev, 1)': 0.07, '(rev, 2)': 0.09, '(rev, 3)': 0.01}}
2024-05-07 21:36:09,208 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:09,208 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315710034468371
2024-05-07 21:36:09,338 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #89: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.18, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:36:09,339 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:09,339 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315710034468371
2024-05-07 21:36:10,207 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #89: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(min, 0)': 0.32, '(min, 1)': 0.24, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:36:10,207 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:10,208 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315710034468371
2024-05-07 21:36:10,415 - MainProcess - INFO - text_logger.py - 51 - Train epoch #89
2024-05-07 21:36:10,418 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.8506e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0324e-01, 0.0000e+00,
        5.3437e-02, 8.0002e-03, 4.2776e-01, 0.0000e+00, 1.3432e-03, 4.1991e-03,
        0.0000e+00, 0.0000e+00, 1.3880e-04, 1.6251e-03, 0.0000e+00, 0.0000e+00,
        3.3898e-05, 2.2959e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5816e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5490e-02, 0.0000e+00,
        6.8451e-02, 1.3173e-02, 2.9987e-02, 0.0000e+00, 6.1484e-03, 1.0961e-02,
        0.0000e+00, 0.0000e+00, 1.8788e-03, 7.2889e-03, 0.0000e+00, 0.0000e+00,
        7.5799e-04, 2.4190e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:36:10,441 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43146512646697066
2024-05-07 21:36:10,444 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.455960.00915
2024-05-07 21:36:10,479 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #90: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(min, 0)': 0.09, '(min, 1)': 0.5, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:36:10,479 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:10,480 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43149543589538314
2024-05-07 21:36:10,510 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #90: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.41, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:36:10,511 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:10,511 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43149543589538314
2024-05-07 21:36:10,553 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #90: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.12, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:36:10,554 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:10,555 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43149543589538314
2024-05-07 21:36:11,653 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #90: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 9)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.32, '(rev, 1)': 0.06, '(rev, 2)': 0.06, '(rev, 4)': 0.01}}
2024-05-07 21:36:11,653 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:11,654 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43149543589538314
2024-05-07 21:36:11,709 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #90: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.18181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.05, '(min, 0)': 0.17, '(min, 1)': 0.39, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:36:11,709 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:11,710 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43149543589538314
2024-05-07 21:36:11,721 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #90: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.06, '(min, 0)': 0.26, '(min, 1)': 0.37, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-07 21:36:11,721 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:11,722 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43149543589538314
2024-05-07 21:36:12,615 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #90: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.18, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:36:12,615 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:12,616 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43149543589538314
2024-05-07 21:36:12,824 - MainProcess - INFO - text_logger.py - 51 - Train epoch #90
2024-05-07 21:36:12,827 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.6964e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0844e-01, 0.0000e+00,
        6.3233e-02, 8.1384e-03, 4.1096e-01, 0.0000e+00, 1.7504e-03, 4.6571e-03,
        0.0000e+00, 0.0000e+00, 2.8962e-04, 1.8241e-03, 0.0000e+00, 0.0000e+00,
        1.1890e-04, 4.0713e-04, 0.0000e+00, 0.0000e+00, 3.5714e-05, 1.5037e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.2038e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.6004e-02, 0.0000e+00,
        1.1055e-01, 1.3674e-02, 4.8604e-02, 0.0000e+00, 7.8226e-03, 1.2268e-02,
        0.0000e+00, 0.0000e+00, 2.7441e-03, 8.1944e-03, 0.0000e+00, 0.0000e+00,
        1.5406e-03, 3.1336e-03, 0.0000e+00, 0.0000e+00, 7.9860e-04, 2.0723e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:36:12,849 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4310525365176248
2024-05-07 21:36:12,852 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.264820.08300
2024-05-07 21:36:13,492 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #91: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36363636363636365, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.35, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-07 21:36:13,493 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:13,494 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43146512646697066
2024-05-07 21:36:13,504 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #91: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2978723404255319, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.18, '(min, 1)': 0.42, '(rev, 1)': 0.07, '(rev, 2)': 0.05}}
2024-05-07 21:36:13,504 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:13,505 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43146512646697066
2024-05-07 21:36:14,108 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #91: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(rev, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5531914893617021, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.38, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:36:14,108 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:14,110 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43146512646697066
2024-05-07 21:36:14,254 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #91: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.01, '(min, 0)': 0.04, '(min, 1)': 0.5, '(rev, 1)': 0.07, '(rev, 2)': 0.03}}
2024-05-07 21:36:14,254 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:14,255 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43146512646697066
2024-05-07 21:36:14,397 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #91: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4318181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(min, 0)': 0.4, '(min, 1)': 0.22, '(rev, 1)': 0.06, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-05-07 21:36:14,397 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:14,397 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43146512646697066
2024-05-07 21:36:14,646 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #91: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.48, '(min, 1)': 0.13, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:36:14,646 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:14,647 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43146512646697066
2024-05-07 21:36:16,129 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #91: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.03, '(ado, 6)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.26, '(rev, 1)': 0.13, '(rev, 2)': 0.08}}
2024-05-07 21:36:16,129 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:16,129 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43146512646697066
2024-05-07 21:36:16,332 - MainProcess - INFO - text_logger.py - 51 - Train epoch #91
2024-05-07 21:36:16,334 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.0725e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0039e-01, 0.0000e+00,
        6.0106e-02, 8.6110e-03, 4.1489e-01, 0.0000e+00, 1.7821e-03, 7.6861e-03,
        0.0000e+00, 0.0000e+00, 5.3915e-04, 4.7007e-03, 0.0000e+00, 0.0000e+00,
        2.8594e-04, 6.1234e-04, 0.0000e+00, 0.0000e+00, 1.1250e-04, 6.6667e-05,
        0.0000e+00, 0.0000e+00, 1.5505e-04, 3.3333e-05, 0.0000e+00, 0.0000e+00,
        3.1250e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5489e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8002e-02, 0.0000e+00,
        8.4864e-02, 1.5191e-02, 4.3121e-02, 0.0000e+00, 7.5230e-03, 2.2263e-02,
        0.0000e+00, 0.0000e+00, 3.9116e-03, 1.6298e-02, 0.0000e+00, 0.0000e+00,
        2.6844e-03, 3.6206e-03, 0.0000e+00, 0.0000e+00, 1.7880e-03, 1.0530e-03,
        0.0000e+00, 0.0000e+00, 2.0230e-03, 7.4536e-04, 0.0000e+00, 0.0000e+00,
        6.9877e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:36:16,356 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43083999282174795
2024-05-07 21:36:16,358 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.364850.06697
2024-05-07 21:36:16,410 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #92: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2765957446808511, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(min, 0)': 0.07, '(min, 1)': 0.5, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:36:16,410 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:16,411 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310525365176248
2024-05-07 21:36:16,964 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #92: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5813953488372093, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(min, 0)': 0.45, '(min, 1)': 0.16, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-05-07 21:36:16,964 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:16,965 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310525365176248
2024-05-07 21:36:17,030 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #92: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3877551020408163, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.07, '(min, 1)': 0.49, '(rev, 1)': 0.06, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-05-07 21:36:17,030 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:17,030 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310525365176248
2024-05-07 21:36:17,101 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #92: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(min, 0)': 0.01, '(min, 1)': 0.58, '(rev, 1)': 0.16}}
2024-05-07 21:36:17,102 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:17,102 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310525365176248
2024-05-07 21:36:17,508 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #92: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7674418604651163, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(min, 0)': 0.09, '(min, 1)': 0.49, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-05-07 21:36:17,508 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:17,509 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310525365176248
2024-05-07 21:36:17,923 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #92: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4878048780487805, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.04, '(ado, 8)': 0.01, '(min, 0)': 0.15, '(min, 1)': 0.49, '(rev, 1)': 0.14, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:36:17,923 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:17,924 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310525365176248
2024-05-07 21:36:19,790 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #92: {'transition': '(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 2, 5, 1, 1),(min, 0)->(exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 3, 5, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.3902439024390244, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.24, '(min, 1)': 0.36, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:36:19,790 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:19,791 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310525365176248
2024-05-07 21:36:19,998 - MainProcess - INFO - text_logger.py - 51 - Train epoch #92
2024-05-07 21:36:20,001 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.5768e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9458e-01, 0.0000e+00,
        6.6621e-02, 8.1883e-03, 4.1780e-01, 0.0000e+00, 1.7978e-03, 6.9124e-03,
        0.0000e+00, 0.0000e+00, 3.5618e-04, 2.9933e-03, 0.0000e+00, 0.0000e+00,
        1.4390e-04, 3.1235e-04, 0.0000e+00, 0.0000e+00, 7.3698e-05, 1.2040e-04,
        0.0000e+00, 0.0000e+00, 3.9216e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8966e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.1442e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9025e-02, 0.0000e+00,
        9.3173e-02, 1.5084e-02, 4.2557e-02, 0.0000e+00, 6.7184e-03, 1.8222e-02,
        0.0000e+00, 0.0000e+00, 2.6924e-03, 1.1229e-02, 0.0000e+00, 0.0000e+00,
        1.6063e-03, 2.6441e-03, 0.0000e+00, 0.0000e+00, 1.1665e-03, 1.9741e-03,
        0.0000e+00, 0.0000e+00, 8.7689e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5421e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:36:20,020 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.430562109450349
2024-05-07 21:36:20,022 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.332180.05558
2024-05-07 21:36:20,030 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #93: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(min, 0)': 0.1, '(min, 1)': 0.48, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-07 21:36:20,030 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:20,031 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43083999282174795
2024-05-07 21:36:20,044 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #93: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(min, 0)': 0.41, '(min, 1)': 0.19, '(rev, 1)': 0.15, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:36:20,044 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:20,046 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43083999282174795
2024-05-07 21:36:20,046 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #93: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 6, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5238095238095238, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(min, 0)': 0.36, '(min, 1)': 0.22, '(rev, 1)': 0.11, '(rev, 2)': 0.04}}
2024-05-07 21:36:20,047 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:20,047 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43083999282174795
2024-05-07 21:36:20,102 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #93: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(min, 0)': 0.11, '(min, 1)': 0.47, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-07 21:36:20,102 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:20,103 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43083999282174795
2024-05-07 21:36:20,637 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #93: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4791666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.4, '(min, 1)': 0.2, '(rev, 1)': 0.05, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-05-07 21:36:20,638 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:20,638 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43083999282174795
2024-05-07 21:36:21,465 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #93: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5714285714285714, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.04, '(min, 0)': 0.1, '(min, 1)': 0.51, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-05-07 21:36:21,465 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:21,466 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43083999282174795
2024-05-07 21:36:22,947 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #93: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6170212765957447, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.09, '(min, 1)': 0.48, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-07 21:36:22,947 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:22,948 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43083999282174795
2024-05-07 21:36:23,152 - MainProcess - INFO - text_logger.py - 51 - Train epoch #93
2024-05-07 21:36:23,155 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.6723e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0143e-01, 0.0000e+00,
        6.3560e-02, 8.8409e-03, 4.1081e-01, 0.0000e+00, 2.7047e-03, 6.6874e-03,
        0.0000e+00, 0.0000e+00, 5.3325e-04, 4.6408e-03, 0.0000e+00, 0.0000e+00,
        1.1152e-04, 5.8987e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.4295e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.9167e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5516e-02, 0.0000e+00,
        8.2949e-02, 1.5640e-02, 3.7776e-02, 0.0000e+00, 8.3454e-03, 1.7394e-02,
        0.0000e+00, 0.0000e+00, 3.6486e-03, 1.3876e-02, 0.0000e+00, 0.0000e+00,
        1.4519e-03, 3.3950e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3321e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:36:23,180 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43074368475603797
2024-05-07 21:36:23,183 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.561900.03810
2024-05-07 21:36:23,199 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #94: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.425531914893617, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(min, 0)': 0.02, '(min, 1)': 0.57, '(rev, 1)': 0.05, '(rev, 2)': 0.08, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:36:23,199 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:23,201 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430562109450349
2024-05-07 21:36:23,214 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #94: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3170731707317073, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.27, '(min, 1)': 0.31, '(rev, 1)': 0.08, '(rev, 2)': 0.06}}
2024-05-07 21:36:23,214 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:23,214 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #94: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.2, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.03}}
2024-05-07 21:36:23,214 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:23,214 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430562109450349
2024-05-07 21:36:23,215 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430562109450349
2024-05-07 21:36:23,229 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #94: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 6, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 7, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34146341463414637, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.04, '(min, 0)': 0.09, '(min, 1)': 0.53, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 5)': 0.01}}
2024-05-07 21:36:23,229 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:23,230 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430562109450349
2024-05-07 21:36:23,245 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #94: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(min, 0)': 0.32, '(min, 1)': 0.27, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:36:23,245 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:23,246 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430562109450349
2024-05-07 21:36:23,686 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #94: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(min, 0)': 0.2, '(min, 1)': 0.41, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-05-07 21:36:23,686 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:23,687 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430562109450349
2024-05-07 21:36:25,416 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #94: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.04, '(min, 0)': 0.18, '(min, 1)': 0.43, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:36:25,417 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:25,417 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430562109450349
2024-05-07 21:36:25,625 - MainProcess - INFO - text_logger.py - 51 - Train epoch #94
2024-05-07 21:36:25,628 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.1817e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9437e-01, 0.0000e+00,
        5.9901e-02, 8.7470e-03, 4.2445e-01, 0.0000e+00, 1.5826e-03, 5.9650e-03,
        0.0000e+00, 0.0000e+00, 8.1818e-05, 4.1409e-03, 0.0000e+00, 0.0000e+00,
        4.5455e-05, 5.4718e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6893e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.1254e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2248e-02, 0.0000e+00,
        7.8079e-02, 1.4720e-02, 3.5672e-02, 0.0000e+00, 6.3680e-03, 1.6340e-02,
        0.0000e+00, 0.0000e+00, 1.3003e-03, 1.4161e-02, 0.0000e+00, 0.0000e+00,
        1.0164e-03, 3.2458e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9112e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:36:25,652 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4305869824528111
2024-05-07 21:36:25,655 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.392770.03277
2024-05-07 21:36:25,671 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #95: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.03, '(min, 0)': 0.52, '(min, 1)': 0.05, '(rev, 1)': 0.09, '(rev, 2)': 0.04}}
2024-05-07 21:36:25,672 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:25,672 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43074368475603797
2024-05-07 21:36:25,833 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #95: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5434782608695652, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.42, '(min, 1)': 0.21, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:36:25,833 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:25,834 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43074368475603797
2024-05-07 21:36:26,011 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #95: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5714285714285714, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.03, '(min, 0)': 0.28, '(min, 1)': 0.33, '(rev, 1)': 0.11, '(rev, 2)': 0.09, '(rev, 3)': 0.01}}
2024-05-07 21:36:26,011 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:26,011 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43074368475603797
2024-05-07 21:36:26,092 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #95: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5208333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.01, '(min, 0)': 0.06, '(min, 1)': 0.5, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:36:26,092 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:26,093 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43074368475603797
2024-05-07 21:36:26,469 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #95: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.05, '(min, 0)': 0.29, '(min, 1)': 0.29, '(rev, 1)': 0.09, '(rev, 2)': 0.05}}
2024-05-07 21:36:26,469 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:26,469 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43074368475603797
2024-05-07 21:36:26,919 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #95: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.625, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(min, 0)': 0.51, '(min, 1)': 0.12, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:36:26,919 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:26,920 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43074368475603797
2024-05-07 21:36:27,922 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #95: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.45454545454545453, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.44, '(min, 1)': 0.2, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-05-07 21:36:27,922 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:27,923 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43074368475603797
2024-05-07 21:36:28,122 - MainProcess - INFO - text_logger.py - 51 - Train epoch #95
2024-05-07 21:36:28,125 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.5919e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0186e-01, 0.0000e+00,
        6.3695e-02, 8.4106e-03, 4.0969e-01, 0.0000e+00, 2.0493e-03, 7.8925e-03,
        0.0000e+00, 0.0000e+00, 3.6669e-04, 5.0016e-03, 0.0000e+00, 0.0000e+00,
        7.4825e-05, 7.4335e-04, 0.0000e+00, 0.0000e+00, 7.7180e-05, 9.4275e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.6983e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5933e-02, 0.0000e+00,
        8.2359e-02, 1.4596e-02, 4.0631e-02, 0.0000e+00, 7.5740e-03, 2.0770e-02,
        0.0000e+00, 0.0000e+00, 2.9551e-03, 1.6222e-02, 0.0000e+00, 0.0000e+00,
        1.1824e-03, 3.8177e-03, 0.0000e+00, 0.0000e+00, 1.2211e-03, 1.2389e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1180e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:36:28,145 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43070905982889335
2024-05-07 21:36:28,148 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.532160.01132
2024-05-07 21:36:28,395 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #96: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(min, 0)': 0.16, '(min, 1)': 0.44, '(rev, 1)': 0.04, '(rev, 2)': 0.07}}
2024-05-07 21:36:28,395 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:28,396 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4305869824528111
2024-05-07 21:36:28,457 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #96: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(min, 0)': 0.22, '(min, 1)': 0.38, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:36:28,458 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:28,458 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4305869824528111
2024-05-07 21:36:29,149 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #96: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 2, 0, 1),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 1, 0, 1)', 'reward_ratio': '0/1', 'revenue': 0.45652173913043476, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.37, '(rev, 1)': 0.08, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-05-07 21:36:29,149 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:29,150 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4305869824528111
2024-05-07 21:36:29,154 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #96: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.16, '(rev, 1)': 0.09, '(rev, 2)': 0.05}}
2024-05-07 21:36:29,155 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:29,156 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4305869824528111
2024-05-07 21:36:29,316 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #96: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36363636363636365, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(min, 0)': 0.15, '(min, 1)': 0.43, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-07 21:36:29,316 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:29,317 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4305869824528111
2024-05-07 21:36:29,356 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #96: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7045454545454546, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.35, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 4)': 0.02, '(rev, 5)': 0.02, '(rev, 6)': 0.01}}
2024-05-07 21:36:29,356 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:29,357 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4305869824528111
2024-05-07 21:36:31,149 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #96: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 5)': 0.01, '(min, 0)': 0.05, '(min, 1)': 0.53, '(rev, 1)': 0.07, '(rev, 2)': 0.08}}
2024-05-07 21:36:31,149 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:31,150 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4305869824528111
2024-05-07 21:36:31,367 - MainProcess - INFO - text_logger.py - 51 - Train epoch #96
2024-05-07 21:36:31,371 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.0160e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9249e-01, 0.0000e+00,
        6.0461e-02, 8.9166e-03, 4.2458e-01, 0.0000e+00, 1.8896e-03, 6.4583e-03,
        0.0000e+00, 0.0000e+00, 5.1617e-04, 3.8123e-03, 0.0000e+00, 0.0000e+00,
        1.8052e-04, 6.1557e-04, 0.0000e+00, 0.0000e+00, 3.3333e-05, 4.0816e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.3754e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.0846e-02, 0.0000e+00,
        7.3715e-02, 1.5184e-02, 3.4627e-02, 0.0000e+00, 6.7748e-03, 1.7052e-02,
        0.0000e+00, 0.0000e+00, 3.2729e-03, 1.5187e-02, 0.0000e+00, 0.0000e+00,
        1.8467e-03, 3.4568e-03, 0.0000e+00, 0.0000e+00, 7.4536e-04, 9.1268e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:36:31,393 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43079745802183994
2024-05-07 21:36:31,395 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.515320.18923
2024-05-07 21:36:31,430 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #97: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.574468085106383, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(min, 0)': 0.24, '(min, 1)': 0.39, '(rev, 1)': 0.09, '(rev, 2)': 0.09, '(rev, 5)': 0.01}}
2024-05-07 21:36:31,431 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:31,432 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43070905982889335
2024-05-07 21:36:31,468 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #97: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.21739130434782608, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.03, '(min, 0)': 0.07, '(min, 1)': 0.49, '(rev, 1)': 0.07, '(rev, 2)': 0.04}}
2024-05-07 21:36:31,468 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:31,469 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43070905982889335
2024-05-07 21:36:31,572 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #97: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.06, '(ado, 5)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.4, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:36:31,572 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:31,573 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43070905982889335
2024-05-07 21:36:31,607 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #97: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.05, '(min, 0)': 0.33, '(min, 1)': 0.26, '(rev, 1)': 0.1, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-05-07 21:36:31,607 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:31,608 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43070905982889335
2024-05-07 21:36:31,720 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #97: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43478260869565216, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.12, '(rev, 1)': 0.06, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-05-07 21:36:31,721 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:31,721 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43070905982889335
2024-05-07 21:36:31,952 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #97: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2608695652173913, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.05, '(ado, 4)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.47, '(rev, 1)': 0.11, '(rev, 2)': 0.03}}
2024-05-07 21:36:31,952 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:31,953 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43070905982889335
2024-05-07 21:36:33,395 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #97: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3617021276595745, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.43, '(min, 1)': 0.13, '(rev, 1)': 0.06, '(rev, 2)': 0.08}}
2024-05-07 21:36:33,395 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:33,396 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43070905982889335
2024-05-07 21:36:33,598 - MainProcess - INFO - text_logger.py - 51 - Train epoch #97
2024-05-07 21:36:33,601 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0876e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0504e-01, 0.0000e+00,
        6.3253e-02, 7.7833e-03, 4.1441e-01, 0.0000e+00, 1.8754e-03, 4.5245e-03,
        0.0000e+00, 0.0000e+00, 3.0268e-04, 2.2725e-03, 0.0000e+00, 0.0000e+00,
        1.6291e-04, 3.1113e-04, 0.0000e+00, 0.0000e+00, 6.3556e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.0280e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2007e-02, 0.0000e+00,
        7.9299e-02, 1.3833e-02, 3.4861e-02, 0.0000e+00, 6.8935e-03, 1.3404e-02,
        0.0000e+00, 0.0000e+00, 2.2435e-03, 9.8919e-03, 0.0000e+00, 0.0000e+00,
        1.6282e-03, 2.3361e-03, 0.0000e+00, 0.0000e+00, 1.0044e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:36:33,623 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43080746966660355
2024-05-07 21:36:33,625 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.476120.09835
2024-05-07 21:36:34,098 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #98: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5227272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.03, '(min, 0)': 0.09, '(min, 1)': 0.47, '(rev, 1)': 0.12, '(rev, 2)': 0.04}}
2024-05-07 21:36:34,099 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:34,099 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43079745802183994
2024-05-07 21:36:34,385 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #98: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(min, 0)': 0.45, '(min, 1)': 0.12, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-07 21:36:34,385 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:34,385 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43079745802183994
2024-05-07 21:36:34,423 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #98: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.17, '(rev, 1)': 0.13, '(rev, 2)': 0.03, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:36:34,424 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:34,424 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43079745802183994
2024-05-07 21:36:34,606 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #98: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(min, 0)': 0.1, '(min, 1)': 0.46, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:36:34,606 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:34,607 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43079745802183994
2024-05-07 21:36:34,791 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #98: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.2978723404255319, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.03, '(min, 0)': 0.06, '(min, 1)': 0.52, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-05-07 21:36:34,791 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:34,792 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43079745802183994
2024-05-07 21:36:35,871 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #98: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.2391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.38, '(min, 1)': 0.23, '(rev, 1)': 0.05, '(rev, 2)': 0.04}}
2024-05-07 21:36:35,871 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:35,872 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43079745802183994
2024-05-07 21:36:36,645 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #98: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5434782608695652, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.2, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:36:36,645 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:36,645 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43079745802183994
2024-05-07 21:36:36,845 - MainProcess - INFO - text_logger.py - 51 - Train epoch #98
2024-05-07 21:36:36,848 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.5779e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9091e-01, 0.0000e+00,
        6.6051e-02, 7.1962e-03, 4.2462e-01, 0.0000e+00, 2.6606e-03, 4.1746e-03,
        0.0000e+00, 0.0000e+00, 8.5929e-04, 2.3848e-03, 0.0000e+00, 0.0000e+00,
        3.0171e-04, 5.2633e-04, 0.0000e+00, 0.0000e+00, 1.5245e-04, 4.0000e-05,
        0.0000e+00, 0.0000e+00, 4.0000e-05, 4.0000e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.0000e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5492e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.1707e-02, 0.0000e+00,
        9.8163e-02, 1.3816e-02, 4.2846e-02, 0.0000e+00, 8.3118e-03, 1.3267e-02,
        0.0000e+00, 0.0000e+00, 4.4897e-03, 1.1953e-02, 0.0000e+00, 0.0000e+00,
        2.3780e-03, 3.4637e-03, 0.0000e+00, 0.0000e+00, 1.7036e-03, 8.9443e-04,
        0.0000e+00, 0.0000e+00, 8.9443e-04, 8.9443e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.9443e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:36:36,868 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4304075522333529
2024-05-07 21:36:36,870 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.271160.02671
2024-05-07 21:36:36,877 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #99: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(min, 0)': 0.2, '(min, 1)': 0.4, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:36:36,877 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:36,878 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43080746966660355
2024-05-07 21:36:37,035 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #99: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.375, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(min, 0)': 0.35, '(min, 1)': 0.25, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 8)': 0.01}}
2024-05-07 21:36:37,036 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:37,036 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43080746966660355
2024-05-07 21:36:37,286 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #99: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5319148936170213, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.16, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:36:37,287 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:37,287 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43080746966660355
2024-05-07 21:36:37,331 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #99: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6976744186046512, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.4, '(min, 1)': 0.16, '(rev, 1)': 0.14, '(rev, 2)': 0.07}}
2024-05-07 21:36:37,331 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:37,331 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43080746966660355
2024-05-07 21:36:37,673 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #99: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(min, 0)': 0.47, '(min, 1)': 0.14, '(rev, 1)': 0.06, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:36:37,673 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:37,674 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43080746966660355
2024-05-07 21:36:38,945 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #99: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(min, 0)': 0.21, '(min, 1)': 0.39, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-05-07 21:36:38,945 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:38,945 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43080746966660355
2024-05-07 21:36:39,825 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #99: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.54, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.16, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:36:39,825 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:39,826 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43080746966660355
2024-05-07 21:36:40,036 - MainProcess - INFO - text_logger.py - 51 - Train epoch #99
2024-05-07 21:36:40,039 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.7860e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0114e-01, 0.0000e+00,
        6.3560e-02, 8.5994e-03, 4.1652e-01, 0.0000e+00, 2.5673e-03, 4.2637e-03,
        0.0000e+00, 0.0000e+00, 6.5466e-04, 2.0050e-03, 0.0000e+00, 0.0000e+00,
        1.3660e-04, 4.2839e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8780e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.4173e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7555e-02, 0.0000e+00,
        8.7327e-02, 1.4637e-02, 3.9026e-02, 0.0000e+00, 8.8428e-03, 1.3143e-02,
        0.0000e+00, 0.0000e+00, 4.2545e-03, 1.1356e-02, 0.0000e+00, 0.0000e+00,
        1.8205e-03, 3.2656e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4092e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.9443e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:36:40,057 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4307934272164457
2024-05-07 21:36:40,059 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.664050.03362
2024-05-07 21:36:40,069 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #100: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46511627906976744, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.03, '(min, 0)': 0.31, '(min, 1)': 0.29, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:36:40,069 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:40,070 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4304075522333529
2024-05-07 21:36:40,085 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #100: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.29545454545454547, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.03, '(min, 0)': 0.2, '(min, 1)': 0.36, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:36:40,085 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:40,085 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4304075522333529
2024-05-07 21:36:40,100 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #100: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 4, 0, 0),(rev, 4)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8157894736842105, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.46, '(rev, 1)': 0.1, '(rev, 2)': 0.08, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-05-07 21:36:40,101 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:40,101 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4304075522333529
2024-05-07 21:36:40,124 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #100: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 1),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 2, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.4772727272727273, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.21, '(rev, 1)': 0.08, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-05-07 21:36:40,124 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:40,125 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4304075522333529
2024-05-07 21:36:40,349 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #100: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5813953488372093, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.14, '(min, 1)': 0.46, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-07 21:36:40,349 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:40,350 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4304075522333529
2024-05-07 21:36:41,264 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #100: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.30434782608695654, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.03, '(min, 0)': 0.38, '(min, 1)': 0.21, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:36:41,266 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:41,267 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4304075522333529
2024-05-07 21:36:42,342 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #100: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40476190476190477, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.03, '(min, 0)': 0.09, '(min, 1)': 0.49, '(rev, 1)': 0.13, '(rev, 2)': 0.07}}
2024-05-07 21:36:42,342 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:36:42,342 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4304075522333529
2024-05-07 21:37:03,636 - MainProcess - INFO - text_logger.py - 51 - Train epoch #100
2024-05-07 21:37:03,639 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.5678e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8586e-01, 0.0000e+00,
        6.6204e-02, 1.1069e-02, 4.2210e-01, 0.0000e+00, 1.2714e-03, 8.1227e-03,
        0.0000e+00, 0.0000e+00, 9.9444e-05, 4.2683e-03, 0.0000e+00, 0.0000e+00,
        4.2553e-05, 9.6318e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.2111e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7959e-02, 0.0000e+00,
        8.8380e-02, 1.7369e-02, 4.2458e-02, 0.0000e+00, 5.5941e-03, 1.9434e-02,
        0.0000e+00, 0.0000e+00, 1.3099e-03, 1.4948e-02, 0.0000e+00, 0.0000e+00,
        9.5152e-04, 4.6686e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:37:03,661 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43072804289261696
2024-05-07 21:37:03,689 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.438420.14297
2024-05-07 21:37:03,689 - MainProcess - INFO - text_logger.py - 51 - Simulated Policy Revenue 0.510540.01378
2024-05-07 21:37:03,699 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #101: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.21428571428571427, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.04, '(min, 0)': 0.47, '(min, 1)': 0.12, '(rev, 1)': 0.11, '(rev, 2)': 0.01}}
2024-05-07 21:37:03,699 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:03,700 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307934272164457
2024-05-07 21:37:03,715 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #101: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(min, 0)': 0.15, '(min, 1)': 0.46, '(rev, 1)': 0.09, '(rev, 2)': 0.09}}
2024-05-07 21:37:03,715 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:03,717 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #101: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2608695652173913, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(min, 0)': 0.26, '(min, 1)': 0.31, '(rev, 1)': 0.07, '(rev, 2)': 0.04}}
2024-05-07 21:37:03,717 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:03,717 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #101: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43478260869565216, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(min, 0)': 0.16, '(min, 1)': 0.45, '(rev, 1)': 0.06, '(rev, 2)': 0.09}}
2024-05-07 21:37:03,717 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:03,717 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307934272164457
2024-05-07 21:37:03,718 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307934272164457
2024-05-07 21:37:03,718 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307934272164457
2024-05-07 21:37:03,731 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #101: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.04, '(min, 0)': 0.33, '(min, 1)': 0.26, '(rev, 1)': 0.13, '(rev, 2)': 0.05}}
2024-05-07 21:37:03,731 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:03,732 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307934272164457
2024-05-07 21:37:04,268 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #101: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.41, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:37:04,268 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:04,269 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307934272164457
2024-05-07 21:37:06,986 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #101: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5681818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.39, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-05-07 21:37:06,986 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:06,987 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307934272164457
2024-05-07 21:37:07,189 - MainProcess - INFO - text_logger.py - 51 - Train epoch #101
2024-05-07 21:37:07,191 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.4487e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0329e-01, 0.0000e+00,
        5.9460e-02, 9.4990e-03, 4.2109e-01, 0.0000e+00, 1.1146e-03, 4.2442e-03,
        0.0000e+00, 0.0000e+00, 6.2049e-05, 1.1264e-03, 0.0000e+00, 0.0000e+00,
        3.0303e-05, 8.1769e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.2827e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3328e-02, 0.0000e+00,
        6.9985e-02, 1.5537e-02, 2.7685e-02, 0.0000e+00, 5.4402e-03, 1.1471e-02,
        0.0000e+00, 0.0000e+00, 9.8036e-04, 6.1997e-03, 0.0000e+00, 0.0000e+00,
        6.7760e-04, 1.2927e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:37:07,215 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43060009438878205
2024-05-07 21:37:07,217 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.407140.19286
2024-05-07 21:37:07,237 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #102: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.42, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(min, 0)': 0.14, '(min, 1)': 0.46, '(rev, 1)': 0.02, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:37:07,237 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #102: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 6, 3, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5476190476190477, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.22, '(rev, 1)': 0.05, '(rev, 2)': 0.1, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:37:07,238 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:07,238 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:07,238 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43072804289261696
2024-05-07 21:37:07,238 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43072804289261696
2024-05-07 21:37:07,252 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #102: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.03, '(min, 0)': 0.17, '(min, 1)': 0.48, '(rev, 1)': 0.13, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 5)': 0.02}}
2024-05-07 21:37:07,253 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:07,253 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43072804289261696
2024-05-07 21:37:07,267 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #102: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.03, '(min, 0)': 0.15, '(min, 1)': 0.51, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.02, '(rev, 6)': 0.01}}
2024-05-07 21:37:07,267 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:07,268 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43072804289261696
2024-05-07 21:37:07,315 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #102: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.5319148936170213, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(min, 0)': 0.14, '(min, 1)': 0.51, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:37:07,315 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:07,316 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43072804289261696
2024-05-07 21:37:07,318 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #102: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.4782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(min, 0)': 0.18, '(min, 1)': 0.45, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:37:07,318 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:07,319 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43072804289261696
2024-05-07 21:37:09,893 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #102: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.05, '(min, 1)': 0.56, '(rev, 1)': 0.06, '(rev, 2)': 0.05}}
2024-05-07 21:37:09,893 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:09,894 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43072804289261696
2024-05-07 21:37:10,107 - MainProcess - INFO - text_logger.py - 51 - Train epoch #102
2024-05-07 21:37:10,110 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0910e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7174e-01, 0.0000e+00,
        7.9574e-02, 1.0771e-02, 4.1241e-01, 0.0000e+00, 1.9110e-03, 1.1012e-02,
        0.0000e+00, 0.0000e+00, 5.3005e-04, 8.4145e-03, 0.0000e+00, 0.0000e+00,
        2.2731e-04, 2.2341e-03, 0.0000e+00, 0.0000e+00, 1.1955e-04, 4.3161e-04,
        0.0000e+00, 0.0000e+00, 8.8780e-05, 3.1437e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.4261e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9216e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9216e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.2101e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8925e-02, 0.0000e+00,
        1.2660e-01, 1.9420e-02, 6.0770e-02, 0.0000e+00, 6.6516e-03, 2.4749e-02,
        0.0000e+00, 0.0000e+00, 3.1561e-03, 2.1982e-02, 0.0000e+00, 0.0000e+00,
        2.1003e-03, 6.4646e-03, 0.0000e+00, 0.0000e+00, 1.5664e-03, 3.0506e-03,
        0.0000e+00, 0.0000e+00, 1.4092e-03, 2.8413e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.6008e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.7689e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.7689e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:37:10,127 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4307054792182805
2024-05-07 21:37:10,129 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.523810.02381
2024-05-07 21:37:10,139 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #103: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.46808510638297873, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.4, '(min, 1)': 0.22, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:37:10,139 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:10,140 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43060009438878205
2024-05-07 21:37:10,170 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #103: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.02, '(min, 0)': 0.41, '(min, 1)': 0.16, '(rev, 1)': 0.06, '(rev, 2)': 0.04}}
2024-05-07 21:37:10,170 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:10,171 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43060009438878205
2024-05-07 21:37:10,180 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #103: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.1, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:37:10,180 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:10,184 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43060009438878205
2024-05-07 21:37:10,189 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #103: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2682926829268293, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.33, '(rev, 1)': 0.06, '(rev, 2)': 0.04}}
2024-05-07 21:37:10,190 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:10,190 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43060009438878205
2024-05-07 21:37:10,336 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #103: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.2127659574468085, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.04, '(ado, 4)': 0.01, '(min, 0)': 0.09, '(min, 1)': 0.49, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:37:10,336 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:10,337 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43060009438878205
2024-05-07 21:37:10,456 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #103: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.13, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:37:10,457 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:10,457 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43060009438878205
2024-05-07 21:37:12,279 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #103: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46511627906976744, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(min, 0)': 0.44, '(min, 1)': 0.18, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 4)': 0.01}}
2024-05-07 21:37:12,279 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:12,280 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43060009438878205
2024-05-07 21:37:12,486 - MainProcess - INFO - text_logger.py - 51 - Train epoch #103
2024-05-07 21:37:12,489 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.2581e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9051e-01, 0.0000e+00,
        6.5810e-02, 9.8002e-03, 4.1600e-01, 0.0000e+00, 1.3076e-03, 8.9482e-03,
        0.0000e+00, 0.0000e+00, 2.9839e-04, 6.0915e-03, 0.0000e+00, 0.0000e+00,
        7.0523e-05, 7.5565e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3323e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1772e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.1279e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7700e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3719e-02, 0.0000e+00,
        1.0265e-01, 1.8208e-02, 5.0433e-02, 0.0000e+00, 6.3641e-03, 2.6817e-02,
        0.0000e+00, 0.0000e+00, 2.8328e-03, 2.2102e-02, 0.0000e+00, 0.0000e+00,
        1.1167e-03, 3.8731e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9744e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.7758e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.9319e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:37:12,511 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43047601095760674
2024-05-07 21:37:12,514 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.356380.14362
2024-05-07 21:37:12,763 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #104: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.5555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(min, 0)': 0.2, '(min, 1)': 0.41, '(rev, 1)': 0.1, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:37:12,763 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:12,764 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307054792182805
2024-05-07 21:37:13,056 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #104: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.39, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:37:13,056 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:13,056 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #104: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5454545454545454, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.29, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:37:13,057 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:13,057 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307054792182805
2024-05-07 21:37:13,057 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307054792182805
2024-05-07 21:37:13,233 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #104: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5681818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(min, 0)': 0.55, '(min, 1)': 0.13, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.02, '(rev, 8)': 0.01}}
2024-05-07 21:37:13,234 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:13,234 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307054792182805
2024-05-07 21:37:13,236 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #104: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.22, '(rev, 1)': 0.04, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.02, '(rev, 7)': 0.01}}
2024-05-07 21:37:13,236 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:13,237 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307054792182805
2024-05-07 21:37:13,311 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #104: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.28, '(rev, 1)': 0.09, '(rev, 2)': 0.04}}
2024-05-07 21:37:13,311 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:13,312 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307054792182805
2024-05-07 21:37:15,458 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #104: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.03, '(min, 0)': 0.07, '(min, 1)': 0.48, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:37:15,459 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:15,459 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4307054792182805
2024-05-07 21:37:15,667 - MainProcess - INFO - text_logger.py - 51 - Train epoch #104
2024-05-07 21:37:15,670 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.9413e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6750e-01, 0.0000e+00,
        9.2718e-02, 9.7889e-03, 4.1399e-01, 0.0000e+00, 2.8414e-03, 5.5604e-03,
        0.0000e+00, 0.0000e+00, 7.4597e-04, 4.4166e-03, 0.0000e+00, 0.0000e+00,
        1.7597e-04, 1.3561e-03, 0.0000e+00, 0.0000e+00, 3.7736e-05, 5.1292e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4150e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.1636e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7795e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.1264e-02, 0.0000e+00,
        1.3778e-01, 1.6393e-02, 6.0578e-02, 0.0000e+00, 8.2993e-03, 1.4861e-02,
        0.0000e+00, 0.0000e+00, 4.0659e-03, 1.4063e-02, 0.0000e+00, 0.0000e+00,
        1.7631e-03, 5.3138e-03, 0.0000e+00, 0.0000e+00, 8.4380e-04, 3.2868e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3434e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.9635e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:37:15,693 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.430701958557668
2024-05-07 21:37:15,696 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.584090.01591
2024-05-07 21:37:15,714 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #105: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(min, 0)': 0.11, '(min, 1)': 0.46, '(rev, 1)': 0.06, '(rev, 2)': 0.05}}
2024-05-07 21:37:15,714 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:15,715 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43047601095760674
2024-05-07 21:37:15,730 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #105: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.05, '(min, 0)': 0.11, '(min, 1)': 0.45, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:37:15,730 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:15,731 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43047601095760674
2024-05-07 21:37:16,318 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #105: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2553191489361702, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.03, '(min, 0)': 0.16, '(min, 1)': 0.43, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:37:16,318 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:16,319 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43047601095760674
2024-05-07 21:37:16,354 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #105: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5106382978723404, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.02, '(min, 0)': 0.42, '(min, 1)': 0.14, '(rev, 1)': 0.08, '(rev, 2)': 0.05}}
2024-05-07 21:37:16,354 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:16,355 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43047601095760674
2024-05-07 21:37:16,744 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #105: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.43, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:37:16,744 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:16,745 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43047601095760674
2024-05-07 21:37:17,566 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #105: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5416666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.03, '(min, 0)': 0.13, '(min, 1)': 0.47, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:37:17,566 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:17,567 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43047601095760674
2024-05-07 21:37:17,756 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #105: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5116279069767442, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.03, '(min, 0)': 0.17, '(min, 1)': 0.43, '(rev, 1)': 0.13, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-05-07 21:37:17,757 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:17,757 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43047601095760674
2024-05-07 21:37:17,969 - MainProcess - INFO - text_logger.py - 51 - Train epoch #105
2024-05-07 21:37:17,972 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.0698e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8126e-01, 0.0000e+00,
        8.9148e-02, 6.6626e-03, 4.1261e-01, 0.0000e+00, 1.9094e-03, 4.0617e-03,
        0.0000e+00, 0.0000e+00, 3.3793e-04, 3.0045e-03, 0.0000e+00, 0.0000e+00,
        1.1555e-04, 6.1458e-04, 0.0000e+00, 0.0000e+00, 3.1250e-05, 1.0899e-04,
        0.0000e+00, 0.0000e+00, 3.1250e-05, 7.4074e-05, 0.0000e+00, 0.0000e+00,
        3.1250e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5702e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8771e-02, 0.0000e+00,
        1.3474e-01, 1.2903e-02, 5.9089e-02, 0.0000e+00, 7.2373e-03, 1.2478e-02,
        0.0000e+00, 0.0000e+00, 2.7197e-03, 1.2857e-02, 0.0000e+00, 0.0000e+00,
        1.5157e-03, 4.0291e-03, 0.0000e+00, 0.0000e+00, 6.9877e-04, 1.9014e-03,
        0.0000e+00, 0.0000e+00, 6.9877e-04, 1.6563e-03, 0.0000e+00, 0.0000e+00,
        6.9877e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:37:17,993 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4308120293040864
2024-05-07 21:37:17,995 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.526150.01551
2024-05-07 21:37:18,452 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #106: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5106382978723404, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(min, 0)': 0.24, '(min, 1)': 0.4, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:37:18,453 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:18,453 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430701958557668
2024-05-07 21:37:18,645 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #106: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.44680851063829785, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.03, '(min, 0)': 0.45, '(min, 1)': 0.17, '(rev, 1)': 0.05, '(rev, 2)': 0.08, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:37:18,645 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:18,646 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430701958557668
2024-05-07 21:37:18,680 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #106: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.12, '(min, 1)': 0.44, '(rev, 1)': 0.1, '(rev, 2)': 0.06}}
2024-05-07 21:37:18,681 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:18,681 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430701958557668
2024-05-07 21:37:19,365 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #106: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 4, 0, 0),(rev, 4)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6585365853658537, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(min, 0)': 0.15, '(min, 1)': 0.49, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-05-07 21:37:19,365 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:19,366 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430701958557668
2024-05-07 21:37:19,593 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #106: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5106382978723404, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.47, '(min, 1)': 0.15, '(rev, 1)': 0.03, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:37:19,593 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:19,594 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430701958557668
2024-05-07 21:37:19,772 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #106: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(min, 0)': 0.4, '(min, 1)': 0.15, '(rev, 1)': 0.1, '(rev, 2)': 0.09}}
2024-05-07 21:37:19,772 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:19,773 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430701958557668
2024-05-07 21:37:20,497 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #106: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40816326530612246, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.09, '(rev, 1)': 0.03, '(rev, 2)': 0.04, '(rev, 5)': 0.02, '(rev, 6)': 0.01}}
2024-05-07 21:37:20,498 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:20,498 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430701958557668
2024-05-07 21:37:20,705 - MainProcess - INFO - text_logger.py - 51 - Train epoch #106
2024-05-07 21:37:20,708 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.6386e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7312e-01, 0.0000e+00,
        7.8269e-02, 1.0164e-02, 4.1856e-01, 0.0000e+00, 1.5202e-03, 8.1485e-03,
        0.0000e+00, 0.0000e+00, 2.1296e-04, 7.5098e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.0355e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7339e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5236e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.3898e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.8088e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3245e-02, 0.0000e+00,
        1.1550e-01, 1.8409e-02, 5.4295e-02, 0.0000e+00, 6.0539e-03, 2.1500e-02,
        0.0000e+00, 0.0000e+00, 1.9531e-03, 2.5328e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 6.8848e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6241e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1213e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.5799e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:37:20,724 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4309505538935539
2024-05-07 21:37:20,726 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.540380.11816
2024-05-07 21:37:21,063 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #107: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.38636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.41, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.02}}
2024-05-07 21:37:21,063 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:21,064 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4308120293040864
2024-05-07 21:37:21,252 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #107: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5454545454545454, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.39, '(rev, 1)': 0.12, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-05-07 21:37:21,252 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:21,253 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4308120293040864
2024-05-07 21:37:21,483 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #107: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(min, 0)': 0.46, '(min, 1)': 0.11, '(rev, 1)': 0.07, '(rev, 2)': 0.04}}
2024-05-07 21:37:21,483 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:21,483 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4308120293040864
2024-05-07 21:37:22,275 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #107: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.04, '(min, 0)': 0.14, '(min, 1)': 0.43, '(rev, 1)': 0.1, '(rev, 2)': 0.01}}
2024-05-07 21:37:22,276 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:22,276 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4308120293040864
2024-05-07 21:37:22,499 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #107: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.2653061224489796, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.23, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:37:22,499 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:22,499 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4308120293040864
2024-05-07 21:37:22,588 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #107: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2608695652173913, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(min, 0)': 0.05, '(min, 1)': 0.52, '(rev, 1)': 0.08, '(rev, 2)': 0.03}}
2024-05-07 21:37:22,588 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:22,589 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4308120293040864
2024-05-07 21:37:22,800 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #107: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(min, 0)': 0.07, '(min, 1)': 0.5, '(rev, 1)': 0.11, '(rev, 2)': 0.08}}
2024-05-07 21:37:22,801 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:22,801 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4308120293040864
2024-05-07 21:37:23,001 - MainProcess - INFO - text_logger.py - 51 - Train epoch #107
2024-05-07 21:37:23,005 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.3753e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8447e-01, 0.0000e+00,
        7.7617e-02, 8.6471e-03, 4.1669e-01, 0.0000e+00, 1.4259e-03, 5.7020e-03,
        0.0000e+00, 0.0000e+00, 1.7798e-04, 3.4524e-03, 0.0000e+00, 0.0000e+00,
        6.3011e-05, 1.5223e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3601e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5381e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.5296e-02, 0.0000e+00,
        1.0439e-01, 1.5729e-02, 4.7855e-02, 0.0000e+00, 6.4296e-03, 1.6312e-02,
        0.0000e+00, 0.0000e+00, 1.8077e-03, 1.3189e-02, 0.0000e+00, 0.0000e+00,
        1.0106e-03, 6.3375e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3564e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:37:23,025 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43053449536309973
2024-05-07 21:37:23,028 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.263090.00222
2024-05-07 21:37:24,019 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #108: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 4)': 0.01, '(min, 0)': 0.07, '(min, 1)': 0.54, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 3)': 0.04}}
2024-05-07 21:37:24,019 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:24,020 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4309505538935539
2024-05-07 21:37:24,161 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #108: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.29, '(rev, 1)': 0.11, '(rev, 2)': 0.04}}
2024-05-07 21:37:24,161 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:24,162 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4309505538935539
2024-05-07 21:37:24,413 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #108: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5319148936170213, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.2, '(rev, 1)': 0.04, '(rev, 2)': 0.09, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:37:24,413 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:24,413 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4309505538935539
2024-05-07 21:37:24,931 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #108: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2558139534883721, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.4, '(rev, 1)': 0.08, '(rev, 2)': 0.05}}
2024-05-07 21:37:24,931 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:24,931 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4309505538935539
2024-05-07 21:37:25,091 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #108: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.03, '(min, 0)': 0.37, '(min, 1)': 0.24, '(rev, 1)': 0.1, '(rev, 2)': 0.09}}
2024-05-07 21:37:25,091 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:25,092 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4309505538935539
2024-05-07 21:37:25,145 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #108: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.05, '(ado, 3)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.39, '(rev, 1)': 0.13, '(rev, 2)': 0.02, '(rev, 3)': 0.03}}
2024-05-07 21:37:25,145 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:25,146 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4309505538935539
2024-05-07 21:37:25,931 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #108: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6976744186046512, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 4)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.53, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 6)': 0.01}}
2024-05-07 21:37:25,931 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:25,932 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4309505538935539
2024-05-07 21:37:26,012 - MainProcess - INFO - text_logger.py - 51 - Train epoch #108
2024-05-07 21:37:26,015 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.2190e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6320e-01, 0.0000e+00,
        1.0129e-01, 8.9943e-03, 4.1408e-01, 0.0000e+00, 3.1978e-03, 5.2325e-03,
        0.0000e+00, 0.0000e+00, 6.4351e-04, 2.3069e-03, 0.0000e+00, 0.0000e+00,
        2.5676e-04, 7.9182e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.1627, 0.0000, 0.0000, 0.0000, 0.0877, 0.0000, 0.1281, 0.0149, 0.0569,
        0.0000, 0.0101, 0.0124, 0.0000, 0.0000, 0.0038, 0.0094, 0.0000, 0.0000,
        0.0024, 0.0047, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-05-07 21:37:26,035 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4306232688969171
2024-05-07 21:37:26,037 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.515500.18217
2024-05-07 21:37:26,529 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #109: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.05, '(min, 0)': 0.03, '(min, 1)': 0.55, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-07 21:37:26,529 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:26,529 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43053449536309973
2024-05-07 21:37:26,885 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #109: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.44, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:37:26,885 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:26,886 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43053449536309973
2024-05-07 21:37:27,244 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #109: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46511627906976744, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.22, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-05-07 21:37:27,244 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:27,244 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43053449536309973
2024-05-07 21:37:27,266 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #109: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5102040816326531, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.39, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:37:27,266 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:27,266 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43053449536309973
2024-05-07 21:37:27,990 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #109: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5227272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.04, '(min, 0)': 0.3, '(min, 1)': 0.37, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 6)': 0.01}}
2024-05-07 21:37:27,991 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:27,991 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43053449536309973
2024-05-07 21:37:28,199 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #109: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.8636363636363636, 'length': 100, 'actions': {'(ado, 1)': 0.04, '(ado, 2)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.28, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.05, '(rev, 4)': 0.02, '(rev, 5)': 0.02, '(rev, 6)': 0.01}}
2024-05-07 21:37:28,199 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:28,200 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43053449536309973
2024-05-07 21:37:29,587 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #109: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 4, 0, 0),(rev, 4)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 1.0227272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(min, 0)': 0.16, '(min, 1)': 0.51, '(rev, 1)': 0.02, '(rev, 2)': 0.04, '(rev, 3)': 0.05, '(rev, 4)': 0.03}}
2024-05-07 21:37:29,587 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:29,589 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43053449536309973
2024-05-07 21:37:29,667 - MainProcess - INFO - text_logger.py - 51 - Train epoch #109
2024-05-07 21:37:29,670 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.8996e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7616e-01, 0.0000e+00,
        8.4954e-02, 8.5897e-03, 4.1566e-01, 0.0000e+00, 2.1111e-03, 5.0082e-03,
        0.0000e+00, 0.0000e+00, 3.8363e-04, 4.7280e-03, 0.0000e+00, 0.0000e+00,
        1.0414e-04, 1.5637e-03, 0.0000e+00, 0.0000e+00, 3.5714e-05, 4.2947e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0240e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.5088e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5088e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.6866e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.8675e-02, 0.0000e+00,
        1.0945e-01, 1.5310e-02, 4.8013e-02, 0.0000e+00, 7.3548e-03, 1.4411e-02,
        0.0000e+00, 0.0000e+00, 2.9033e-03, 1.8715e-02, 0.0000e+00, 0.0000e+00,
        1.3423e-03, 6.5659e-03, 0.0000e+00, 0.0000e+00, 7.9860e-04, 3.1925e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0638e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.8459e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.8459e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:37:29,688 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43156739831516017
2024-05-07 21:37:29,690 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.943180.07955
2024-05-07 21:37:29,712 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #110: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(min, 0)': 0.09, '(min, 1)': 0.5, '(rev, 1)': 0.09, '(rev, 2)': 0.07}}
2024-05-07 21:37:29,712 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #110: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.3404255319148936, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.04, '(min, 0)': 0.07, '(min, 1)': 0.53, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:37:29,712 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:29,712 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:29,713 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4306232688969171
2024-05-07 21:37:29,713 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4306232688969171
2024-05-07 21:37:29,728 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #110: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3191489361702128, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(ado, 4)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.44, '(rev, 1)': 0.08, '(rev, 2)': 0.06}}
2024-05-07 21:37:29,729 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:29,729 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4306232688969171
2024-05-07 21:37:29,961 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #110: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(min, 0)': 0.36, '(min, 1)': 0.24, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:37:29,961 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:29,962 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4306232688969171
2024-05-07 21:37:30,693 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #110: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(min, 0)': 0.48, '(min, 1)': 0.11, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:37:30,695 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:30,696 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4306232688969171
2024-05-07 21:37:31,014 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #110: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5434782608695652, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.03, '(ado, 5)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.26, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:37:31,014 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:31,014 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4306232688969171
2024-05-07 21:37:31,858 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #110: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.01, '(min, 0)': 0.12, '(min, 1)': 0.43, '(rev, 1)': 0.09, '(rev, 2)': 0.04}}
2024-05-07 21:37:31,859 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:31,860 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4306232688969171
2024-05-07 21:37:31,938 - MainProcess - INFO - text_logger.py - 51 - Train epoch #110
2024-05-07 21:37:31,941 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.9206e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7461e-01, 0.0000e+00,
        8.3869e-02, 7.6625e-03, 4.2210e-01, 0.0000e+00, 2.1012e-03, 4.6793e-03,
        0.0000e+00, 0.0000e+00, 2.9152e-04, 3.1737e-03, 0.0000e+00, 0.0000e+00,
        1.4892e-04, 1.1095e-03, 0.0000e+00, 0.0000e+00, 6.6667e-05, 4.2553e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.0000e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 6.6667e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.3367e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3141e-02, 0.0000e+00,
        1.2033e-01, 1.4275e-02, 5.4973e-02, 0.0000e+00, 8.3057e-03, 1.3935e-02,
        0.0000e+00, 0.0000e+00, 2.7274e-03, 1.5429e-02, 0.0000e+00, 0.0000e+00,
        1.9946e-03, 6.1861e-03, 0.0000e+00, 0.0000e+00, 1.4907e-03, 9.5152e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7889e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.4907e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:37:31,959 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.431208497430373
2024-05-07 21:37:31,961 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.291670.04167
2024-05-07 21:37:31,985 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #111: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.18604651162790697, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.05, '(min, 1)': 0.48, '(rev, 1)': 0.1, '(rev, 2)': 0.02}}
2024-05-07 21:37:31,985 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:31,986 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43156739831516017
2024-05-07 21:37:32,283 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #111: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(min, 0)': 0.26, '(min, 1)': 0.34, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:37:32,283 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:32,284 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43156739831516017
2024-05-07 21:37:33,117 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #111: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.03, '(min, 0)': 0.13, '(min, 1)': 0.47, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-07 21:37:33,117 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:33,118 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43156739831516017
2024-05-07 21:37:33,201 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #111: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.44680851063829785, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.2, '(rev, 1)': 0.05, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:37:33,202 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:33,202 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43156739831516017
2024-05-07 21:37:33,432 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #111: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5581395348837209, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.28, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:37:33,432 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:33,433 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43156739831516017
2024-05-07 21:37:34,507 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #111: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.12195121951219512, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.39, '(rev, 1)': 0.07, '(rev, 2)': 0.03}}
2024-05-07 21:37:34,507 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:34,508 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43156739831516017
2024-05-07 21:37:35,353 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #111: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8888888888888888, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.09, '(min, 1)': 0.52, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:37:35,353 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:35,354 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43156739831516017
2024-05-07 21:37:35,424 - MainProcess - INFO - text_logger.py - 51 - Train epoch #111
2024-05-07 21:37:35,427 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.6441e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6949e-01, 0.0000e+00,
        9.6141e-02, 7.7318e-03, 4.1166e-01, 0.0000e+00, 2.9757e-03, 4.6224e-03,
        0.0000e+00, 0.0000e+00, 8.5359e-04, 3.6908e-03, 0.0000e+00, 0.0000e+00,
        4.5156e-04, 1.8996e-03, 0.0000e+00, 0.0000e+00, 1.4879e-04, 1.1855e-04,
        0.0000e+00, 0.0000e+00, 4.0000e-05, 1.7814e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7086e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8831e-02, 0.0000e+00,
        1.3395e-01, 1.4725e-02, 6.0532e-02, 0.0000e+00, 8.9126e-03, 1.3082e-02,
        0.0000e+00, 0.0000e+00, 4.1664e-03, 1.2846e-02, 0.0000e+00, 0.0000e+00,
        2.9334e-03, 7.0187e-03, 0.0000e+00, 0.0000e+00, 1.6621e-03, 1.3518e-03,
        0.0000e+00, 0.0000e+00, 8.9443e-04, 2.1926e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:37:35,446 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.431713291636025
2024-05-07 21:37:35,448 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.723510.16537
2024-05-07 21:37:35,456 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #112: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2553191489361702, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.09, '(min, 1)': 0.47, '(rev, 1)': 0.09, '(rev, 2)': 0.04}}
2024-05-07 21:37:35,457 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:35,457 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431208497430373
2024-05-07 21:37:35,458 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #112: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36585365853658536, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(min, 0)': 0.19, '(min, 1)': 0.41, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-05-07 21:37:35,458 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:35,459 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431208497430373
2024-05-07 21:37:35,489 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #112: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.03, '(min, 0)': 0.22, '(min, 1)': 0.43, '(rev, 1)': 0.08, '(rev, 2)': 0.07, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:37:35,489 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:35,490 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431208497430373
2024-05-07 21:37:35,968 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #112: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 6, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(min, 0)': 0.12, '(min, 1)': 0.45, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:37:35,968 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:35,969 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431208497430373
2024-05-07 21:37:36,712 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #112: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 3, 1, 1),(min, 0)->(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 2, 3, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.8863636363636364, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.46, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-07 21:37:36,712 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:36,713 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431208497430373
2024-05-07 21:37:37,042 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #112: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.05, '(min, 0)': 0.23, '(min, 1)': 0.35, '(rev, 1)': 0.12, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:37:37,042 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:37,042 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431208497430373
2024-05-07 21:37:38,496 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #112: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.25, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:37:38,496 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:38,497 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431208497430373
2024-05-07 21:37:38,576 - MainProcess - INFO - text_logger.py - 51 - Train epoch #112
2024-05-07 21:37:38,579 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.9370e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7206e-01, 0.0000e+00,
        8.3981e-02, 9.2545e-03, 4.1971e-01, 0.0000e+00, 1.9534e-03, 5.9882e-03,
        0.0000e+00, 0.0000e+00, 2.3396e-04, 4.6932e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.5094e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6163e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6164e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 9.7208e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7942e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7547e-02, 0.0000e+00,
        1.1177e-01, 1.5579e-02, 5.1256e-02, 0.0000e+00, 7.0917e-03, 1.3458e-02,
        0.0000e+00, 0.0000e+00, 2.2574e-03, 1.4353e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 6.2901e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7189e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6192e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.2551e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:37:38,599 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43137105741790444
2024-05-07 21:37:38,602 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.300000.10000
2024-05-07 21:37:38,623 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #113: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.375, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.05, '(min, 0)': 0.21, '(min, 1)': 0.39, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 4)': 0.01}}
2024-05-07 21:37:38,624 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:38,625 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431713291636025
2024-05-07 21:37:38,638 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #113: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.36, '(min, 1)': 0.22, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-05-07 21:37:38,638 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #113: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3125, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.02, '(min, 0)': 0.06, '(min, 1)': 0.49, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:37:38,639 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:38,639 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:38,639 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431713291636025
2024-05-07 21:37:38,640 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431713291636025
2024-05-07 21:37:38,942 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #113: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6363636363636364, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.04, '(min, 0)': 0.16, '(min, 1)': 0.48, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:37:38,942 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:38,943 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431713291636025
2024-05-07 21:37:39,582 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #113: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(min, 0)': 0.16, '(min, 1)': 0.45, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:37:39,582 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:39,584 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431713291636025
2024-05-07 21:37:40,013 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #113: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.29545454545454547, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.05, '(ado, 3)': 0.01, '(min, 0)': 0.02, '(min, 1)': 0.59, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:37:40,013 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:40,014 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431713291636025
2024-05-07 21:37:41,623 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #113: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 3)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.46, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:37:41,623 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:41,624 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431713291636025
2024-05-07 21:37:41,700 - MainProcess - INFO - text_logger.py - 51 - Train epoch #113
2024-05-07 21:37:41,703 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.9488e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6090e-01, 0.0000e+00,
        1.0770e-01, 8.4631e-03, 4.0620e-01, 0.0000e+00, 3.4466e-03, 4.9098e-03,
        0.0000e+00, 0.0000e+00, 9.0763e-04, 4.5316e-03, 0.0000e+00, 0.0000e+00,
        1.7508e-04, 1.8956e-03, 0.0000e+00, 0.0000e+00, 4.0000e-05, 4.1236e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4010e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.0096e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.4074e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.9053e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.7467e-02, 0.0000e+00,
        1.4901e-01, 1.4598e-02, 6.8635e-02, 0.0000e+00, 1.0797e-02, 1.2241e-02,
        0.0000e+00, 0.0000e+00, 4.7219e-03, 1.4429e-02, 0.0000e+00, 0.0000e+00,
        1.9716e-03, 7.2892e-03, 0.0000e+00, 0.0000e+00, 8.9443e-04, 2.8630e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3338e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.6395e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6563e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:37:41,723 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4311504141088748
2024-05-07 21:37:41,725 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.360800.04830
2024-05-07 21:37:41,732 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #114: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(min, 0)': 0.4, '(min, 1)': 0.14, '(rev, 1)': 0.1, '(rev, 2)': 0.07}}
2024-05-07 21:37:41,732 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #114: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.5869565217391305, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(min, 0)': 0.45, '(min, 1)': 0.11, '(rev, 1)': 0.09, '(rev, 2)': 0.06}}
2024-05-07 21:37:41,732 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:41,732 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:41,733 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43137105741790444
2024-05-07 21:37:41,733 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43137105741790444
2024-05-07 21:37:41,778 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #114: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(min, 0)': 0.16, '(min, 1)': 0.42, '(rev, 1)': 0.1, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-05-07 21:37:41,778 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:41,779 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43137105741790444
2024-05-07 21:37:41,784 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #114: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43902439024390244, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.37, '(rev, 1)': 0.11, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:37:41,785 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:41,786 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43137105741790444
2024-05-07 21:37:42,136 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #114: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4883720930232558, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(min, 0)': 0.31, '(min, 1)': 0.27, '(rev, 1)': 0.12, '(rev, 2)': 0.05, '(rev, 3)': 0.03}}
2024-05-07 21:37:42,136 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:42,137 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43137105741790444
2024-05-07 21:37:42,425 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #114: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7446808510638298, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.07, '(min, 1)': 0.54, '(rev, 1)': 0.08, '(rev, 2)': 0.08, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:37:42,425 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:42,426 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43137105741790444
2024-05-07 21:37:44,383 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #114: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2708333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 3)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.14, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:37:44,383 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:44,384 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43137105741790444
2024-05-07 21:37:44,459 - MainProcess - INFO - text_logger.py - 51 - Train epoch #114
2024-05-07 21:37:44,462 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.1990e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6604e-01, 0.0000e+00,
        9.3853e-02, 8.4425e-03, 4.1979e-01, 0.0000e+00, 2.1390e-03, 5.1872e-03,
        0.0000e+00, 0.0000e+00, 3.5731e-04, 2.9384e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.2167e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5088e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.1677e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7614e-02, 0.0000e+00,
        1.1184e-01, 1.4520e-02, 4.9710e-02, 0.0000e+00, 7.9276e-03, 1.2337e-02,
        0.0000e+00, 0.0000e+00, 2.8817e-03, 1.0509e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 5.9446e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.8459e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:37:44,484 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4310659697458266
2024-05-07 21:37:44,486 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.428890.15806
2024-05-07 21:37:44,524 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #115: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.03, '(min, 0)': 0.2, '(min, 1)': 0.36, '(rev, 1)': 0.08, '(rev, 2)': 0.05}}
2024-05-07 21:37:44,524 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:44,525 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #115: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.04, '(min, 1)': 0.53, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-07 21:37:44,525 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:44,525 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4311504141088748
2024-05-07 21:37:44,525 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4311504141088748
2024-05-07 21:37:44,544 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #115: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3617021276595745, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.44, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:37:44,545 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:44,545 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4311504141088748
2024-05-07 21:37:44,664 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #115: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.04, '(min, 0)': 0.01, '(min, 1)': 0.55, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:37:44,665 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:44,665 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4311504141088748
2024-05-07 21:37:44,713 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #115: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4186046511627907, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.03, '(min, 0)': 0.21, '(min, 1)': 0.4, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-05-07 21:37:44,714 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:44,714 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4311504141088748
2024-05-07 21:37:45,463 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #115: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34146341463414637, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.05, '(ado, 4)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.35, '(rev, 1)': 0.13, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-05-07 21:37:45,463 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:45,463 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4311504141088748
2024-05-07 21:37:47,508 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #115: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6739130434782609, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.03, '(min, 0)': 0.42, '(min, 1)': 0.15, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:37:47,508 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:47,509 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4311504141088748
2024-05-07 21:37:47,584 - MainProcess - INFO - text_logger.py - 51 - Train epoch #115
2024-05-07 21:37:47,587 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.8834e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7943e-01, 0.0000e+00,
        8.5095e-02, 8.5289e-03, 4.1930e-01, 0.0000e+00, 2.2118e-03, 3.8309e-03,
        0.0000e+00, 0.0000e+00, 3.2431e-04, 1.1685e-03, 0.0000e+00, 0.0000e+00,
        1.1384e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.0712, 0.0000, 0.0000, 0.0000, 0.0738, 0.0000, 0.1063, 0.0143, 0.0441,
        0.0000, 0.0081, 0.0093, 0.0000, 0.0000, 0.0026, 0.0056, 0.0000, 0.0000,
        0.0015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-05-07 21:37:47,606 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43126431523785097
2024-05-07 21:37:47,608 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.570290.10362
2024-05-07 21:37:47,631 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #116: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(min, 0)': 0.21, '(min, 1)': 0.42, '(rev, 1)': 0.08, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:37:47,631 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:47,631 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:47,632 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310659697458266
2024-05-07 21:37:47,632 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310659697458266
2024-05-07 21:37:47,668 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #116: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(min, 0)': 0.11, '(min, 1)': 0.46, '(rev, 1)': 0.08, '(rev, 2)': 0.08}}
2024-05-07 21:37:47,668 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:47,669 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310659697458266
2024-05-07 21:37:47,895 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #116: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7272727272727273, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.04, '(min, 0)': 0.12, '(min, 1)': 0.48, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:37:47,895 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:47,896 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310659697458266
2024-05-07 21:37:48,266 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #116: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5217391304347826, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.04, '(min, 0)': 0.16, '(min, 1)': 0.51, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 4)': 0.04, '(rev, 5)': 0.01}}
2024-05-07 21:37:48,266 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:48,266 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310659697458266
2024-05-07 21:37:48,598 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #116: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 6, 2, 1, 1),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, exi, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 6, 3, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.37209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.44, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:37:48,598 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:48,599 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310659697458266
2024-05-07 21:37:50,916 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #116: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 1, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.6739130434782609, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(min, 0)': 0.27, '(min, 1)': 0.39, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:37:50,916 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:50,917 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310659697458266
2024-05-07 21:37:50,991 - MainProcess - INFO - text_logger.py - 51 - Train epoch #116
2024-05-07 21:37:50,994 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.6556e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4995e-01, 0.0000e+00,
        1.1259e-01, 8.4483e-03, 4.0872e-01, 0.0000e+00, 3.6028e-03, 6.4989e-03,
        0.0000e+00, 0.0000e+00, 8.0545e-04, 5.9469e-03, 0.0000e+00, 0.0000e+00,
        2.2440e-04, 2.7522e-03, 0.0000e+00, 0.0000e+00, 3.1250e-05, 2.6855e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3458e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.5714e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.8337e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.4581e-02, 0.0000e+00,
        1.4155e-01, 1.5189e-02, 6.6392e-02, 0.0000e+00, 1.0880e-02, 1.4018e-02,
        0.0000e+00, 0.0000e+00, 4.3709e-03, 1.6687e-02, 0.0000e+00, 0.0000e+00,
        2.0795e-03, 8.6981e-03, 0.0000e+00, 0.0000e+00, 6.9877e-04, 2.4515e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8001e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.9860e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:37:51,015 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4317232667904814
2024-05-07 21:37:51,017 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.700590.02668
2024-05-07 21:37:51,038 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #117: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.24444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.03, '(min, 0)': 0.06, '(min, 1)': 0.49, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
 4)': 0.02, '(rev, 6)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:37:51,038 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:51,039 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43126431523785097
2024-05-07 21:37:51,039 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43126431523785097
2024-05-07 21:37:51,054 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #117: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43478260869565216, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:37:51,055 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:51,055 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43126431523785097
2024-05-07 21:37:51,078 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #117: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5581395348837209, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.22, '(rev, 1)': 0.12, '(rev, 2)': 0.11, '(rev, 3)': 0.01}}
2024-05-07 21:37:51,078 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:51,078 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43126431523785097
2024-05-07 21:37:51,209 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #117: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0),(rev, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.6326530612244898, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.32, '(min, 1)': 0.24, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:37:51,209 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:51,210 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43126431523785097
2024-05-07 21:37:52,437 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #117: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 1.0217391304347827, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.44, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:37:52,437 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:52,437 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43126431523785097
2024-05-07 21:37:54,259 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #117: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6829268292682927, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.49, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:37:54,259 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:54,260 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43126431523785097
2024-05-07 21:37:54,331 - MainProcess - INFO - text_logger.py - 51 - Train epoch #117
2024-05-07 21:37:54,334 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.3169e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7129e-01, 0.0000e+00,
        9.4762e-02, 8.4740e-03, 4.1535e-01, 0.0000e+00, 2.1636e-03, 4.5760e-03,
        0.0000e+00, 0.0000e+00, 2.3989e-04, 1.9014e-03, 0.0000e+00, 0.0000e+00,
        1.5374e-04, 3.7893e-04, 0.0000e+00, 0.0000e+00, 1.2088e-04, 1.1614e-04,
        0.0000e+00, 0.0000e+00, 4.1667e-05, 2.7391e-04, 0.0000e+00, 0.0000e+00,
        1.2167e-04, 3.9216e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.0104e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.5348e-02, 0.0000e+00,
        1.3279e-01, 1.5251e-02, 6.0373e-02, 0.0000e+00, 7.7967e-03, 1.1119e-02,
        0.0000e+00, 0.0000e+00, 2.2117e-03, 8.8644e-03, 0.0000e+00, 0.0000e+00,
        1.7173e-03, 3.5204e-03, 0.0000e+00, 0.0000e+00, 1.5580e-03, 1.9291e-03,
        0.0000e+00, 0.0000e+00, 9.3170e-04, 2.8142e-03, 0.0000e+00, 0.0000e+00,
        2.0153e-03, 8.7689e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:37:54,352 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43216163382023376
2024-05-07 21:37:54,355 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.690300.00737
2024-05-07 21:37:54,363 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #118: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.3958333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.03, '(ado, 4)': 0.01, '(min, 0)': 0.14, '(min, 1)': 0.46, '(rev, 1)': 0.07, '(rev, 2)': 0.08, '(rev, 3)': 0.02}}
2024-05-07 21:37:54,363 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #118: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.10869565217391304, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.03, '(min, 0)': 0.07, '(min, 1)': 0.47, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-05-07 21:37:54,363 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:54,363 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:54,364 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4317232667904814
2024-05-07 21:37:54,364 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4317232667904814
2024-05-07 21:37:54,387 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #118: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.02, '(min, 1)': 0.55, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-07 21:37:54,387 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:54,388 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4317232667904814
2024-05-07 21:37:54,418 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #118: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6818181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(min, 0)': 0.04, '(min, 1)': 0.57, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-05-07 21:37:54,418 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:54,419 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4317232667904814
2024-05-07 21:37:54,427 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #118: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.40425531914893614, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(min, 0)': 0.07, '(min, 1)': 0.52, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:37:54,427 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:54,427 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4317232667904814
2024-05-07 21:37:55,078 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #118: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6818181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(min, 0)': 0.01, '(min, 1)': 0.56, '(rev, 1)': 0.12, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-05-07 21:37:55,078 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:55,079 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4317232667904814
2024-05-07 21:37:56,716 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #118: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.47058823529411764, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(min, 0)': 0.49, '(min, 1)': 0.11, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 5)': 0.02}}
2024-05-07 21:37:56,716 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:56,717 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4317232667904814
2024-05-07 21:37:56,783 - MainProcess - INFO - text_logger.py - 51 - Train epoch #118
2024-05-07 21:37:56,786 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.6178e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7158e-01, 0.0000e+00,
        8.7982e-02, 6.9367e-03, 4.2551e-01, 0.0000e+00, 1.8022e-03, 3.4758e-03,
        0.0000e+00, 0.0000e+00, 2.9261e-04, 1.9667e-03, 0.0000e+00, 0.0000e+00,
        3.3898e-05, 4.1952e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.6771e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.6929e-02, 0.0000e+00,
        1.1524e-01, 1.3454e-02, 5.0476e-02, 0.0000e+00, 7.6145e-03, 1.0315e-02,
        0.0000e+00, 0.0000e+00, 2.6879e-03, 8.7261e-03, 0.0000e+00, 0.0000e+00,
        7.5799e-04, 3.3186e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:37:56,805 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4320942431565562
2024-05-07 21:37:56,807 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.437420.03317
2024-05-07 21:37:56,831 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #119: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.1, '(min, 1)': 0.47, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:37:56,831 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:56,832 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43216163382023376
2024-05-07 21:37:56,862 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #119: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(min, 0)': 0.2, '(min, 1)': 0.4, '(rev, 1)': 0.08, '(rev, 2)': 0.06}}
2024-05-07 21:37:56,862 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:56,863 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43216163382023376
2024-05-07 21:37:56,863 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #119: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(min, 0)': 0.1, '(min, 1)': 0.49, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-07 21:37:56,863 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:56,864 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43216163382023376
2024-05-07 21:37:56,903 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #119: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5714285714285714, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(min, 0)': 0.2, '(min, 1)': 0.48, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:37:56,903 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:56,903 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43216163382023376
2024-05-07 21:37:57,142 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #119: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.46808510638297873, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(min, 0)': 0.34, '(min, 1)': 0.28, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:37:57,142 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:57,142 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43216163382023376
2024-05-07 21:37:58,225 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #119: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1875, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.45, '(rev, 1)': 0.02, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:37:58,225 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:58,226 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43216163382023376
2024-05-07 21:37:59,093 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #119: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0),(rev, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.36363636363636365, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(min, 0)': 0.06, '(min, 1)': 0.53, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:37:59,093 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:59,094 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43216163382023376
2024-05-07 21:37:59,166 - MainProcess - INFO - text_logger.py - 51 - Train epoch #119
2024-05-07 21:37:59,169 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.2246e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7238e-01, 0.0000e+00,
        9.5980e-02, 7.7294e-03, 4.1397e-01, 0.0000e+00, 2.3996e-03, 3.9111e-03,
        0.0000e+00, 0.0000e+00, 3.5399e-04, 2.1393e-03, 0.0000e+00, 0.0000e+00,
        1.1477e-04, 4.8774e-04, 0.0000e+00, 0.0000e+00, 7.4773e-05, 2.0880e-04,
        0.0000e+00, 0.0000e+00, 7.7736e-05, 2.7778e-05, 0.0000e+00, 0.0000e+00,
        3.7736e-05, 2.7778e-05, 0.0000e+00, 0.0000e+00, 3.7736e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.7736e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.4248e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.4463e-02, 0.0000e+00,
        1.5438e-01, 1.4400e-02, 7.1648e-02, 0.0000e+00, 8.4463e-03, 1.0633e-02,
        0.0000e+00, 0.0000e+00, 2.6384e-03, 8.7022e-03, 0.0000e+00, 0.0000e+00,
        1.4796e-03, 3.7414e-03, 0.0000e+00, 0.0000e+00, 1.1811e-03, 2.2672e-03,
        0.0000e+00, 0.0000e+00, 1.2284e-03, 6.2113e-04, 0.0000e+00, 0.0000e+00,
        8.4380e-04, 6.2113e-04, 0.0000e+00, 0.0000e+00, 8.4380e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.4380e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:37:59,190 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4320870738735006
2024-05-07 21:37:59,193 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.467530.10390
2024-05-07 21:37:59,511 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #120: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.4, '(rev, 1)': 0.12, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:37:59,511 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:59,512 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320942431565562
2024-05-07 21:37:59,660 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #120: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 7, 5, 0, 0),(rev, 5)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 7, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4473684210526316, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.46, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 5)': 0.02}}
2024-05-07 21:37:59,661 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:59,661 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320942431565562
2024-05-07 21:37:59,682 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #120: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5106382978723404, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(min, 0)': 0.38, '(min, 1)': 0.24, '(rev, 1)': 0.06, '(rev, 2)': 0.09, '(rev, 3)': 0.02}}
2024-05-07 21:37:59,682 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:37:59,683 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320942431565562
2024-05-07 21:38:00,144 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #120: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6744186046511628, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(min, 0)': 0.18, '(min, 1)': 0.43, '(rev, 1)': 0.11, '(rev, 2)': 0.01, '(rev, 3)': 0.04, '(rev, 4)': 0.01}}
2024-05-07 21:38:00,144 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:00,145 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320942431565562
2024-05-07 21:38:00,734 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #120: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 2)': 0.02, '(min, 0)': 0.47, '(min, 1)': 0.17}}
2024-05-07 21:38:00,734 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:00,735 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320942431565562
2024-05-07 21:38:01,697 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #120: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5909090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.35, '(rev, 1)': 0.05, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:38:01,697 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:01,698 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320942431565562
2024-05-07 21:38:01,992 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #120: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.25, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.02, '(rev, 6)': 0.01}}
2024-05-07 21:38:01,992 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:01,992 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320942431565562
2024-05-07 21:38:02,201 - MainProcess - INFO - text_logger.py - 51 - Train epoch #120
2024-05-07 21:38:02,204 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.3399e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7106e-01, 0.0000e+00,
        2.2912e-01, 7.0107e-03, 3.4581e-01, 0.0000e+00, 1.2076e-02, 6.9381e-03,
        0.0000e+00, 0.0000e+00, 3.9447e-03, 5.1774e-03, 0.0000e+00, 0.0000e+00,
        3.2020e-03, 2.9464e-03, 0.0000e+00, 0.0000e+00, 2.7178e-03, 7.8806e-04,
        0.0000e+00, 0.0000e+00, 2.5774e-03, 5.8503e-04, 0.0000e+00, 0.0000e+00,
        2.4347e-03, 3.9930e-04, 0.0000e+00, 0.0000e+00, 1.8843e-03, 1.1901e-04,
        0.0000e+00, 0.0000e+00, 9.6613e-04, 3.8462e-05, 0.0000e+00, 0.0000e+00,
        2.0906e-04, 0.0000e+00, 0.0000e+00])  tensor([2.9601e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7552e-01, 0.0000e+00,
        2.8004e-01, 1.4305e-02, 1.5066e-01, 0.0000e+00, 2.0834e-02, 1.5782e-02,
        0.0000e+00, 0.0000e+00, 8.3194e-03, 1.6707e-02, 0.0000e+00, 0.0000e+00,
        7.2960e-03, 1.7779e-02, 0.0000e+00, 0.0000e+00, 6.4571e-03, 3.6379e-03,
        0.0000e+00, 0.0000e+00, 6.2585e-03, 3.2523e-03, 0.0000e+00, 0.0000e+00,
        6.0169e-03, 2.5733e-03, 0.0000e+00, 0.0000e+00, 5.3233e-03, 1.3503e-03,
        0.0000e+00, 0.0000e+00, 3.8707e-03, 8.6003e-04, 0.0000e+00, 0.0000e+00,
        1.7866e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:38:02,225 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43241016735094023
2024-05-07 21:38:02,228 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.632660.04175
2024-05-07 21:38:02,275 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #121: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5208333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(min, 0)': 0.05, '(min, 1)': 0.51, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-07 21:38:02,275 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:02,276 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320870738735006
2024-05-07 21:38:02,277 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #121: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.4375, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(min, 0)': 0.44, '(min, 1)': 0.14, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 4)': 0.01}}
2024-05-07 21:38:02,277 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:02,278 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320870738735006
2024-05-07 21:38:03,200 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #121: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25925925925925924, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.12, '(min, 1)': 0.46, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:38:03,200 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:03,201 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320870738735006
2024-05-07 21:38:03,397 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #121: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.62, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.02, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.42, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-07 21:38:03,397 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:03,398 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320870738735006
2024-05-07 21:38:03,477 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #121: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5681818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 3)': 0.02, '(min, 0)': 0.16, '(min, 1)': 0.48, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:38:03,477 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:03,477 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320870738735006
2024-05-07 21:38:04,311 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #121: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5227272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.09, '(min, 1)': 0.55, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.02, '(rev, 7)': 0.01}}
2024-05-07 21:38:04,311 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:04,312 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320870738735006
2024-05-07 21:38:04,372 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #121: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.42, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:38:04,372 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:04,373 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4320870738735006
2024-05-07 21:38:04,578 - MainProcess - INFO - text_logger.py - 51 - Train epoch #121
2024-05-07 21:38:04,581 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.2795e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5099e-01, 0.0000e+00,
        1.3262e-01, 7.8415e-03, 3.9573e-01, 0.0000e+00, 4.9582e-03, 3.9673e-03,
        0.0000e+00, 0.0000e+00, 7.7075e-04, 1.1592e-03, 0.0000e+00, 0.0000e+00,
        4.3445e-04, 1.7999e-04, 0.0000e+00, 0.0000e+00, 3.7306e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.3765e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5765e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3785e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0474e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.7736e-05, 0.0000e+00, 0.0000e+00])  tensor([1.4721e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2535e-01, 0.0000e+00,
        2.0428e-01, 1.4718e-02, 9.9294e-02, 0.0000e+00, 1.4874e-02, 1.0292e-02,
        0.0000e+00, 0.0000e+00, 4.0486e-03, 5.8248e-03, 0.0000e+00, 0.0000e+00,
        2.9135e-03, 2.0922e-03, 0.0000e+00, 0.0000e+00, 2.8060e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.8120e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.1792e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0419e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2130e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.4380e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:38:04,601 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4325588422237288
2024-05-07 21:38:04,603 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.545450.02273
2024-05-07 21:38:04,657 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #122: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.11904761904761904, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.04, '(min, 0)': 0.04, '(min, 1)': 0.52, '(rev, 1)': 0.09, '(rev, 2)': 0.02}}
2024-05-07 21:38:04,657 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:04,658 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43241016735094023
2024-05-07 21:38:04,788 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #122: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.23, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-05-07 21:38:04,788 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:04,789 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43241016735094023
2024-05-07 21:38:05,813 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #122: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.33, '(min, 1)': 0.28}}
2024-05-07 21:38:05,813 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:05,814 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43241016735094023
2024-05-07 21:38:05,894 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #122: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.07, '(min, 0)': 0.09, '(min, 1)': 0.51, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:38:05,894 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:05,895 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43241016735094023
2024-05-07 21:38:06,563 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #122: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.45454545454545453, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.25, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:38:06,564 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:06,564 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43241016735094023
2024-05-07 21:38:07,083 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #122: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2978723404255319, 'length': 100, 'actions': {'(ado, 1)': 0.05, '(ado, 2)': 0.01, '(ado, 3)': 0.06, '(ado, 4)': 0.02, '(min, 0)': 0.24, '(min, 1)': 0.45, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.03}}
2024-05-07 21:38:07,084 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:07,084 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43241016735094023
2024-05-07 21:38:07,332 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #122: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 8, 4, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 8, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.39, '(rev, 1)': 0.09, '(rev, 2)': 0.07}}
2024-05-07 21:38:07,332 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:07,333 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43241016735094023
2024-05-07 21:38:07,403 - MainProcess - INFO - text_logger.py - 51 - Train epoch #122
2024-05-07 21:38:07,406 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.8404e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2960e-01, 0.0000e+00,
        1.3707e-01, 8.8902e-03, 4.0396e-01, 0.0000e+00, 8.2698e-03, 5.1861e-03,
        0.0000e+00, 0.0000e+00, 1.9456e-03, 2.6761e-03, 0.0000e+00, 0.0000e+00,
        7.5805e-04, 1.2412e-03, 0.0000e+00, 0.0000e+00, 1.1889e-04, 1.5335e-04,
        0.0000e+00, 0.0000e+00, 3.7736e-05, 3.8462e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 6.0606e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.3680e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1564e-01, 0.0000e+00,
        1.7541e-01, 1.5302e-02, 8.7922e-02, 0.0000e+00, 2.3564e-02, 1.2727e-02,
        0.0000e+00, 0.0000e+00, 7.4347e-03, 9.4182e-03, 0.0000e+00, 0.0000e+00,
        4.6439e-03, 6.7936e-03, 0.0000e+00, 0.0000e+00, 1.5368e-03, 2.0739e-03,
        0.0000e+00, 0.0000e+00, 8.4380e-04, 8.6003e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.3552e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:38:07,426 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4323166080056083
2024-05-07 21:38:07,428 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.350000.35000
2024-05-07 21:38:07,449 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #123: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.425531914893617, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.24, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-05-07 21:38:07,449 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:07,450 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4325588422237288
2024-05-07 21:38:07,519 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #123: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 7, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 8, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.225, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.35, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:38:07,519 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:07,520 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4325588422237288
2024-05-07 21:38:08,038 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #123: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.42, '(min, 1)': 0.19}}
2024-05-07 21:38:08,038 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:08,038 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4325588422237288
2024-05-07 21:38:08,740 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #123: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.21052631578947367, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 5)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.2, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:38:08,740 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:08,741 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4325588422237288
2024-05-07 21:38:09,269 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #123: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 6, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 4, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8048780487804879, 'length': 100, 'actions': {'(ado, 1)': 0.08, '(min, 0)': 0.37, '(min, 1)': 0.34, '(rev, 1)': 0.06, '(rev, 2)': 0.08, '(rev, 3)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:38:09,270 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:09,270 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4325588422237288
2024-05-07 21:38:09,511 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #123: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.14893617021276595, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(ado, 3)': 0.03, '(ado, 4)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.41, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:38:09,511 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:09,511 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4325588422237288
2024-05-07 21:38:11,296 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #123: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4791666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.43, '(rev, 1)': 0.02, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:38:11,296 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:11,297 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4325588422237288
2024-05-07 21:38:11,372 - MainProcess - INFO - text_logger.py - 51 - Train epoch #123
2024-05-07 21:38:11,375 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.5527e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8008e-01, 0.0000e+00,
        2.2261e-01, 6.2803e-03, 3.3727e-01, 0.0000e+00, 1.9757e-02, 3.9389e-03,
        0.0000e+00, 0.0000e+00, 7.0662e-03, 2.9097e-03, 0.0000e+00, 0.0000e+00,
        5.5444e-03, 3.2817e-03, 0.0000e+00, 0.0000e+00, 2.9639e-03, 2.7974e-04,
        0.0000e+00, 0.0000e+00, 2.7779e-03, 3.0450e-04, 0.0000e+00, 0.0000e+00,
        2.1365e-03, 3.8462e-05, 0.0000e+00, 0.0000e+00, 1.7828e-03, 3.8462e-05,
        0.0000e+00, 0.0000e+00, 8.2494e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2185e-04, 0.0000e+00, 0.0000e+00])  tensor([2.1132e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7829e-01, 0.0000e+00,
        2.4715e-01, 1.2980e-02, 1.4489e-01, 0.0000e+00, 3.7636e-02, 1.1131e-02,
        0.0000e+00, 0.0000e+00, 1.5035e-02, 9.2889e-03, 0.0000e+00, 0.0000e+00,
        1.2976e-02, 1.4571e-02, 0.0000e+00, 0.0000e+00, 9.0503e-03, 2.2291e-03,
        0.0000e+00, 0.0000e+00, 8.5983e-03, 2.7971e-03, 0.0000e+00, 0.0000e+00,
        7.1570e-03, 8.6003e-04, 0.0000e+00, 0.0000e+00, 6.0468e-03, 8.6003e-04,
        0.0000e+00, 0.0000e+00, 3.6620e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3871e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:38:11,395 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4318535404541543
2024-05-07 21:38:11,397 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.239580.23958
2024-05-07 21:38:11,436 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #124: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.32, '(min, 1)': 0.27}}
2024-05-07 21:38:11,436 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:11,437 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323166080056083
2024-05-07 21:38:11,450 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #124: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.52, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.4, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:38:11,451 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:11,451 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323166080056083
 not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43478260869565216, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(ado, 5)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.49, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.04, '(rev, 4)': 0.02, '(rev, 5)': 0.02}}
2024-05-07 21:38:11,452 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:11,452 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323166080056083
2024-05-07 21:38:12,747 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #124: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.4423076923076923, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.37, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:38:12,748 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:12,748 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323166080056083
2024-05-07 21:38:12,808 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #124: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.11320754716981132, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 4)': 0.03, '(ado, 7)': 0.02, '(min, 0)': 0.38, '(min, 1)': 0.33, '(rev, 1)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:38:12,809 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:12,809 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323166080056083
2024-05-07 21:38:12,990 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #124: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8043478260869565, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(min, 0)': 0.39, '(min, 1)': 0.28, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.02, '(rev, 6)': 0.01}}
2024-05-07 21:38:12,990 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:12,991 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323166080056083
2024-05-07 21:38:15,584 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #124: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 4, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(ado, 5)': 0.02, '(min, 0)': 0.46, '(min, 1)': 0.25}}
2024-05-07 21:38:15,584 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:15,585 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323166080056083
2024-05-07 21:38:15,655 - MainProcess - INFO - text_logger.py - 51 - Train epoch #124
2024-05-07 21:38:15,658 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([9.1564e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5916e-01, 0.0000e+00,
        2.2786e-01, 7.4732e-03, 3.4648e-01, 0.0000e+00, 1.9160e-02, 5.1545e-03,
        0.0000e+00, 0.0000e+00, 7.5725e-03, 3.9169e-03, 0.0000e+00, 0.0000e+00,
        6.0472e-03, 3.8426e-03, 0.0000e+00, 0.0000e+00, 3.3794e-03, 8.1958e-04,
        0.0000e+00, 0.0000e+00, 2.9014e-03, 6.5636e-04, 0.0000e+00, 0.0000e+00,
        2.1613e-03, 2.2711e-04, 0.0000e+00, 0.0000e+00, 1.7303e-03, 6.8622e-05,
        0.0000e+00, 0.0000e+00, 1.0082e-03, 6.8622e-05, 0.0000e+00, 0.0000e+00,
        3.1100e-04, 0.0000e+00, 0.0000e+00])  tensor([3.7421e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8511e-01, 0.0000e+00,
        2.8551e-01, 1.5029e-02, 1.6641e-01, 0.0000e+00, 3.4807e-02, 1.2520e-02,
        0.0000e+00, 0.0000e+00, 1.5012e-02, 1.0738e-02, 0.0000e+00, 0.0000e+00,
        1.3305e-02, 1.1183e-02, 0.0000e+00, 0.0000e+00, 9.3678e-03, 3.8335e-03,
        0.0000e+00, 0.0000e+00, 8.5829e-03, 3.5921e-03, 0.0000e+00, 0.0000e+00,
        7.0835e-03, 1.9345e-03, 0.0000e+00, 0.0000e+00, 5.8621e-03, 1.0859e-03,
        0.0000e+00, 0.0000e+00, 4.0597e-03, 1.0859e-03, 0.0000e+00, 0.0000e+00,
        2.6272e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:38:15,678 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43091130623603374
2024-05-07 21:38:15,681 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:38:15,688 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #125: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7659574468085106, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.14, '(min, 1)': 0.49, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:38:15,688 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:15,689 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318535404541543
2024-05-07 21:38:15,702 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #125: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.05, '(min, 0)': 0.42, '(min, 1)': 0.18, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 4)': 0.01}}
2024-05-07 21:38:15,702 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:15,703 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318535404541543
2024-05-07 21:38:15,734 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #125: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4166666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.38, '(rev, 1)': 0.04, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:38:15,734 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:15,734 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #125: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.3, '(min, 1)': 0.31}}
2024-05-07 21:38:15,734 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:15,735 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318535404541543
2024-05-07 21:38:15,735 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318535404541543
2024-05-07 21:38:15,778 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #125: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.04, '(min, 0)': 0.05, '(min, 1)': 0.55, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:38:15,778 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:15,779 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318535404541543
2024-05-07 21:38:15,808 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #125: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2708333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.19, '(rev, 1)': 0.02, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:38:15,808 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:15,809 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318535404541543
2024-05-07 21:38:17,728 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #125: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 2, 7, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.37, '(min, 1)': 0.24}}
2024-05-07 21:38:17,729 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:17,729 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318535404541543
2024-05-07 21:38:17,804 - MainProcess - INFO - text_logger.py - 51 - Train epoch #125
2024-05-07 21:38:17,807 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.1748e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4682e-01, 0.0000e+00,
        1.3068e-01, 9.2841e-03, 3.8847e-01, 0.0000e+00, 7.9411e-03, 5.1099e-03,
        0.0000e+00, 0.0000e+00, 2.2738e-03, 2.4805e-03, 0.0000e+00, 0.0000e+00,
        1.6538e-03, 1.7873e-03, 0.0000e+00, 0.0000e+00, 1.0801e-03, 3.7736e-05,
        0.0000e+00, 0.0000e+00, 7.9189e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.4362e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.3415e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.1376e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.0289e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2915e-01, 0.0000e+00,
        1.8738e-01, 1.5786e-02, 1.0242e-01, 0.0000e+00, 2.5086e-02, 1.1689e-02,
        0.0000e+00, 0.0000e+00, 9.4028e-03, 8.5287e-03, 0.0000e+00, 0.0000e+00,
        7.7678e-03, 7.9162e-03, 0.0000e+00, 0.0000e+00, 5.8380e-03, 8.4380e-04,
        0.0000e+00, 0.0000e+00, 4.7318e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.4712e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8004e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.9769e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:38:17,827 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4299690720179132
2024-05-07 21:38:17,830 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:38:18,056 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #126: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.45, '(min, 1)': 0.2}}
2024-05-07 21:38:18,057 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:18,057 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43091130623603374
2024-05-07 21:38:18,100 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #126: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35714285714285715, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(min, 0)': 0.15, '(min, 1)': 0.46, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:38:18,100 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:18,101 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43091130623603374
2024-05-07 21:38:18,283 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #126: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4375, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.14, '(min, 1)': 0.47, '(rev, 1)': 0.06, '(rev, 2)': 0.06, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:38:18,283 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:18,284 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43091130623603374
2024-05-07 21:38:18,285 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #126: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0),(ado, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/3', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.3, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:38:18,286 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:18,286 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43091130623603374
2024-05-07 21:38:18,387 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #126: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(min, 0)': 0.21, '(min, 1)': 0.4, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:38:18,387 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:18,388 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43091130623603374
2024-05-07 21:38:18,960 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #126: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.42, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:38:18,960 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:18,960 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43091130623603374
2024-05-07 21:38:20,025 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #126: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 3, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.38, '(min, 1)': 0.25}}
2024-05-07 21:38:20,025 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:20,026 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43091130623603374
2024-05-07 21:38:20,101 - MainProcess - INFO - text_logger.py - 51 - Train epoch #126
2024-05-07 21:38:20,104 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.2995e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4427e-01, 0.0000e+00,
        1.1021e-01, 8.1405e-03, 4.2517e-01, 0.0000e+00, 3.2171e-03, 4.1778e-03,
        0.0000e+00, 0.0000e+00, 7.8356e-04, 1.9810e-03, 0.0000e+00, 0.0000e+00,
        5.6338e-05, 1.6390e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3385e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2000e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7125e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.3373e-02, 0.0000e+00,
        1.4455e-01, 1.4191e-02, 6.7112e-02, 0.0000e+00, 1.0428e-02, 9.9807e-03,
        0.0000e+00, 0.0000e+00, 4.7205e-03, 7.3493e-03, 0.0000e+00, 0.0000e+00,
        1.2598e-03, 7.5232e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7345e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9984e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:38:20,124 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4290268377997926
2024-05-07 21:38:20,126 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:38:20,488 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #127: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.32, '(min, 1)': 0.28, '(rev, 1)': 0.09, '(rev, 2)': 0.07}}
2024-05-07 21:38:20,488 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:20,489 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4299690720179132
2024-05-07 21:38:20,691 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #127: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.27906976744186046, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.1, '(min, 1)': 0.49, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-05-07 21:38:20,691 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:20,692 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4299690720179132
2024-05-07 21:38:20,726 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #127: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 6, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 4, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(ado, 2)': 0.02, '(min, 0)': 0.52, '(min, 1)': 0.07}}
2024-05-07 21:38:20,726 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:20,727 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4299690720179132
2024-05-07 21:38:21,036 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #127: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4166666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.32, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:38:21,036 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:21,037 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4299690720179132
2024-05-07 21:38:21,783 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #127: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 3, 0, 0),(ado, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/3', 'revenue': 0.5416666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.35, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.02, '(rev, 8)': 0.01}}
2024-05-07 21:38:21,783 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:21,783 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4299690720179132
2024-05-07 21:38:22,333 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #127: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4791666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.45, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.02}}
2024-05-07 21:38:22,333 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:22,334 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4299690720179132
2024-05-07 21:38:23,189 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #127: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.2}}
2024-05-07 21:38:23,189 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:23,190 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4299690720179132
2024-05-07 21:38:23,256 - MainProcess - INFO - text_logger.py - 51 - Train epoch #127
2024-05-07 21:38:23,259 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.8715e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4234e-01, 0.0000e+00,
        1.6057e-01, 5.6637e-03, 3.7065e-01, 0.0000e+00, 7.9509e-03, 2.6170e-03,
        0.0000e+00, 0.0000e+00, 3.0132e-03, 1.3489e-03, 0.0000e+00, 0.0000e+00,
        2.0045e-03, 1.0113e-03, 0.0000e+00, 0.0000e+00, 1.0460e-03, 3.5209e-04,
        0.0000e+00, 0.0000e+00, 7.5377e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8445e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6856e-04, 7.6923e-05,
        0.0000e+00, 0.0000e+00, 1.1450e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.6364e-05, 0.0000e+00, 0.0000e+00])  tensor([2.0924e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3936e-01, 0.0000e+00,
        2.0800e-01, 1.1855e-02, 1.0442e-01, 0.0000e+00, 1.9879e-02, 7.5041e-03,
        0.0000e+00, 0.0000e+00, 9.8907e-03, 5.6533e-03, 0.0000e+00, 0.0000e+00,
        8.2859e-03, 5.3299e-03, 0.0000e+00, 0.0000e+00, 5.8687e-03, 3.3701e-03,
        0.0000e+00, 0.0000e+00, 4.7802e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.6563e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9050e-03, 1.7201e-03,
        0.0000e+00, 0.0000e+00, 1.4767e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.1312e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:38:23,283 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.428084603581672
2024-05-07 21:38:23,286 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:38:23,334 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #128: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.375, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(ado, 3)': 0.02, '(min, 0)': 0.27, '(min, 1)': 0.39, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 9)': 0.01}}
2024-05-07 21:38:23,334 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:23,335 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4290268377997926
2024-05-07 21:38:23,364 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #128: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.38, '(rev, 1)': 0.15, '(rev, 2)': 0.01}}
2024-05-07 21:38:23,364 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:23,365 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4290268377997926
2024-05-07 21:38:23,586 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #128: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6190476190476191, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.02, '(min, 0)': 0.35, '(min, 1)': 0.35, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:38:23,586 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:23,588 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4290268377997926
2024-05-07 21:38:24,274 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #128: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5128205128205128, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.02, '(min, 0)': 0.06, '(min, 1)': 0.55, '(rev, 1)': 0.17, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:38:24,275 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:24,275 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4290268377997926
2024-05-07 21:38:25,006 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #128: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8043478260869565, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.16, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 5)': 0.01}}
2024-05-07 21:38:25,006 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:25,006 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4290268377997926
2024-05-07 21:38:25,387 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #128: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.44, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:38:25,387 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:25,388 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4290268377997926
2024-05-07 21:38:26,248 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #128: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.43, '(min, 1)': 0.21}}
2024-05-07 21:38:26,249 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:26,249 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4290268377997926
2024-05-07 21:38:26,319 - MainProcess - INFO - text_logger.py - 51 - Train epoch #128
2024-05-07 21:38:26,322 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.8620e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8447e-01, 0.0000e+00,
        1.8030e-01, 8.6590e-03, 3.9124e-01, 0.0000e+00, 1.1451e-02, 5.7399e-03,
        0.0000e+00, 0.0000e+00, 4.0492e-03, 3.4836e-03, 0.0000e+00, 0.0000e+00,
        2.8122e-03, 3.6856e-03, 0.0000e+00, 0.0000e+00, 1.6681e-03, 3.1651e-04,
        0.0000e+00, 0.0000e+00, 1.1990e-03, 1.7305e-04, 0.0000e+00, 0.0000e+00,
        4.1241e-04, 8.9127e-05, 0.0000e+00, 0.0000e+00, 1.3779e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.0000e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.0000e-05, 0.0000e+00, 0.0000e+00])  tensor([2.5196e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3891e-01, 0.0000e+00,
        2.1639e-01, 1.6042e-02, 1.2397e-01, 0.0000e+00, 2.7069e-02, 1.1963e-02,
        0.0000e+00, 0.0000e+00, 1.1694e-02, 1.0244e-02, 0.0000e+00, 0.0000e+00,
        9.8904e-03, 1.2370e-02, 0.0000e+00, 0.0000e+00, 7.5107e-03, 2.3730e-03,
        0.0000e+00, 0.0000e+00, 6.1978e-03, 2.1643e-03, 0.0000e+00, 0.0000e+00,
        3.3336e-03, 1.4784e-03, 0.0000e+00, 0.0000e+00, 1.7844e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.9443e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7889e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:38:26,343 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4276206302331167
2024-05-07 21:38:26,345 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.239130.23913
2024-05-07 21:38:26,349 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #129: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40476190476190477, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.03, '(min, 0)': 0.29, '(min, 1)': 0.33, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:38:26,349 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:26,350 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.428084603581672
2024-05-07 21:38:26,397 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #129: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6458333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.38, '(min, 1)': 0.27, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.02, '(rev, 6)': 0.01}}
2024-05-07 21:38:26,397 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:26,398 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.428084603581672
2024-05-07 21:38:26,670 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #129: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10869565217391304, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.38, '(rev, 1)': 0.06, '(rev, 2)': 0.03}}
2024-05-07 21:38:26,670 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:26,670 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.428084603581672
2024-05-07 21:38:27,546 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #129: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.29545454545454547, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.05, '(ado, 3)': 0.01, '(min, 0)': 0.08, '(min, 1)': 0.53, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:38:27,546 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:27,546 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.428084603581672
2024-05-07 21:38:27,867 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #129: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.09, '(min, 1)': 0.52, '(rev, 1)': 0.1, '(rev, 2)': 0.01}}
2024-05-07 21:38:27,867 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:27,868 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.428084603581672
2024-05-07 21:38:28,512 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #129: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 3, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 3, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.48, '(min, 1)': 0.14}}
2024-05-07 21:38:28,512 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:28,512 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.428084603581672
2024-05-07 21:38:28,553 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #129: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.02, '(min, 0)': 0.43, '(min, 1)': 0.13, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:38:28,554 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:28,554 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.428084603581672
2024-05-07 21:38:28,773 - MainProcess - INFO - text_logger.py - 51 - Train epoch #129
2024-05-07 21:38:28,776 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.6150e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4825e-01, 0.0000e+00,
        1.5127e-01, 6.6155e-03, 3.6276e-01, 0.0000e+00, 8.7379e-03, 3.9967e-03,
        0.0000e+00, 0.0000e+00, 3.7452e-03, 2.6285e-03, 0.0000e+00, 0.0000e+00,
        3.0212e-03, 1.8784e-03, 0.0000e+00, 0.0000e+00, 2.2109e-03, 2.8347e-04,
        0.0000e+00, 0.0000e+00, 1.8601e-03, 1.5418e-04, 0.0000e+00, 0.0000e+00,
        1.4992e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2702e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.1936e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5714e-05, 0.0000e+00, 0.0000e+00])  tensor([2.4142e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4427e-01, 0.0000e+00,
        1.9772e-01, 1.3935e-02, 1.0807e-01, 0.0000e+00, 2.2684e-02, 1.1105e-02,
        0.0000e+00, 0.0000e+00, 1.2628e-02, 9.7335e-03, 0.0000e+00, 0.0000e+00,
        1.1162e-02, 8.3536e-03, 0.0000e+00, 0.0000e+00, 8.4066e-03, 2.6815e-03,
        0.0000e+00, 0.0000e+00, 7.3326e-03, 2.1361e-03, 0.0000e+00, 0.0000e+00,
        6.2409e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3442e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.0118e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.9860e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:38:28,796 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.427083157919758
2024-05-07 21:38:28,799 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.202380.20238
2024-05-07 21:38:28,963 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #130: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1388888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 3)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.1, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:38:28,964 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:28,964 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4276206302331167
2024-05-07 21:38:29,673 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #130: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5714285714285714, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.04, '(min, 0)': 0.23, '(min, 1)': 0.45, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:38:29,674 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:29,674 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4276206302331167
2024-05-07 21:38:29,861 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #130: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.08333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.29, '(rev, 1)': 0.06}}
2024-05-07 21:38:29,862 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:29,862 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4276206302331167
2024-05-07 21:38:29,918 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #130: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3404255319148936, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.06, '(rev, 1)': 0.05, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-05-07 21:38:29,919 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:29,919 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4276206302331167
2024-05-07 21:38:30,445 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #130: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.5333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.03, '(min, 0)': 0.47, '(min, 1)': 0.09, '(rev, 1)': 0.12, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:38:30,446 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:30,446 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4276206302331167
2024-05-07 21:38:31,134 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #130: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4418604651162791, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(min, 0)': 0.31, '(min, 1)': 0.31, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:38:31,134 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:31,135 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4276206302331167
2024-05-07 21:38:31,214 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #130: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 7, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 8, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.04, '(min, 0)': 0.13, '(min, 1)': 0.5, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:38:31,215 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:31,215 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4276206302331167
2024-05-07 21:38:31,343 - MainProcess - INFO - text_logger.py - 51 - Train epoch #130
2024-05-07 21:38:31,346 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.0499e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7823e-01, 0.0000e+00,
        1.7024e-01, 6.6323e-03, 3.9911e-01, 0.0000e+00, 1.4045e-02, 3.5631e-03,
        0.0000e+00, 0.0000e+00, 6.0884e-03, 2.3923e-03, 0.0000e+00, 0.0000e+00,
        5.2898e-03, 2.0088e-03, 0.0000e+00, 0.0000e+00, 3.6000e-03, 3.2895e-04,
        0.0000e+00, 0.0000e+00, 2.9504e-03, 2.6028e-04, 0.0000e+00, 0.0000e+00,
        2.3940e-03, 7.6923e-05, 0.0000e+00, 0.0000e+00, 1.8204e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.8587e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8865e-04, 0.0000e+00, 0.0000e+00])  tensor([2.3318e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5390e-01, 0.0000e+00,
        2.1764e-01, 1.3369e-02, 1.4520e-01, 0.0000e+00, 3.2716e-02, 1.0845e-02,
        0.0000e+00, 0.0000e+00, 1.6417e-02, 9.3805e-03, 0.0000e+00, 0.0000e+00,
        1.4741e-02, 9.0169e-03, 0.0000e+00, 0.0000e+00, 1.0509e-02, 2.4665e-03,
        0.0000e+00, 0.0000e+00, 9.0832e-03, 2.5697e-03, 0.0000e+00, 0.0000e+00,
        7.7961e-03, 1.7201e-03, 0.0000e+00, 0.0000e+00, 6.3507e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.6351e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7379e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:38:31,366 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4266798125905263
2024-05-07 21:38:31,368 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.269440.13056
2024-05-07 21:38:31,391 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #131: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.58, '(min, 1)': 0.06}}
2024-05-07 21:38:31,391 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:31,392 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.427083157919758
2024-05-07 21:38:32,246 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #131: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3125, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.41, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:38:32,246 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:32,247 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.427083157919758
2024-05-07 21:38:32,428 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #131: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.044444444444444446, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 9)': 0.01, '(min, 0)': 0.52, '(min, 1)': 0.11, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-05-07 21:38:32,428 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:32,429 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.427083157919758
2024-05-07 21:38:32,479 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #131: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1590909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.36, '(min, 1)': 0.3, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-05-07 21:38:32,479 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:32,480 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.427083157919758
2024-05-07 21:38:33,590 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #131: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.49, '(min, 1)': 0.13, '(rev, 1)': 0.01}}
2024-05-07 21:38:33,590 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:33,590 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.427083157919758
2024-05-07 21:38:33,709 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #131: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22916666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 8)': 0.02, '(min, 0)': 0.39, '(min, 1)': 0.27, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.03}}
2024-05-07 21:38:33,709 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:33,710 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.427083157919758
2024-05-07 21:38:34,551 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #131: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 5, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.9523809523809523, 'length': 100, 'actions': {'(ado, 1)': 0.09, '(ado, 3)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.21, '(rev, 1)': 0.12, '(rev, 2)': 0.03, '(rev, 3)': 0.04, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:38:34,551 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:34,552 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.427083157919758
2024-05-07 21:38:34,622 - MainProcess - INFO - text_logger.py - 51 - Train epoch #131
2024-05-07 21:38:34,625 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.5942e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.2670e-01,
         0.0000e+00,  4.0952e-01,  2.5105e-03,  1.7680e-01,  0.0000e+00,
         6.2959e-02,  1.2357e-03,  0.0000e+00,  0.0000e+00,  3.0890e-02,
         7.7158e-04,  0.0000e+00,  0.0000e+00,  2.7290e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  2.0133e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  1.6927e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         1.1409e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  8.5219e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.7018e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.3077e-04,  0.0000e+00,  0.0000e+00])  tensor([1.3729, 0.0000, 0.0000, 0.0000, 0.2249, 0.0000, 0.2555, 0.0085, 0.1656,
        0.0000, 0.0498, 0.0053, 0.0000, 0.0000, 0.0263, 0.0042, 0.0000, 0.0000,
        0.0240, 0.0000, 0.0000, 0.0000, 0.0186, 0.0000, 0.0000, 0.0000, 0.0167,
        0.0000, 0.0000, 0.0000, 0.0139, 0.0000, 0.0000, 0.0000, 0.0116, 0.0000,
        0.0000, 0.0000, 0.0075, 0.0000, 0.0000, 0.0000, 0.0032, 0.0000, 0.0000]) (500)
2024-05-07 21:38:34,644 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4266899593247867
2024-05-07 21:38:34,646 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.476190.47619
2024-05-07 21:38:34,659 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #132: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(min, 0)': 0.5, '(min, 1)': 0.09, '(rev, 1)': 0.06, '(rev, 2)': 0.07}}
2024-05-07 21:38:34,659 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:34,660 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266798125905263
2024-05-07 21:38:34,700 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #132: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.42, '(min, 1)': 0.2}}
}
2024-05-07 21:38:34,700 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:34,700 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:34,701 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266798125905263
2024-05-07 21:38:34,701 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266798125905263
2024-05-07 21:38:36,016 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #132: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.725, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 3)': 0.02, '(min, 0)': 0.3, '(min, 1)': 0.36, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.04, '(rev, 4)': 0.02}}
2024-05-07 21:38:36,016 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:36,017 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266798125905263
2024-05-07 21:38:36,022 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #132: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.11538461538461539, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.05, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.13, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:38:36,023 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:36,023 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266798125905263
2024-05-07 21:38:36,186 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #132: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17391304347826086, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 3)': 0.05, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.37, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:38:36,186 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:36,187 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266798125905263
2024-05-07 21:38:36,898 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #132: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.33, '(min, 1)': 0.25}}
2024-05-07 21:38:36,898 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:36,899 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266798125905263
2024-05-07 21:38:36,973 - MainProcess - INFO - text_logger.py - 51 - Train epoch #132
2024-05-07 21:38:36,976 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.3048e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.1992e-01,
         0.0000e+00,  2.1459e-01,  6.5803e-03,  3.5190e-01,  0.0000e+00,
         3.4513e-02,  3.2846e-03,  0.0000e+00,  0.0000e+00,  1.6990e-02,
         2.5261e-03,  0.0000e+00,  0.0000e+00,  1.3699e-02,  1.9375e-03,
         0.0000e+00,  0.0000e+00,  1.0716e-02,  1.7470e-04,  0.0000e+00,
         0.0000e+00,  9.4048e-03,  6.2261e-05,  0.0000e+00,  0.0000e+00,
         8.0637e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.1301e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.3384e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  1.7181e-04,  0.0000e+00,  0.0000e+00])  tensor([2.5062e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8023e-01, 0.0000e+00,
        2.1744e-01, 1.4223e-02, 1.8249e-01, 0.0000e+00, 5.4164e-02, 1.0665e-02,
        0.0000e+00, 0.0000e+00, 2.8380e-02, 1.0745e-02, 0.0000e+00, 0.0000e+00,
        2.4315e-02, 9.9166e-03, 0.0000e+00, 0.0000e+00, 1.8899e-02, 2.0692e-03,
        0.0000e+00, 0.0000e+00, 1.6671e-02, 9.8915e-04, 0.0000e+00, 0.0000e+00,
        1.4877e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0167e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.0773e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7300e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:38:36,996 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.42574772510666603
2024-05-07 21:38:36,998 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:38:37,021 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #133: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.49, '(min, 1)': 0.08}}
2024-05-07 21:38:37,021 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:37,022 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266899593247867
2024-05-07 21:38:37,163 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #133: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 3, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.23, '(rev, 1)': 0.01}}
2024-05-07 21:38:37,163 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:37,163 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266899593247867
2024-05-07 21:38:37,393 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #133: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 0, 1, 0),(rev, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '11/1', 'revenue': 0.6976744186046512, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.39, '(rev, 1)': 0.16, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:38:37,394 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:37,394 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266899593247867
2024-05-07 21:38:38,735 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #133: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.3684210526315789, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(min, 0)': 0.5, '(min, 1)': 0.13, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:38:38,735 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:38,736 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266899593247867
2024-05-07 21:38:39,446 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #133: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.02, '(ado, 3)': 0.04, '(ado, 5)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.47, '(rev, 1)': 0.14, '(rev, 2)': 0.01}}
2024-05-07 21:38:39,446 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:39,446 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266899593247867
2024-05-07 21:38:39,615 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #133: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3023255813953488, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.23, '(min, 1)': 0.38, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:38:39,616 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:39,616 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266899593247867
2024-05-07 21:38:40,217 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #133: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 7)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.15}}
2024-05-07 21:38:40,217 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:40,218 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4266899593247867
2024-05-07 21:38:40,293 - MainProcess - INFO - text_logger.py - 51 - Train epoch #133
2024-05-07 21:38:40,296 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.3374e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3973e-01, 0.0000e+00,
        2.1102e-01, 7.7528e-03, 3.5380e-01, 0.0000e+00, 2.1735e-02, 8.2866e-03,
        0.0000e+00, 0.0000e+00, 1.0643e-02, 7.7164e-03, 0.0000e+00, 0.0000e+00,
        8.8872e-03, 5.1656e-03, 0.0000e+00, 0.0000e+00, 7.6764e-03, 2.3801e-04,
        0.0000e+00, 0.0000e+00, 6.9228e-03, 7.2066e-05, 0.0000e+00, 0.0000e+00,
        4.9209e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0699e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2293e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3125e-04, 0.0000e+00, 0.0000e+00])  tensor([2.3357e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6691e-01, 0.0000e+00,
        2.1804e-01, 1.5835e-02, 1.6055e-01, 0.0000e+00, 4.0121e-02, 1.9716e-02,
        0.0000e+00, 0.0000e+00, 2.1407e-02, 2.5038e-02, 0.0000e+00, 0.0000e+00,
        1.9015e-02, 1.9039e-02, 0.0000e+00, 0.0000e+00, 1.7050e-02, 2.0248e-03,
        0.0000e+00, 0.0000e+00, 1.5907e-02, 1.1484e-03, 0.0000e+00, 0.0000e+00,
        1.2248e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0759e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.0353e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4833e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:38:40,336 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4248054908885455
2024-05-07 21:38:40,339 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:38:40,372 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #134: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.5, '(min, 1)': 0.11}}
2024-05-07 21:38:40,372 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:40,373 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42574772510666603
2024-05-07 21:38:40,388 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #134: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.19444444444444445, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.27, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:38:40,388 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:40,389 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42574772510666603
2024-05-07 21:38:40,406 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #134: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.15, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 9)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.24, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-05-07 21:38:40,406 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:40,407 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42574772510666603
2024-05-07 21:38:42,566 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #134: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 3, 7, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 3, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24390243902439024, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.49, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-05-07 21:38:42,567 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:42,567 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42574772510666603
2024-05-07 21:38:42,570 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #134: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.29, '(min, 1)': 0.28}}
2024-05-07 21:38:42,570 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:42,571 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42574772510666603
2024-05-07 21:38:42,713 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #134: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 4, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 6, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.02127659574468085, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.02, '(ado, 9)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.29, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:38:42,713 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:42,714 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42574772510666603
2024-05-07 21:38:42,817 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #134: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 6, 9, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 6, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5263157894736842, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.27, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:38:42,818 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:42,818 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42574772510666603
2024-05-07 21:38:43,025 - MainProcess - INFO - text_logger.py - 51 - Train epoch #134
2024-05-07 21:38:43,028 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.8384e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4546e-01, 0.0000e+00,
        3.3795e-01, 4.2050e-03, 2.4580e-01, 0.0000e+00, 5.7459e-02, 4.0435e-03,
        0.0000e+00, 0.0000e+00, 2.4811e-02, 3.3477e-03, 0.0000e+00, 0.0000e+00,
        2.0374e-02, 2.4528e-03, 0.0000e+00, 0.0000e+00, 1.7247e-02, 1.3903e-04,
        0.0000e+00, 0.0000e+00, 1.5198e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1467e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.4610e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.2835e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.0678e-04, 0.0000e+00, 0.0000e+00])  tensor([2.2513e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9801e-01, 0.0000e+00,
        2.5094e-01, 1.2148e-02, 1.9180e-01, 0.0000e+00, 5.9159e-02, 1.2980e-02,
        0.0000e+00, 0.0000e+00, 2.8584e-02, 1.2599e-02, 0.0000e+00, 0.0000e+00,
        2.4843e-02, 1.1392e-02, 0.0000e+00, 0.0000e+00, 2.2180e-02, 1.8099e-03,
        0.0000e+00, 0.0000e+00, 2.0506e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7562e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3946e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.9388e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3043e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:38:43,051 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4238632566704249
2024-05-07 21:38:43,053 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:38:43,073 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #135: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17777777777777778, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:38:43,073 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:43,074 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4248054908885455
2024-05-07 21:38:43,088 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #135: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.48, '(min, 1)': 0.14}}
2024-05-07 21:38:43,089 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:43,089 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4248054908885455
2024-05-07 21:38:43,775 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #135: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6976744186046512, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.35, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-05-07 21:38:43,775 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:43,776 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4248054908885455
2024-05-07 21:38:44,901 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #135: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.48, '(min, 1)': 0.14}}
2024-05-07 21:38:44,901 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:44,902 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4248054908885455
2024-05-07 21:38:45,153 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #135: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.14893617021276595, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 7)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.28, '(rev, 1)': 0.02, '(rev, 6)': 0.01}}
2024-05-07 21:38:45,153 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:45,154 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4248054908885455
2024-05-07 21:38:45,332 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #135: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0784313725490196, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.14, '(rev, 1)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:38:45,333 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:45,333 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4248054908885455
2024-05-07 21:38:46,420 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #135: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7115384615384616, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.14, '(min, 1)': 0.5, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-05-07 21:38:46,420 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:46,420 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4248054908885455
2024-05-07 21:38:46,628 - MainProcess - INFO - text_logger.py - 51 - Train epoch #135
2024-05-07 21:38:46,631 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.3978e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4828e-01, 0.0000e+00,
        3.0883e-01, 5.2644e-03, 2.6643e-01, 0.0000e+00, 4.4209e-02, 3.9623e-03,
        0.0000e+00, 0.0000e+00, 2.8125e-02, 2.6784e-03, 0.0000e+00, 0.0000e+00,
        2.2716e-02, 1.0164e-03, 0.0000e+00, 0.0000e+00, 1.9744e-02, 1.1333e-04,
        0.0000e+00, 0.0000e+00, 1.7966e-02, 7.1429e-05, 0.0000e+00, 0.0000e+00,
        1.5731e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8865e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.2025e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.7635e-04, 0.0000e+00, 0.0000e+00])  tensor([2.6810e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9311e-01, 0.0000e+00,
        2.4081e-01, 1.3227e-02, 2.0485e-01, 0.0000e+00, 4.7975e-02, 1.1308e-02,
        0.0000e+00, 0.0000e+00, 3.3079e-02, 9.0925e-03, 0.0000e+00, 0.0000e+00,
        2.7781e-02, 6.1008e-03, 0.0000e+00, 0.0000e+00, 2.4731e-02, 1.9365e-03,
        0.0000e+00, 0.0000e+00, 2.2680e-02, 1.5972e-03, 0.0000e+00, 0.0000e+00,
        2.0095e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4605e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.7165e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5885e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:38:46,654 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.42292102245230434
2024-05-07 21:38:46,657 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:38:46,675 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #136: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.45, '(min, 1)': 0.2}}
2024-05-07 21:38:46,675 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:46,676 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4238632566704249
2024-05-07 21:38:46,723 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #136: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.44680851063829785, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.15, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:38:46,723 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:46,724 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4238632566704249
2024-05-07 21:38:47,171 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #136: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.23333333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(ado, 9)': 0.02, '(min, 0)': 0.41, '(min, 1)': 0.22, '(rev, 1)': 0.02, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-05-07 21:38:47,172 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:47,172 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4238632566704249
2024-05-07 21:38:47,802 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #136: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 4)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.11, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:38:47,802 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:47,803 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4238632566704249
2024-05-07 21:38:47,831 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #136: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.47619047619047616, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.34, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:38:47,831 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:47,832 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4238632566704249
2024-05-07 21:38:48,618 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #136: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(ado, 7)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.18}}
2024-05-07 21:38:48,618 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:48,619 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4238632566704249
2024-05-07 21:38:49,088 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #136: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 6, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6111111111111112, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.35, '(rev, 1)': 0.12, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:38:49,088 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:49,088 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4238632566704249
2024-05-07 21:38:49,293 - MainProcess - INFO - text_logger.py - 51 - Train epoch #136
2024-05-07 21:38:49,296 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.1528e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4231e-01, 0.0000e+00,
        2.0358e-01, 7.2246e-03, 3.4289e-01, 0.0000e+00, 2.6765e-02, 7.5528e-03,
        0.0000e+00, 0.0000e+00, 1.3583e-02, 6.2323e-03, 0.0000e+00, 0.0000e+00,
        1.1580e-02, 4.6583e-03, 0.0000e+00, 0.0000e+00, 9.1712e-03, 4.3432e-04,
        0.0000e+00, 0.0000e+00, 8.7522e-03, 5.4054e-05, 0.0000e+00, 0.0000e+00,
        7.2265e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0496e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.3377e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.9571e-04, 0.0000e+00, 0.0000e+00])  tensor([2.0924e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6680e-01, 0.0000e+00,
        1.9073e-01, 1.4794e-02, 1.6065e-01, 0.0000e+00, 4.9397e-02, 1.5709e-02,
        0.0000e+00, 0.0000e+00, 2.7653e-02, 1.8118e-02, 0.0000e+00, 0.0000e+00,
        2.5301e-02, 1.6459e-02, 0.0000e+00, 0.0000e+00, 2.0344e-02, 3.2828e-03,
        0.0000e+00, 0.0000e+00, 1.9684e-02, 1.2087e-03, 0.0000e+00, 0.0000e+00,
        1.6469e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1930e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.0765e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.1177e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:38:49,316 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.42197878823418383
2024-05-07 21:38:49,319 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:38:49,357 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #137: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.56, '(min, 1)': 0.06}}
2024-05-07 21:38:49,358 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:49,358 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42292102245230434
2024-05-07 21:38:49,658 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #137: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.16, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:38:49,659 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:49,659 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42292102245230434
2024-05-07 21:38:50,306 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #137: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7948717948717948, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(min, 0)': 0.18, '(min, 1)': 0.45, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.03}}
2024-05-07 21:38:50,307 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:50,307 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42292102245230434
2024-05-07 21:38:50,316 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #137: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 4, 7, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 5, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3684210526315789, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 5)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.37, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-07 21:38:50,316 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:50,317 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42292102245230434
2024-05-07 21:38:50,465 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #137: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.31, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:38:50,465 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:50,466 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42292102245230434
2024-05-07 21:38:50,977 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #137: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.52, '(min, 1)': 0.07}}
2024-05-07 21:38:50,977 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:50,978 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42292102245230434
2024-05-07 21:38:51,566 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #137: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 4)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.23, '(rev, 1)': 0.01}}
2024-05-07 21:38:51,566 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:51,567 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42292102245230434
2024-05-07 21:38:51,776 - MainProcess - INFO - text_logger.py - 51 - Train epoch #137
2024-05-07 21:38:51,779 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.8674e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1105e-01, 0.0000e+00,
        2.5110e-01, 5.9614e-03, 3.1957e-01, 0.0000e+00, 2.8922e-02, 4.5877e-03,
        0.0000e+00, 0.0000e+00, 1.7229e-02, 3.7805e-03, 0.0000e+00, 0.0000e+00,
        1.3958e-02, 2.3958e-03, 0.0000e+00, 0.0000e+00, 1.2725e-02, 1.1774e-04,
        0.0000e+00, 0.0000e+00, 1.1176e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.5872e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8826e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.6920e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7440e-04, 0.0000e+00, 0.0000e+00])  tensor([1.9167e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8288e-01, 0.0000e+00,
        2.3351e-01, 1.3550e-02, 1.8426e-01, 0.0000e+00, 4.2745e-02, 1.2814e-02,
        0.0000e+00, 0.0000e+00, 2.7498e-02, 1.3621e-02, 0.0000e+00, 0.0000e+00,
        2.2925e-02, 1.0088e-02, 0.0000e+00, 0.0000e+00, 2.1574e-02, 1.5175e-03,
        0.0000e+00, 0.0000e+00, 1.9582e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7868e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2846e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.7453e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.1718e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:38:51,799 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.42103655401606316
2024-05-07 21:38:51,801 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:38:52,217 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #138: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 9)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.46, '(rev, 1)': 0.06, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:38:52,217 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:52,218 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42197878823418383
2024-05-07 21:38:52,887 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #138: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(ado, 6)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 3, 0, 0)', 'reward_ratio': '0/6', 'revenue': 0.4318181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 6)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.16, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:38:52,887 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:52,888 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42197878823418383
2024-05-07 21:38:53,284 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #138: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.4, '(min, 1)': 0.21}}
2024-05-07 21:38:53,284 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:53,285 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42197878823418383
2024-05-07 21:38:53,577 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #138: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.2830188679245283, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.24, '(rev, 1)': 0.04, '(rev, 2)': 0.01}}
2024-05-07 21:38:53,577 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:53,578 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42197878823418383
2024-05-07 21:38:53,817 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #138: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.32653061224489793, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.3, '(rev, 1)': 0.01, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:38:53,818 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:53,818 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42197878823418383
2024-05-07 21:38:54,009 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #138: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.58, '(min, 1)': 0.08, '(rev, 1)': 0.01}}
2024-05-07 21:38:54,009 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:54,010 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42197878823418383
2024-05-07 21:38:54,127 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #138: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.25}}
2024-05-07 21:38:54,128 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:54,128 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42197878823418383
2024-05-07 21:38:54,214 - MainProcess - INFO - text_logger.py - 51 - Train epoch #138
2024-05-07 21:38:54,217 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.2208e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.3518e-01,
         0.0000e+00,  2.7444e-01,  3.1202e-03,  2.3519e-01,  0.0000e+00,
         6.3325e-02,  1.6597e-03,  0.0000e+00,  0.0000e+00,  4.1458e-02,
         7.7611e-04,  0.0000e+00,  0.0000e+00,  3.6244e-02,  4.7647e-04,
         0.0000e+00,  0.0000e+00,  3.2952e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  2.7602e-02,  7.1429e-05,  0.0000e+00,  0.0000e+00,
         2.5820e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.6643e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.3335e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  7.1369e-04,  0.0000e+00,  0.0000e+00])  tensor([1.8078e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9683e-01, 0.0000e+00,
        1.8608e-01, 9.5051e-03, 1.9759e-01, 0.0000e+00, 5.6890e-02, 7.2867e-03,
        0.0000e+00, 0.0000e+00, 3.8961e-02, 5.6608e-03, 0.0000e+00, 0.0000e+00,
        3.5396e-02, 4.1608e-03, 0.0000e+00, 0.0000e+00, 3.3341e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.9394e-02, 1.5972e-03, 0.0000e+00, 0.0000e+00,
        2.9014e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0164e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.3067e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.3824e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:38:54,236 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4200943197979426
2024-05-07 21:38:54,239 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:38:54,959 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #139: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.03}}
2024-05-07 21:38:54,959 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:54,960 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42103655401606316
2024-05-07 21:38:55,461 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #139: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.2, '(rev, 1)': 0.01}}
2024-05-07 21:38:55,461 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:55,462 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42103655401606316
2024-05-07 21:38:55,545 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #139: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.57, '(min, 1)': 0.03}}
2024-05-07 21:38:55,546 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:55,546 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42103655401606316
2024-05-07 21:38:56,473 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #139: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.47, '(min, 1)': 0.14}}
2024-05-07 21:38:56,473 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:56,474 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42103655401606316
2024-05-07 21:38:56,478 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #139: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.18604651162790697, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.15, '(rev, 1)': 0.06, '(rev, 2)': 0.04}}
2024-05-07 21:38:56,478 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:56,478 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42103655401606316
2024-05-07 21:38:56,790 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #139: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.23404255319148937, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 8)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.17, '(rev, 1)': 0.05, '(rev, 2)': 0.04}}
2024-05-07 21:38:56,790 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:56,791 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42103655401606316
2024-05-07 21:38:57,252 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #139: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3076923076923077, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.22, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:38:57,252 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:57,252 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.42103655401606316
2024-05-07 21:38:57,463 - MainProcess - INFO - text_logger.py - 51 - Train epoch #139
2024-05-07 21:38:57,466 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.0141e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9014e-01, 0.0000e+00,
        2.6981e-01, 5.2293e-03, 2.9283e-01, 0.0000e+00, 3.8843e-02, 3.4740e-03,
        0.0000e+00, 0.0000e+00, 2.3052e-02, 2.6448e-03, 0.0000e+00, 0.0000e+00,
        1.8557e-02, 1.3080e-03, 0.0000e+00, 0.0000e+00, 1.5940e-02, 2.4143e-04,
        0.0000e+00, 0.0000e+00, 1.4052e-02, 1.3164e-04, 0.0000e+00, 0.0000e+00,
        1.2033e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.2183e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.3338e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6628e-04, 0.0000e+00, 0.0000e+00])  tensor([1.9598e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9505e-01, 0.0000e+00,
        2.4274e-01, 1.2688e-02, 1.9504e-01, 0.0000e+00, 4.8336e-02, 1.0400e-02,
        0.0000e+00, 0.0000e+00, 3.0533e-02, 1.1353e-02, 0.0000e+00, 0.0000e+00,
        2.6291e-02, 7.0550e-03, 0.0000e+00, 0.0000e+00, 2.4008e-02, 2.3485e-03,
        0.0000e+00, 0.0000e+00, 2.2360e-02, 1.4726e-03, 0.0000e+00, 0.0000e+00,
        2.0109e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6435e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.0205e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6758e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:38:57,488 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.41915208557982203
2024-05-07 21:38:57,490 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:38:57,494 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #140: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.21739130434782608, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(min, 0)': 0.5, '(min, 1)': 0.09, '(rev, 1)': 0.06, '(rev, 2)': 0.05}}
2024-05-07 21:38:57,494 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:57,495 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4200943197979426
2024-05-07 21:38:59,051 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #140: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.44, '(min, 1)': 0.31, '(rev, 1)': 0.01}}
2024-05-07 21:38:59,051 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:59,051 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4200943197979426
2024-05-07 21:38:59,104 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #140: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 6, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 7, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2972972972972973, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.37, '(rev, 1)': 0.06, '(rev, 2)': 0.05}}
2024-05-07 21:38:59,104 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:59,105 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4200943197979426
2024-05-07 21:38:59,485 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #140: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.08, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.47, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:38:59,486 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:59,486 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4200943197979426
2024-05-07 21:38:59,563 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #140: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.33, '(rev, 1)': 0.04, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:38:59,563 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:59,563 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4200943197979426
2024-05-07 21:38:59,624 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #140: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.02564102564102564, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.52, '(min, 1)': 0.09, '(rev, 1)': 0.01}}
2024-05-07 21:38:59,624 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:59,625 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4200943197979426
2024-05-07 21:38:59,816 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #140: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.34, '(rev, 1)': 0.04, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:38:59,816 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:38:59,817 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4200943197979426
2024-05-07 21:39:00,031 - MainProcess - INFO - text_logger.py - 51 - Train epoch #140
2024-05-07 21:39:00,034 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.6362e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0083e-01, 0.0000e+00,
        2.0344e-01, 6.3883e-03, 3.1002e-01, 0.0000e+00, 4.9185e-02, 3.7111e-03,
        0.0000e+00, 0.0000e+00, 2.7737e-02, 2.8420e-03, 0.0000e+00, 0.0000e+00,
        2.4301e-02, 2.4362e-03, 0.0000e+00, 0.0000e+00, 2.1381e-02, 1.6987e-04,
        0.0000e+00, 0.0000e+00, 1.7757e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6215e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0779e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.5101e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.0517e-04, 0.0000e+00, 0.0000e+00])  tensor([1.6505, 0.0000, 0.0000, 0.0000, 0.1897, 0.0000, 0.1809, 0.0141, 0.1894,
        0.0000, 0.0639, 0.0117, 0.0000, 0.0000, 0.0381, 0.0131, 0.0000, 0.0000,
        0.0356, 0.0114, 0.0000, 0.0000, 0.0334, 0.0020, 0.0000, 0.0000, 0.0293,
        0.0000, 0.0000, 0.0000, 0.0283, 0.0000, 0.0000, 0.0000, 0.0193, 0.0000,
        0.0000, 0.0000, 0.0075, 0.0000, 0.0000, 0.0000, 0.0023, 0.0000, 0.0000]) (500)
2024-05-07 21:39:00,054 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.41848549238734256
2024-05-07 21:39:00,057 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.137820.11218
2024-05-07 21:39:00,874 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #141: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 5, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6097560975609756, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(min, 0)': 0.15, '(min, 1)': 0.47, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:39:00,874 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:00,875 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41915208557982203
2024-05-07 21:39:01,638 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #141: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10638297872340426, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 9)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.17, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:39:01,638 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:01,639 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41915208557982203
2024-05-07 21:39:01,860 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #141: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 3, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.44, '(min, 1)': 0.17}}
2024-05-07 21:39:01,860 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:01,861 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41915208557982203
2024-05-07 21:39:02,372 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #141: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6136363636363636, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(min, 0)': 0.14, '(min, 1)': 0.46, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:39:02,372 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:02,373 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41915208557982203
2024-05-07 21:39:02,536 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #141: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1875, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.16, '(rev, 1)': 0.08, '(rev, 2)': 0.04}}
2024-05-07 21:39:02,536 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:02,537 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41915208557982203
2024-05-07 21:39:03,097 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #141: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.21818181818181817, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.04, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.42, '(rev, 1)': 0.03, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:39:03,097 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:03,098 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41915208557982203
2024-05-07 21:39:03,709 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #141: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.2, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:39:03,709 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:03,710 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41915208557982203
2024-05-07 21:39:03,779 - MainProcess - INFO - text_logger.py - 51 - Train epoch #141
2024-05-07 21:39:03,782 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.9417e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4688e-01, 0.0000e+00,
        2.0225e-01, 6.9166e-03, 3.4418e-01, 0.0000e+00, 2.3317e-02, 3.5633e-03,
        0.0000e+00, 0.0000e+00, 1.5635e-02, 2.1161e-03, 0.0000e+00, 0.0000e+00,
        1.2962e-02, 1.2358e-03, 0.0000e+00, 0.0000e+00, 1.2098e-02, 2.2684e-04,
        0.0000e+00, 0.0000e+00, 9.9228e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.2827e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3079e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.8549e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5212e-04, 0.0000e+00, 0.0000e+00])  tensor([1.8619, 0.0000, 0.0000, 0.0000, 0.1782, 0.0000, 0.2130, 0.0145, 0.1743,
        0.0000, 0.0394, 0.0112, 0.0000, 0.0000, 0.0292, 0.0108, 0.0000, 0.0000,
        0.0257, 0.0074, 0.0000, 0.0000, 0.0245, 0.0026, 0.0000, 0.0000, 0.0208,
        0.0000, 0.0000, 0.0000, 0.0197, 0.0000, 0.0000, 0.0000, 0.0158, 0.0000,
        0.0000, 0.0000, 0.0062, 0.0000, 0.0000, 0.0000, 0.0020, 0.0000, 0.0000]) (500)
2024-05-07 21:39:03,802 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.41805436928033307
2024-05-07 21:39:03,804 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.255560.25556
2024-05-07 21:39:03,827 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #142: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37037037037037035, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.03, '(ado, 9)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.14, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:39:03,827 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:03,828 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41848549238734256
2024-05-07 21:39:03,902 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #142: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.07, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-07 21:39:03,902 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:03,902 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41848549238734256
2024-05-07 21:39:04,083 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #142: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.48, '(min, 1)': 0.15}}
2024-05-07 21:39:04,083 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:04,084 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41848549238734256
2024-05-07 21:39:04,827 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #142: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.25, '(rev, 1)': 0.11, '(rev, 2)': 0.01, '(rev, 3)': 0.03}}
2024-05-07 21:39:04,827 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:04,827 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41848549238734256
2024-05-07 21:39:05,944 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #142: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 2, 1, 1),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.2608695652173913, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.19, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:39:05,945 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:05,945 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41848549238734256
2024-05-07 21:39:06,048 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #142: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.56, '(min, 1)': 0.01}}
2024-05-07 21:39:06,048 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:06,049 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41848549238734256
2024-05-07 21:39:06,294 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #142: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 5, 0, 1),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 5, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.17, '(min, 1)': 0.44, '(rev, 1)': 0.06, '(rev, 2)': 0.06}}
2024-05-07 21:39:06,294 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:06,295 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41848549238734256
2024-05-07 21:39:06,512 - MainProcess - INFO - text_logger.py - 51 - Train epoch #142
2024-05-07 21:39:06,516 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([9.2871e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1393e-01, 0.0000e+00,
        1.1417e-01, 7.7451e-03, 4.1860e-01, 0.0000e+00, 1.2916e-02, 3.4339e-03,
        0.0000e+00, 0.0000e+00, 7.0701e-03, 1.2815e-03, 0.0000e+00, 0.0000e+00,
        5.9288e-03, 4.0196e-04, 0.0000e+00, 0.0000e+00, 4.9667e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.7117e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.3057e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0809e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.2635e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4483e-05, 0.0000e+00, 0.0000e+00])  tensor([1.3769e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2447e-01, 0.0000e+00,
        1.4591e-01, 1.4839e-02, 1.2343e-01, 0.0000e+00, 3.5676e-02, 9.8066e-03,
        0.0000e+00, 0.0000e+00, 2.1961e-02, 6.5837e-03, 0.0000e+00, 0.0000e+00,
        2.0244e-02, 3.7448e-03, 0.0000e+00, 0.0000e+00, 1.8226e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.4471e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3790e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.2119e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.1913e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.7106e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:39:06,536 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.41711213506221245
2024-05-07 21:39:06,538 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:39:06,574 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #143: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 3, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 3, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.49, '(min, 1)': 0.13}}
2024-05-07 21:39:06,574 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:06,575 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41805436928033307
2024-05-07 21:39:07,166 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #143: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.46, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.13, '(rev, 1)': 0.11, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:39:07,166 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:07,166 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41805436928033307
2024-05-07 21:39:07,574 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #143: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 7, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1282051282051282, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.3, '(rev, 5)': 0.01}}
2024-05-07 21:39:07,574 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:07,575 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41805436928033307
2024-05-07 21:39:08,552 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #143: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.21951219512195122, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.22, '(rev, 1)': 0.07, '(rev, 2)': 0.04}}
2024-05-07 21:39:08,552 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:08,552 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41805436928033307
2024-05-07 21:39:08,707 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #143: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3404255319148936, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 9)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.39, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-05-07 21:39:08,707 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:08,707 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41805436928033307
2024-05-07 21:39:09,375 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #143: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 5, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2553191489361702, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.35, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 6)': 0.01}}
2024-05-07 21:39:09,376 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:09,376 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41805436928033307
2024-05-07 21:39:09,763 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #143: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.37, '(rev, 1)': 0.03, '(rev, 2)': 0.03}}
2024-05-07 21:39:09,763 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:09,764 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41805436928033307
2024-05-07 21:39:09,831 - MainProcess - INFO - text_logger.py - 51 - Train epoch #143
2024-05-07 21:39:09,834 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.4367e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3872e-01, 0.0000e+00,
        2.0018e-01, 5.6961e-03, 3.3868e-01, 0.0000e+00, 3.2642e-02, 2.3705e-03,
        0.0000e+00, 0.0000e+00, 2.0182e-02, 1.5493e-03, 0.0000e+00, 0.0000e+00,
        1.6231e-02, 1.0022e-03, 0.0000e+00, 0.0000e+00, 1.4174e-02, 1.2548e-04,
        0.0000e+00, 0.0000e+00, 1.0911e-02, 7.1429e-05, 0.0000e+00, 0.0000e+00,
        9.4563e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2378e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.6080e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6797e-04, 0.0000e+00, 0.0000e+00])  tensor([1.6451e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7809e-01, 0.0000e+00,
        2.0688e-01, 1.3590e-02, 1.7697e-01, 0.0000e+00, 5.0534e-02, 8.6905e-03,
        0.0000e+00, 0.0000e+00, 3.3943e-02, 7.3539e-03, 0.0000e+00, 0.0000e+00,
        2.9788e-02, 6.5778e-03, 0.0000e+00, 0.0000e+00, 2.7713e-02, 2.0011e-03,
        0.0000e+00, 0.0000e+00, 2.3230e-02, 1.5972e-03, 0.0000e+00, 0.0000e+00,
        2.1771e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5428e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.8532e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6973e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:39:09,854 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.41647899175318287
2024-05-07 21:39:09,857 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.154550.15455
2024-05-07 21:39:09,863 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #144: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.45, '(min, 0)': 0.42, '(min, 1)': 0.13}}
2024-05-07 21:39:09,863 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:09,864 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41711213506221245
2024-05-07 21:39:10,147 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #144: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 5)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.31, '(rev, 1)': 0.01, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:39:10,147 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:10,147 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41711213506221245
2024-05-07 21:39:10,489 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #144: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.65, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(min, 0)': 0.22, '(min, 1)': 0.41, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:39:10,490 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:10,490 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41711213506221245
2024-05-07 21:39:10,921 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #144: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 6)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.14}}
2024-05-07 21:39:10,922 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:10,922 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41711213506221245
2024-05-07 21:39:12,178 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #144: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.024390243902439025, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 9)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.2, '(rev, 1)': 0.02}}
2024-05-07 21:39:12,178 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:12,179 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41711213506221245
2024-05-07 21:39:12,259 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #144: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(min, 0)': 0.5, '(min, 1)': 0.16}}
2024-05-07 21:39:12,260 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:12,260 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41711213506221245
2024-05-07 21:39:13,156 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #144: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.52, '(min, 1)': 0.19, '(rev, 1)': 0.01}}
2024-05-07 21:39:13,156 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:13,156 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41711213506221245
2024-05-07 21:39:13,384 - MainProcess - INFO - text_logger.py - 51 - Train epoch #144
2024-05-07 21:39:13,387 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.3074e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.7883e-01,
         0.0000e+00,  3.2801e-01,  2.5755e-03,  1.8010e-01,  0.0000e+00,
         6.9948e-02,  1.7457e-03,  0.0000e+00,  0.0000e+00,  5.2827e-02,
         1.2128e-03,  0.0000e+00,  0.0000e+00,  4.5870e-02,  6.0014e-04,
         0.0000e+00,  0.0000e+00,  4.0756e-02,  7.4074e-05,  0.0000e+00,
         0.0000e+00,  3.4107e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.2038e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.4864e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  5.7115e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  7.3494e-04,  0.0000e+00,  0.0000e+00])  tensor([2.0438e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8490e-01, 0.0000e+00,
        1.9680e-01, 1.0139e-02, 1.9102e-01, 0.0000e+00, 4.8756e-02, 7.7043e-03,
        0.0000e+00, 0.0000e+00, 3.9203e-02, 6.6002e-03, 0.0000e+00, 0.0000e+00,
        3.5908e-02, 4.3085e-03, 0.0000e+00, 0.0000e+00, 3.3661e-02, 1.6563e-03,
        0.0000e+00, 0.0000e+00, 2.8872e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7981e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2055e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.6482e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4146e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:39:13,408 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4155367575350623
2024-05-07 21:39:13,411 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:39:13,416 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #145: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 7, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 7, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.48936170212765956, 'length': 100, 'actions': {'(ado, 1)': 0.04, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.36, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.03, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:39:13,416 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #145: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.55, '(min, 1)': 0.1}}
2024-05-07 21:39:13,416 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:13,416 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:13,417 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41647899175318287
2024-05-07 21:39:13,417 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41647899175318287
2024-05-07 21:39:13,448 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #145: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.58, '(min, 1)': 0.08}}
2024-05-07 21:39:13,449 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:13,449 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41647899175318287
2024-05-07 21:39:14,156 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #145: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 10)': 0.01, '(min, 0)': 0.61, '(min, 1)': 0.07}}
2024-05-07 21:39:14,156 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:14,156 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41647899175318287
2024-05-07 21:39:14,396 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #145: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.32, '(min, 1)': 0.31}}
2024-05-07 21:39:14,396 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:14,397 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41647899175318287
2024-05-07 21:39:15,536 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #145: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2682926829268293, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.28, '(rev, 1)': 0.01}}
2024-05-07 21:39:15,536 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:15,537 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41647899175318287
2024-05-07 21:39:15,837 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #145: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.18604651162790697, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.33, '(rev, 1)': 0.01, '(rev, 2)': 0.04}}
2024-05-07 21:39:15,837 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:15,838 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41647899175318287
2024-05-07 21:39:16,058 - MainProcess - INFO - text_logger.py - 51 - Train epoch #145
2024-05-07 21:39:16,061 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-7.1296e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2924e-01,
         0.0000e+00,  3.2166e-01,  1.9962e-03,  1.3337e-01,  0.0000e+00,
         1.0312e-01,  9.8649e-04,  0.0000e+00,  0.0000e+00,  6.8767e-02,
         4.5025e-04,  0.0000e+00,  0.0000e+00,  6.1879e-02,  1.6517e-04,
         0.0000e+00,  0.0000e+00,  5.5077e-02,  7.1429e-05,  0.0000e+00,
         0.0000e+00,  4.4419e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.9456e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.0135e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  7.7585e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  1.4573e-03,  0.0000e+00,  0.0000e+00])  tensor([1.4272, 0.0000, 0.0000, 0.0000, 0.1513, 0.0000, 0.1345, 0.0086, 0.1597,
        0.0000, 0.0495, 0.0057, 0.0000, 0.0000, 0.0358, 0.0035, 0.0000, 0.0000,
        0.0348, 0.0021, 0.0000, 0.0000, 0.0335, 0.0016, 0.0000, 0.0000, 0.0291,
        0.0000, 0.0000, 0.0000, 0.0278, 0.0000, 0.0000, 0.0000, 0.0219, 0.0000,
        0.0000, 0.0000, 0.0108, 0.0000, 0.0000, 0.0000, 0.0049, 0.0000, 0.0000]) (500)
2024-05-07 21:39:16,079 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.41459452331694174
2024-05-07 21:39:16,081 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:39:16,136 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #146: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.49, '(min, 1)': 0.08}}
2024-05-07 21:39:16,136 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #146: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.02, '(min, 0)': 0.45, '(min, 1)': 0.22}}
2024-05-07 21:39:16,136 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:16,136 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:16,137 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4155367575350623
2024-05-07 21:39:16,137 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4155367575350623
2024-05-07 21:39:16,729 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #146: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.51, '(min, 1)': 0.08}}
2024-05-07 21:39:16,729 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:16,730 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4155367575350623
2024-05-07 21:39:17,358 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #146: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.18, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:39:17,358 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:17,358 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4155367575350623
2024-05-07 21:39:17,443 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #146: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.23}}
2024-05-07 21:39:17,443 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:17,444 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4155367575350623
2024-05-07 21:39:18,339 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #146: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 4)': 0.01, '(ado, 7)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.61, '(min, 1)': 0.08}}
2024-05-07 21:39:18,339 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:18,340 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4155367575350623
2024-05-07 21:39:18,900 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #146: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.02, '(ado, 8)': 0.02, '(min, 0)': 0.48, '(min, 1)': 0.24, '(rev, 1)': 0.01}}
2024-05-07 21:39:18,900 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:18,900 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4155367575350623
2024-05-07 21:39:19,113 - MainProcess - INFO - text_logger.py - 51 - Train epoch #146
2024-05-07 21:39:19,116 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-4.5010e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4411e-01,
         0.0000e+00,  3.5800e-01,  1.0648e-03,  1.4846e-01,  0.0000e+00,
         8.1611e-02,  5.2349e-04,  0.0000e+00,  0.0000e+00,  6.0310e-02,
         1.9307e-04,  0.0000e+00,  0.0000e+00,  5.1730e-02,  7.1429e-05,
         0.0000e+00,  0.0000e+00,  4.6823e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  3.7948e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.4656e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.6576e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  6.8143e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  1.1101e-03,  0.0000e+00,  0.0000e+00])  tensor([1.9707e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6081e-01, 0.0000e+00,
        1.6090e-01, 7.1607e-03, 1.6738e-01, 0.0000e+00, 4.2326e-02, 3.7744e-03,
        0.0000e+00, 0.0000e+00, 3.3764e-02, 2.2417e-03, 0.0000e+00, 0.0000e+00,
        3.1772e-02, 1.5972e-03, 0.0000e+00, 0.0000e+00, 3.1148e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.7740e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7328e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3357e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0634e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.1742e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:39:19,136 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4136522890988211
2024-05-07 21:39:19,138 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:39:19,161 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #147: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.39, '(min, 1)': 0.19}}
2024-05-07 21:39:19,161 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:19,162 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41459452331694174
2024-05-07 21:39:19,176 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #147: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 5, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.13}}
2024-05-07 21:39:19,177 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:19,177 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41459452331694174
2024-05-07 21:39:19,974 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #147: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.11627906976744186, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.26, '(rev, 1)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:39:19,974 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:19,974 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41459452331694174
2024-05-07 21:39:20,229 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #147: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32653061224489793, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.14, '(rev, 6)': 0.01}}
2024-05-07 21:39:20,229 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:20,230 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41459452331694174
2024-05-07 21:39:20,263 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #147: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.29545454545454547, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.25, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:39:20,264 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:20,264 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41459452331694174
2024-05-07 21:39:21,238 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #147: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.28846153846153844, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 8)': 0.02, '(min, 0)': 0.41, '(min, 1)': 0.29, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 6)': 0.01}}
2024-05-07 21:39:21,238 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:21,239 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41459452331694174
2024-05-07 21:39:22,575 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #147: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 5, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0975609756097561, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.26, '(rev, 3)': 0.01}}
2024-05-07 21:39:22,577 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:22,577 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41459452331694174
2024-05-07 21:39:22,790 - MainProcess - INFO - text_logger.py - 51 - Train epoch #147
2024-05-07 21:39:22,793 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-6.0318e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.6513e-01,
         0.0000e+00,  2.8501e-01,  1.5497e-03,  1.7003e-01,  0.0000e+00,
         1.0215e-01,  1.8539e-03,  0.0000e+00,  0.0000e+00,  6.2745e-02,
         1.7886e-03,  0.0000e+00,  0.0000e+00,  5.5057e-02,  4.6168e-04,
         0.0000e+00,  0.0000e+00,  4.8059e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  3.9982e-02,  6.8966e-05,  0.0000e+00,  0.0000e+00,
         3.3653e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.5306e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  6.1652e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  9.8754e-04,  0.0000e+00,  0.0000e+00])  tensor([1.4239, 0.0000, 0.0000, 0.0000, 0.1659, 0.0000, 0.1329, 0.0075, 0.1671,
        0.0000, 0.0633, 0.0086, 0.0000, 0.0000, 0.0425, 0.0095, 0.0000, 0.0000,
        0.0406, 0.0043, 0.0000, 0.0000, 0.0374, 0.0000, 0.0000, 0.0000, 0.0333,
        0.0015, 0.0000, 0.0000, 0.0305, 0.0000, 0.0000, 0.0000, 0.0257, 0.0000,
        0.0000, 0.0000, 0.0110, 0.0000, 0.0000, 0.0000, 0.0040, 0.0000, 0.0000]) (500)
2024-05-07 21:39:22,814 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4130365854929454
2024-05-07 21:39:22,817 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.163270.16327
2024-05-07 21:39:22,821 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #148: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.56, '(min, 1)': 0.07}}
2024-05-07 21:39:22,821 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:22,822 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4136522890988211
2024-05-07 21:39:22,867 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #148: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.42, '(min, 1)': 0.19}}
2024-05-07 21:39:22,867 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:22,868 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4136522890988211
2024-05-07 21:39:22,907 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #148: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.41025641025641024, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.24, '(min, 1)': 0.39, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:39:22,907 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:22,908 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4136522890988211
2024-05-07 21:39:23,529 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #148: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5882352941176471, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.35, '(rev, 1)': 0.02, '(rev, 2)': 0.03, '(rev, 3)': 0.04, '(rev, 4)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:39:23,529 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:23,529 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4136522890988211
2024-05-07 21:39:23,915 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #148: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2926829268292683, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.39, '(rev, 1)': 0.11, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:39:23,916 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:23,916 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4136522890988211
2024-05-07 21:39:24,275 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #148: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.28, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:39:24,275 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:24,276 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4136522890988211
2024-05-07 21:39:26,392 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #148: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.18, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.33, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:39:26,392 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:26,393 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4136522890988211
2024-05-07 21:39:26,615 - MainProcess - INFO - text_logger.py - 51 - Train epoch #148
2024-05-07 21:39:26,618 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0252e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3738e-01, 0.0000e+00,
        2.8764e-01, 3.3703e-03, 2.4286e-01, 0.0000e+00, 5.1060e-02, 2.8756e-03,
        0.0000e+00, 0.0000e+00, 3.8639e-02, 3.2626e-03, 0.0000e+00, 0.0000e+00,
        3.3058e-02, 1.5359e-03, 0.0000e+00, 0.0000e+00, 2.9828e-02, 2.6294e-04,
        0.0000e+00, 0.0000e+00, 2.4469e-02, 1.8746e-04, 0.0000e+00, 0.0000e+00,
        2.1916e-02, 6.8966e-05, 0.0000e+00, 0.0000e+00, 1.6613e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.1433e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.3220e-04, 0.0000e+00, 0.0000e+00])  tensor([2.2117e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9026e-01, 0.0000e+00,
        1.9499e-01, 1.0731e-02, 1.9217e-01, 0.0000e+00, 4.8693e-02, 1.1615e-02,
        0.0000e+00, 0.0000e+00, 4.0195e-02, 1.5964e-02, 0.0000e+00, 0.0000e+00,
        3.6413e-02, 9.1956e-03, 0.0000e+00, 0.0000e+00, 3.3995e-02, 2.3788e-03,
        0.0000e+00, 0.0000e+00, 2.8905e-02, 2.0146e-03, 0.0000e+00, 0.0000e+00,
        2.7439e-02, 1.5421e-03, 0.0000e+00, 0.0000e+00, 2.1627e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.1865e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.1631e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:39:26,640 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4125046076850813
2024-05-07 21:39:26,643 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.205130.20513
2024-05-07 21:39:26,647 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #149: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 0, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.358974358974359, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.42, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:39:26,647 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:26,648 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4130365854929454
2024-05-07 21:39:26,663 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #149: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.49, '(min, 1)': 0.14}}
, 8)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.13, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-05-07 21:39:26,664 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:26,664 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:26,665 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4130365854929454
2024-05-07 21:39:26,665 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4130365854929454
2024-05-07 21:39:26,679 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #149: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0851063829787234, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.35, '(rev, 1)': 0.03, '(rev, 2)': 0.01}}
2024-05-07 21:39:26,680 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:26,680 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4130365854929454
2024-05-07 21:39:28,076 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #149: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.25, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:39:28,076 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:28,077 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4130365854929454
2024-05-07 21:39:28,227 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #149: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17391304347826086, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.26, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:39:28,227 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:28,228 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4130365854929454
2024-05-07 21:39:29,794 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #149: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6122448979591837, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.39, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:39:29,794 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:29,795 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4130365854929454
2024-05-07 21:39:30,002 - MainProcess - INFO - text_logger.py - 51 - Train epoch #149
2024-05-07 21:39:30,005 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.9765e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7802e-01, 0.0000e+00,
        2.1620e-01, 3.2671e-03, 2.8842e-01, 0.0000e+00, 5.0110e-02, 4.0361e-03,
        0.0000e+00, 0.0000e+00, 3.3051e-02, 4.8190e-03, 0.0000e+00, 0.0000e+00,
        2.9956e-02, 2.5086e-03, 0.0000e+00, 0.0000e+00, 2.6768e-02, 6.0657e-04,
        0.0000e+00, 0.0000e+00, 2.2365e-02, 3.4164e-04, 0.0000e+00, 0.0000e+00,
        2.1026e-02, 3.4164e-04, 0.0000e+00, 0.0000e+00, 1.4853e-02, 1.4737e-04,
        0.0000e+00, 0.0000e+00, 2.6984e-03, 3.1746e-05, 0.0000e+00, 0.0000e+00,
        4.3727e-04, 0.0000e+00, 0.0000e+00])  tensor([2.9181e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8253e-01, 0.0000e+00,
        1.8194e-01, 9.4647e-03, 1.8797e-01, 0.0000e+00, 6.1781e-02, 1.2156e-02,
        0.0000e+00, 0.0000e+00, 4.5654e-02, 1.6398e-02, 0.0000e+00, 0.0000e+00,
        4.3692e-02, 9.5210e-03, 0.0000e+00, 0.0000e+00, 4.0146e-02, 3.6784e-03,
        0.0000e+00, 0.0000e+00, 3.4219e-02, 2.2144e-03, 0.0000e+00, 0.0000e+00,
        3.3257e-02, 2.2144e-03, 0.0000e+00, 0.0000e+00, 2.4211e-02, 1.4817e-03,
        0.0000e+00, 0.0000e+00, 7.8942e-03, 7.0986e-04, 0.0000e+00, 0.0000e+00,
        3.0052e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:39:30,023 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.41182904013362737
2024-05-07 21:39:30,026 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.133330.13333
2024-05-07 21:39:30,034 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #150: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3870967741935484, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(min, 0)': 0.47, '(min, 1)': 0.22, '(rev, 2)': 0.02}}
2024-05-07 21:39:30,034 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:30,035 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4125046076850813
2024-05-07 21:39:30,050 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #150: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 6, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 0, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.18421052631578946, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.11, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:39:30,050 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:30,051 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4125046076850813
2024-05-07 21:39:30,088 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #150: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.48, '(min, 1)': 0.15, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.03}}
2024-05-07 21:39:30,088 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:30,089 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4125046076850813
2024-05-07 21:39:30,094 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #150: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.21621621621621623, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.24, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:39:30,094 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:30,094 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4125046076850813
2024-05-07 21:39:30,868 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #150: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.02857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 4)': 0.01, '(min, 0)': 0.58, '(min, 1)': 0.09, '(rev, 1)': 0.02}}
2024-05-07 21:39:30,868 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:30,869 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4125046076850813
2024-05-07 21:39:32,684 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #150: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5116279069767442, 'length': 100, 'actions': {'(ado, 1)': 0.09, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.38, '(rev, 1)': 0.12, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:39:32,684 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:32,684 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4125046076850813
2024-05-07 21:39:33,060 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #150: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 3, 0, 1),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 4, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.23255813953488372, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.34, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:39:33,061 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:33,061 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4125046076850813
2024-05-07 21:39:33,277 - MainProcess - INFO - text_logger.py - 51 - Train epoch #150
2024-05-07 21:39:33,280 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.1719e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5299e-01, 0.0000e+00,
        2.5925e-01, 4.1345e-03, 2.5238e-01, 0.0000e+00, 5.2184e-02, 4.1247e-03,
        0.0000e+00, 0.0000e+00, 3.7771e-02, 3.6176e-03, 0.0000e+00, 0.0000e+00,
        3.2699e-02, 1.1973e-03, 0.0000e+00, 0.0000e+00, 3.0444e-02, 1.0869e-04,
        0.0000e+00, 0.0000e+00, 2.6051e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.2088e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7073e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.4242e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.6489e-04, 0.0000e+00, 0.0000e+00])  tensor([2.0352e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8868e-01, 0.0000e+00,
        1.7737e-01, 1.0828e-02, 1.8839e-01, 0.0000e+00, 5.7822e-02, 1.1575e-02,
        0.0000e+00, 0.0000e+00, 4.4427e-02, 1.2260e-02, 0.0000e+00, 0.0000e+00,
        4.0327e-02, 6.1558e-03, 0.0000e+00, 0.0000e+00, 3.8322e-02, 1.4065e-03,
        0.0000e+00, 0.0000e+00, 3.3855e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9961e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4418e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.5504e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7785e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:39:33,304 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4114961249119226
2024-05-07 21:39:33,306 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.304660.08244
2024-05-07 21:39:33,340 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #151: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.57, '(min, 1)': 0.02}}
2024-05-07 21:39:33,340 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:33,342 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41182904013362737
2024-05-07 21:39:33,356 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #151: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 4, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.4, '(min, 1)': 0.24}}
2024-05-07 21:39:33,356 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:33,357 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41182904013362737
2024-05-07 21:39:33,670 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #151: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 8)': 0.01, '(min, 0)': 0.54, '(min, 1)': 0.14}}
2024-05-07 21:39:33,671 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:33,671 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41182904013362737
2024-05-07 21:39:33,988 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #151: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.28, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.28, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:39:33,988 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:33,989 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41182904013362737
2024-05-07 21:39:34,171 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #151: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 8, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 8, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.43, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:39:34,171 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:34,171 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41182904013362737
2024-05-07 21:39:35,191 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #151: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(min, 0)': 0.48, '(min, 1)': 0.18}}
2024-05-07 21:39:35,191 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:35,192 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41182904013362737
2024-05-07 21:39:36,212 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #151: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 4)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 6, 0, 0)', 'reward_ratio': '0/4', 'revenue': 0.1276595744680851, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.61, '(min, 1)': 0.05, '(rev, 1)': 0.03, '(rev, 2)': 0.02}}
2024-05-07 21:39:36,213 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:36,213 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.41182904013362737
2024-05-07 21:39:36,419 - MainProcess - INFO - text_logger.py - 51 - Train epoch #151
2024-05-07 21:39:36,422 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.0225,  0.0000,  0.0000,  0.0000,  0.2118,  0.0000,  0.2180,  0.0030,
         0.2124,  0.0000,  0.0639,  0.0015,  0.0000,  0.0000,  0.0608,  0.0008,
         0.0000,  0.0000,  0.0550,  0.0003,  0.0000,  0.0000,  0.0494,  0.0000,
         0.0000,  0.0000,  0.0432,  0.0000,  0.0000,  0.0000,  0.0417,  0.0000,
         0.0000,  0.0000,  0.0307,  0.0000,  0.0000,  0.0000,  0.0064,  0.0000,
         0.0000,  0.0000,  0.0011,  0.0000,  0.0000])  tensor([1.7540, 0.0000, 0.0000, 0.0000, 0.1985, 0.0000, 0.1559, 0.0093, 0.2039,
        0.0000, 0.0515, 0.0067, 0.0000, 0.0000, 0.0516, 0.0051, 0.0000, 0.0000,
        0.0483, 0.0030, 0.0000, 0.0000, 0.0446, 0.0000, 0.0000, 0.0000, 0.0399,
        0.0000, 0.0000, 0.0000, 0.0405, 0.0000, 0.0000, 0.0000, 0.0317, 0.0000,
        0.0000, 0.0000, 0.0113, 0.0000, 0.0000, 0.0000, 0.0046, 0.0000, 0.0000]) (500)
2024-05-07 21:39:36,445 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.410553890693802
2024-05-07 21:39:36,448 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:39:36,466 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #152: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2777777777777778, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.24, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:39:36,466 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:36,466 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4114961249119226
2024-05-07 21:39:36,497 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #152: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.53, '(min, 1)': 0.06}}
2024-05-07 21:39:36,498 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:36,498 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4114961249119226
2024-05-07 21:39:36,709 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #152: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.19, '(rev, 1)': 0.04, '(rev, 2)': 0.01}}
2024-05-07 21:39:36,709 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:36,710 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4114961249119226
2024-05-07 21:39:36,807 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #152: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.23076923076923078, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.4, '(min, 1)': 0.19, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:39:36,807 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:36,808 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4114961249119226
2024-05-07 21:39:37,082 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #152: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46938775510204084, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.42, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:39:37,082 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:37,083 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4114961249119226
2024-05-07 21:39:37,853 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #152: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.09615384615384616, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.27, '(rev, 1)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:39:37,853 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:37,854 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4114961249119226
2024-05-07 21:39:39,014 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #152: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.44, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 8)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.38, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:39:39,014 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:39,015 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4114961249119226
2024-05-07 21:39:39,222 - MainProcess - INFO - text_logger.py - 51 - Train epoch #152
2024-05-07 21:39:39,225 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.4981e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1142e-01, 0.0000e+00,
        1.8637e-01, 5.5172e-03, 3.1292e-01, 0.0000e+00, 4.0879e-02, 2.4447e-03,
        0.0000e+00, 0.0000e+00, 3.3140e-02, 1.2396e-03, 0.0000e+00, 0.0000e+00,
        2.6541e-02, 2.1366e-04, 0.0000e+00, 0.0000e+00, 2.5403e-02, 6.8966e-05,
        0.0000e+00, 0.0000e+00, 2.0926e-02, 7.1429e-05, 0.0000e+00, 0.0000e+00,
        1.8101e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1910e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.3906e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.4729e-04, 0.0000e+00, 0.0000e+00])  tensor([1.5449e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8635e-01, 0.0000e+00,
        1.6126e-01, 1.2008e-02, 1.8985e-01, 0.0000e+00, 5.2215e-02, 8.4647e-03,
        0.0000e+00, 0.0000e+00, 4.5525e-02, 6.5322e-03, 0.0000e+00, 0.0000e+00,
        3.8554e-02, 2.4008e-03, 0.0000e+00, 0.0000e+00, 3.8760e-02, 1.5421e-03,
        0.0000e+00, 0.0000e+00, 3.2811e-02, 1.5972e-03, 0.0000e+00, 0.0000e+00,
        3.0385e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1597e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.0674e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.6839e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:39:39,247 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.40993774343220307
2024-05-07 21:39:39,250 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.163040.16304
2024-05-07 21:39:39,268 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #153: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.46, '(min, 1)': 0.16, '(rev, 1)': 0.01}}
2024-05-07 21:39:39,268 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:39,269 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.410553890693802
2024-05-07 21:39:39,300 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #153: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(min, 0)': 0.19, '(min, 1)': 0.5, '(rev, 1)': 0.07, '(rev, 2)': 0.09, '(rev, 3)': 0.01, '(rev, 9)': 0.01}}
2024-05-07 21:39:39,301 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:39,301 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.410553890693802
2024-05-07 21:39:39,517 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #153: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.38636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.3, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 6)': 0.01}}
2024-05-07 21:39:39,517 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:39,517 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.410553890693802
2024-05-07 21:39:40,767 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #153: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 3, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.9024390243902439, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 8)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.23, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.04}}
2024-05-07 21:39:40,767 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:40,768 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.410553890693802
2024-05-07 21:39:40,947 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #153: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.39215686274509803, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.27, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:39:40,947 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:40,948 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.410553890693802
2024-05-07 21:39:41,588 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #153: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 5, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.43, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:39:41,589 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:41,589 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.410553890693802
2024-05-07 21:39:42,250 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #153: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.18, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(ado, 7)': 0.02, '(min, 0)': 0.35, '(min, 1)': 0.32, '(rev, 1)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:39:42,250 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:42,251 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.410553890693802
2024-05-07 21:39:42,465 - MainProcess - INFO - text_logger.py - 51 - Train epoch #153
2024-05-07 21:39:42,468 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.1279e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4416e-01, 0.0000e+00,
        1.7112e-01, 6.1278e-03, 3.5513e-01, 0.0000e+00, 2.8798e-02, 4.8385e-03,
        0.0000e+00, 0.0000e+00, 1.9774e-02, 3.6792e-03, 0.0000e+00, 0.0000e+00,
        1.7930e-02, 1.4059e-03, 0.0000e+00, 0.0000e+00, 1.4833e-02, 1.9076e-04,
        0.0000e+00, 0.0000e+00, 1.2585e-02, 5.4054e-05, 0.0000e+00, 0.0000e+00,
        1.0690e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.5923e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.3204e-04, 8.0000e-05, 0.0000e+00, 0.0000e+00,
        7.5472e-05, 0.0000e+00, 0.0000e+00])  tensor([1.8093e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6102e-01, 0.0000e+00,
        1.6146e-01, 1.2750e-02, 1.6546e-01, 0.0000e+00, 4.8455e-02, 1.2521e-02,
        0.0000e+00, 0.0000e+00, 3.7543e-02, 1.3784e-02, 0.0000e+00, 0.0000e+00,
        3.6621e-02, 6.5890e-03, 0.0000e+00, 0.0000e+00, 3.1984e-02, 2.2051e-03,
        0.0000e+00, 0.0000e+00, 2.8579e-02, 1.2087e-03, 0.0000e+00, 0.0000e+00,
        2.6529e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0806e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.9365e-03, 1.7889e-03, 0.0000e+00, 0.0000e+00,
        1.1921e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:39:42,488 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.40989794823847286
2024-05-07 21:39:42,490 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.451220.45122
2024-05-07 21:39:42,496 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #154: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.14634146341463414, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 4)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.26, '(rev, 1)': 0.01, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:39:42,496 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:42,497 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40993774343220307
2024-05-07 21:39:42,543 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #154: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.47, '(min, 1)': 0.13}}
2024-05-07 21:39:42,544 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:42,544 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40993774343220307
2024-05-07 21:39:42,978 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #154: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.57}}
2024-05-07 21:39:42,979 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:42,979 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40993774343220307
2024-05-07 21:39:43,383 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #154: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.15789473684210525, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.31, '(rev, 1)': 0.03, '(rev, 2)': 0.02}}
2024-05-07 21:39:43,383 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:43,384 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40993774343220307
2024-05-07 21:39:43,526 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #154: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5813953488372093, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 4)': 0.02, '(min, 0)': 0.48, '(min, 1)': 0.26, '(rev, 1)': 0.02, '(rev, 4)': 0.01, '(rev, 9)': 0.01}}
2024-05-07 21:39:43,527 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:43,527 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40993774343220307
2024-05-07 21:39:44,274 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #154: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.16326530612244897, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.24, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:39:44,274 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:44,275 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40993774343220307
2024-05-07 21:39:45,200 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #154: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4411764705882353, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 3)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.44, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 6)': 0.01}}
2024-05-07 21:39:45,200 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:45,201 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40993774343220307
2024-05-07 21:39:45,405 - MainProcess - INFO - text_logger.py - 51 - Train epoch #154
2024-05-07 21:39:45,408 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.3593e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1974e-01, 0.0000e+00,
        2.2319e-01, 3.1044e-03, 2.2322e-01, 0.0000e+00, 6.7876e-02, 1.8800e-03,
        0.0000e+00, 0.0000e+00, 5.5979e-02, 9.6925e-04, 0.0000e+00, 0.0000e+00,
        5.0612e-02, 4.0187e-04, 0.0000e+00, 0.0000e+00, 4.5425e-02, 6.6667e-05,
        0.0000e+00, 0.0000e+00, 3.9384e-02, 7.1429e-05, 0.0000e+00, 0.0000e+00,
        3.5947e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6661e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.8901e-03, 8.0000e-05, 0.0000e+00, 0.0000e+00,
        5.0543e-04, 0.0000e+00, 0.0000e+00])  tensor([1.7328e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9200e-01, 0.0000e+00,
        1.4809e-01, 9.6970e-03, 1.9526e-01, 0.0000e+00, 5.7121e-02, 7.6116e-03,
        0.0000e+00, 0.0000e+00, 5.0977e-02, 6.6851e-03, 0.0000e+00, 0.0000e+00,
        4.8482e-02, 3.6536e-03, 0.0000e+00, 0.0000e+00, 4.5503e-02, 1.4907e-03,
        0.0000e+00, 0.0000e+00, 4.0474e-02, 1.5972e-03, 0.0000e+00, 0.0000e+00,
        3.8816e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0736e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0289e-02, 1.7889e-03, 0.0000e+00, 0.0000e+00,
        2.8275e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:39:45,429 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4089557140203523
2024-05-07 21:39:45,432 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:39:45,437 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #155: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.41, '(min, 1)': 0.2}}
2024-05-07 21:39:45,437 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:45,438 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40989794823847286
2024-05-07 21:39:45,485 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #155: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.037037037037037035, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.6, '(min, 1)': 0.09, '(rev, 2)': 0.01}}
2024-05-07 21:39:45,485 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:45,486 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40989794823847286
2024-05-07 21:39:45,758 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #155: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(ado, 7)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.12}}
2024-05-07 21:39:45,758 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:45,759 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40989794823847286
2024-05-07 21:39:45,827 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #155: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.17, '(rev, 1)': 0.02}}
2024-05-07 21:39:45,827 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:45,828 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40989794823847286
2024-05-07 21:39:45,932 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #155: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.15}}
2024-05-07 21:39:45,932 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:45,933 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40989794823847286
2024-05-07 21:39:47,091 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #155: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.175, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.22, '(rev, 1)': 0.04, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:39:47,091 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:47,092 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40989794823847286
2024-05-07 21:39:47,673 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #155: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.13725490196078433, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.06, '(ado, 6)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.13, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:39:47,674 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:47,674 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40989794823847286
2024-05-07 21:39:47,877 - MainProcess - INFO - text_logger.py - 51 - Train epoch #155
2024-05-07 21:39:47,880 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-9.4576e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.3839e-01,
         0.0000e+00,  2.5547e-01,  1.6836e-03,  1.3638e-01,  0.0000e+00,
         8.5522e-02,  8.0394e-04,  0.0000e+00,  0.0000e+00,  8.3764e-02,
         3.5670e-04,  0.0000e+00,  0.0000e+00,  7.1286e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.7785e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  5.6551e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         5.3369e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.6018e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0249e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  2.3766e-03,  0.0000e+00,  0.0000e+00])  tensor([1.1493, 0.0000, 0.0000, 0.0000, 0.1698, 0.0000, 0.1148, 0.0073, 0.1693,
        0.0000, 0.0456, 0.0048, 0.0000, 0.0000, 0.0472, 0.0033, 0.0000, 0.0000,
        0.0426, 0.0000, 0.0000, 0.0000, 0.0420, 0.0000, 0.0000, 0.0000, 0.0361,
        0.0000, 0.0000, 0.0000, 0.0359, 0.0000, 0.0000, 0.0000, 0.0266, 0.0000,
        0.0000, 0.0000, 0.0123, 0.0000, 0.0000, 0.0000, 0.0060, 0.0000, 0.0000]) (500)
2024-05-07 21:39:47,896 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4082634798022317
2024-05-07 21:39:47,899 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.125000.12500
2024-05-07 21:39:48,133 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #156: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.55, '(min, 1)': 0.08}}
2024-05-07 21:39:48,133 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:48,133 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4089557140203523
2024-05-07 21:39:48,500 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #156: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.16071428571428573, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.55, '(min, 1)': 0.04, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:39:48,500 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:48,500 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4089557140203523
2024-05-07 21:39:48,615 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #156: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7547169811320755, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 8)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.38, '(rev, 1)': 0.06, '(rev, 2)': 0.03}}
2024-05-07 21:39:48,615 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:48,616 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4089557140203523
2024-05-07 21:39:48,924 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #156: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 3, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3829787234042553, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.23, '(rev, 1)': 0.08, '(rev, 2)': 0.01}}
2024-05-07 21:39:48,925 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:48,925 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4089557140203523
2024-05-07 21:39:49,842 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #156: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.19230769230769232, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.23, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:39:49,842 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:49,843 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4089557140203523
2024-05-07 21:39:50,900 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #156: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.34, '(rev, 1)': 0.08, '(rev, 2)': 0.05}}
2024-05-07 21:39:50,900 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:50,901 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4089557140203523
2024-05-07 21:39:51,626 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #156: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 5, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40425531914893614, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 10)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.31, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 7)': 0.01}}
2024-05-07 21:39:51,627 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:51,627 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4089557140203523
2024-05-07 21:39:51,829 - MainProcess - INFO - text_logger.py - 51 - Train epoch #156
2024-05-07 21:39:51,832 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.8047e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7267e-01, 0.0000e+00,
        1.7987e-01, 3.9938e-03, 2.8692e-01, 0.0000e+00, 5.0936e-02, 2.2459e-03,
        0.0000e+00, 0.0000e+00, 4.3654e-02, 1.8777e-03, 0.0000e+00, 0.0000e+00,
        3.9793e-02, 6.4466e-04, 0.0000e+00, 0.0000e+00, 3.4638e-02, 9.3506e-05,
        0.0000e+00, 0.0000e+00, 3.0058e-02, 1.4061e-04, 0.0000e+00, 0.0000e+00,
        2.7008e-02, 6.2500e-05, 0.0000e+00, 0.0000e+00, 2.0399e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.1149e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.8316e-04, 0.0000e+00, 0.0000e+00])  tensor([2.3126e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9388e-01, 0.0000e+00,
        1.4544e-01, 1.0927e-02, 2.0396e-01, 0.0000e+00, 5.6880e-02, 8.7911e-03,
        0.0000e+00, 0.0000e+00, 5.2259e-02, 9.1131e-03, 0.0000e+00, 0.0000e+00,
        4.9876e-02, 4.2234e-03, 0.0000e+00, 0.0000e+00, 4.4758e-02, 1.5132e-03,
        0.0000e+00, 0.0000e+00, 4.0318e-02, 2.2421e-03, 0.0000e+00, 0.0000e+00,
        3.7667e-02, 1.3975e-03, 0.0000e+00, 0.0000e+00, 2.9719e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.9680e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.8185e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:39:51,856 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.40807596256524314
2024-05-07 21:39:51,858 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.377360.37736
2024-05-07 21:39:51,894 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #157: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.54, '(min, 1)': 0.03}}
2024-05-07 21:39:51,894 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
sition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(min, 0)': 0.46, '(min, 1)': 0.15, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:39:51,894 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:51,895 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4082634798022317
2024-05-07 21:39:51,895 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4082634798022317
2024-05-07 21:39:51,927 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #157: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 1, 2, 10, 0, 0),(ado, 6)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 4, 0, 0)', 'reward_ratio': '0/6', 'revenue': 0.40816326530612246, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.26, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.03}}
2024-05-07 21:39:51,927 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:51,927 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #157: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 4, 0, 0),(rev, 5)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '5/5', 'revenue': 0.22, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.27, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 5)': 0.01}}
2024-05-07 21:39:51,928 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:51,928 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4082634798022317
2024-05-07 21:39:51,928 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4082634798022317
2024-05-07 21:39:52,520 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #157: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 5, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 5, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5945945945945946, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.02, '(min, 0)': 0.39, '(min, 1)': 0.33, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 5)': 0.02}}
2024-05-07 21:39:52,520 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:52,520 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4082634798022317
2024-05-07 21:39:53,377 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #157: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.4888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.15, '(rev, 1)': 0.11, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:39:53,378 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:53,378 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4082634798022317
2024-05-07 21:39:54,275 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #157: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.06521739130434782, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.17, '(rev, 1)': 0.05, '(rev, 2)': 0.02}}
2024-05-07 21:39:54,275 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:54,276 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4082634798022317
2024-05-07 21:39:54,489 - MainProcess - INFO - text_logger.py - 51 - Train epoch #157
2024-05-07 21:39:54,492 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.2380e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9401e-01, 0.0000e+00,
        1.9307e-01, 6.2266e-03, 3.0956e-01, 0.0000e+00, 4.2893e-02, 5.2179e-03,
        0.0000e+00, 0.0000e+00, 3.2665e-02, 2.8518e-03, 0.0000e+00, 0.0000e+00,
        2.7392e-02, 8.5915e-04, 0.0000e+00, 0.0000e+00, 2.5809e-02, 1.4835e-04,
        0.0000e+00, 0.0000e+00, 2.1585e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9398e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3471e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.9549e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.8404e-04, 0.0000e+00, 0.0000e+00])  tensor([1.8002, 0.0000, 0.0000, 0.0000, 0.1798, 0.0000, 0.1487, 0.0142, 0.1865,
        0.0000, 0.0569, 0.0127, 0.0000, 0.0000, 0.0474, 0.0118, 0.0000, 0.0000,
        0.0422, 0.0049, 0.0000, 0.0000, 0.0416, 0.0023, 0.0000, 0.0000, 0.0357,
        0.0000, 0.0000, 0.0000, 0.0334, 0.0000, 0.0000, 0.0000, 0.0245, 0.0000,
        0.0000, 0.0000, 0.0096, 0.0000, 0.0000, 0.0000, 0.0041, 0.0000, 0.0000]) (500)
2024-05-07 21:39:54,511 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.40754281925621355
2024-05-07 21:39:54,513 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.204550.20455
2024-05-07 21:39:54,536 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #158: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(min, 0)': 0.6, '(min, 1)': 0.07}}
2024-05-07 21:39:54,536 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:54,537 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40807596256524314
2024-05-07 21:39:55,443 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #158: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(ado, 7)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.15}}
2024-05-07 21:39:55,443 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:55,444 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40807596256524314
2024-05-07 21:39:55,497 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #158: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 4, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4186046511627907, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.09, '(min, 1)': 0.52, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:39:55,497 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:55,497 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40807596256524314
2024-05-07 21:39:55,580 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #158: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4772727272727273, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 8)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.39, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-05-07 21:39:55,580 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:55,580 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40807596256524314
2024-05-07 21:39:55,941 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #158: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.01, '(min, 0)': 0.54, '(min, 1)': 0.1, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-05-07 21:39:55,941 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:55,942 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40807596256524314
2024-05-07 21:39:56,566 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #158: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 8, 5, 0, 0),(rev, 6)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '6/6', 'revenue': 0.39215686274509803, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.22, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:39:56,566 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:56,567 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40807596256524314
2024-05-07 21:39:56,763 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #158: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.625, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 3)': 0.02, '(min, 0)': 0.36, '(min, 1)': 0.31, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-05-07 21:39:56,763 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:56,764 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40807596256524314
2024-05-07 21:39:56,972 - MainProcess - INFO - text_logger.py - 51 - Train epoch #158
2024-05-07 21:39:56,975 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.4100e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0130e-01, 0.0000e+00,
        1.8032e-01, 6.2105e-03, 3.1474e-01, 0.0000e+00, 3.5126e-02, 7.0497e-03,
        0.0000e+00, 0.0000e+00, 3.1923e-02, 6.6437e-03, 0.0000e+00, 0.0000e+00,
        2.7498e-02, 2.9706e-03, 0.0000e+00, 0.0000e+00, 2.6508e-02, 3.8468e-04,
        0.0000e+00, 0.0000e+00, 2.1681e-02, 2.5610e-04, 0.0000e+00, 0.0000e+00,
        2.0270e-02, 1.0854e-04, 0.0000e+00, 0.0000e+00, 1.3647e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.0597e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.1002e-04, 0.0000e+00, 0.0000e+00])  tensor([2.4491e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7560e-01, 0.0000e+00,
        1.4583e-01, 1.3946e-02, 1.8253e-01, 0.0000e+00, 4.9574e-02, 1.5649e-02,
        0.0000e+00, 0.0000e+00, 4.8879e-02, 1.7610e-02, 0.0000e+00, 0.0000e+00,
        4.3897e-02, 9.1213e-03, 0.0000e+00, 0.0000e+00, 4.3430e-02, 2.8159e-03,
        0.0000e+00, 0.0000e+00, 3.5902e-02, 2.1999e-03, 0.0000e+00, 0.0000e+00,
        3.4563e-02, 1.3991e-03, 0.0000e+00, 0.0000e+00, 2.5056e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.7091e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3125e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:39:56,995 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4066005850380929
2024-05-07 21:39:56,998 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:39:58,217 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #159: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1875, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.29, '(rev, 1)': 0.05, '(rev, 2)': 0.04}}
2024-05-07 21:39:58,217 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:58,218 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40754281925621355
2024-05-07 21:39:58,277 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #159: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.48, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 10)': 0.01, '(ado, 2)': 0.02, '(min, 0)': 0.38, '(min, 1)': 0.29, '(rev, 1)': 0.06, '(rev, 2)': 0.1, '(rev, 3)': 0.02}}
2024-05-07 21:39:58,277 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:58,277 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40754281925621355
2024-05-07 21:39:58,450 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #159: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0392156862745098, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.13, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-05-07 21:39:58,450 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:58,451 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40754281925621355
2024-05-07 21:39:58,516 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #159: {'transition': '(exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 7, 8, 1, 1),(min, 0)->(exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 8, 8, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.55, '(min, 1)': 0.09}}
2024-05-07 21:39:58,516 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:58,517 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40754281925621355
2024-05-07 21:39:58,553 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #159: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5686274509803921, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.38, '(rev, 1)': 0.07, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-05-07 21:39:58,553 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:58,554 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40754281925621355
2024-05-07 21:39:59,342 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #159: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.16, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:39:59,342 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:39:59,343 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40754281925621355
2024-05-07 21:40:00,312 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #159: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.30612244897959184, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.05, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.19, '(rev, 1)': 0.05, '(rev, 2)': 0.02}}
2024-05-07 21:40:00,313 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:00,313 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40754281925621355
2024-05-07 21:40:00,516 - MainProcess - INFO - text_logger.py - 51 - Train epoch #159
2024-05-07 21:40:00,519 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.9521e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5073e-01, 0.0000e+00,
        1.8441e-01, 5.0175e-03, 2.5912e-01, 0.0000e+00, 5.2106e-02, 3.8791e-03,
        0.0000e+00, 0.0000e+00, 5.3894e-02, 2.2819e-03, 0.0000e+00, 0.0000e+00,
        4.7177e-02, 8.3496e-04, 0.0000e+00, 0.0000e+00, 4.2402e-02, 2.3273e-04,
        0.0000e+00, 0.0000e+00, 3.5159e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4533e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2681e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.7664e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.7741e-04, 0.0000e+00, 0.0000e+00])  tensor([2.0855e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9650e-01, 0.0000e+00,
        1.3828e-01, 1.2398e-02, 2.0653e-01, 0.0000e+00, 5.3940e-02, 1.0972e-02,
        0.0000e+00, 0.0000e+00, 5.7942e-02, 9.2041e-03, 0.0000e+00, 0.0000e+00,
        5.2116e-02, 4.5548e-03, 0.0000e+00, 0.0000e+00, 4.7671e-02, 1.9993e-03,
        0.0000e+00, 0.0000e+00, 4.0293e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.2171e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0468e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0445e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.6673e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:40:00,539 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4062269782709527
2024-05-07 21:40:00,541 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.284310.28431
2024-05-07 21:40:00,579 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #160: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.23404255319148937, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(ado, 3)': 0.02, '(min, 0)': 0.43, '(min, 1)': 0.16, '(rev, 1)': 0.08, '(rev, 2)': 0.05}}
2024-05-07 21:40:00,579 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:00,580 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4066005850380929
2024-05-07 21:40:01,080 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #160: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4883720930232558, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(min, 0)': 0.39, '(min, 1)': 0.27, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 6)': 0.01}}
2024-05-07 21:40:01,080 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:01,081 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4066005850380929
2024-05-07 21:40:01,732 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #160: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.16, '(min, 1)': 0.44, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:40:01,732 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:01,733 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4066005850380929
2024-05-07 21:40:01,892 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #160: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0),(rev, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.5434782608695652, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.12, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:40:01,892 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:01,892 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4066005850380929
2024-05-07 21:40:02,063 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #160: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 5, 1, 0, 1),(rev, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 1, 5, 1, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.5714285714285714, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.19, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:40:02,063 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:02,064 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4066005850380929
2024-05-07 21:40:02,567 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #160: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.16, '(rev, 1)': 0.05, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-05-07 21:40:02,567 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:02,568 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4066005850380929
2024-05-07 21:40:02,630 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #160: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4594594594594595, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(min, 0)': 0.38, '(min, 1)': 0.29, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:40:02,630 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:02,631 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4066005850380929
2024-05-07 21:40:02,770 - MainProcess - INFO - text_logger.py - 51 - Train epoch #160
2024-05-07 21:40:02,773 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.3948e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4013e-01, 0.0000e+00,
        8.7566e-02, 8.7107e-03, 4.5009e-01, 0.0000e+00, 2.8540e-03, 5.0727e-03,
        0.0000e+00, 0.0000e+00, 5.2712e-04, 3.6034e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.0649e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0801e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2751e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.4537e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8159e-02, 0.0000e+00,
        1.1217e-01, 1.5903e-02, 6.2330e-02, 0.0000e+00, 9.9640e-03, 1.2758e-02,
        0.0000e+00, 0.0000e+00, 3.9795e-03, 1.1933e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.9108e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5410e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1493e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:40:02,793 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4063156320837202
2024-05-07 21:40:02,796 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.515440.05598
2024-05-07 21:40:02,882 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #161: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.01, '(min, 0)': 0.1, '(min, 1)': 0.46, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:40:02,882 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:02,883 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4062269782709527
2024-05-07 21:40:04,222 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #161: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.3125, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.02, '(min, 0)': 0.43, '(min, 1)': 0.13, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:40:04,222 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:04,222 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4062269782709527
2024-05-07 21:40:04,231 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #161: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7659574468085106, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 4)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.17, '(rev, 1)': 0.1, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:40:04,231 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:04,232 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4062269782709527
2024-05-07 21:40:05,053 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #161: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.19148936170212766, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 7)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.33, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:40:05,053 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:05,054 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4062269782709527
2024-05-07 21:40:05,170 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #161: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6086956521739131, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.35, '(rev, 1)': 0.12, '(rev, 2)': 0.08, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:40:05,171 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:05,171 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4062269782709527
2024-05-07 21:40:05,497 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #161: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40816326530612246, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.12, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:40:05,497 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:05,498 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4062269782709527
2024-05-07 21:40:05,957 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #161: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 6, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 5, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.13513513513513514, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(min, 0)': 0.49, '(min, 1)': 0.17, '(rev, 1)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:40:05,958 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:05,958 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4062269782709527
2024-05-07 21:40:06,032 - MainProcess - INFO - text_logger.py - 51 - Train epoch #161
2024-05-07 21:40:06,035 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([9.2391e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0733e-01, 0.0000e+00,
        1.0857e-01, 8.4689e-03, 4.1728e-01, 0.0000e+00, 1.0433e-02, 4.8292e-03,
        0.0000e+00, 0.0000e+00, 9.0920e-03, 2.8250e-03, 0.0000e+00, 0.0000e+00,
        7.6383e-03, 6.5229e-04, 0.0000e+00, 0.0000e+00, 7.0296e-03, 2.1842e-04,
        0.0000e+00, 0.0000e+00, 5.8711e-03, 9.7959e-05, 0.0000e+00, 0.0000e+00,
        5.7514e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3197e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.3587e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.1427e-05, 0.0000e+00, 0.0000e+00])  tensor([1.6880e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2139e-01, 0.0000e+00,
        1.2988e-01, 1.5705e-02, 1.2363e-01, 0.0000e+00, 2.8706e-02, 1.2147e-02,
        0.0000e+00, 0.0000e+00, 3.0270e-02, 1.0714e-02, 0.0000e+00, 0.0000e+00,
        2.6878e-02, 4.1064e-03, 0.0000e+00, 0.0000e+00, 2.5342e-02, 2.1912e-03,
        0.0000e+00, 0.0000e+00, 2.1459e-02, 1.5687e-03, 0.0000e+00, 0.0000e+00,
        2.1309e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4549e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.7872e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.9071e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:40:06,055 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4059166962660408
2024-05-07 21:40:06,057 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.271650.13651
2024-05-07 21:40:06,478 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #162: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5681818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.04, '(min, 0)': 0.46, '(min, 1)': 0.15, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:40:06,478 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:06,479 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4063156320837202
2024-05-07 21:40:06,768 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #162: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2558139534883721, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.04, '(min, 0)': 0.42, '(min, 1)': 0.18, '(rev, 1)': 0.09, '(rev, 2)': 0.03}}
2024-05-07 21:40:06,768 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:06,769 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4063156320837202
2024-05-07 21:40:07,268 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #162: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6444444444444445, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(min, 0)': 0.47, '(min, 1)': 0.16, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-05-07 21:40:07,268 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:07,269 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4063156320837202
2024-05-07 21:40:07,517 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #162: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2978723404255319, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(ado, 4)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.1, '(rev, 1)': 0.09, '(rev, 2)': 0.05}}
2024-05-07 21:40:07,517 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:07,518 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4063156320837202
2024-05-07 21:40:07,858 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #162: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3829787234042553, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(min, 0)': 0.17, '(min, 1)': 0.43, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:40:07,858 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:07,858 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4063156320837202
2024-05-07 21:40:08,230 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #162: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.38, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.16, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.03}}
2024-05-07 21:40:08,230 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:08,231 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4063156320837202
2024-05-07 21:40:08,492 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #162: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 1.0232558139534884, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(min, 0)': 0.14, '(min, 1)': 0.45, '(rev, 1)': 0.12, '(rev, 2)': 0.1, '(rev, 3)': 0.01}}
2024-05-07 21:40:08,492 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:08,492 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4063156320837202
2024-05-07 21:40:08,565 - MainProcess - INFO - text_logger.py - 51 - Train epoch #162
2024-05-07 21:40:08,568 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.1372e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3214e-01, 0.0000e+00,
        9.6810e-02, 8.6303e-03, 4.4435e-01, 0.0000e+00, 4.6469e-03, 4.7946e-03,
        0.0000e+00, 0.0000e+00, 1.7683e-03, 3.6156e-03, 0.0000e+00, 0.0000e+00,
        9.3621e-04, 1.3773e-03, 0.0000e+00, 0.0000e+00, 3.8942e-04, 3.6311e-04,
        0.0000e+00, 0.0000e+00, 1.4426e-04, 3.5714e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.8020e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7619e-02, 0.0000e+00,
        1.1998e-01, 1.6110e-02, 7.5612e-02, 0.0000e+00, 1.6601e-02, 1.3159e-02,
        0.0000e+00, 0.0000e+00, 8.9636e-03, 1.2937e-02, 0.0000e+00, 0.0000e+00,
        6.5397e-03, 5.8798e-03, 0.0000e+00, 0.0000e+00, 3.7545e-03, 2.9621e-03,
        0.0000e+00, 0.0000e+00, 2.4850e-03, 7.9860e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:40:08,588 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.40637771786187377
2024-05-07 21:40:08,590 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.701630.32163
2024-05-07 21:40:09,515 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #163: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(min, 0)': 0.26, '(min, 1)': 0.4, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-05-07 21:40:09,516 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:09,516 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4059166962660408
2024-05-07 21:40:09,605 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #163: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.11764705882352941, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.3, '(rev, 1)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:40:09,606 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:09,606 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4059166962660408
2024-05-07 21:40:10,040 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #163: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 5, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.47, '(min, 1)': 0.2, '(rev, 1)': 0.01}}
2024-05-07 21:40:10,040 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:10,041 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4059166962660408
2024-05-07 21:40:10,307 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #163: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3404255319148936, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.28, '(min, 1)': 0.34, '(rev, 1)': 0.08, '(rev, 2)': 0.06}}
2024-05-07 21:40:10,307 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:10,308 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4059166962660408
2024-05-07 21:40:10,516 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #163: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(min, 0)': 0.5, '(min, 1)': 0.07, '(rev, 1)': 0.12, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-05-07 21:40:10,516 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:10,517 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4059166962660408
2024-05-07 21:40:10,909 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #163: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.44680851063829785, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.15, '(rev, 1)': 0.07, '(rev, 2)': 0.03}}
2024-05-07 21:40:10,909 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:10,910 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4059166962660408
2024-05-07 21:40:11,052 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #163: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1794871794871795, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(min, 0)': 0.54, '(min, 1)': 0.08, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:40:11,052 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:11,053 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4059166962660408
2024-05-07 21:40:11,119 - MainProcess - INFO - text_logger.py - 51 - Train epoch #163
2024-05-07 21:40:11,122 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-4.0008e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7973e-01,
         0.0000e+00,  1.6793e-01,  6.4994e-03,  2.8721e-01,  0.0000e+00,
         4.4569e-02,  3.8946e-03,  0.0000e+00,  0.0000e+00,  4.6010e-02,
         2.3665e-03,  0.0000e+00,  0.0000e+00,  4.1727e-02,  1.3571e-03,
         0.0000e+00,  0.0000e+00,  3.6587e-02,  3.1157e-04,  0.0000e+00,
         0.0000e+00,  2.9943e-02,  1.9176e-04,  0.0000e+00,  0.0000e+00,
         2.9566e-02,  1.1046e-04,  0.0000e+00,  0.0000e+00,  1.8221e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.2906e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  4.8957e-04,  0.0000e+00,  0.0000e+00])  tensor([2.4018e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9190e-01, 0.0000e+00,
        1.3464e-01, 1.5086e-02, 1.9660e-01, 0.0000e+00, 5.1404e-02, 1.1288e-02,
        0.0000e+00, 0.0000e+00, 5.6256e-02, 8.9426e-03, 0.0000e+00, 0.0000e+00,
        5.3223e-02, 5.5814e-03, 0.0000e+00, 0.0000e+00, 4.7659e-02, 2.3505e-03,
        0.0000e+00, 0.0000e+00, 4.0166e-02, 1.9970e-03, 0.0000e+00, 0.0000e+00,
        4.1029e-02, 1.4234e-03, 0.0000e+00, 0.0000e+00, 2.8512e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.4381e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9218e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:40:11,141 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4060932316928056
2024-05-07 21:40:11,143 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.328870.14939
2024-05-07 21:40:12,202 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #164: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.06666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.17, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:40:12,202 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:12,203 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40637771786187377
2024-05-07 21:40:12,951 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #164: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.32653061224489793, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.17, '(rev, 1)': 0.02, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-05-07 21:40:12,951 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:12,951 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40637771786187377
2024-05-07 21:40:12,952 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #164: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 2, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4523809523809524, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.34, '(min, 1)': 0.32, '(rev, 1)': 0.02, '(rev, 2)': 0.07, '(rev, 3)': 0.02}}
2024-05-07 21:40:12,952 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:12,953 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40637771786187377
2024-05-07 21:40:14,005 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #164: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7058823529411765, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(min, 0)': 0.52, '(min, 1)': 0.19, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:40:14,005 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:14,006 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40637771786187377
2024-05-07 21:40:14,067 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #164: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.02, '(min, 0)': 0.47, '(min, 1)': 0.2, '(rev, 4)': 0.01}}
2024-05-07 21:40:14,067 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:14,068 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40637771786187377
2024-05-07 21:40:14,526 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #164: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 1.0, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(min, 0)': 0.24, '(min, 1)': 0.42, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.03}}
2024-05-07 21:40:14,526 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:14,527 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40637771786187377
2024-05-07 21:40:14,556 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #164: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.56, '(min, 1)': 0.1}}
2024-05-07 21:40:14,556 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:14,556 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40637771786187377
2024-05-07 21:40:14,730 - MainProcess - INFO - text_logger.py - 51 - Train epoch #164
2024-05-07 21:40:14,733 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-6.2910e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.5056e-01,
         0.0000e+00,  1.9087e-01,  5.2479e-03,  2.6325e-01,  0.0000e+00,
         5.2813e-02,  3.4092e-03,  0.0000e+00,  0.0000e+00,  5.2660e-02,
         2.4925e-03,  0.0000e+00,  0.0000e+00,  4.8417e-02,  4.0305e-04,
         0.0000e+00,  0.0000e+00,  4.1687e-02,  1.2051e-04,  0.0000e+00,
         0.0000e+00,  3.3941e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.2274e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.8567e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8703e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  4.1487e-04,  0.0000e+00,  0.0000e+00])  tensor([2.4772e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9048e-01, 0.0000e+00,
        1.4756e-01, 1.5540e-02, 2.0069e-01, 0.0000e+00, 5.2065e-02, 1.0618e-02,
        0.0000e+00, 0.0000e+00, 5.6088e-02, 1.0361e-02, 0.0000e+00, 0.0000e+00,
        5.3272e-02, 3.2496e-03, 0.0000e+00, 0.0000e+00, 4.7572e-02, 1.5606e-03,
        0.0000e+00, 0.0000e+00, 3.9620e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.1309e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7990e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.7689e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5893e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:40:14,753 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.40585687982762625
2024-05-07 21:40:14,755 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.352940.35294
2024-05-07 21:40:16,201 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #165: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5526315789473685, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.41, '(min, 1)': 0.28, '(rev, 1)': 0.03, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:40:16,201 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:16,202 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4060932316928056
2024-05-07 21:40:16,403 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #165: {'transition': '(exi, not, exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 3, 5, 1, 1),(min, 0)->(exi, not, exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 3, 6, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.5348837209302325, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 4)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.36, '(rev, 1)': 0.06, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-05-07 21:40:16,403 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:16,404 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4060932316928056
2024-05-07 21:40:16,754 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #165: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2653061224489796, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.09, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:40:16,754 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:16,755 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4060932316928056
2024-05-07 21:40:16,885 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #165: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 8, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 8, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.45454545454545453, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.22, '(rev, 1)': 0.03, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:40:16,885 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:16,886 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4060932316928056
2024-05-07 21:40:17,126 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #165: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.11904761904761904, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.2, '(rev, 1)': 0.05, '(rev, 2)': 0.02}}
2024-05-07 21:40:17,126 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:17,127 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4060932316928056
2024-05-07 21:40:17,840 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #165: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40425531914893614, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.15, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:40:17,840 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:17,841 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4060932316928056
2024-05-07 21:40:17,859 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #165: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.42857142857142855, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.14, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-05-07 21:40:17,859 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:17,860 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4060932316928056
2024-05-07 21:40:17,928 - MainProcess - INFO - text_logger.py - 51 - Train epoch #165
2024-05-07 21:40:17,931 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.8201e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.5865e-01,
         0.0000e+00,  1.7815e-01,  7.1666e-03,  2.6661e-01,  0.0000e+00,
         4.8965e-02,  5.8353e-03,  0.0000e+00,  0.0000e+00,  5.0157e-02,
         4.1996e-03,  0.0000e+00,  0.0000e+00,  4.6287e-02,  1.7925e-03,
         0.0000e+00,  0.0000e+00,  4.2496e-02,  1.6104e-04,  0.0000e+00,
         0.0000e+00,  3.4392e-02,  8.1633e-05,  0.0000e+00,  0.0000e+00,
         3.3327e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.8998e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.3980e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.3389e-04,  0.0000e+00,  0.0000e+00])  tensor([2.4577e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8875e-01, 0.0000e+00,
        1.3565e-01, 1.7534e-02, 1.9692e-01, 0.0000e+00, 5.3262e-02, 1.6078e-02,
        0.0000e+00, 0.0000e+00, 5.6593e-02, 1.4496e-02, 0.0000e+00, 0.0000e+00,
        5.3920e-02, 7.0877e-03, 0.0000e+00, 0.0000e+00, 5.0400e-02, 1.7963e-03,
        0.0000e+00, 0.0000e+00, 4.1474e-02, 1.2894e-03, 0.0000e+00, 0.0000e+00,
        4.2508e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8683e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.0427e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3680e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:40:17,953 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.405747472357226
2024-05-07 21:40:17,955 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.416410.01216
2024-05-07 21:40:19,320 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #166: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.20408163265306123, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.14, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-07 21:40:19,320 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:19,320 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40585687982762625
2024-05-07 21:40:19,739 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #166: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3125, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.29, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 3)': 0.03}}
2024-05-07 21:40:19,739 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:19,740 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40585687982762625
2024-05-07 21:40:19,899 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #166: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8125, 'length': 100, 'actions': {'(ado, 1)': 0.07, '(ado, 2)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.39, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.05, '(rev, 4)': 0.03, '(rev, 7)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:40:19,900 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:19,900 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40585687982762625
2024-05-07 21:40:20,457 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #166: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.02, '(min, 0)': 0.42, '(min, 1)': 0.17, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:40:20,457 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:20,458 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40585687982762625
2024-05-07 21:40:20,485 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #166: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.6222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.15, '(min, 1)': 0.49, '(rev, 1)': 0.11, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-05-07 21:40:20,486 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:20,486 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40585687982762625
2024-05-07 21:40:21,053 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #166: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.14035087719298245, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.03, '(ado, 5)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.35, '(rev, 1)': 0.02, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:40:21,053 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:21,054 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40585687982762625
2024-05-07 21:40:21,841 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #166: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.02702702702702703, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.18, '(rev, 1)': 0.02, '(rev, 2)': 0.01}}
2024-05-07 21:40:21,841 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:21,842 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40585687982762625
2024-05-07 21:40:21,917 - MainProcess - INFO - text_logger.py - 51 - Train epoch #166
2024-05-07 21:40:21,921 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.5310e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2649e-01, 0.0000e+00,
        1.5943e-01, 8.6192e-03, 3.5569e-01, 0.0000e+00, 2.1193e-02, 1.5676e-02,
        0.0000e+00, 0.0000e+00, 1.7139e-02, 2.2552e-02, 0.0000e+00, 0.0000e+00,
        1.6149e-02, 6.9162e-03, 0.0000e+00, 0.0000e+00, 1.4698e-02, 6.7581e-04,
        0.0000e+00, 0.0000e+00, 1.2528e-02, 5.3237e-04, 0.0000e+00, 0.0000e+00,
        1.1397e-02, 4.3411e-04, 0.0000e+00, 0.0000e+00, 7.7251e-03, 3.0303e-04,
        0.0000e+00, 0.0000e+00, 1.4471e-03, 5.8925e-05, 0.0000e+00, 0.0000e+00,
        3.5120e-04, 0.0000e+00, 0.0000e+00])  tensor([3.0633e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5537e-01, 0.0000e+00,
        1.6159e-01, 2.0085e-02, 1.6157e-01, 0.0000e+00, 3.9819e-02, 3.6001e-02,
        0.0000e+00, 0.0000e+00, 4.0091e-02, 6.6479e-02, 0.0000e+00, 0.0000e+00,
        3.9885e-02, 2.2108e-02, 0.0000e+00, 0.0000e+00, 3.6887e-02, 3.3731e-03,
        0.0000e+00, 0.0000e+00, 3.2063e-02, 3.0642e-03, 0.0000e+00, 0.0000e+00,
        2.9745e-02, 3.1142e-03, 0.0000e+00, 0.0000e+00, 2.0861e-02, 2.8015e-03,
        0.0000e+00, 0.0000e+00, 5.8649e-03, 9.3495e-04, 0.0000e+00, 0.0000e+00,
        2.7911e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:40:21,942 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4052100429439103
2024-05-07 21:40:21,944 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.202400.17538
2024-05-07 21:40:21,996 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #167: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6578947368421053, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.01, '(min, 0)': 0.08, '(min, 1)': 0.55, '(rev, 1)': 0.2, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:40:21,997 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:21,998 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.405747472357226
2024-05-07 21:40:22,294 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #167: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34210526315789475, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(min, 0)': 0.3, '(min, 1)': 0.3, '(rev, 1)': 0.12, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:40:22,295 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:22,295 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.405747472357226
2024-05-07 21:40:23,024 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #167: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.04, '(min, 0)': 0.04, '(min, 1)': 0.54, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:40:23,024 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:23,025 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.405747472357226
2024-05-07 21:40:23,299 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #167: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5609756097560976, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(min, 0)': 0.42, '(min, 1)': 0.21, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 5)': 0.01, '(rev, 6)': 0.02}}
2024-05-07 21:40:23,299 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:23,300 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.405747472357226
2024-05-07 21:40:23,330 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #167: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7441860465116279, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.42, '(min, 1)': 0.22, '(rev, 1)': 0.12, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-05-07 21:40:23,330 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:23,331 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.405747472357226
2024-05-07 21:40:23,603 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #167: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34146341463414637, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.34, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:40:23,603 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:23,603 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.405747472357226
2024-05-07 21:40:25,627 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #167: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.14}}
2024-05-07 21:40:25,627 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:25,628 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.405747472357226
2024-05-07 21:40:25,702 - MainProcess - INFO - text_logger.py - 51 - Train epoch #167
2024-05-07 21:40:25,705 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.4985e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1709e-01, 0.0000e+00,
        1.3372e-01, 1.1124e-02, 4.1570e-01, 0.0000e+00, 3.0937e-03, 1.0682e-02,
        0.0000e+00, 0.0000e+00, 6.0215e-04, 5.5736e-03, 0.0000e+00, 0.0000e+00,
        7.5472e-05, 2.1555e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8058e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7942e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.8180e-02, 0.0000e+00,
        1.3024e-01, 1.8693e-02, 7.4437e-02, 0.0000e+00, 1.0886e-02, 2.0055e-02,
        0.0000e+00, 0.0000e+00, 4.6262e-03, 1.6106e-02, 0.0000e+00, 0.0000e+00,
        1.6876e-03, 8.4858e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3773e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:40:25,724 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4048287843355457
2024-05-07 21:40:25,726 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.280490.28049
2024-05-07 21:40:25,749 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #168: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.3695652173913043, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.18, '(rev, 1)': 0.08, '(rev, 2)': 0.06}}
rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:40:25,749 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:25,750 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:25,750 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4052100429439103
2024-05-07 21:40:25,750 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4052100429439103
2024-05-07 21:40:25,779 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #168: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(min, 0)': 0.36, '(min, 1)': 0.23, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.04, '(rev, 4)': 0.01}}
2024-05-07 21:40:25,779 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:25,780 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4052100429439103
2024-05-07 21:40:25,840 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #168: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.05405405405405406, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.5, '(min, 1)': 0.13, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-05-07 21:40:25,840 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:25,840 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4052100429439103
2024-05-07 21:40:25,893 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #168: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 1, 0, 1),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 2, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.04, '(min, 0)': 0.44, '(min, 1)': 0.17, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-05-07 21:40:25,894 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:25,894 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4052100429439103
2024-05-07 21:40:25,932 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #168: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.44, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(min, 0)': 0.32, '(min, 1)': 0.27, '(rev, 1)': 0.06, '(rev, 2)': 0.07, '(rev, 3)': 0.02}}
2024-05-07 21:40:25,932 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:25,933 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4052100429439103
2024-05-07 21:40:27,959 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #168: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 3, 7, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 4, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.6, '(min, 1)': 0.05}}
2024-05-07 21:40:27,959 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:27,960 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4052100429439103
2024-05-07 21:40:28,031 - MainProcess - INFO - text_logger.py - 51 - Train epoch #168
2024-05-07 21:40:28,034 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.1649e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1481e-01, 0.0000e+00,
        1.0911e-01, 1.2777e-02, 4.3944e-01, 0.0000e+00, 3.5474e-03, 9.3685e-03,
        0.0000e+00, 0.0000e+00, 6.0275e-04, 8.1899e-03, 0.0000e+00, 0.0000e+00,
        8.0000e-05, 2.0372e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1250e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7188e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.0459e-02, 0.0000e+00,
        1.2850e-01, 2.1541e-02, 7.8542e-02, 0.0000e+00, 1.2053e-02, 2.0513e-02,
        0.0000e+00, 0.0000e+00, 4.9841e-03, 3.0190e-02, 0.0000e+00, 0.0000e+00,
        1.7889e-03, 9.4126e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9877e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:40:28,056 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4039406041714792
2024-05-07 21:40:28,058 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.027030.02703
2024-05-07 21:40:28,121 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #169: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.48, '(min, 1)': 0.12}}
2024-05-07 21:40:28,121 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:28,122 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4048287843355457
2024-05-07 21:40:28,220 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #169: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3469387755102041, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.4, '(rev, 1)': 0.02, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-05-07 21:40:28,220 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:28,221 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4048287843355457
2024-05-07 21:40:28,659 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #169: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.03, '(min, 0)': 0.16, '(min, 1)': 0.46, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:40:28,660 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:28,660 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4048287843355457
2024-05-07 21:40:28,662 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #169: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4583333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.23, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:40:28,662 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:28,663 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4048287843355457
2024-05-07 21:40:28,763 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #169: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40540540540540543, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(min, 0)': 0.54, '(min, 1)': 0.11, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:40:28,763 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:28,763 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4048287843355457
2024-05-07 21:40:28,949 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #169: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8372093023255814, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.47, '(min, 1)': 0.15, '(rev, 1)': 0.07, '(rev, 2)': 0.08, '(rev, 3)': 0.03, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:40:28,950 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:28,950 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4048287843355457
2024-05-07 21:40:30,317 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #169: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.44, '(min, 1)': 0.2}}
2024-05-07 21:40:30,317 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:30,318 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4048287843355457
2024-05-07 21:40:30,382 - MainProcess - INFO - text_logger.py - 51 - Train epoch #169
2024-05-07 21:40:30,385 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.8475e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6965e-01, 0.0000e+00,
        1.2271e-01, 8.2456e-03, 3.6792e-01, 0.0000e+00, 2.1630e-02, 5.7522e-03,
        0.0000e+00, 0.0000e+00, 2.3207e-02, 4.3132e-03, 0.0000e+00, 0.0000e+00,
        1.9955e-02, 1.5716e-03, 0.0000e+00, 0.0000e+00, 1.8154e-02, 3.2329e-04,
        0.0000e+00, 0.0000e+00, 1.4673e-02, 6.4516e-05, 0.0000e+00, 0.0000e+00,
        1.4147e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9671e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.5596e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.7210e-05, 0.0000e+00, 0.0000e+00])  tensor([2.1885e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6139e-01, 0.0000e+00,
        1.2819e-01, 1.7481e-02, 1.5872e-01, 0.0000e+00, 3.9773e-02, 1.6558e-02,
        0.0000e+00, 0.0000e+00, 4.7394e-02, 1.7882e-02, 0.0000e+00, 0.0000e+00,
        4.2303e-02, 7.6882e-03, 0.0000e+00, 0.0000e+00, 3.9762e-02, 3.0183e-03,
        0.0000e+00, 0.0000e+00, 3.2998e-02, 1.4426e-03, 0.0000e+00, 0.0000e+00,
        3.3841e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8722e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.6545e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.2262e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:40:30,403 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.40299836995335864
2024-05-07 21:40:30,405 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:40:30,584 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #170: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4583333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(min, 0)': 0.54, '(min, 1)': 0.05, '(rev, 1)': 0.04, '(rev, 2)': 0.1, '(rev, 3)': 0.01}}
2024-05-07 21:40:30,586 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:30,586 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4039406041714792
2024-05-07 21:40:30,608 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #170: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:40:30,608 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:30,609 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4039406041714792
2024-05-07 21:40:31,426 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #170: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2653061224489796, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(ado, 8)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.17, '(rev, 1)': 0.09, '(rev, 2)': 0.05}}
2024-05-07 21:40:31,426 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:31,428 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4039406041714792
2024-05-07 21:40:31,559 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #170: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.225, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 4)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.34, '(rev, 1)': 0.06, '(rev, 2)': 0.04}}
2024-05-07 21:40:31,559 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:31,560 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4039406041714792
2024-05-07 21:40:32,011 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #170: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5675675675675675, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.23, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:40:32,011 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:32,012 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4039406041714792
2024-05-07 21:40:32,220 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #170: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1276595744680851, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 8)': 0.02, '(min, 0)': 0.54, '(min, 1)': 0.14, '(rev, 1)': 0.06, '(rev, 2)': 0.03}}
2024-05-07 21:40:32,220 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:32,221 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4039406041714792
2024-05-07 21:40:33,003 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #170: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 3)': 0.03, '(min, 0)': 0.5, '(min, 1)': 0.1, '(rev, 1)': 0.12, '(rev, 2)': 0.07}}
2024-05-07 21:40:33,003 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:33,004 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4039406041714792
2024-05-07 21:40:33,068 - MainProcess - INFO - text_logger.py - 51 - Train epoch #170
2024-05-07 21:40:33,071 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.8475e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.6679e-01,
         0.0000e+00,  1.2974e-01,  7.7702e-03,  3.8264e-01,  0.0000e+00,
         2.0132e-02,  5.5949e-03,  0.0000e+00,  0.0000e+00,  2.0424e-02,
         4.1827e-03,  0.0000e+00,  0.0000e+00,  1.7383e-02,  1.3336e-03,
         0.0000e+00,  0.0000e+00,  1.4594e-02,  1.1014e-04,  0.0000e+00,
         0.0000e+00,  1.1641e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         1.1427e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  5.5182e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  5.0604e-04,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  2.1493e-04,  0.0000e+00,  0.0000e+00])  tensor([1.4930, 0.0000, 0.0000, 0.0000, 0.1534, 0.0000, 0.1325, 0.0173, 0.1559,
        0.0000, 0.0382, 0.0183, 0.0000, 0.0000, 0.0438, 0.0200, 0.0000, 0.0000,
        0.0398, 0.0064, 0.0000, 0.0000, 0.0356, 0.0018, 0.0000, 0.0000, 0.0299,
        0.0000, 0.0000, 0.0000, 0.0316, 0.0000, 0.0000, 0.0000, 0.0166, 0.0000,
        0.0000, 0.0000, 0.0031, 0.0000, 0.0000, 0.0000, 0.0023, 0.0000, 0.0000]) (500)
2024-05-07 21:40:33,091 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4030343966048033
2024-05-07 21:40:33,093 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.489130.14130
2024-05-07 21:40:33,116 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #171: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:40:33,117 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:33,117 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40299836995335864
2024-05-07 21:40:33,408 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #171: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 0, 1, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.29, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:40:33,408 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:33,409 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40299836995335864
2024-05-07 21:40:33,793 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #171: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4186046511627907, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.25, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-07 21:40:33,793 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:33,794 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40299836995335864
2024-05-07 21:40:34,249 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #171: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0),(rev, 3)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.21153846153846154, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.16, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:40:34,250 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:34,250 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40299836995335864
2024-05-07 21:40:34,500 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #171: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(min, 0)': 0.06, '(min, 1)': 0.52, '(rev, 1)': 0.08, '(rev, 2)': 0.07}}
2024-05-07 21:40:34,500 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:34,501 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40299836995335864
2024-05-07 21:40:35,730 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #171: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.16, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.23, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-07 21:40:35,731 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:35,731 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40299836995335864
2024-05-07 21:40:36,323 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #171: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 5, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.9743589743589743, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(min, 0)': 0.37, '(min, 1)': 0.3, '(rev, 1)': 0.12, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 6)': 0.01}}
2024-05-07 21:40:36,323 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:36,324 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40299836995335864
2024-05-07 21:40:36,396 - MainProcess - INFO - text_logger.py - 51 - Train epoch #171
2024-05-07 21:40:36,400 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-5.7090e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.4455e-01,
         0.0000e+00,  1.3916e-01,  6.9328e-03,  3.4218e-01,  0.0000e+00,
         2.4705e-02,  4.1493e-03,  0.0000e+00,  0.0000e+00,  2.9974e-02,
         1.2924e-03,  0.0000e+00,  0.0000e+00,  2.6705e-02,  5.5556e-05,
         0.0000e+00,  0.0000e+00,  2.4926e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  2.0576e-02,  8.0000e-05,  0.0000e+00,  0.0000e+00,
         2.1493e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0778e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.9253e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  5.1898e-04,  0.0000e+00,  0.0000e+00])  tensor([1.3351e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7387e-01, 0.0000e+00,
        1.2244e-01, 1.6586e-02, 1.7313e-01, 0.0000e+00, 3.8431e-02, 1.2491e-02,
        0.0000e+00, 0.0000e+00, 5.2354e-02, 7.1642e-03, 0.0000e+00, 0.0000e+00,
        4.8163e-02, 1.2423e-03, 0.0000e+00, 0.0000e+00, 4.5716e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.9102e-02, 1.7889e-03, 0.0000e+00, 0.0000e+00,
        4.1432e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2286e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.9705e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8972e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:40:36,420 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4035331880277083
2024-05-07 21:40:36,422 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.720510.25385
2024-05-07 21:40:36,443 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #172: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.9347826086956522, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.18, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.03}}
2024-05-07 21:40:36,443 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #172: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.3125, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.57, '(min, 1)': 0.06, '(rev, 1)': 0.08, '(rev, 2)': 0.05}}
2024-05-07 21:40:36,443 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:36,443 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:36,444 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #172: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5641025641025641, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.29, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:40:36,444 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4030343966048033
2024-05-07 21:40:36,444 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4030343966048033
2024-05-07 21:40:36,445 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:36,445 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4030343966048033
2024-05-07 21:40:36,643 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #172: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(min, 0)': 0.43, '(min, 1)': 0.18, '(rev, 1)': 0.09, '(rev, 2)': 0.08, '(rev, 3)': 0.02}}
2024-05-07 21:40:36,643 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:36,644 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4030343966048033
2024-05-07 21:40:37,888 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #172: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.24, '(rev, 1)': 0.03, '(rev, 2)': 0.06}}
2024-05-07 21:40:37,889 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:37,889 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4030343966048033
2024-05-07 21:40:39,753 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #172: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.8936170212765957, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(min, 0)': 0.29, '(min, 1)': 0.36, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:40:39,754 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:39,755 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4030343966048033
2024-05-07 21:40:39,920 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #172: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5227272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.17, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:40:39,920 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:39,921 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4030343966048033
2024-05-07 21:40:39,990 - MainProcess - INFO - text_logger.py - 51 - Train epoch #172
2024-05-07 21:40:39,993 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.4436e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6131e-01, 0.0000e+00,
        1.3548e-01, 9.6877e-03, 3.7672e-01, 0.0000e+00, 2.0872e-02, 5.9047e-03,
        0.0000e+00, 0.0000e+00, 2.0052e-02, 2.2092e-03, 0.0000e+00, 0.0000e+00,
        1.7552e-02, 3.6937e-04, 0.0000e+00, 0.0000e+00, 1.6113e-02, 5.8824e-05,
        0.0000e+00, 0.0000e+00, 1.3046e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2885e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.3559e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1237e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.6420e-04, 0.0000e+00, 0.0000e+00])  tensor([1.7403e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5267e-01, 0.0000e+00,
        1.3030e-01, 1.9009e-02, 1.5762e-01, 0.0000e+00, 3.9679e-02, 1.6271e-02,
        0.0000e+00, 0.0000e+00, 4.3665e-02, 1.1050e-02, 0.0000e+00, 0.0000e+00,
        4.0492e-02, 3.8025e-03, 0.0000e+00, 0.0000e+00, 3.9209e-02, 1.3153e-03,
        0.0000e+00, 0.0000e+00, 3.2809e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.3493e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7173e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.6667e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.1046e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:40:40,012 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4040484636910107
2024-05-07 21:40:40,014 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.728750.20603
2024-05-07 21:40:40,037 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #173: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5714285714285714, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.02, '(min, 0)': 0.11, '(min, 1)': 0.53, '(rev, 1)': 0.12, '(rev, 2)': 0.03, '(rev, 3)': 0.04, '(rev, 4)': 0.01}}
2024-05-07 21:40:40,037 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #173: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37254901960784315, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.05, '(ado, 5)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.43, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:40:40,037 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:40,037 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:40,038 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4035331880277083
2024-05-07 21:40:40,038 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4035331880277083
2024-05-07 21:40:40,055 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #173: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(min, 0)': 0.06, '(min, 1)': 0.51, '(rev, 1)': 0.12, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:40:40,055 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:40,056 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4035331880277083
2024-05-07 21:40:40,439 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #173: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.8181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.24, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 7)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:40:40,439 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:40,440 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4035331880277083
2024-05-07 21:40:41,213 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #173: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6078431372549019, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 9)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.18, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:40:41,213 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:41,214 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4035331880277083
2024-05-07 21:40:42,366 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #173: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10638297872340426, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.07}}
2024-05-07 21:40:42,366 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:42,366 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4035331880277083
2024-05-07 21:40:43,135 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #173: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.574468085106383, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 3)': 0.04, '(min, 0)': 0.41, '(min, 1)': 0.21, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:40:43,135 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:43,136 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4035331880277083
2024-05-07 21:40:43,205 - MainProcess - INFO - text_logger.py - 51 - Train epoch #173
2024-05-07 21:40:43,208 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.7324e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7549e-01, 0.0000e+00,
        1.4118e-01, 1.0241e-02, 3.8783e-01, 0.0000e+00, 1.3973e-02, 1.3194e-02,
        0.0000e+00, 0.0000e+00, 1.0366e-02, 1.1856e-02, 0.0000e+00, 0.0000e+00,
        8.3648e-03, 3.3314e-03, 0.0000e+00, 0.0000e+00, 7.7459e-03, 6.9482e-05,
        0.0000e+00, 0.0000e+00, 6.4932e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.8022e-03, 7.4074e-05, 0.0000e+00, 0.0000e+00, 3.3914e-03, 8.0000e-05,
        0.0000e+00, 0.0000e+00, 4.4637e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.0262e-05, 0.0000e+00, 0.0000e+00])  tensor([2.0287e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3140e-01, 0.0000e+00,
        1.4381e-01, 2.1023e-02, 1.3196e-01, 0.0000e+00, 3.3026e-02, 3.2828e-02,
        0.0000e+00, 0.0000e+00, 3.1904e-02, 4.2028e-02, 0.0000e+00, 0.0000e+00,
        2.8552e-02, 1.3945e-02, 0.0000e+00, 0.0000e+00, 2.7858e-02, 1.1016e-03,
        0.0000e+00, 0.0000e+00, 2.4023e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3211e-02, 1.6563e-03, 0.0000e+00, 0.0000e+00, 1.3979e-02, 1.7889e-03,
        0.0000e+00, 0.0000e+00, 3.0419e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1105e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:40:43,228 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4042806975579965
2024-05-07 21:40:43,231 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.587230.01277
2024-05-07 21:40:43,237 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #174: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3902439024390244, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.15, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:40:43,238 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:43,239 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4040484636910107
2024-05-07 21:40:43,256 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #174: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 2, 7, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13513513513513514, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:40:43,256 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:43,257 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4040484636910107
2024-05-07 21:40:43,286 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #174: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.43902439024390244, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.32, '(rev, 1)': 0.15, '(rev, 2)': 0.04}}
2024-05-07 21:40:43,286 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:43,286 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4040484636910107
2024-05-07 21:40:43,292 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #174: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.35, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.05}}
2024-05-07 21:40:43,292 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:43,294 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4040484636910107
2024-05-07 21:40:43,592 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #174: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.2, '(rev, 1)': 0.13, '(rev, 2)': 0.01}}
2024-05-07 21:40:43,592 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:43,592 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4040484636910107
2024-05-07 21:40:44,892 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #174: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.26, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.04, '(rev, 4)': 0.01}}
2024-05-07 21:40:44,892 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:44,892 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4040484636910107
2024-05-07 21:40:47,147 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #174: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6595744680851063, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.25, '(rev, 1)': 0.12, '(rev, 2)': 0.01}}
2024-05-07 21:40:47,147 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:47,149 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4040484636910107
2024-05-07 21:40:47,224 - MainProcess - INFO - text_logger.py - 51 - Train epoch #174
2024-05-07 21:40:47,227 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.3217e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0672e-01, 0.0000e+00,
        1.2532e-01, 1.2705e-02, 4.1476e-01, 0.0000e+00, 2.8891e-03, 1.9012e-02,
        0.0000e+00, 0.0000e+00, 5.2655e-04, 1.4673e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.2702e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2429e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.2344, 0.0000, 0.0000, 0.0000, 0.0859, 0.0000, 0.1205, 0.0231, 0.0806,
        0.0000, 0.0101, 0.0358, 0.0000, 0.0000, 0.0042, 0.0396, 0.0000, 0.0000,
        0.0000, 0.0132, 0.0000, 0.0000, 0.0000, 0.0016, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-05-07 21:40:47,247 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.40413317294309614
2024-05-07 21:40:47,249 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.397350.26222
2024-05-07 21:40:47,256 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #175: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.44680851063829785, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.02, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 6)': 0.02}}
2024-05-07 21:40:47,256 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:47,256 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #175: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.53, '(min, 1)': 0.07}}
2024-05-07 21:40:47,256 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #175: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 7)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.32, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:40:47,257 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:47,257 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:47,257 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4042806975579965
2024-05-07 21:40:47,257 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4042806975579965
2024-05-07 21:40:47,257 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4042806975579965
2024-05-07 21:40:47,304 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #175: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.06521739130434782, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.27, '(rev, 1)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:40:47,305 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:47,305 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4042806975579965
2024-05-07 21:40:47,330 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #175: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.27906976744186046, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.19, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:40:47,331 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:47,331 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4042806975579965
2024-05-07 21:40:47,884 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #175: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.20930232558139536, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.05, '(min, 0)': 0.33, '(min, 1)': 0.29, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:40:47,884 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:47,885 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4042806975579965
2024-05-07 21:40:50,086 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #175: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5526315789473685, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.42, '(min, 1)': 0.3, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:40:50,087 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:50,087 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4042806975579965
2024-05-07 21:40:50,153 - MainProcess - INFO - text_logger.py - 51 - Train epoch #175
2024-05-07 21:40:50,156 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.1545e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2270e-01, 0.0000e+00,
        1.6591e-01, 7.0322e-03, 3.3568e-01, 0.0000e+00, 3.0147e-02, 7.6731e-03,
        0.0000e+00, 0.0000e+00, 2.8160e-02, 9.0031e-03, 0.0000e+00, 0.0000e+00,
        2.4131e-02, 3.1577e-03, 0.0000e+00, 0.0000e+00, 2.1343e-02, 3.0086e-04,
        0.0000e+00, 0.0000e+00, 1.7479e-02, 1.7043e-04, 0.0000e+00, 0.0000e+00,
        1.6798e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.4958e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.5998e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.1733e-04, 0.0000e+00, 0.0000e+00])  tensor([2.1587e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6897e-01, 0.0000e+00,
        1.5290e-01, 1.7983e-02, 1.7226e-01, 0.0000e+00, 4.5801e-02, 2.5344e-02,
        0.0000e+00, 0.0000e+00, 4.8629e-02, 3.3012e-02, 0.0000e+00, 0.0000e+00,
        4.4818e-02, 1.1515e-02, 0.0000e+00, 0.0000e+00, 4.1361e-02, 2.4379e-03,
        0.0000e+00, 0.0000e+00, 3.5847e-02, 2.2821e-03, 0.0000e+00, 0.0000e+00,
        3.6393e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9492e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.6959e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8552e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:40:50,175 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.403743570303923
2024-05-07 21:40:50,178 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.276320.27632
2024-05-07 21:40:50,184 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #176: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.38, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.03}}
2024-05-07 21:40:50,184 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:50,185 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40413317294309614
2024-05-07 21:40:50,215 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #176: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(min, 0)': 0.62, '(min, 1)': 0.04}}
2024-05-07 21:40:50,216 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:50,216 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #176: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.39215686274509803, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.51, '(min, 1)': 0.15, '(rev, 1)': 0.05, '(rev, 2)': 0.06, '(rev, 7)': 0.01}}
2024-05-07 21:40:50,216 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:50,216 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40413317294309614
2024-05-07 21:40:50,217 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40413317294309614
2024-05-07 21:40:50,231 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #176: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 4, 7, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 5, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35714285714285715, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.02, '(ado, 9)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.31, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:40:50,232 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:50,232 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40413317294309614
2024-05-07 21:40:50,731 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #176: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2708333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.18, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:40:50,731 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:50,731 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40413317294309614
2024-05-07 21:40:50,951 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #176: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.509090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(ado, 8)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.16, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:40:50,951 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:50,952 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40413317294309614
2024-05-07 21:40:52,504 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #176: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.47, '(min, 1)': 0.11}}
2024-05-07 21:40:52,504 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:52,505 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40413317294309614
2024-05-07 21:40:52,579 - MainProcess - INFO - text_logger.py - 51 - Train epoch #176
2024-05-07 21:40:52,582 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.1060e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6844e-01, 0.0000e+00,
        1.4348e-01, 1.0435e-02, 3.7782e-01, 0.0000e+00, 2.1918e-02, 6.3251e-03,
        0.0000e+00, 0.0000e+00, 1.8180e-02, 3.6251e-03, 0.0000e+00, 0.0000e+00,
        1.4455e-02, 1.5505e-03, 0.0000e+00, 0.0000e+00, 1.1898e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.6950e-03, 5.7143e-05, 0.0000e+00, 0.0000e+00,
        8.1446e-03, 1.2702e-04, 0.0000e+00, 0.0000e+00, 3.5799e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.3756e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.7037e-05, 0.0000e+00, 0.0000e+00])  tensor([1.5849e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5022e-01, 0.0000e+00,
        1.5024e-01, 2.0284e-02, 1.4936e-01, 0.0000e+00, 4.2540e-02, 2.0971e-02,
        0.0000e+00, 0.0000e+00, 4.1177e-02, 1.8257e-02, 0.0000e+00, 0.0000e+00,
        3.6165e-02, 8.1638e-03, 0.0000e+00, 0.0000e+00, 3.1648e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.7396e-02, 1.2778e-03, 0.0000e+00, 0.0000e+00,
        2.5433e-02, 2.0065e-03, 0.0000e+00, 0.0000e+00, 1.2510e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.2069e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.2817e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:40:52,603 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.40280133608580243
2024-05-07 21:40:52,605 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:40:52,654 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #177: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.54, '(min, 1)': 0.04}}
2024-05-07 21:40:52,654 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:52,655 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.403743570303923
2024-05-07 21:40:52,694 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #177: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.52, '(min, 1)': 0.09, '(rev, 1)': 0.01}}
2024-05-07 21:40:52,694 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:52,695 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.403743570303923
2024-05-07 21:40:53,059 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #177: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3137254901960784, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.26, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:40:53,059 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:53,060 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.403743570303923
2024-05-07 21:40:53,178 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #177: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5652173913043478, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(min, 0)': 0.47, '(min, 1)': 0.13, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.04}}
2024-05-07 21:40:53,178 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:53,178 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.403743570303923
2024-05-07 21:40:53,718 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #177: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4375, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(min, 0)': 0.48, '(min, 1)': 0.17, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:40:53,718 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:53,719 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.403743570303923
2024-05-07 21:40:54,203 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #177: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.05405405405405406, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 8)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.22, '(rev, 1)': 0.02, '(rev, 2)': 0.01}}
2024-05-07 21:40:54,203 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:54,204 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.403743570303923
2024-05-07 21:40:55,777 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #177: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.37735849056603776, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.16, '(rev, 1)': 0.07, '(rev, 2)': 0.04}}
2024-05-07 21:40:55,777 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:55,777 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.403743570303923
2024-05-07 21:40:55,846 - MainProcess - INFO - text_logger.py - 51 - Train epoch #177
2024-05-07 21:40:55,849 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-6.2968e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7983e-01,
         0.0000e+00,  1.7507e-01,  6.1281e-03,  2.8548e-01,  0.0000e+00,
         4.4540e-02,  4.1661e-03,  0.0000e+00,  0.0000e+00,  4.8640e-02,
         3.2028e-03,  0.0000e+00,  0.0000e+00,  4.0809e-02,  7.5930e-04,
         0.0000e+00,  0.0000e+00,  3.6107e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  2.9809e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.9857e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.3112e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.1004e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.9259e-04,  0.0000e+00,  0.0000e+00])  tensor([1.7779, 0.0000, 0.0000, 0.0000, 0.1886, 0.0000, 0.1458, 0.0162, 0.1919,
        0.0000, 0.0510, 0.0165, 0.0000, 0.0000, 0.0604, 0.0181, 0.0000, 0.0000,
        0.0525, 0.0056, 0.0000, 0.0000, 0.0481, 0.0000, 0.0000, 0.0000, 0.0402,
        0.0000, 0.0000, 0.0000, 0.0422, 0.0000, 0.0000, 0.0000, 0.0217, 0.0000,
        0.0000, 0.0000, 0.0064, 0.0000, 0.0000, 0.0000, 0.0025, 0.0000, 0.0000]) (500)
2024-05-07 21:40:55,870 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4022364603582479
2024-05-07 21:40:55,872 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.188680.18868
2024-05-07 21:40:55,894 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #178: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.26, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.02}}
2024-05-07 21:40:55,894 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #178: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3191489361702128, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.15, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 8)': 0.01}}
2024-05-07 21:40:55,895 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:55,895 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:55,895 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40280133608580243
2024-05-07 21:40:55,895 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40280133608580243
2024-05-07 21:40:55,925 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #178: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.39, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-05-07 21:40:55,926 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:55,926 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40280133608580243
2024-05-07 21:40:56,801 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #178: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.03389830508474576, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 7)': 0.03, '(ado, 9)': 0.01, '(min, 0)': 0.6, '(min, 1)': 0.1, '(rev, 1)': 0.04}}
2024-05-07 21:40:56,801 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:56,801 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40280133608580243
2024-05-07 21:40:57,001 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #178: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.18, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-05-07 21:40:57,001 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:57,001 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40280133608580243
2024-05-07 21:40:57,359 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #178: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.13}}
2024-05-07 21:40:57,360 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:57,360 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40280133608580243
2024-05-07 21:40:58,515 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #178: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40425531914893614, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 3)': 0.03, '(min, 0)': 0.52, '(min, 1)': 0.14, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:40:58,515 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:58,516 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40280133608580243
2024-05-07 21:40:58,584 - MainProcess - INFO - text_logger.py - 51 - Train epoch #178
2024-05-07 21:40:58,587 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.4546e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2989e-01, 0.0000e+00,
        1.6140e-01, 7.1088e-03, 3.3973e-01, 0.0000e+00, 2.9847e-02, 6.5525e-03,
        0.0000e+00, 0.0000e+00, 2.8976e-02, 1.0642e-02, 0.0000e+00, 0.0000e+00,
        2.3174e-02, 2.9189e-03, 0.0000e+00, 0.0000e+00, 2.0181e-02, 2.1436e-04,
        0.0000e+00, 0.0000e+00, 1.6461e-02, 1.3436e-04, 0.0000e+00, 0.0000e+00,
        1.5202e-02, 1.3436e-04, 0.0000e+00, 0.0000e+00, 6.4497e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.4844e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3450e-04, 0.0000e+00, 0.0000e+00])  tensor([2.2248e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6746e-01, 0.0000e+00,
        1.4234e-01, 1.7983e-02, 1.6841e-01, 0.0000e+00, 4.7008e-02, 2.2986e-02,
        0.0000e+00, 0.0000e+00, 5.1711e-02, 4.6609e-02, 0.0000e+00, 0.0000e+00,
        4.3237e-02, 1.3430e-02, 0.0000e+00, 0.0000e+00, 3.9209e-02, 2.3322e-03,
        0.0000e+00, 0.0000e+00, 3.3080e-02, 1.5036e-03, 0.0000e+00, 0.0000e+00,
        3.2761e-02, 1.5036e-03, 0.0000e+00, 0.0000e+00, 1.5765e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.9209e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.5152e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:40:58,607 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.40169848145927617
2024-05-07 21:40:58,609 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.202130.20213
2024-05-07 21:40:58,613 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #179: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43902439024390244, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.03, '(ado, 5)': 0.01, '(min, 0)': 0.15, '(min, 1)': 0.48, '(rev, 1)': 0.13, '(rev, 2)': 0.02, '(rev, 3)': 0.04, '(rev, 4)': 0.02}}
2024-05-07 21:40:58,614 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:58,614 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4022364603582479
2024-05-07 21:40:58,633 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #179: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.45, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:40:58,633 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:58,633 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4022364603582479
2024-05-07 21:40:58,827 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #179: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 3, 0, 0),(rev, 4)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '4/4', 'revenue': 0.7272727272727273, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.45, '(rev, 1)': 0.13, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-05-07 21:40:58,827 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:58,827 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4022364603582479
2024-05-07 21:40:59,572 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #179: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2682926829268293, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 3)': 0.04, '(min, 0)': 0.14, '(min, 1)': 0.5, '(rev, 1)': 0.14, '(rev, 3)': 0.01}}
2024-05-07 21:40:59,573 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:59,573 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4022364603582479
2024-05-07 21:40:59,645 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #179: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.54, '(min, 1)': 0.07}}
2024-05-07 21:40:59,645 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:59,646 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4022364603582479
2024-05-07 21:40:59,829 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #179: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 4)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.56, '(min, 1)': 0.11, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:40:59,829 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:40:59,830 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4022364603582479
2024-05-07 21:41:02,714 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #179: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 1, 1, 7, 0, 1),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 1, 1, 8, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.3170731707317073, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 9)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.36, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:41:02,714 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:02,715 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4022364603582479
2024-05-07 21:41:02,787 - MainProcess - INFO - text_logger.py - 51 - Train epoch #179
2024-05-07 21:41:02,790 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.7597e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4589e-01, 0.0000e+00,
        1.6583e-01, 8.2906e-03, 3.5654e-01, 0.0000e+00, 2.1020e-02, 9.4412e-03,
        0.0000e+00, 0.0000e+00, 1.8564e-02, 9.8281e-03, 0.0000e+00, 0.0000e+00,
        1.5781e-02, 4.8980e-03, 0.0000e+00, 0.0000e+00, 1.3845e-02, 8.0000e-05,
        0.0000e+00, 0.0000e+00, 1.1781e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1357e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1817e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2998e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.7557e-04, 0.0000e+00, 0.0000e+00])  tensor([1.8622e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4977e-01, 0.0000e+00,
        1.4143e-01, 1.8280e-02, 1.4971e-01, 0.0000e+00, 4.1145e-02, 2.4955e-02,
        0.0000e+00, 0.0000e+00, 4.2650e-02, 3.7383e-02, 0.0000e+00, 0.0000e+00,
        3.9000e-02, 2.0729e-02, 0.0000e+00, 0.0000e+00, 3.5605e-02, 1.7889e-03,
        0.0000e+00, 0.0000e+00, 3.1552e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2047e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5195e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.0977e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5309e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:41:02,810 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.40107332041188737
2024-05-07 21:41:02,812 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.158540.15854
2024-05-07 21:41:02,819 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #180: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32558139534883723, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(min, 0)': 0.34, '(min, 1)': 0.24, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-07 21:41:02,819 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:02,820 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40169848145927617
2024-05-07 21:41:02,835 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #180: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.045454545454545456, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.59, '(min, 1)': 0.07, '(rev, 1)': 0.04}}
2024-05-07 21:41:02,836 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:02,836 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40169848145927617
2024-05-07 21:41:02,851 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #180: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.34, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 6)': 0.01}}
2024-05-07 21:41:02,851 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:02,852 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40169848145927617
2024-05-07 21:41:02,878 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #180: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(min, 0)': 0.4, '(min, 1)': 0.2, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:41:02,878 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:02,879 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40169848145927617
2024-05-07 21:41:03,154 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #180: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 1.0, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.26, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.04, '(rev, 4)': 0.01}}
2024-05-07 21:41:03,154 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:03,155 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40169848145927617
2024-05-07 21:41:03,499 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #180: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5319148936170213, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.33, '(rev, 1)': 0.06, '(rev, 10)': 0.01, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:41:03,499 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:03,500 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40169848145927617
2024-05-07 21:41:05,069 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #180: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2619047619047619, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.17, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-07 21:41:05,070 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:05,070 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40169848145927617
2024-05-07 21:41:05,137 - MainProcess - INFO - text_logger.py - 51 - Train epoch #180
2024-05-07 21:41:05,141 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([9.9981e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7074e-01, 0.0000e+00,
        1.3267e-01, 9.5156e-03, 3.8528e-01, 0.0000e+00, 1.7534e-02, 6.6747e-03,
        0.0000e+00, 0.0000e+00, 1.6119e-02, 7.7814e-03, 0.0000e+00, 0.0000e+00,
        1.3396e-02, 3.1074e-03, 0.0000e+00, 0.0000e+00, 1.1876e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0359e-02, 7.4074e-05, 0.0000e+00, 0.0000e+00,
        9.6375e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1566e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.6652e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.1161e-04, 0.0000e+00, 0.0000e+00])  tensor([2.2575e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4396e-01, 0.0000e+00,
        1.3364e-01, 2.0606e-02, 1.4719e-01, 0.0000e+00, 3.8358e-02, 2.0154e-02,
        0.0000e+00, 0.0000e+00, 4.1009e-02, 2.9786e-02, 0.0000e+00, 0.0000e+00,
        3.6087e-02, 1.4251e-02, 0.0000e+00, 0.0000e+00, 3.3243e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.9556e-02, 1.6563e-03, 0.0000e+00, 0.0000e+00,
        2.8478e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2858e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.0084e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9386e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:41:05,163 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4009249058492886
2024-05-07 21:41:05,166 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.396910.13501
2024-05-07 21:41:05,397 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #181: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.35714285714285715, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.27, '(rev, 1)': 0.13, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:41:05,397 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:05,398 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40107332041188737
2024-05-07 21:41:05,688 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #181: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5813953488372093, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.03, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.11, '(rev, 2)': 0.07, '(rev, 3)': 0.04, '(rev, 4)': 0.01}}
2024-05-07 21:41:05,689 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:05,689 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40107332041188737
2024-05-07 21:41:06,098 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #181: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.75, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.2, '(min, 1)': 0.43, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.04, '(rev, 4)': 0.02, '(rev, 6)': 0.01}}
2024-05-07 21:41:06,098 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:06,099 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40107332041188737
2024-05-07 21:41:06,325 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #181: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.18181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.14, '(min, 1)': 0.44, '(rev, 1)': 0.06, '(rev, 2)': 0.03}}
2024-05-07 21:41:06,325 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:06,326 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40107332041188737
2024-05-07 21:41:06,423 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #181: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.27, '(rev, 1)': 0.12, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-07 21:41:06,423 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:06,424 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40107332041188737
2024-05-07 21:41:06,602 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #181: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.46, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 3)': 0.05}}
2024-05-07 21:41:06,603 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:06,603 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40107332041188737
2024-05-07 21:41:07,779 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #181: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 6, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4418604651162791, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.23, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:41:07,780 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:07,780 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.40107332041188737
2024-05-07 21:41:07,857 - MainProcess - INFO - text_logger.py - 51 - Train epoch #181
2024-05-07 21:41:07,860 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.5774e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0225e-01, 0.0000e+00,
        1.3933e-01, 1.0202e-02, 4.1750e-01, 0.0000e+00, 4.6811e-03, 9.3393e-03,
        0.0000e+00, 0.0000e+00, 1.4140e-03, 1.0007e-02, 0.0000e+00, 0.0000e+00,
        5.0588e-04, 4.2101e-03, 0.0000e+00, 0.0000e+00, 2.4462e-04, 1.6379e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5460e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.2242e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.1370e-02, 0.0000e+00,
        1.4814e-01, 1.9503e-02, 9.1952e-02, 0.0000e+00, 1.5087e-02, 1.9937e-02,
        0.0000e+00, 0.0000e+00, 8.2338e-03, 2.8534e-02, 0.0000e+00, 0.0000e+00,
        4.5185e-03, 1.6317e-02, 0.0000e+00, 0.0000e+00, 2.7821e-03, 1.8287e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1100e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:41:07,881 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4011454623288424
2024-05-07 21:41:07,883 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.581400.13953
2024-05-07 21:41:08,303 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #182: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5454545454545454, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.37, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:41:08,304 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:08,304 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4009249058492886
2024-05-07 21:41:08,385 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #182: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5227272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.22, '(min, 1)': 0.4, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:41:08,385 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:08,386 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4009249058492886
2024-05-07 21:41:08,570 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #182: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5116279069767442, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.15, '(min, 1)': 0.47, '(rev, 1)': 0.13, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-07 21:41:08,570 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:08,571 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4009249058492886
2024-05-07 21:41:10,149 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #182: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 6, 2, 0, 0),(rev, 6)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '6/6', 'revenue': 0.6530612244897959, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.14, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:41:10,149 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:10,149 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4009249058492886
2024-05-07 21:41:10,772 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #182: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.9210526315789473, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.45, '(min, 1)': 0.2, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:41:10,773 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:10,774 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4009249058492886
2024-05-07 21:41:10,860 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #182: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5531914893617021, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.04, '(min, 0)': 0.42, '(min, 1)': 0.18, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:41:10,861 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:10,861 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4009249058492886
2024-05-07 21:41:11,598 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #182: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6578947368421053, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.38, '(min, 1)': 0.24, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.04, '(rev, 4)': 0.02}}
2024-05-07 21:41:11,598 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:11,598 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4009249058492886
2024-05-07 21:41:11,681 - MainProcess - INFO - text_logger.py - 51 - Train epoch #182
2024-05-07 21:41:11,684 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.1110e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7575e-01, 0.0000e+00,
        1.3460e-01, 1.0575e-02, 3.9318e-01, 0.0000e+00, 1.3626e-02, 7.8943e-03,
        0.0000e+00, 0.0000e+00, 1.2642e-02, 9.3880e-03, 0.0000e+00, 0.0000e+00,
        1.0279e-02, 4.6432e-03, 0.0000e+00, 0.0000e+00, 9.0750e-03, 8.1667e-05,
        0.0000e+00, 0.0000e+00, 7.3455e-03, 1.1143e-04, 0.0000e+00, 0.0000e+00,
        7.2506e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7054e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.2426e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3025e-04, 0.0000e+00, 0.0000e+00])  tensor([2.2523e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2918e-01, 0.0000e+00,
        1.3574e-01, 2.0610e-02, 1.3429e-01, 0.0000e+00, 3.2269e-02, 1.9952e-02,
        0.0000e+00, 0.0000e+00, 3.6950e-02, 2.9144e-02, 0.0000e+00, 0.0000e+00,
        3.1953e-02, 1.5781e-02, 0.0000e+00, 0.0000e+00, 2.9307e-02, 1.2902e-03,
        0.0000e+00, 0.0000e+00, 2.4588e-02, 1.8290e-03, 0.0000e+00, 0.0000e+00,
        2.5284e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1079e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.5852e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9525e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:41:11,706 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4017821754791429
2024-05-07 21:41:11,708 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.789470.13158
2024-05-07 21:41:11,729 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #183: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.31, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 9)': 0.01}}
2024-05-07 21:41:11,729 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:11,730 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4011454623288424
2024-05-07 21:41:11,761 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #183: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2608695652173913, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.16, '(rev, 1)': 0.09, '(rev, 2)': 0.04}}
2024-05-07 21:41:11,761 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:11,762 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4011454623288424
2024-05-07 21:41:11,780 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #183: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 6, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5365853658536586, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.24, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 5)': 0.01}}
2024-05-07 21:41:11,781 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:11,781 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4011454623288424
2024-05-07 21:41:12,408 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #183: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.12, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03}}
2024-05-07 21:41:12,408 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:12,408 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4011454623288424
2024-05-07 21:41:13,125 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #183: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.49, '(min, 1)': 0.1}}
2024-05-07 21:41:13,126 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:13,126 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4011454623288424
2024-05-07 21:41:13,429 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #183: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 6, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2558139534883721, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.51, '(min, 1)': 0.12, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:41:13,429 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:13,430 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4011454623288424
2024-05-07 21:41:14,458 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #183: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(ado, 7)': 0.01, '(min, 0)': 0.57, '(min, 1)': 0.03}}
2024-05-07 21:41:14,458 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:14,459 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4011454623288424
2024-05-07 21:41:14,532 - MainProcess - INFO - text_logger.py - 51 - Train epoch #183
2024-05-07 21:41:14,535 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.0953e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9609e-01, 0.0000e+00,
        1.3242e-01, 1.0125e-02, 4.0118e-01, 0.0000e+00, 1.3687e-02, 4.6696e-03,
        0.0000e+00, 0.0000e+00, 1.1697e-02, 2.6881e-03, 0.0000e+00, 0.0000e+00,
        8.8958e-03, 7.5115e-04, 0.0000e+00, 0.0000e+00, 6.8979e-03, 5.5556e-05,
        0.0000e+00, 0.0000e+00, 5.0737e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.0209e-03, 8.0000e-05, 0.0000e+00, 0.0000e+00, 1.3455e-03, 7.1429e-05,
        0.0000e+00, 0.0000e+00, 1.4400e-04, 7.4074e-05, 0.0000e+00, 0.0000e+00,
        3.5714e-05, 0.0000e+00, 0.0000e+00])  tensor([1.7152e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2468e-01, 0.0000e+00,
        1.5105e-01, 1.9670e-02, 1.2437e-01, 0.0000e+00, 3.2026e-02, 1.3436e-02,
        0.0000e+00, 0.0000e+00, 3.3713e-02, 1.1902e-02, 0.0000e+00, 0.0000e+00,
        2.8134e-02, 5.1924e-03, 0.0000e+00, 0.0000e+00, 2.3925e-02, 1.2423e-03,
        0.0000e+00, 0.0000e+00, 1.9968e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9732e-02, 1.7889e-03, 0.0000e+00, 0.0000e+00, 7.5343e-03, 1.5972e-03,
        0.0000e+00, 0.0000e+00, 1.6157e-03, 1.6563e-03, 0.0000e+00, 0.0000e+00,
        7.9860e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:41:14,556 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4008399412610223
2024-05-07 21:41:14,558 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:41:14,580 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #184: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.14, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:41:14,581 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:14,581 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4017821754791429
2024-05-07 21:41:14,611 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #184: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.6, '(min, 1)': 0.05}}
2024-05-07 21:41:14,612 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:14,612 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4017821754791429
2024-05-07 21:41:14,947 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #184: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.8636363636363636, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(min, 0)': 0.21, '(min, 1)': 0.38, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-05-07 21:41:14,947 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:14,948 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4017821754791429
2024-05-07 21:41:15,077 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #184: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.19, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:41:15,077 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:15,078 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4017821754791429
2024-05-07 21:41:15,504 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #184: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.46, '(min, 1)': 0.13}}
2024-05-07 21:41:15,505 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:15,505 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4017821754791429
2024-05-07 21:41:16,623 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #184: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5306122448979592, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.19, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:41:16,623 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:16,624 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4017821754791429
2024-05-07 21:41:17,659 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #184: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.55, '(min, 1)': 0.06}}
2024-05-07 21:41:17,659 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:17,659 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4017821754791429
2024-05-07 21:41:17,740 - MainProcess - INFO - text_logger.py - 51 - Train epoch #184
2024-05-07 21:41:17,743 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-7.1204e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.0704e-01,
         0.0000e+00,  1.4755e-01,  6.2597e-03,  3.1584e-01,  0.0000e+00,
         3.5579e-02,  2.7512e-03,  0.0000e+00,  0.0000e+00,  4.2881e-02,
         2.0899e-03,  0.0000e+00,  0.0000e+00,  3.7167e-02,  1.2775e-03,
         0.0000e+00,  0.0000e+00,  3.2450e-02,  2.8169e-05,  0.0000e+00,
         0.0000e+00,  2.7719e-02,  2.8169e-05,  0.0000e+00,  0.0000e+00,
         2.7499e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1224e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.1410e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  4.7908e-04,  0.0000e+00,  0.0000e+00])  tensor([2.2079e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8519e-01, 0.0000e+00,
        1.2865e-01, 1.6114e-02, 1.9203e-01, 0.0000e+00, 4.7958e-02, 1.0434e-02,
        0.0000e+00, 0.0000e+00, 6.1690e-02, 1.1245e-02, 0.0000e+00, 0.0000e+00,
        5.4466e-02, 8.2611e-03, 0.0000e+00, 0.0000e+00, 4.8733e-02, 6.2988e-04,
        0.0000e+00, 0.0000e+00, 4.2482e-02, 6.2988e-04, 0.0000e+00, 0.0000e+00,
        4.4201e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9262e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.2368e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7597e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:41:17,762 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.39989770704290173
2024-05-07 21:41:17,765 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:41:17,788 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #185: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3191489361702128, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 6)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.26, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
v, 8)': 0.01}}
2024-05-07 21:41:17,789 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:17,789 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4008399412610223
2024-05-07 21:41:17,790 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4008399412610223
2024-05-07 21:41:17,809 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #185: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5652173913043478, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.43, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 6)': 0.01, '(rev, 9)': 0.01}}
2024-05-07 21:41:17,809 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:17,810 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4008399412610223
2024-05-07 21:41:17,945 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #185: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.58, '(min, 1)': 0.03}}
2024-05-07 21:41:17,945 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:17,946 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4008399412610223
2024-05-07 21:41:18,400 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #185: {'transition': '(exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 2, 4, 1, 1),(min, 0)->(exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 2, 5, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.03, '(min, 0)': 0.4, '(min, 1)': 0.2, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-07 21:41:18,401 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:18,401 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4008399412610223
2024-05-07 21:41:19,437 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #185: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.02, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.29, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:41:19,437 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:19,438 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4008399412610223
2024-05-07 21:41:20,155 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #185: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.55, '(min, 1)': 0.06}}
2024-05-07 21:41:20,155 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:20,155 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4008399412610223
2024-05-07 21:41:20,235 - MainProcess - INFO - text_logger.py - 51 - Train epoch #185
2024-05-07 21:41:20,238 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0148e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5612e-01, 0.0000e+00,
        1.4781e-01, 8.9569e-03, 3.6265e-01, 0.0000e+00, 2.1143e-02, 5.1436e-03,
        0.0000e+00, 0.0000e+00, 2.1543e-02, 9.3914e-03, 0.0000e+00, 0.0000e+00,
        1.7217e-02, 7.0398e-03, 0.0000e+00, 0.0000e+00, 1.4499e-02, 1.6766e-04,
        0.0000e+00, 0.0000e+00, 1.1739e-02, 6.9412e-05, 0.0000e+00, 0.0000e+00,
        1.1395e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2705e-03, 8.0000e-05,
        0.0000e+00, 0.0000e+00, 5.7801e-04, 7.4074e-05, 0.0000e+00, 0.0000e+00,
        1.1970e-04, 0.0000e+00, 0.0000e+00])  tensor([2.1285e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5722e-01, 0.0000e+00,
        1.5586e-01, 2.0240e-02, 1.5475e-01, 0.0000e+00, 3.9846e-02, 1.6691e-02,
        0.0000e+00, 0.0000e+00, 4.7675e-02, 3.8426e-02, 0.0000e+00, 0.0000e+00,
        4.0287e-02, 2.9447e-02, 0.0000e+00, 0.0000e+00, 3.5370e-02, 1.7013e-03,
        0.0000e+00, 0.0000e+00, 2.9311e-02, 1.1091e-03, 0.0000e+00, 0.0000e+00,
        2.9689e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2292e-02, 1.7889e-03,
        0.0000e+00, 0.0000e+00, 3.2145e-03, 1.6563e-03, 0.0000e+00, 0.0000e+00,
        1.3507e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:41:20,259 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.39895547282478117
2024-05-07 21:41:20,261 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:41:20,435 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #186: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.58, '(min, 1)': 0.03}}
2024-05-07 21:41:20,435 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:20,436 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39989770704290173
2024-05-07 21:41:20,817 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #186: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 3)': 0.03, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.28, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:41:20,817 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:20,817 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39989770704290173
2024-05-07 21:41:20,883 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #186: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6744186046511628, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(min, 0)': 0.28, '(min, 1)': 0.4, '(rev, 1)': 0.13, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:41:20,883 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:20,884 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39989770704290173
2024-05-07 21:41:21,060 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #186: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.44, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:41:21,060 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:21,061 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39989770704290173
2024-05-07 21:41:21,453 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #186: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 3)': 0.04, '(ado, 7)': 0.01, '(min, 0)': 0.55, '(min, 1)': 0.12, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:41:21,453 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:21,454 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39989770704290173
2024-05-07 21:41:22,242 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #186: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.17777777777777778, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.16, '(rev, 1)': 0.05, '(rev, 2)': 0.05}}
2024-05-07 21:41:22,242 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:22,243 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39989770704290173
2024-05-07 21:41:22,533 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #186: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.59, '(min, 1)': 0.04}}
2024-05-07 21:41:22,533 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:22,534 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39989770704290173
2024-05-07 21:41:22,607 - MainProcess - INFO - text_logger.py - 51 - Train epoch #186
2024-05-07 21:41:22,610 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.7896e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3690e-01, 0.0000e+00,
        1.8179e-01, 8.8743e-03, 3.4849e-01, 0.0000e+00, 2.3540e-02, 8.5922e-03,
        0.0000e+00, 0.0000e+00, 1.8740e-02, 1.1535e-02, 0.0000e+00, 0.0000e+00,
        1.5702e-02, 5.4604e-03, 0.0000e+00, 0.0000e+00, 1.3348e-02, 4.2553e-05,
        0.0000e+00, 0.0000e+00, 1.1368e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0790e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2686e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.8869e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.5579e-05, 0.0000e+00, 0.0000e+00])  tensor([1.8945e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4857e-01, 0.0000e+00,
        1.5555e-01, 1.9877e-02, 1.4962e-01, 0.0000e+00, 4.2194e-02, 2.1758e-02,
        0.0000e+00, 0.0000e+00, 4.2225e-02, 5.0945e-02, 0.0000e+00, 0.0000e+00,
        4.0149e-02, 2.6867e-02, 0.0000e+00, 0.0000e+00, 3.5732e-02, 9.5152e-04,
        0.0000e+00, 0.0000e+00, 3.1706e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.1784e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3247e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.0333e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1947e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:41:22,632 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3980132386066606
2024-05-07 21:41:22,634 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:41:22,799 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #187: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 1, 7, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 2, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.53, '(min, 1)': 0.06}}
2024-05-07 21:41:22,800 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:22,800 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39895547282478117
2024-05-07 21:41:23,873 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #187: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5476190476190477, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.35, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.02}}
2024-05-07 21:41:23,874 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:23,874 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39895547282478117
2024-05-07 21:41:24,052 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #187: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.36, '(rev, 1)': 0.01, '(rev, 2)': 0.02, '(rev, 3)': 0.04, '(rev, 4)': 0.02, '(rev, 5)': 0.02, '(rev, 6)': 0.01}}
2024-05-07 21:41:24,052 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:24,053 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39895547282478117
2024-05-07 21:41:24,238 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #187: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.32, '(min, 1)': 0.33, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 7)': 0.01}}
2024-05-07 21:41:24,238 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:24,239 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39895547282478117
2024-05-07 21:41:24,650 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #187: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 5, 0, 1),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 6, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.7142857142857143, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.04, '(min, 0)': 0.26, '(min, 1)': 0.38, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:41:24,651 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:24,651 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39895547282478117
2024-05-07 21:41:24,729 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #187: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4358974358974359, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.46, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:41:24,729 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:24,730 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39895547282478117
2024-05-07 21:41:24,823 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #187: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.5, '(min, 1)': 0.12}}
2024-05-07 21:41:24,823 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:24,824 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39895547282478117
2024-05-07 21:41:24,935 - MainProcess - INFO - text_logger.py - 51 - Train epoch #187
2024-05-07 21:41:24,938 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.6158e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6732e-01, 0.0000e+00,
        1.9010e-01, 1.0160e-02, 3.7991e-01, 0.0000e+00, 1.0263e-02, 1.0553e-02,
        0.0000e+00, 0.0000e+00, 4.2493e-03, 1.2523e-02, 0.0000e+00, 0.0000e+00,
        2.4123e-03, 7.4764e-03, 0.0000e+00, 0.0000e+00, 1.5045e-03, 4.3374e-04,
        0.0000e+00, 0.0000e+00, 1.2673e-03, 1.5692e-04, 0.0000e+00, 0.0000e+00,
        1.0589e-03, 6.4516e-05, 0.0000e+00, 0.0000e+00, 4.9495e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.5556e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.3149e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1694e-01, 0.0000e+00,
        1.8141e-01, 2.0813e-02, 1.1373e-01, 0.0000e+00, 2.5393e-02, 2.2779e-02,
        0.0000e+00, 0.0000e+00, 1.7939e-02, 3.2120e-02, 0.0000e+00, 0.0000e+00,
        1.3689e-02, 2.2963e-02, 0.0000e+00, 0.0000e+00, 1.1267e-02, 3.2393e-03,
        0.0000e+00, 0.0000e+00, 1.0087e-02, 2.4792e-03, 0.0000e+00, 0.0000e+00,
        9.4340e-03, 1.4426e-03, 0.0000e+00, 0.0000e+00, 4.5595e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2423e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:41:24,958 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.39707100438854004
2024-05-07 21:41:24,960 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:41:25,202 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #188: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.52, '(min, 1)': 0.09}}
2024-05-07 21:41:25,202 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:25,203 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3980132386066606
2024-05-07 21:41:26,232 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #188: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40425531914893614, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.19, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-07 21:41:26,232 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:26,233 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3980132386066606
2024-05-07 21:41:26,472 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #188: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(ado, 4)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.13, '(rev, 1)': 0.09, '(rev, 2)': 0.05}}
2024-05-07 21:41:26,472 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:26,473 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3980132386066606
2024-05-07 21:41:26,801 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #188: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.17, '(rev, 1)': 0.03, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:41:26,801 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:26,802 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3980132386066606
2024-05-07 21:41:27,194 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #188: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.02, '(min, 0)': 0.13, '(min, 1)': 0.48, '(rev, 1)': 0.12, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:41:27,194 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:27,195 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3980132386066606
2024-05-07 21:41:27,402 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #188: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.21, '(rev, 1)': 0.11, '(rev, 2)': 0.05}}
2024-05-07 21:41:27,402 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:27,403 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3980132386066606
2024-05-07 21:41:28,371 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #188: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 6, 0, 1),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 6, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.56, '(min, 1)': 0.1}}
2024-05-07 21:41:28,371 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:28,372 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3980132386066606
2024-05-07 21:41:28,446 - MainProcess - INFO - text_logger.py - 51 - Train epoch #188
2024-05-07 21:41:28,449 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.3038e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2336e-01, 0.0000e+00,
        1.2156e-01, 1.2352e-02, 4.2876e-01, 0.0000e+00, 3.8628e-03, 4.9883e-03,
        0.0000e+00, 0.0000e+00, 1.3180e-03, 2.0387e-03, 0.0000e+00, 0.0000e+00,
        5.2997e-04, 7.4198e-04, 0.0000e+00, 0.0000e+00, 2.9984e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2311e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.0606e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([0.9026, 0.0000, 0.0000, 0.0000, 0.0742, 0.0000, 0.1307, 0.0213, 0.0755,
        0.0000, 0.0134, 0.0131, 0.0000, 0.0000, 0.0089, 0.0094, 0.0000, 0.0000,
        0.0047, 0.0054, 0.0000, 0.0000, 0.0036, 0.0000, 0.0000, 0.0000, 0.0019,
        0.0000, 0.0000, 0.0000, 0.0014, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-05-07 21:41:28,469 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3961287701704194
2024-05-07 21:41:28,471 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:41:28,695 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #189: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3617021276595745, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.02, '(min, 0)': 0.12, '(min, 1)': 0.45, '(rev, 1)': 0.12, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:41:28,695 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:28,695 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39707100438854004
2024-05-07 21:41:28,814 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #189: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5185185185185185, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.13, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:41:28,815 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:28,815 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39707100438854004
2024-05-07 21:41:29,654 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #189: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(ado, 4)': 0.02, '(min, 0)': 0.1, '(min, 1)': 0.52, '(rev, 1)': 0.12, '(rev, 2)': 0.01}}
2024-05-07 21:41:29,654 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:29,655 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39707100438854004
2024-05-07 21:41:30,157 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #189: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.42857142857142855, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.5, '(min, 1)': 0.18, '(rev, 1)': 0.03, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:41:30,157 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:30,158 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39707100438854004
2024-05-07 21:41:30,818 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #189: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.14, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-07 21:41:30,818 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:30,819 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39707100438854004
2024-05-07 21:41:31,379 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #189: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46511627906976744, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.29, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:41:31,379 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:31,380 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39707100438854004
2024-05-07 21:41:31,758 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #189: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 8)': 0.01, '(min, 0)': 0.55, '(min, 1)': 0.07, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-05-07 21:41:31,758 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:31,758 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39707100438854004
2024-05-07 21:41:31,832 - MainProcess - INFO - text_logger.py - 51 - Train epoch #189
2024-05-07 21:41:31,835 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.8897e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7843e-01, 0.0000e+00,
        1.2070e-01, 1.1169e-02, 3.9358e-01, 0.0000e+00, 1.6431e-02, 6.9143e-03,
        0.0000e+00, 0.0000e+00, 1.6289e-02, 6.6723e-03, 0.0000e+00, 0.0000e+00,
        1.2946e-02, 2.5548e-03, 0.0000e+00, 0.0000e+00, 1.1258e-02, 1.3942e-04,
        0.0000e+00, 0.0000e+00, 9.3836e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.9753e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9569e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.6461e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.7037e-05, 0.0000e+00, 0.0000e+00])  tensor([2.0857e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3897e-01, 0.0000e+00,
        1.3750e-01, 2.2038e-02, 1.4499e-01, 0.0000e+00, 3.6800e-02, 1.6703e-02,
        0.0000e+00, 0.0000e+00, 4.3030e-02, 2.1481e-02, 0.0000e+00, 0.0000e+00,
        3.6069e-02, 1.1340e-02, 0.0000e+00, 0.0000e+00, 3.2934e-02, 2.2141e-03,
        0.0000e+00, 0.0000e+00, 2.7800e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7447e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2598e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.4976e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.2817e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:41:31,854 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3959876631664696
2024-05-07 21:41:31,856 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.400560.11795
2024-05-07 21:41:31,895 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #190: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.02, '(min, 0)': 0.47, '(min, 1)': 0.14, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.02}}
2024-05-07 21:41:31,895 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:31,896 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3961287701704194
2024-05-07 21:41:32,543 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #190: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.9555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.44, '(min, 1)': 0.18, '(rev, 1)': 0.12, '(rev, 2)': 0.09}}
2024-05-07 21:41:32,543 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:32,544 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3961287701704194
2024-05-07 21:41:32,653 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #190: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8297872340425532, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.21, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 5)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:41:32,653 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:32,653 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3961287701704194
2024-05-07 21:41:33,774 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #190: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.02, '(min, 0)': 0.52, '(min, 1)': 0.13, '(rev, 1)': 0.03, '(rev, 2)': 0.02}}
2024-05-07 21:41:33,774 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:33,774 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3961287701704194
2024-05-07 21:41:34,219 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #190: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.16666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.51, '(min, 1)': 0.1, '(rev, 1)': 0.02, '(rev, 2)': 0.04}}
2024-05-07 21:41:34,220 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:34,220 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3961287701704194
2024-05-07 21:41:34,457 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #190: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5869565217391305, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.54, '(min, 1)': 0.07, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-05-07 21:41:34,457 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:34,457 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #190: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.027777777777777776, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.46, '(min, 1)': 0.18, '(rev, 1)': 0.01}}
2024-05-07 21:41:34,458 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:34,458 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3961287701704194
2024-05-07 21:41:34,458 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3961287701704194
2024-05-07 21:41:34,670 - MainProcess - INFO - text_logger.py - 51 - Train epoch #190
2024-05-07 21:41:34,673 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.7531e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.3885e-01,
         0.0000e+00,  1.3715e-01,  7.4365e-03,  3.4872e-01,  0.0000e+00,
         2.8093e-02,  2.7624e-03,  0.0000e+00,  0.0000e+00,  3.3816e-02,
         9.5473e-04,  0.0000e+00,  0.0000e+00,  2.8217e-02,  5.9649e-04,
         0.0000e+00,  0.0000e+00,  2.3652e-02,  5.5556e-05,  0.0000e+00,
         0.0000e+00,  1.9666e-02,  7.4074e-05,  0.0000e+00,  0.0000e+00,
         2.0031e-02,  6.0606e-05,  0.0000e+00,  0.0000e+00,  8.4198e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.3197e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  1.2500e-04,  0.0000e+00,  0.0000e+00])  tensor([2.0564e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6851e-01, 0.0000e+00,
        1.2682e-01, 1.7027e-02, 1.7638e-01, 0.0000e+00, 4.3802e-02, 9.4239e-03,
        0.0000e+00, 0.0000e+00, 5.8001e-02, 6.7685e-03, 0.0000e+00, 0.0000e+00,
        5.0376e-02, 4.1474e-03, 0.0000e+00, 0.0000e+00, 4.3453e-02, 1.2423e-03,
        0.0000e+00, 0.0000e+00, 3.6926e-02, 1.6563e-03, 0.0000e+00, 0.0000e+00,
        3.9488e-02, 1.3552e-03, 0.0000e+00, 0.0000e+00, 1.7687e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.1141e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4115e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:41:34,694 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3954732067261267
2024-05-07 21:41:34,696 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.213890.18611
2024-05-07 21:41:34,829 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #191: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5217391304347826, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.38, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:41:34,829 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:34,830 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3959876631664696
2024-05-07 21:41:34,956 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #191: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0),(rev, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.4186046511627907, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.4, '(rev, 1)': 0.11, '(rev, 2)': 0.05, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:41:34,956 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:34,956 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3959876631664696
2024-05-07 21:41:35,177 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #191: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.05, '(ado, 4)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.19, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:41:35,177 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:35,178 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3959876631664696
2024-05-07 21:41:36,642 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #191: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.15384615384615385, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.25, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:41:36,642 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:36,643 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3959876631664696
2024-05-07 21:41:36,859 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #191: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.56, '(min, 1)': 0.07}}
2024-05-07 21:41:36,859 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:36,860 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3959876631664696
2024-05-07 21:41:37,426 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #191: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.16, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:41:37,427 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:37,427 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3959876631664696
2024-05-07 21:41:37,918 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #191: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 4, 0, 0),(rev, 4)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.9523809523809523, 'length': 100, 'actions': {'(ado, 1)': 0.06, '(ado, 3)': 0.02, '(min, 0)': 0.44, '(min, 1)': 0.31, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.03, '(rev, 5)': 0.02, '(rev, 6)': 0.01}}
2024-05-07 21:41:37,918 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:37,919 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3959876631664696
2024-05-07 21:41:38,134 - MainProcess - INFO - text_logger.py - 51 - Train epoch #191
2024-05-07 21:41:38,137 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.2686e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6164e-01, 0.0000e+00,
        1.4873e-01, 1.2940e-02, 3.7645e-01, 0.0000e+00, 1.7487e-02, 9.0300e-03,
        0.0000e+00, 0.0000e+00, 1.5983e-02, 7.4526e-03, 0.0000e+00, 0.0000e+00,
        1.2739e-02, 3.6654e-03, 0.0000e+00, 0.0000e+00, 1.0613e-02, 5.9511e-04,
        0.0000e+00, 0.0000e+00, 9.1549e-03, 5.7143e-05, 0.0000e+00, 0.0000e+00,
        8.7599e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7679e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.1028e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.2061e-04, 0.0000e+00, 0.0000e+00])  tensor([2.1614e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3880e-01, 0.0000e+00,
        1.4751e-01, 2.5368e-02, 1.4294e-01, 0.0000e+00, 3.5935e-02, 1.9277e-02,
        0.0000e+00, 0.0000e+00, 4.2349e-02, 2.3617e-02, 0.0000e+00, 0.0000e+00,
        3.6564e-02, 1.2443e-02, 0.0000e+00, 0.0000e+00, 3.1610e-02, 3.7895e-03,
        0.0000e+00, 0.0000e+00, 2.7470e-02, 1.2778e-03, 0.0000e+00, 0.0000e+00,
        2.7843e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2299e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.7197e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8815e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:41:38,156 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.395052711638441
2024-05-07 21:41:38,158 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.260870.26087
2024-05-07 21:41:38,182 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #192: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(min, 0)': 0.1, '(min, 1)': 0.49, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.03}}
2024-05-07 21:41:38,183 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:38,183 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3954732067261267
2024-05-07 21:41:38,198 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #192: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5869565217391305, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.27, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:41:38,199 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:38,199 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3954732067261267
2024-05-07 21:41:38,875 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #192: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 6, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.04, '(ado, 5)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.2, '(rev, 1)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:41:38,875 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:38,876 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3954732067261267
2024-05-07 21:41:39,223 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #192: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.45, '(min, 1)': 0.18}}
2024-05-07 21:41:39,223 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:39,224 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3954732067261267
2024-05-07 21:41:40,146 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #192: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.09, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.35, '(rev, 1)': 0.12, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 6)': 0.01}}
2024-05-07 21:41:40,146 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:40,146 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3954732067261267
2024-05-07 21:41:40,172 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #192: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 6, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 3, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.35, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:41:40,173 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:40,173 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3954732067261267
2024-05-07 21:41:40,463 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #192: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.58, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.46, '(min, 1)': 0.16, '(rev, 1)': 0.07, '(rev, 2)': 0.09, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:41:40,463 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:40,464 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3954732067261267
2024-05-07 21:41:40,678 - MainProcess - INFO - text_logger.py - 51 - Train epoch #192
2024-05-07 21:41:40,681 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0594e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9887e-01, 0.0000e+00,
        1.3335e-01, 1.4341e-02, 4.1568e-01, 0.0000e+00, 5.5006e-03, 1.0636e-02,
        0.0000e+00, 0.0000e+00, 1.7484e-03, 1.2153e-02, 0.0000e+00, 0.0000e+00,
        7.6204e-04, 5.7109e-03, 0.0000e+00, 0.0000e+00, 3.7719e-04, 2.0916e-04,
        0.0000e+00, 0.0000e+00, 2.3793e-04, 2.1435e-04, 0.0000e+00, 0.0000e+00,
        5.5556e-05, 1.4923e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.3529e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.6281e-02, 0.0000e+00,
        1.5318e-01, 2.5856e-02, 9.2866e-02, 0.0000e+00, 1.6466e-02, 2.2228e-02,
        0.0000e+00, 0.0000e+00, 1.0721e-02, 3.6914e-02, 0.0000e+00, 0.0000e+00,
        6.5356e-03, 1.9302e-02, 0.0000e+00, 0.0000e+00, 3.9203e-03, 1.9218e-03,
        0.0000e+00, 0.0000e+00, 3.4657e-03, 2.3386e-03, 0.0000e+00, 0.0000e+00,
        1.2423e-03, 2.0975e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:41:40,697 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.39443656437684216
2024-05-07 21:41:40,700 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.163040.16304
2024-05-07 21:41:40,724 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #193: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.04, '(min, 0)': 0.42, '(min, 1)': 0.17, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:41:40,724 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:40,725 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.395052711638441
2024-05-07 21:41:41,509 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #193: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.5, '(min, 1)': 0.1}}
2024-05-07 21:41:41,509 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:41,510 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.395052711638441
2024-05-07 21:41:41,651 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #193: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.66, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(min, 0)': 0.42, '(min, 1)': 0.16, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 6)': 0.01}}
2024-05-07 21:41:41,651 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:41,652 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.395052711638441
2024-05-07 21:41:42,332 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #193: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.45652173913043476, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(ado, 7)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.16, '(rev, 1)': 0.08, '(rev, 2)': 0.04}}
2024-05-07 21:41:42,332 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:42,333 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.395052711638441
2024-05-07 21:41:42,761 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #193: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.16666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.04, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.19, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:41:42,761 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:42,762 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.395052711638441
2024-05-07 21:41:42,963 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #193: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4489795918367347, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(min, 0)': 0.41, '(min, 1)': 0.19, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:41:42,963 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:42,964 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.395052711638441
2024-05-07 21:41:43,704 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #193: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6363636363636364, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.03, '(min, 0)': 0.39, '(min, 1)': 0.28, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:41:43,704 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:43,704 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.395052711638441
2024-05-07 21:41:43,909 - MainProcess - INFO - text_logger.py - 51 - Train epoch #193
2024-05-07 21:41:43,912 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.4531e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8880e-01, 0.0000e+00,
        1.2337e-01, 9.8615e-03, 4.0346e-01, 0.0000e+00, 1.2120e-02, 5.0587e-03,
        0.0000e+00, 0.0000e+00, 1.2184e-02, 4.8215e-03, 0.0000e+00, 0.0000e+00,
        9.7303e-03, 3.5860e-03, 0.0000e+00, 0.0000e+00, 8.5514e-03, 1.9384e-04,
        0.0000e+00, 0.0000e+00, 6.9852e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.3172e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2460e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.4373e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7755e-04, 0.0000e+00, 0.0000e+00])  tensor([2.1003, 0.0000, 0.0000, 0.0000, 0.1277, 0.0000, 0.1310, 0.0204, 0.1308,
        0.0000, 0.0313, 0.0154, 0.0000, 0.0000, 0.0385, 0.0212, 0.0000, 0.0000,
        0.0330, 0.0155, 0.0000, 0.0000, 0.0295, 0.0023, 0.0000, 0.0000, 0.0246,
        0.0000, 0.0000, 0.0000, 0.0264, 0.0000, 0.0000, 0.0000, 0.0121, 0.0000,
        0.0000, 0.0000, 0.0034, 0.0000, 0.0000, 0.0000, 0.0022, 0.0000, 0.0000]) (500)
2024-05-07 21:41:43,933 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3937769388543737
2024-05-07 21:41:43,936 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.141300.14130
2024-05-07 21:41:43,973 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #194: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 4)': 0.02, '(min, 0)': 0.37, '(min, 1)': 0.25, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.02}}
2024-05-07 21:41:43,974 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:43,975 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39443656437684216
2024-05-07 21:41:43,988 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #194: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.42, '(min, 1)': 0.15}}
2024-05-07 21:41:43,988 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #194: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 4)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.17, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:41:43,988 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:43,988 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:43,989 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39443656437684216
2024-05-07 21:41:43,989 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39443656437684216
2024-05-07 21:41:45,508 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #194: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6590909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.36, '(min, 1)': 0.27, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-05-07 21:41:45,509 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:45,509 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39443656437684216
2024-05-07 21:41:45,773 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #194: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5227272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.03, '(min, 0)': 0.32, '(min, 1)': 0.33, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 6)': 0.02, '(rev, 8)': 0.01}}
2024-05-07 21:41:45,773 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:45,774 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39443656437684216
2024-05-07 21:41:46,100 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #194: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.4666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 3)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.47, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-05-07 21:41:46,100 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:46,101 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39443656437684216
2024-05-07 21:41:47,580 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #194: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34210526315789475, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.03, '(ado, 6)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.37, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:41:47,580 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:47,581 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39443656437684216
2024-05-07 21:41:47,794 - MainProcess - INFO - text_logger.py - 51 - Train epoch #194
2024-05-07 21:41:47,797 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.5767e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8885e-01, 0.0000e+00,
        1.5810e-01, 1.2539e-02, 3.9667e-01, 0.0000e+00, 1.1001e-02, 6.7220e-03,
        0.0000e+00, 0.0000e+00, 6.6047e-03, 4.3203e-03, 0.0000e+00, 0.0000e+00,
        4.5173e-03, 1.4596e-03, 0.0000e+00, 0.0000e+00, 3.3861e-03, 7.8462e-05,
        0.0000e+00, 0.0000e+00, 2.5715e-03, 7.8462e-05, 0.0000e+00, 0.0000e+00,
        2.2129e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.0844e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.0000e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7044e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1313e-01, 0.0000e+00,
        1.6689e-01, 2.3384e-02, 1.1317e-01, 0.0000e+00, 2.7838e-02, 1.4718e-02,
        0.0000e+00, 0.0000e+00, 2.5906e-02, 1.4407e-02, 0.0000e+00, 0.0000e+00,
        2.0319e-02, 7.2457e-03, 0.0000e+00, 0.0000e+00, 1.7569e-02, 1.2396e-03,
        0.0000e+00, 0.0000e+00, 1.4212e-02, 1.2396e-03, 0.0000e+00, 0.0000e+00,
        1.2798e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8279e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.7889e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:41:47,817 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3932260089840793
2024-05-07 21:41:47,819 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.195650.19565
2024-05-07 21:41:47,825 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #195: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.61, '(min, 1)': 0.01}}
2024-05-07 21:41:47,825 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:47,826 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3937769388543737
2024-05-07 21:41:47,841 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #195: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.07, '(min, 0)': 0.38, '(min, 1)': 0.21, '(rev, 1)': 0.08}}
2024-05-07 21:41:47,841 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:47,842 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3937769388543737
2024-05-07 21:41:47,875 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #195: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28205128205128205, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.34, '(min, 1)': 0.28, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-07 21:41:47,876 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:47,876 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3937769388543737
2024-05-07 21:41:47,895 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #195: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.45454545454545453, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 3)': 0.02, '(min, 0)': 0.32, '(min, 1)': 0.29, '(rev, 1)': 0.13, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:41:47,895 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:47,895 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3937769388543737
2024-05-07 21:41:47,990 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #195: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43478260869565216, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 4)': 0.02, '(min, 0)': 0.46, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-05-07 21:41:47,990 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:47,990 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3937769388543737
2024-05-07 21:41:49,425 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #195: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5833333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.45, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-07 21:41:49,425 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:49,426 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3937769388543737
2024-05-07 21:41:49,907 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #195: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 2)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.1}}
2024-05-07 21:41:49,907 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:49,908 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3937769388543737
2024-05-07 21:41:50,111 - MainProcess - INFO - text_logger.py - 51 - Train epoch #195
2024-05-07 21:41:50,114 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-5.1586e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.4520e-01,
         0.0000e+00,  1.2968e-01,  9.4073e-03,  3.5440e-01,  0.0000e+00,
         2.4809e-02,  3.5355e-03,  0.0000e+00,  0.0000e+00,  2.9421e-02,
         1.7147e-03,  0.0000e+00,  0.0000e+00,  2.5264e-02,  8.8275e-04,
         0.0000e+00,  0.0000e+00,  2.3099e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  1.9597e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.0357e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.9583e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.2136e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  4.6608e-04,  0.0000e+00,  0.0000e+00])  tensor([1.6134, 0.0000, 0.0000, 0.0000, 0.1659, 0.0000, 0.1148, 0.0212, 0.1714,
        0.0000, 0.0431, 0.0112, 0.0000, 0.0000, 0.0559, 0.0094, 0.0000, 0.0000,
        0.0491, 0.0073, 0.0000, 0.0000, 0.0453, 0.0000, 0.0000, 0.0000, 0.0388,
        0.0000, 0.0000, 0.0000, 0.0406, 0.0000, 0.0000, 0.0000, 0.0203, 0.0000,
        0.0000, 0.0000, 0.0065, 0.0000, 0.0000, 0.0000, 0.0028, 0.0000, 0.0000]) (500)
2024-05-07 21:41:50,135 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.39256582604801
2024-05-07 21:41:50,138 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.141030.14103
2024-05-07 21:41:50,157 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #196: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.44, '(min, 1)': 0.15}}
2024-05-07 21:41:50,157 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:50,158 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3932260089840793
2024-05-07 21:41:50,243 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #196: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.55, '(min, 1)': 0.06}}
2024-05-07 21:41:50,244 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:50,244 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3932260089840793
2024-05-07 21:41:50,550 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #196: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.11904761904761904, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 8)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.27, '(rev, 1)': 0.05, '(rev, 2)': 0.01}}
2024-05-07 21:41:50,550 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:50,550 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3932260089840793
2024-05-07 21:41:51,017 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #196: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.41, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.04, '(rev, 4)': 0.01}}
2024-05-07 21:41:51,017 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:51,018 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3932260089840793
2024-05-07 21:41:51,118 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #196: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3953488372093023, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.03, '(min, 0)': 0.27, '(min, 1)': 0.41, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:41:51,118 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:51,119 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3932260089840793
2024-05-07 21:41:51,645 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #196: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(min, 0)': 0.54, '(min, 1)': 0.02, '(rev, 1)': 0.11, '(rev, 2)': 0.07}}
2024-05-07 21:41:51,645 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:51,646 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3932260089840793
2024-05-07 21:41:53,721 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #196: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.375, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.19, '(rev, 1)': 0.01, '(rev, 2)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:41:53,722 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:53,722 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3932260089840793
2024-05-07 21:41:53,925 - MainProcess - INFO - text_logger.py - 51 - Train epoch #196
2024-05-07 21:41:53,928 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-4.0498e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.1069e-01,
         0.0000e+00,  1.5229e-01,  9.6481e-03,  3.1546e-01,  0.0000e+00,
         3.5905e-02,  5.3707e-03,  0.0000e+00,  0.0000e+00,  3.9377e-02,
         4.3350e-03,  0.0000e+00,  0.0000e+00,  3.2917e-02,  3.1541e-03,
         0.0000e+00,  0.0000e+00,  2.8961e-02,  7.1096e-05,  0.0000e+00,
         0.0000e+00,  2.4462e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.4559e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0510e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.8857e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  4.0828e-04,  0.0000e+00,  0.0000e+00])  tensor([2.2107e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7914e-01, 0.0000e+00,
        1.3434e-01, 2.2752e-02, 1.8127e-01, 0.0000e+00, 5.0838e-02, 1.6992e-02,
        0.0000e+00, 0.0000e+00, 6.1568e-02, 1.8859e-02, 0.0000e+00, 0.0000e+00,
        5.2997e-02, 1.5051e-02, 0.0000e+00, 0.0000e+00, 4.7635e-02, 1.1660e-03,
        0.0000e+00, 0.0000e+00, 4.0597e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.1693e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9756e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.9922e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5409e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:41:53,951 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3916235918298894
2024-05-07 21:41:53,954 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:41:53,988 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #197: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17307692307692307, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.12, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:41:53,988 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:53,989 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39256582604801
2024-05-07 21:41:54,004 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #197: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8823529411764706, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 9)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.21, '(rev, 1)': 0.06, '(rev, 2)': 0.06}}
2024-05-07 21:41:54,005 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:54,006 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #197: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4186046511627907, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.29, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 3)': 0.03}}
2024-05-07 21:41:54,006 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39256582604801
2024-05-07 21:41:54,006 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:54,007 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39256582604801
2024-05-07 21:41:54,022 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #197: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.47, '(min, 1)': 0.12}}
2024-05-07 21:41:54,022 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:54,023 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39256582604801
2024-05-07 21:41:54,028 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #197: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.23, '(rev, 1)': 0.08, '(rev, 2)': 0.07}}
2024-05-07 21:41:54,028 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:54,029 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39256582604801
2024-05-07 21:41:54,357 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #197: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5909090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(min, 0)': 0.16, '(min, 1)': 0.46, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:41:54,358 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:54,358 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39256582604801
2024-05-07 21:41:56,886 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #197: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6136363636363636, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.05, '(min, 0)': 0.45, '(min, 1)': 0.15, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:41:56,887 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:56,887 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39256582604801
2024-05-07 21:41:57,091 - MainProcess - INFO - text_logger.py - 51 - Train epoch #197
2024-05-07 21:41:57,094 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.9830e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7758e-01, 0.0000e+00,
        1.2606e-01, 1.2059e-02, 3.9118e-01, 0.0000e+00, 1.2700e-02, 7.5230e-03,
        0.0000e+00, 0.0000e+00, 1.3072e-02, 6.0513e-03, 0.0000e+00, 0.0000e+00,
        1.1854e-02, 2.5183e-03, 0.0000e+00, 0.0000e+00, 1.1053e-02, 7.6923e-05,
        0.0000e+00, 0.0000e+00, 9.9872e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0546e-02, 8.0000e-05, 0.0000e+00, 0.0000e+00, 5.4183e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.6831e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.6135e-04, 0.0000e+00, 0.0000e+00])  tensor([2.3233e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3778e-01, 0.0000e+00,
        1.3349e-01, 2.4492e-02, 1.4187e-01, 0.0000e+00, 3.1628e-02, 1.8497e-02,
        0.0000e+00, 0.0000e+00, 3.9934e-02, 2.2979e-02, 0.0000e+00, 0.0000e+00,
        3.6545e-02, 1.3451e-02, 0.0000e+00, 0.0000e+00, 3.4423e-02, 1.7201e-03,
        0.0000e+00, 0.0000e+00, 3.1167e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.3029e-02, 1.7889e-03, 0.0000e+00, 0.0000e+00, 1.7024e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.0024e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.1084e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:41:57,118 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.39156371055294525
2024-05-07 21:41:57,121 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.441180.44118
2024-05-07 21:41:57,152 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #198: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5609756097560976, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(min, 0)': 0.35, '(min, 1)': 0.27, '(rev, 1)': 0.12, '(rev, 2)': 0.04, '(rev, 3)': 0.04}}
2024-05-07 21:41:57,152 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:57,153 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3916235918298894
2024-05-07 21:41:57,167 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #198: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 2, 7, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.46, '(min, 1)': 0.13}}
2024-05-07 21:41:57,167 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:57,168 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3916235918298894
2024-05-07 21:41:57,178 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #198: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4523809523809524, 'length': 100, 'actions': {'(ado, 1)': 0.09, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.4, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.06, '(rev, 4)': 0.01}}
2024-05-07 21:41:57,178 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:57,179 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3916235918298894
2024-05-07 21:41:57,194 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #198: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13953488372093023, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.03, '(ado, 4)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.21, '(rev, 1)': 0.1, '(rev, 2)': 0.02}}
2024-05-07 21:41:57,194 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:57,195 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3916235918298894
2024-05-07 21:41:57,208 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #198: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.30952380952380953, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.05, '(min, 0)': 0.31, '(min, 1)': 0.29, '(rev, 1)': 0.14, '(rev, 2)': 0.02}}
2024-05-07 21:41:57,208 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:57,209 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3916235918298894
2024-05-07 21:41:57,934 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #198: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.14583333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.3, '(rev, 1)': 0.01, '(rev, 2)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:41:57,934 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:57,935 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3916235918298894
2024-05-07 21:41:59,375 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #198: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.4186046511627907, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.05, '(min, 0)': 0.44, '(min, 1)': 0.17, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:41:59,375 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:59,376 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3916235918298894
2024-05-07 21:41:59,590 - MainProcess - INFO - text_logger.py - 51 - Train epoch #198
2024-05-07 21:41:59,593 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0202e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6178e-01, 0.0000e+00,
        1.5751e-01, 1.0424e-02, 3.6909e-01, 0.0000e+00, 1.7599e-02, 1.1160e-02,
        0.0000e+00, 0.0000e+00, 1.2598e-02, 1.4480e-02, 0.0000e+00, 0.0000e+00,
        9.5457e-03, 9.0465e-03, 0.0000e+00, 0.0000e+00, 8.3486e-03, 1.5250e-04,
        0.0000e+00, 0.0000e+00, 7.1192e-03, 5.8472e-05, 0.0000e+00, 0.0000e+00,
        6.5935e-03, 5.8472e-05, 0.0000e+00, 0.0000e+00, 3.4594e-03, 3.0303e-05,
        0.0000e+00, 0.0000e+00, 7.8415e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6185e-04, 0.0000e+00, 0.0000e+00])  tensor([2.1084e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3903e-01, 0.0000e+00,
        1.5311e-01, 2.3402e-02, 1.3928e-01, 0.0000e+00, 4.2514e-02, 2.6838e-02,
        0.0000e+00, 0.0000e+00, 3.6257e-02, 4.7634e-02, 0.0000e+00, 0.0000e+00,
        3.0080e-02, 3.2188e-02, 0.0000e+00, 0.0000e+00, 2.7836e-02, 1.5451e-03,
        0.0000e+00, 0.0000e+00, 2.4411e-02, 9.2421e-04, 0.0000e+00, 0.0000e+00,
        2.4160e-02, 9.2421e-04, 0.0000e+00, 0.0000e+00, 1.3513e-02, 6.7760e-04,
        0.0000e+00, 0.0000e+00, 4.2478e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6339e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:41:59,613 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.39118245194458073
2024-05-07 21:41:59,616 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.280490.28049
2024-05-07 21:41:59,705 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #199: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.08823529411764706, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.44, '(min, 1)': 0.21, '(rev, 1)': 0.02, '(rev, 2)': 0.02}}
2024-05-07 21:41:59,705 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:59,706 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39156371055294525
2024-05-07 21:41:59,911 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #199: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.45652173913043476, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.05, '(ado, 5)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.25, '(rev, 1)': 0.14, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:41:59,912 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:41:59,912 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39156371055294525
2024-05-07 21:42:00,295 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #199: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(min, 0)': 0.41, '(min, 1)': 0.21, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-07 21:42:00,295 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:00,296 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39156371055294525
2024-05-07 21:42:00,664 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #199: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5869565217391305, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(min, 0)': 0.33, '(min, 1)': 0.26, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:42:00,664 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:00,665 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39156371055294525
2024-05-07 21:42:00,699 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #199: {'transition': '(exi, not, exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 3, 1, 1, 1),(rev, 1)->(exi, not, exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 1, 3, 1, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.5227272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.21, '(min, 1)': 0.43, '(rev, 1)': 0.05, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:42:00,699 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:00,700 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39156371055294525
2024-05-07 21:42:00,897 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #199: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 7)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.22}}
2024-05-07 21:42:00,897 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:00,898 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39156371055294525
2024-05-07 21:42:01,893 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #199: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4146341463414634, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 6)': 0.01, '(min, 0)': 0.57, '(min, 1)': 0.08, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:42:01,893 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:01,894 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39156371055294525
2024-05-07 21:42:02,098 - MainProcess - INFO - text_logger.py - 51 - Train epoch #199
2024-05-07 21:42:02,101 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.2106e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1349e-01, 0.0000e+00,
        1.2235e-01, 1.3235e-02, 4.3036e-01, 0.0000e+00, 5.1258e-03, 7.2030e-03,
        0.0000e+00, 0.0000e+00, 1.8110e-03, 3.7334e-03, 0.0000e+00, 0.0000e+00,
        8.8587e-04, 9.9227e-04, 0.0000e+00, 0.0000e+00, 4.1640e-04, 2.1587e-04,
        0.0000e+00, 0.0000e+00, 1.8573e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.4076, 0.0000, 0.0000, 0.0000, 0.0816, 0.0000, 0.1357, 0.0246, 0.0841,
        0.0000, 0.0188, 0.0165, 0.0000, 0.0000, 0.0107, 0.0140, 0.0000, 0.0000,
        0.0067, 0.0055, 0.0000, 0.0000, 0.0040, 0.0026, 0.0000, 0.0000, 0.0031,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-05-07 21:42:02,121 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.39032845302057784
2024-05-07 21:42:02,123 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.044120.04412
2024-05-07 21:42:02,312 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #200: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.34, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 9)': 0.01}}
2024-05-07 21:42:02,313 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:02,313 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39118245194458073
2024-05-07 21:42:02,952 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #200: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40476190476190477, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.26, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:42:02,953 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:02,953 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39118245194458073
2024-05-07 21:42:03,237 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #200: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 3, 0, 0),(ado, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/3', 'revenue': 0.4791666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 3)': 0.04, '(ado, 6)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.47, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:42:03,237 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:03,238 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39118245194458073
2024-05-07 21:42:03,414 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #200: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(min, 0)': 0.44, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.03}}
2024-05-07 21:42:03,415 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:03,415 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39118245194458073
2024-05-07 21:42:03,556 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #200: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.325, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.41, '(min, 1)': 0.23, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:42:03,557 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:03,557 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39118245194458073
2024-05-07 21:42:04,447 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #200: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6590909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.32, '(rev, 1)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:42:04,447 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:04,447 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39118245194458073
2024-05-07 21:42:05,484 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #200: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.11363636363636363, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.54, '(min, 1)': 0.18, '(rev, 1)': 0.01, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:42:05,484 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:05,485 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39118245194458073
2024-05-07 21:42:24,089 - MainProcess - INFO - text_logger.py - 51 - Train epoch #200
2024-05-07 21:42:24,093 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.5415e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3259e-01, 0.0000e+00,
        1.6329e-01, 9.7860e-03, 3.4208e-01, 0.0000e+00, 2.6899e-02, 7.1985e-03,
        0.0000e+00, 0.0000e+00, 2.6177e-02, 8.9776e-03, 0.0000e+00, 0.0000e+00,
        2.0467e-02, 6.6442e-03, 0.0000e+00, 0.0000e+00, 1.7668e-02, 2.8843e-04,
        0.0000e+00, 0.0000e+00, 1.5681e-02, 7.5904e-05, 0.0000e+00, 0.0000e+00,
        1.4403e-02, 1.5590e-04, 0.0000e+00, 0.0000e+00, 6.3414e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1300e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.5182e-04, 0.0000e+00, 0.0000e+00])  tensor([2.3841e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5827e-01, 0.0000e+00,
        1.5086e-01, 2.2837e-02, 1.6295e-01, 0.0000e+00, 4.6020e-02, 1.9275e-02,
        0.0000e+00, 0.0000e+00, 5.1770e-02, 3.4755e-02, 0.0000e+00, 0.0000e+00,
        4.3323e-02, 2.7031e-02, 0.0000e+00, 0.0000e+00, 3.8485e-02, 2.6944e-03,
        0.0000e+00, 0.0000e+00, 3.4899e-02, 1.2024e-03, 0.0000e+00, 0.0000e+00,
        3.4317e-02, 2.1526e-03, 0.0000e+00, 0.0000e+00, 1.6614e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.3211e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.5379e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:42:24,112 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.39011955213579064
2024-05-07 21:42:24,141 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.366670.01111
2024-05-07 21:42:24,141 - MainProcess - INFO - text_logger.py - 51 - Simulated Policy Revenue 0.413860.03114
2024-05-07 21:42:24,184 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #201: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6190476190476191, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.34, '(rev, 1)': 0.13, '(rev, 2)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:42:24,184 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:24,185 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39032845302057784
2024-05-07 21:42:25,227 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #201: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2553191489361702, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.32, '(min, 1)': 0.31, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:42:25,227 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:25,228 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39032845302057784
2024-05-07 21:42:25,330 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #201: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 5)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.18, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-05-07 21:42:25,330 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:25,330 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39032845302057784
2024-05-07 21:42:25,921 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #201: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.68, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.25, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.02, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:42:25,922 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:25,922 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39032845302057784
2024-05-07 21:42:26,763 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #201: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0),(ado, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/3', 'revenue': 0.8913043478260869, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 3)': 0.03, '(min, 0)': 0.53, '(min, 1)': 0.1, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:42:26,764 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:26,764 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39032845302057784
2024-05-07 21:42:26,827 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #201: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.1, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:42:26,828 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:26,828 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39032845302057784
2024-05-07 21:42:26,869 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #201: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6818181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.37, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:42:26,870 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:26,870 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39032845302057784
2024-05-07 21:42:27,035 - MainProcess - INFO - text_logger.py - 51 - Train epoch #201
2024-05-07 21:42:27,039 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.2663e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3717e-01, 0.0000e+00,
        1.5331e-01, 1.0235e-02, 3.5578e-01, 0.0000e+00, 2.5257e-02, 6.8076e-03,
        0.0000e+00, 0.0000e+00, 2.5374e-02, 5.9345e-03, 0.0000e+00, 0.0000e+00,
        2.0291e-02, 3.7870e-03, 0.0000e+00, 0.0000e+00, 1.7023e-02, 1.6479e-04,
        0.0000e+00, 0.0000e+00, 1.4998e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4955e-02, 1.6000e-04, 0.0000e+00, 0.0000e+00, 6.8079e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.6071e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4334e-04, 0.0000e+00, 0.0000e+00])  tensor([2.8897e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5982e-01, 0.0000e+00,
        1.5502e-01, 2.2611e-02, 1.6824e-01, 0.0000e+00, 4.4579e-02, 1.8347e-02,
        0.0000e+00, 0.0000e+00, 5.2031e-02, 2.5417e-02, 0.0000e+00, 0.0000e+00,
        4.3717e-02, 1.8119e-02, 0.0000e+00, 0.0000e+00, 3.7756e-02, 2.0561e-03,
        0.0000e+00, 0.0000e+00, 3.4038e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5478e-02, 2.5273e-03, 0.0000e+00, 0.0000e+00, 1.8000e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.9547e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.4425e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:42:27,060 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3904781837185359
2024-05-07 21:42:27,063 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.650430.03139
2024-05-07 21:42:27,679 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #202: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 4)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.1}}
2024-05-07 21:42:27,679 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:27,680 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39011955213579064
2024-05-07 21:42:27,779 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #202: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 4, 0, 0),(ado, 4)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/4', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.26, '(min, 1)': 0.35, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-05-07 21:42:27,779 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:27,779 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39011955213579064
2024-05-07 21:42:29,287 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #202: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(min, 0)': 0.15, '(min, 1)': 0.43, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-07 21:42:29,287 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:29,288 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39011955213579064
2024-05-07 21:42:29,544 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #202: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10416666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.21, '(rev, 1)': 0.07, '(rev, 2)': 0.01}}
2024-05-07 21:42:29,544 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:29,545 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39011955213579064
2024-05-07 21:42:29,662 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #202: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6739130434782609, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.03, '(min, 0)': 0.18, '(min, 1)': 0.44, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:42:29,662 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:29,663 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39011955213579064
2024-05-07 21:42:29,825 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #202: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 8)': 0.02, '(min, 0)': 0.53, '(min, 1)': 0.2}}
2024-05-07 21:42:29,825 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:29,825 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39011955213579064
2024-05-07 21:42:30,357 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #202: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.15789473684210525, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.29, '(rev, 1)': 0.05, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:42:30,358 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:30,358 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39011955213579064
2024-05-07 21:42:30,567 - MainProcess - INFO - text_logger.py - 51 - Train epoch #202
2024-05-07 21:42:30,570 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-8.9284e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.9061e-01,
         0.0000e+00,  1.5729e-01,  7.2132e-03,  2.8647e-01,  0.0000e+00,
         4.2718e-02,  2.9842e-03,  0.0000e+00,  0.0000e+00,  5.1286e-02,
         1.4148e-03,  0.0000e+00,  0.0000e+00,  4.1195e-02,  6.4395e-04,
         0.0000e+00,  0.0000e+00,  3.6777e-02,  7.6923e-05,  0.0000e+00,
         0.0000e+00,  3.1566e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.1447e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4998e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.9372e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.7309e-04,  0.0000e+00,  0.0000e+00])  tensor([1.6390, 0.0000, 0.0000, 0.0000, 0.1889, 0.0000, 0.1241, 0.0193, 0.1892,
        0.0000, 0.0522, 0.0107, 0.0000, 0.0000, 0.0668, 0.0089, 0.0000, 0.0000,
        0.0551, 0.0063, 0.0000, 0.0000, 0.0503, 0.0017, 0.0000, 0.0000, 0.0440,
        0.0000, 0.0000, 0.0000, 0.0458, 0.0000, 0.0000, 0.0000, 0.0226, 0.0000,
        0.0000, 0.0000, 0.0076, 0.0000, 0.0000, 0.0000, 0.0025, 0.0000, 0.0000]) (500)
2024-05-07 21:42:30,587 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.39020986254389356
2024-05-07 21:42:30,589 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.336960.33696
2024-05-07 21:42:30,631 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #203: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.19, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:42:30,631 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:30,632 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3904781837185359
2024-05-07 21:42:31,260 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #203: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.11904761904761904, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.28, '(rev, 1)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:42:31,261 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:31,261 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3904781837185359
2024-05-07 21:42:31,988 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #203: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.22, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:42:31,988 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:31,989 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3904781837185359
2024-05-07 21:42:32,367 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #203: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5319148936170213, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(min, 0)': 0.5, '(min, 1)': 0.15, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 4)': 0.02}}
2024-05-07 21:42:32,367 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:32,368 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3904781837185359
2024-05-07 21:42:32,652 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #203: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.5555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.35, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-07 21:42:32,652 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:32,653 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3904781837185359
2024-05-07 21:42:32,752 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #203: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 2)': 0.01, '(min, 0)': 0.56, '(min, 1)': 0.09}}
2024-05-07 21:42:32,753 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:32,753 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3904781837185359
2024-05-07 21:42:33,729 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #203: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 8)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.21, '(rev, 1)': 0.03, '(rev, 2)': 0.02}}
2024-05-07 21:42:33,729 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:33,731 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3904781837185359
2024-05-07 21:42:33,803 - MainProcess - INFO - text_logger.py - 51 - Train epoch #203
2024-05-07 21:42:33,806 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-2.3802e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8808e-01,
         0.0000e+00,  1.4349e-01,  1.0063e-02,  3.0436e-01,  0.0000e+00,
         3.9059e-02,  6.7947e-03,  0.0000e+00,  0.0000e+00,  4.3794e-02,
         9.4265e-03,  0.0000e+00,  0.0000e+00,  3.6672e-02,  8.9409e-03,
         0.0000e+00,  0.0000e+00,  3.3219e-02,  3.9216e-05,  0.0000e+00,
         0.0000e+00,  2.9319e-02,  8.0000e-05,  0.0000e+00,  0.0000e+00,
         2.9422e-02,  8.0000e-05,  0.0000e+00,  0.0000e+00,  1.3940e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8957e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.2565e-04,  0.0000e+00,  0.0000e+00])  tensor([2.3125e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8277e-01, 0.0000e+00,
        1.2890e-01, 2.4650e-02, 1.9264e-01, 0.0000e+00, 5.4414e-02, 2.1177e-02,
        0.0000e+00, 0.0000e+00, 6.4132e-02, 4.0373e-02, 0.0000e+00, 0.0000e+00,
        5.4484e-02, 4.0108e-02, 0.0000e+00, 0.0000e+00, 4.9976e-02, 8.7689e-04,
        0.0000e+00, 0.0000e+00, 4.4870e-02, 1.7889e-03, 0.0000e+00, 0.0000e+00,
        4.5916e-02, 1.7889e-03, 0.0000e+00, 0.0000e+00, 2.2366e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.6665e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3123e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:42:33,823 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.39015651721466177
2024-05-07 21:42:33,826 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.444440.11111
2024-05-07 21:42:33,835 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #204: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7380952380952381, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.13, '(min, 1)': 0.49, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:42:33,835 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:33,836 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39020986254389356
2024-05-07 21:42:34,767 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #204: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.06, '(min, 0)': 0.18, '(min, 1)': 0.47, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 6)': 0.01}}
2024-05-07 21:42:34,767 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:34,768 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39020986254389356
2024-05-07 21:42:34,791 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #204: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.14814814814814814, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.36, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:42:34,792 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:34,792 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39020986254389356
2024-05-07 21:42:34,860 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #204: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 4, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3953488372093023, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.23, '(rev, 1)': 0.07, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-05-07 21:42:34,861 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:34,861 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39020986254389356
2024-05-07 21:42:36,184 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #204: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.44, '(min, 1)': 0.17}}
2024-05-07 21:42:36,184 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:36,185 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39020986254389356
2024-05-07 21:42:36,297 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #204: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.68, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.41, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:42:36,297 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:36,298 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39020986254389356
2024-05-07 21:42:36,517 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #204: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.775, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 3)': 0.01, '(min, 0)': 0.14, '(min, 1)': 0.56, '(rev, 1)': 0.04, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:42:36,517 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:36,518 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39020986254389356
2024-05-07 21:42:36,599 - MainProcess - INFO - text_logger.py - 51 - Train epoch #204
2024-05-07 21:42:36,602 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([9.5252e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7815e-01, 0.0000e+00,
        1.5366e-01, 1.2881e-02, 3.8164e-01, 0.0000e+00, 1.2984e-02, 1.3405e-02,
        0.0000e+00, 0.0000e+00, 7.7748e-03, 1.2146e-02, 0.0000e+00, 0.0000e+00,
        5.7433e-03, 6.8130e-03, 0.0000e+00, 0.0000e+00, 5.0300e-03, 2.7027e-05,
        0.0000e+00, 0.0000e+00, 4.1634e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5957e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8280e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2493e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5714e-05, 0.0000e+00, 0.0000e+00])  tensor([2.0713e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2168e-01, 0.0000e+00,
        1.5248e-01, 2.7837e-02, 1.2219e-01, 0.0000e+00, 3.2597e-02, 3.0647e-02,
        0.0000e+00, 0.0000e+00, 2.9292e-02, 4.0319e-02, 0.0000e+00, 0.0000e+00,
        2.4209e-02, 2.9327e-02, 0.0000e+00, 0.0000e+00, 2.2465e-02, 6.0434e-04,
        0.0000e+00, 0.0000e+00, 1.9422e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8004e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.6485e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.6268e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.9860e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:42:36,622 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3899892829965413
2024-05-07 21:42:36,625 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.387500.38750
2024-05-07 21:42:36,722 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #205: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.627906976744186, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(min, 0)': 0.39, '(min, 1)': 0.3, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.03, '(rev, 5)': 0.01}}
2024-05-07 21:42:36,723 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:36,724 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39015651721466177
2024-05-07 21:42:37,182 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #205: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(min, 0)': 0.39, '(min, 1)': 0.2, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:42:37,182 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:37,183 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39015651721466177
2024-05-07 21:42:37,583 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #205: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.15555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.05, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.21, '(rev, 1)': 0.11, '(rev, 2)': 0.02}}
2024-05-07 21:42:37,583 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:37,584 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39015651721466177
2024-05-07 21:42:37,813 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #205: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.3, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.03}}
2024-05-07 21:42:37,814 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:37,814 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39015651721466177
2024-05-07 21:42:38,500 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #205: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.43, '(min, 1)': 0.15}}
2024-05-07 21:42:38,500 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:38,501 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39015651721466177
2024-05-07 21:42:38,956 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #205: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0975609756097561, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.18, '(rev, 1)': 0.05}}
2024-05-07 21:42:38,956 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:38,956 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39015651721466177
2024-05-07 21:42:40,602 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #205: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 0, 1, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 10)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.13}}
2024-05-07 21:42:40,602 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:40,603 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.39015651721466177
2024-05-07 21:42:40,686 - MainProcess - INFO - text_logger.py - 51 - Train epoch #205
2024-05-07 21:42:40,689 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([9.3132e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4375e-01, 0.0000e+00,
        1.6227e-01, 1.1867e-02, 3.5813e-01, 0.0000e+00, 2.2236e-02, 9.3000e-03,
        0.0000e+00, 0.0000e+00, 1.8391e-02, 9.4604e-03, 0.0000e+00, 0.0000e+00,
        1.4366e-02, 7.0051e-03, 0.0000e+00, 0.0000e+00, 1.3019e-02, 1.3812e-04,
        0.0000e+00, 0.0000e+00, 1.1538e-02, 3.5088e-05, 0.0000e+00, 0.0000e+00,
        1.0810e-02, 3.5088e-05, 0.0000e+00, 0.0000e+00, 5.7676e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.5179e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.6109e-04, 0.0000e+00, 0.0000e+00])  tensor([2.0224e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4928e-01, 0.0000e+00,
        1.4915e-01, 2.5385e-02, 1.5273e-01, 0.0000e+00, 4.7707e-02, 2.2654e-02,
        0.0000e+00, 0.0000e+00, 4.4401e-02, 3.4346e-02, 0.0000e+00, 0.0000e+00,
        3.6660e-02, 3.1727e-02, 0.0000e+00, 0.0000e+00, 3.4463e-02, 1.8673e-03,
        0.0000e+00, 0.0000e+00, 3.1255e-02, 7.8459e-04, 0.0000e+00, 0.0000e+00,
        3.0689e-02, 7.8459e-04, 0.0000e+00, 0.0000e+00, 1.7394e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.2064e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5546e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:42:40,711 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3890470487784207
2024-05-07 21:42:40,713 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:42:40,752 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #206: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.47619047619047616, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(ado, 5)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.32, '(rev, 1)': 0.05, '(rev, 2)': 0.03}}
2024-05-07 21:42:40,752 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:40,753 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3899892829965413
2024-05-07 21:42:40,766 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #206: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4166666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.09, '(min, 1)': 0.5, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:42:40,766 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #206: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.38636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.45, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:42:40,766 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:40,766 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:40,767 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3899892829965413
2024-05-07 21:42:40,767 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3899892829965413
2024-05-07 21:42:40,821 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #206: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.48, '(min, 1)': 0.12}}
2024-05-07 21:42:40,821 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:40,822 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3899892829965413
2024-05-07 21:42:41,152 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #206: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.28, '(rev, 1)': 0.04, '(rev, 2)': 0.03}}
2024-05-07 21:42:41,152 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:41,153 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3899892829965413
2024-05-07 21:42:41,617 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #206: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.12244897959183673, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.16, '(rev, 1)': 0.04, '(rev, 2)': 0.02}}
2024-05-07 21:42:41,617 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:41,618 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3899892829965413
2024-05-07 21:42:42,991 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #206: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40425531914893614, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 2)': 0.02, '(min, 0)': 0.12, '(min, 1)': 0.43, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:42:42,991 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:42,992 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3899892829965413
2024-05-07 21:42:43,069 - MainProcess - INFO - text_logger.py - 51 - Train epoch #206
2024-05-07 21:42:43,072 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.4703e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2427e-01, 0.0000e+00,
        1.3982e-01, 9.5868e-03, 3.2411e-01, 0.0000e+00, 3.4743e-02, 5.7932e-03,
        0.0000e+00, 0.0000e+00, 3.6863e-02, 3.9600e-03, 0.0000e+00, 0.0000e+00,
        2.9755e-02, 2.2245e-03, 0.0000e+00, 0.0000e+00, 2.7633e-02, 1.3556e-04,
        0.0000e+00, 0.0000e+00, 2.3920e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3304e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1133e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.4573e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9435e-04, 0.0000e+00, 0.0000e+00])  tensor([1.9086, 0.0000, 0.0000, 0.0000, 0.1787, 0.0000, 0.1215, 0.0226, 0.1802,
        0.0000, 0.0534, 0.0177, 0.0000, 0.0000, 0.0595, 0.0179, 0.0000, 0.0000,
        0.0492, 0.0116, 0.0000, 0.0000, 0.0465, 0.0022, 0.0000, 0.0000, 0.0410,
        0.0000, 0.0000, 0.0000, 0.0418, 0.0000, 0.0000, 0.0000, 0.0220, 0.0000,
        0.0000, 0.0000, 0.0076, 0.0000, 0.0000, 0.0000, 0.0022, 0.0000, 0.0000]) (500)
2024-05-07 21:42:43,092 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38850906987944905
2024-05-07 21:42:43,094 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.202130.20213
2024-05-07 21:42:43,104 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #207: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.21818181818181817, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 4)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.24, '(rev, 1)': 0.05, '(rev, 2)': 0.05}}
2024-05-07 21:42:43,104 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:43,105 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3890470487784207
2024-05-07 21:42:43,117 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #207: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1276595744680851, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.06, '(min, 0)': 0.45, '(min, 1)': 0.11, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:42:43,117 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:43,118 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3890470487784207
2024-05-07 21:42:43,335 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #207: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(min, 0)': 0.62, '(min, 1)': 0.05}}
2024-05-07 21:42:43,335 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:43,336 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3890470487784207
2024-05-07 21:42:43,595 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #207: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.14285714285714285, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.03, '(min, 0)': 0.42, '(min, 1)': 0.14, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:42:43,595 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:43,595 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3890470487784207
2024-05-07 21:42:43,764 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #207: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.13953488372093023, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.2, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-05-07 21:42:43,764 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:43,765 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3890470487784207
2024-05-07 21:42:44,337 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #207: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5957446808510638, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.42, '(min, 1)': 0.19, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03}}
2024-05-07 21:42:44,337 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:44,337 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3890470487784207
2024-05-07 21:42:45,521 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #207: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.5111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.03, '(min, 0)': 0.23, '(min, 1)': 0.39, '(rev, 1)': 0.1, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:42:45,521 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:45,521 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3890470487784207
2024-05-07 21:42:45,585 - MainProcess - INFO - text_logger.py - 51 - Train epoch #207
2024-05-07 21:42:45,588 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.5615e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6761e-01, 0.0000e+00,
        1.2332e-01, 1.0113e-02, 3.7984e-01, 0.0000e+00, 2.0863e-02, 4.6692e-03,
        0.0000e+00, 0.0000e+00, 2.1890e-02, 3.1495e-03, 0.0000e+00, 0.0000e+00,
        1.7162e-02, 1.5990e-03, 0.0000e+00, 0.0000e+00, 1.5416e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.3357e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3361e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.4057e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0734e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6736e-04, 0.0000e+00, 0.0000e+00])  tensor([1.6963e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5017e-01, 0.0000e+00,
        1.2045e-01, 2.3273e-02, 1.5631e-01, 0.0000e+00, 4.4001e-02, 1.4367e-02,
        0.0000e+00, 0.0000e+00, 4.9620e-02, 2.2341e-02, 0.0000e+00, 0.0000e+00,
        4.0451e-02, 1.9166e-02, 0.0000e+00, 0.0000e+00, 3.7025e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2618e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4043e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7775e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.8907e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6910e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:42:45,609 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3880779467724396
2024-05-07 21:42:45,612 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.255560.25556
2024-05-07 21:42:45,617 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #208: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3488372093023256, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(min, 0)': 0.34, '(min, 1)': 0.25, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:42:45,618 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:45,618 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38850906987944905
2024-05-07 21:42:45,736 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #208: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.58, '(min, 1)': 0.06}}
2024-05-07 21:42:45,736 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:45,737 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38850906987944905
2024-05-07 21:42:45,761 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #208: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4878048780487805, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.35, '(min, 1)': 0.27, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:42:45,761 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:45,761 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38850906987944905
2024-05-07 21:42:45,924 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #208: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2608695652173913, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.04, '(min, 0)': 0.16, '(min, 1)': 0.4, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:42:45,924 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:45,925 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38850906987944905
2024-05-07 21:42:46,146 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #208: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3125, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.04, '(min, 0)': 0.23, '(min, 1)': 0.37, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-05-07 21:42:46,147 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:46,147 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38850906987944905
2024-05-07 21:42:46,882 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #208: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.36363636363636365, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.5, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:42:46,883 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:46,883 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38850906987944905
2024-05-07 21:42:48,205 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #208: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.22, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:42:48,205 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:48,205 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38850906987944905
2024-05-07 21:42:48,283 - MainProcess - INFO - text_logger.py - 51 - Train epoch #208
2024-05-07 21:42:48,286 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.9409e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2442e-01, 0.0000e+00,
        1.2279e-01, 1.2521e-02, 4.2715e-01, 0.0000e+00, 2.8147e-03, 5.6821e-03,
        0.0000e+00, 0.0000e+00, 1.3248e-04, 2.9688e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.4024e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2692e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([0.9832, 0.0000, 0.0000, 0.0000, 0.0719, 0.0000, 0.1303, 0.0252, 0.0749,
        0.0000, 0.0092, 0.0163, 0.0000, 0.0000, 0.0017, 0.0128, 0.0000, 0.0000,
        0.0000, 0.0099, 0.0000, 0.0000, 0.0000, 0.0020, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-05-07 21:42:48,303 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38764682366543013
2024-05-07 21:42:48,305 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.255560.25556
2024-05-07 21:42:48,325 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #209: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2127659574468085, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.42, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:42:48,325 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:48,326 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3880779467724396
2024-05-07 21:42:48,330 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #209: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.22, '(min, 1)': 0.43, '(rev, 1)': 0.11, '(rev, 2)': 0.01, '(rev, 3)': 0.03, '(rev, 8)': 0.01}}
2024-05-07 21:42:48,332 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:48,333 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3880779467724396
2024-05-07 21:42:48,362 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #209: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.52, '(min, 1)': 0.08}}
2024-05-07 21:42:48,363 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:48,363 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3880779467724396
2024-05-07 21:42:48,488 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #209: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2926829268292683, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(min, 0)': 0.22, '(min, 1)': 0.37, '(rev, 1)': 0.12, '(rev, 2)': 0.03}}
2024-05-07 21:42:48,488 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:48,489 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3880779467724396
2024-05-07 21:42:48,591 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #209: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5952380952380952, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.08, '(min, 0)': 0.4, '(min, 1)': 0.21, '(rev, 1)': 0.13, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:42:48,592 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:48,592 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3880779467724396
2024-05-07 21:42:49,428 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #209: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35714285714285715, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(min, 0)': 0.12, '(min, 1)': 0.47, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:42:49,428 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:49,429 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3880779467724396
2024-05-07 21:42:50,579 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #209: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(min, 0)': 0.1, '(min, 1)': 0.5, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:42:50,579 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:50,580 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3880779467724396
2024-05-07 21:42:50,657 - MainProcess - INFO - text_logger.py - 51 - Train epoch #209
2024-05-07 21:42:50,660 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.9445e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8192e-01, 0.0000e+00,
        1.4783e-01, 1.2758e-02, 3.9328e-01, 0.0000e+00, 1.1086e-02, 6.7951e-03,
        0.0000e+00, 0.0000e+00, 8.5470e-03, 5.2137e-03, 0.0000e+00, 0.0000e+00,
        6.8552e-03, 4.6794e-03, 0.0000e+00, 0.0000e+00, 5.9897e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.4683e-03, 6.6667e-05, 0.0000e+00, 0.0000e+00,
        5.7177e-03, 6.2500e-05, 0.0000e+00, 0.0000e+00, 2.9197e-03, 6.8966e-05,
        0.0000e+00, 0.0000e+00, 6.1811e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2834e-04, 0.0000e+00, 0.0000e+00])  tensor([1.6695e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2148e-01, 0.0000e+00,
        1.4701e-01, 2.4580e-02, 1.2410e-01, 0.0000e+00, 3.2005e-02, 1.6974e-02,
        0.0000e+00, 0.0000e+00, 3.2168e-02, 2.5248e-02, 0.0000e+00, 0.0000e+00,
        2.7293e-02, 2.6398e-02, 0.0000e+00, 0.0000e+00, 2.4372e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.2424e-02, 1.4907e-03, 0.0000e+00, 0.0000e+00,
        2.3871e-02, 1.3975e-03, 0.0000e+00, 0.0000e+00, 1.2511e-02, 1.5421e-03,
        0.0000e+00, 0.0000e+00, 3.7059e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4513e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:42:50,680 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38705241553426606
2024-05-07 21:42:50,683 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.173910.17391
2024-05-07 21:42:50,739 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #210: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.03, '(min, 0)': 0.43, '(min, 1)': 0.17, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:42:50,739 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:50,740 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38764682366543013
2024-05-07 21:42:50,868 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #210: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4772727272727273, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.03, '(min, 0)': 0.39, '(min, 1)': 0.24, '(rev, 1)': 0.08, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:42:50,868 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:50,869 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38764682366543013
2024-05-07 21:42:50,960 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #210: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 3)': 0.02, '(min, 0)': 0.05, '(min, 1)': 0.58, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:42:50,961 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:50,961 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38764682366543013
2024-05-07 21:42:51,287 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #210: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1590909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.03, '(min, 0)': 0.44, '(min, 1)': 0.12, '(rev, 1)': 0.07, '(rev, 2)': 0.03}}
2024-05-07 21:42:51,288 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:51,288 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38764682366543013
2024-05-07 21:42:51,817 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #210: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.05, '(min, 0)': 0.35, '(min, 1)': 0.26, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-05-07 21:42:51,818 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:51,818 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38764682366543013
2024-05-07 21:42:52,781 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #210: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 3, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.15384615384615385, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.25, '(rev, 1)': 0.02, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:42:52,782 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:52,782 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38764682366543013
2024-05-07 21:42:54,075 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #210: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.05405405405405406, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.41, '(min, 1)': 0.22, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-05-07 21:42:54,075 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:54,075 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38764682366543013
2024-05-07 21:42:54,143 - MainProcess - INFO - text_logger.py - 51 - Train epoch #210
2024-05-07 21:42:54,146 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.7972e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9573e-01, 0.0000e+00,
        1.2203e-01, 1.2367e-02, 4.0413e-01, 0.0000e+00, 1.1887e-02, 5.4730e-03,
        0.0000e+00, 0.0000e+00, 1.0507e-02, 2.9901e-03, 0.0000e+00, 0.0000e+00,
        8.6950e-03, 1.4967e-03, 0.0000e+00, 0.0000e+00, 7.6634e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.7300e-03, 6.0606e-05, 0.0000e+00, 0.0000e+00,
        6.6101e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9584e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.4168e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3489e-04, 0.0000e+00, 0.0000e+00])  tensor([1.4653e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2269e-01, 0.0000e+00,
        1.3146e-01, 2.5938e-02, 1.2655e-01, 0.0000e+00, 3.2307e-02, 1.6491e-02,
        0.0000e+00, 0.0000e+00, 3.5333e-02, 1.4864e-02, 0.0000e+00, 0.0000e+00,
        3.0267e-02, 1.0952e-02, 0.0000e+00, 0.0000e+00, 2.7591e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.4849e-02, 1.3552e-03, 0.0000e+00, 0.0000e+00,
        2.5200e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2560e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.5016e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.5242e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:42:54,167 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38651979092575517
2024-05-07 21:42:54,170 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.204800.15075
2024-05-07 21:42:54,175 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #211: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34146341463414637, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(min, 0)': 0.17, '(min, 1)': 0.42, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 4)': 0.01}}
2024-05-07 21:42:54,175 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:54,176 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38705241553426606
2024-05-07 21:42:54,221 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #211: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(min, 0)': 0.39, '(min, 1)': 0.25, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:42:54,221 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:54,222 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38705241553426606
2024-05-07 21:42:54,224 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #211: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 7, 4, 0, 0),(rev, 4)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 7, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35135135135135137, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.05, '(min, 0)': 0.27, '(min, 1)': 0.36, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:42:54,224 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:54,225 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38705241553426606
2024-05-07 21:42:54,445 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #211: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17777777777777778, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.35, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:42:54,445 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:54,446 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38705241553426606
2024-05-07 21:42:54,904 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #211: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4473684210526316, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.29, '(min, 1)': 0.39, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:42:54,904 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:54,904 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38705241553426606
2024-05-07 21:42:55,275 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #211: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.03, '(ado, 7)': 0.01, '(min, 0)': 0.18, '(min, 1)': 0.39, '(rev, 1)': 0.09, '(rev, 2)': 0.05}}
2024-05-07 21:42:55,275 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:55,276 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38705241553426606
2024-05-07 21:42:57,517 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #211: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 10)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.34, '(rev, 1)': 0.09, '(rev, 8)': 0.01}}
2024-05-07 21:42:57,517 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:57,518 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38705241553426606
2024-05-07 21:42:57,582 - MainProcess - INFO - text_logger.py - 51 - Train epoch #211
2024-05-07 21:42:57,584 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.1607e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6161e-01, 0.0000e+00,
        1.5399e-01, 1.0995e-02, 3.6929e-01, 0.0000e+00, 1.9624e-02, 6.3479e-03,
        0.0000e+00, 0.0000e+00, 1.6561e-02, 4.7408e-03, 0.0000e+00, 0.0000e+00,
        1.3263e-02, 3.3907e-03, 0.0000e+00, 0.0000e+00, 1.1854e-02, 2.7615e-04,
        0.0000e+00, 0.0000e+00, 1.0833e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0743e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1870e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0527e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3432e-04, 0.0000e+00, 0.0000e+00])  tensor([1.5749, 0.0000, 0.0000, 0.0000, 0.1464, 0.0000, 0.1508, 0.0251, 0.1489,
        0.0000, 0.0438, 0.0178, 0.0000, 0.0000, 0.0423, 0.0196, 0.0000, 0.0000,
        0.0362, 0.0170, 0.0000, 0.0000, 0.0334, 0.0027, 0.0000, 0.0000, 0.0309,
        0.0000, 0.0000, 0.0000, 0.0324, 0.0000, 0.0000, 0.0000, 0.0162, 0.0000,
        0.0000, 0.0000, 0.0049, 0.0000, 0.0000, 0.0000, 0.0020, 0.0000, 0.0000]) (500)
2024-05-07 21:42:57,600 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3865955747256526
2024-05-07 21:42:57,602 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.509010.15766
2024-05-07 21:42:57,613 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #212: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.625, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.05, '(min, 0)': 0.34, '(min, 1)': 0.28, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 7)': 0.01}}
2024-05-07 21:42:57,614 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #212: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7692307692307693, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.13, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:42:57,614 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:57,614 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:57,614 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #212: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.4339622641509434, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.37, '(rev, 1)': 0.05, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:42:57,614 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:57,614 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #212: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.41, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:42:57,614 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:57,614 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38651979092575517
2024-05-07 21:42:57,615 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38651979092575517
2024-05-07 21:42:57,615 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38651979092575517
2024-05-07 21:42:57,615 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38651979092575517
2024-05-07 21:42:57,643 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #212: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46511627906976744, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.03, '(min, 0)': 0.15, '(min, 1)': 0.46, '(rev, 1)': 0.13, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-07 21:42:57,644 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:57,644 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38651979092575517
2024-05-07 21:42:57,659 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #212: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6585365853658537, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.03, '(ado, 3)': 0.02, '(min, 0)': 0.17, '(min, 1)': 0.46, '(rev, 1)': 0.14, '(rev, 2)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:42:57,659 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:42:57,660 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38651979092575517
2024-05-07 21:43:00,236 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #212: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.46808510638297873, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.42, '(rev, 1)': 0.06, '(rev, 2)': 0.06, '(rev, 4)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:43:00,236 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:00,237 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38651979092575517
2024-05-07 21:43:00,305 - MainProcess - INFO - text_logger.py - 51 - Train epoch #212
2024-05-07 21:43:00,308 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.8990e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0049e-01, 0.0000e+00,
        1.3337e-01, 1.5096e-02, 4.1356e-01, 0.0000e+00, 6.0260e-03, 7.0337e-03,
        0.0000e+00, 0.0000e+00, 3.5493e-03, 5.1711e-03, 0.0000e+00, 0.0000e+00,
        2.8855e-03, 4.2088e-03, 0.0000e+00, 0.0000e+00, 2.4861e-03, 1.1329e-04,
        0.0000e+00, 0.0000e+00, 2.3873e-03, 6.0606e-05, 0.0000e+00, 0.0000e+00,
        2.3762e-03, 6.8966e-05, 0.0000e+00, 0.0000e+00, 1.0381e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.2078e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.6421e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9035e-02, 0.0000e+00,
        1.4105e-01, 2.8851e-02, 9.8071e-02, 0.0000e+00, 1.9301e-02, 1.6596e-02,
        0.0000e+00, 0.0000e+00, 2.0403e-02, 2.2817e-02, 0.0000e+00, 0.0000e+00,
        1.8016e-02, 2.1224e-02, 0.0000e+00, 0.0000e+00, 1.6654e-02, 1.9011e-03,
        0.0000e+00, 0.0000e+00, 1.5980e-02, 1.3552e-03, 0.0000e+00, 0.0000e+00,
        1.6001e-02, 1.5421e-03, 0.0000e+00, 0.0000e+00, 7.1752e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1386e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:43:00,329 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38689065638314574
2024-05-07 21:43:00,332 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.618660.15057
2024-05-07 21:43:00,336 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #213: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(min, 0)': 0.52, '(min, 1)': 0.08, '(rev, 1)': 0.07, '(rev, 2)': 0.08}}
2024-05-07 21:43:00,336 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:00,337 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3865955747256526
2024-05-07 21:43:00,383 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #213: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.375, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.05, '(min, 0)': 0.31, '(min, 1)': 0.32, '(rev, 1)': 0.12, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:43:00,383 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #213: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(min, 0)': 0.46, '(min, 1)': 0.15, '(rev, 1)': 0.09, '(rev, 2)': 0.08, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:43:00,384 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:00,384 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:00,384 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3865955747256526
2024-05-07 21:43:00,385 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3865955747256526
2024-05-07 21:43:00,444 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #213: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6744186046511628, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(min, 0)': 0.35, '(min, 1)': 0.31, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.05, '(rev, 4)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:43:00,444 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:00,445 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3865955747256526
2024-05-07 21:43:01,386 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #213: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.525, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.48, '(min, 1)': 0.19, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:43:01,386 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:01,387 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3865955747256526
2024-05-07 21:43:01,505 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #213: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7659574468085106, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 3)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.45, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 4)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:43:01,505 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:01,506 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3865955747256526
2024-05-07 21:43:03,596 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #213: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.49, '(min, 1)': 0.13}}
2024-05-07 21:43:03,596 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:03,596 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3865955747256526
2024-05-07 21:43:03,657 - MainProcess - INFO - text_logger.py - 51 - Train epoch #213
2024-05-07 21:43:03,659 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.3197e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9817e-01, 0.0000e+00,
        1.3048e-01, 1.4701e-02, 4.1086e-01, 0.0000e+00, 7.6858e-03, 7.4232e-03,
        0.0000e+00, 0.0000e+00, 5.5578e-03, 4.8158e-03, 0.0000e+00, 0.0000e+00,
        4.2793e-03, 3.4504e-03, 0.0000e+00, 0.0000e+00, 3.6845e-03, 2.1445e-04,
        0.0000e+00, 0.0000e+00, 3.2854e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.3668e-03, 5.7143e-05, 0.0000e+00, 0.0000e+00, 1.7164e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.8463e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.0846e-05, 0.0000e+00, 0.0000e+00])  tensor([1.9846e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0968e-01, 0.0000e+00,
        1.4697e-01, 2.9689e-02, 1.1223e-01, 0.0000e+00, 2.4615e-02, 1.9452e-02,
        0.0000e+00, 0.0000e+00, 2.5490e-02, 2.0661e-02, 0.0000e+00, 0.0000e+00,
        2.1186e-02, 1.7311e-02, 0.0000e+00, 0.0000e+00, 1.9406e-02, 2.7791e-03,
        0.0000e+00, 0.0000e+00, 1.7642e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8668e-02, 1.2778e-03, 0.0000e+00, 0.0000e+00, 1.0001e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.8487e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1195e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:43:03,672 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3866228407696763
2024-05-07 21:43:03,674 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.337210.33721
2024-05-07 21:43:03,689 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #214: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.04, '(ado, 7)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.44, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:43:03,690 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:03,690 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38689065638314574
2024-05-07 21:43:03,705 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #214: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.09, '(min, 1)': 0.53, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:43:03,705 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:03,706 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38689065638314574
2024-05-07 21:43:03,721 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #214: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.21, '(min, 1)': 0.38, '(rev, 1)': 0.1, '(rev, 2)': 0.08}}
2024-05-07 21:43:03,721 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:03,722 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38689065638314574
2024-05-07 21:43:03,726 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #214: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 9)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.19}}
2024-05-07 21:43:03,726 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:03,727 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38689065638314574
2024-05-07 21:43:03,820 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #214: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.02, '(ado, 3)': 0.04, '(min, 0)': 0.18, '(min, 1)': 0.46, '(rev, 1)': 0.13, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:43:03,820 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:03,820 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38689065638314574
2024-05-07 21:43:04,081 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #214: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3137254901960784, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.19, '(rev, 1)': 0.03, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:43:04,081 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:04,081 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38689065638314574
2024-05-07 21:43:05,968 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #214: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.4, '(min, 1)': 0.19}}
2024-05-07 21:43:05,968 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:05,968 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38689065638314574
2024-05-07 21:43:06,045 - MainProcess - INFO - text_logger.py - 51 - Train epoch #214
2024-05-07 21:43:06,049 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-2.8974e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8560e-01,
         0.0000e+00,  1.8011e-01,  8.3630e-03,  2.9465e-01,  0.0000e+00,
         4.4135e-02,  4.3314e-03,  0.0000e+00,  0.0000e+00,  4.1013e-02,
         2.4086e-03,  0.0000e+00,  0.0000e+00,  3.4158e-02,  2.1865e-03,
         0.0000e+00,  0.0000e+00,  3.0994e-02,  1.6295e-04,  0.0000e+00,
         0.0000e+00,  2.7620e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.6629e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4615e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7364e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  2.8124e-04,  0.0000e+00,  0.0000e+00])  tensor([1.9063, 0.0000, 0.0000, 0.0000, 0.1765, 0.0000, 0.1412, 0.0217, 0.1823,
        0.0000, 0.0581, 0.0143, 0.0000, 0.0000, 0.0581, 0.0118, 0.0000, 0.0000,
        0.0504, 0.0145, 0.0000, 0.0000, 0.0470, 0.0022, 0.0000, 0.0000, 0.0435,
        0.0000, 0.0000, 0.0000, 0.0442, 0.0000, 0.0000, 0.0000, 0.0246, 0.0000,
        0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.0021, 0.0000, 0.0000]) (500)
2024-05-07 21:43:06,079 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3860719108993818
2024-05-07 21:43:06,081 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.195650.19565
2024-05-07 21:43:06,503 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #215: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.36538461538461536, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.31, '(rev, 1)': 0.05, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:43:06,504 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:06,504 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3866228407696763
2024-05-07 21:43:06,535 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #215: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(ado, 6)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.19, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:43:06,536 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:06,537 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3866228407696763
2024-05-07 21:43:06,948 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #215: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.45652173913043476, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.28, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 4)': 0.03}}
2024-05-07 21:43:06,949 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:06,949 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3866228407696763
2024-05-07 21:43:07,182 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #215: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 10)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.52, '(min, 1)': 0.21, '(rev, 1)': 0.03, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:43:07,182 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:07,183 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3866228407696763
2024-05-07 21:43:07,748 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #215: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.625, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.55, '(min, 1)': 0.16, '(rev, 1)': 0.02, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:43:07,748 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:07,749 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3866228407696763
2024-05-07 21:43:08,043 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #215: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6046511627906976, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.48, '(min, 1)': 0.22, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:43:08,043 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:08,044 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3866228407696763
2024-05-07 21:43:10,818 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #215: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.37037037037037035, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.54, '(min, 1)': 0.11, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:43:10,818 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:10,820 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3866228407696763
2024-05-07 21:43:10,909 - MainProcess - INFO - text_logger.py - 51 - Train epoch #215
2024-05-07 21:43:10,913 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.2244e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0903e-01, 0.0000e+00,
        1.7026e-01, 1.3949e-02, 3.2505e-01, 0.0000e+00, 3.1776e-02, 7.9809e-03,
        0.0000e+00, 0.0000e+00, 2.8761e-02, 9.0325e-03, 0.0000e+00, 0.0000e+00,
        2.4303e-02, 8.5608e-03, 0.0000e+00, 0.0000e+00, 2.1428e-02, 4.1752e-04,
        0.0000e+00, 0.0000e+00, 1.9310e-02, 1.6611e-04, 0.0000e+00, 0.0000e+00,
        1.8856e-02, 1.2444e-04, 0.0000e+00, 0.0000e+00, 9.6046e-03, 3.2787e-05,
        0.0000e+00, 0.0000e+00, 1.1823e-03, 3.2787e-05, 0.0000e+00, 0.0000e+00,
        1.4425e-04, 0.0000e+00, 0.0000e+00])  tensor([3.2666e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6679e-01, 0.0000e+00,
        1.5798e-01, 3.0964e-02, 1.7013e-01, 0.0000e+00, 5.1670e-02, 2.0677e-02,
        0.0000e+00, 0.0000e+00, 5.1661e-02, 2.8709e-02, 0.0000e+00, 0.0000e+00,
        4.6412e-02, 2.7282e-02, 0.0000e+00, 0.0000e+00, 4.2256e-02, 2.8443e-03,
        0.0000e+00, 0.0000e+00, 3.8909e-02, 1.6757e-03, 0.0000e+00, 0.0000e+00,
        4.0071e-02, 1.3965e-03, 0.0000e+00, 0.0000e+00, 2.1309e-02, 7.3314e-04,
        0.0000e+00, 0.0000e+00, 4.9518e-03, 7.3314e-04, 0.0000e+00, 0.0000e+00,
        1.6084e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:43:10,938 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38612504705163164
2024-05-07 21:43:10,941 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.497690.12731
2024-05-07 21:43:10,957 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #216: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10204081632653061, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 3)': 0.03, '(ado, 7)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.28, '(rev, 1)': 0.03, '(rev, 2)': 0.02}}
2024-05-07 21:43:10,958 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:10,959 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3860719108993818
2024-05-07 21:43:11,004 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #216: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.44, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(ado, 7)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.33, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:43:11,004 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:11,005 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3860719108993818
2024-05-07 21:43:11,298 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #216: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 7)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.17, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:43:11,299 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:11,300 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3860719108993818
2024-05-07 21:43:12,813 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #216: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 3, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4523809523809524, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.36, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:43:12,813 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:12,815 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3860719108993818
2024-05-07 21:43:13,967 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #216: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6808510638297872, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 3)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.32, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:43:13,968 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:13,969 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3860719108993818
2024-05-07 21:43:13,984 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #216: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.24, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:43:13,984 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:13,985 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3860719108993818
2024-05-07 21:43:15,222 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #216: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0),(ado, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/3', 'revenue': 0.4489795918367347, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.02, '(min, 0)': 0.13, '(min, 1)': 0.53, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 6)': 0.02}}
2024-05-07 21:43:15,223 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:15,224 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3860719108993818
2024-05-07 21:43:15,296 - MainProcess - INFO - text_logger.py - 51 - Train epoch #216
2024-05-07 21:43:15,299 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0019e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3065e-01, 0.0000e+00,
        1.6467e-01, 1.4358e-02, 3.4731e-01, 0.0000e+00, 2.3544e-02, 1.1830e-02,
        0.0000e+00, 0.0000e+00, 1.7552e-02, 1.5828e-02, 0.0000e+00, 0.0000e+00,
        1.3851e-02, 1.7479e-02, 0.0000e+00, 0.0000e+00, 1.2470e-02, 3.8029e-04,
        0.0000e+00, 0.0000e+00, 1.1242e-02, 3.8207e-04, 0.0000e+00, 0.0000e+00,
        1.0497e-02, 4.6844e-04, 0.0000e+00, 0.0000e+00, 5.7370e-03, 1.0220e-04,
        0.0000e+00, 0.0000e+00, 1.3030e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4187e-04, 0.0000e+00, 0.0000e+00])  tensor([3.6852e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5614e-01, 0.0000e+00,
        1.7193e-01, 3.2481e-02, 1.5502e-01, 0.0000e+00, 4.5890e-02, 2.9939e-02,
        0.0000e+00, 0.0000e+00, 4.0615e-02, 5.7556e-02, 0.0000e+00, 0.0000e+00,
        3.5295e-02, 7.9199e-02, 0.0000e+00, 0.0000e+00, 3.3608e-02, 2.7980e-03,
        0.0000e+00, 0.0000e+00, 3.1569e-02, 2.7955e-03, 0.0000e+00, 0.0000e+00,
        3.1680e-02, 3.5852e-03, 0.0000e+00, 0.0000e+00, 1.8548e-02, 1.3280e-03,
        0.0000e+00, 0.0000e+00, 5.4197e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.4298e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:43:15,321 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38588179242534776
2024-05-07 21:43:15,323 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.349490.09949
2024-05-07 21:43:15,343 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #217: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.16, '(rev, 1)': 0.03, '(rev, 2)': 0.01}}
2024-05-07 21:43:15,343 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:15,344 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38612504705163164
2024-05-07 21:43:15,611 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #217: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5909090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.47, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.02}}
2024-05-07 21:43:15,611 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:15,612 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38612504705163164
2024-05-07 21:43:16,034 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #217: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.2653061224489796, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.15, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-07 21:43:16,034 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:16,035 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38612504705163164
2024-05-07 21:43:16,152 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #217: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1875, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.21, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:43:16,152 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:16,153 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38612504705163164
2024-05-07 21:43:16,685 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #217: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.42, '(min, 1)': 0.18}}
2024-05-07 21:43:16,685 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:16,686 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38612504705163164
2024-05-07 21:43:18,638 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #217: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5384615384615384, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.2, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:43:18,638 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:18,638 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38612504705163164
2024-05-07 21:43:19,458 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #217: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7631578947368421, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 3)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.29, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:43:19,458 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:19,459 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38612504705163164
2024-05-07 21:43:19,530 - MainProcess - INFO - text_logger.py - 51 - Train epoch #217
2024-05-07 21:43:19,533 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.9989e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3106e-01, 0.0000e+00,
        1.6781e-01, 1.0057e-02, 3.3691e-01, 0.0000e+00, 3.2211e-02, 5.3360e-03,
        0.0000e+00, 0.0000e+00, 2.6592e-02, 3.0907e-03, 0.0000e+00, 0.0000e+00,
        2.1920e-02, 1.3093e-03, 0.0000e+00, 0.0000e+00, 1.9508e-02, 2.7834e-04,
        0.0000e+00, 0.0000e+00, 1.7564e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6097e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.9360e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1776e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4783e-04, 0.0000e+00, 0.0000e+00])  tensor([1.8385e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6605e-01, 0.0000e+00,
        1.5645e-01, 2.5185e-02, 1.6904e-01, 0.0000e+00, 5.3335e-02, 1.4858e-02,
        0.0000e+00, 0.0000e+00, 4.9110e-02, 1.1521e-02, 0.0000e+00, 0.0000e+00,
        4.4084e-02, 6.9401e-03, 0.0000e+00, 0.0000e+00, 4.0526e-02, 2.8767e-03,
        0.0000e+00, 0.0000e+00, 3.7217e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5587e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1001e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.2128e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6498e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:43:19,553 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38570271610196405
2024-05-07 21:43:19,556 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.381580.38158
2024-05-07 21:43:19,560 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #218: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.02702702702702703, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.02, '(min, 0)': 0.47, '(min, 1)': 0.17, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-05-07 21:43:19,561 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #218: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2653061224489796, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.21, '(rev, 1)': 0.05, '(rev, 2)': 0.06}}
2024-05-07 21:43:19,561 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:19,561 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:19,561 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #218: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.20930232558139536, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.03, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.26, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:43:19,561 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:19,561 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38588179242534776
2024-05-07 21:43:19,561 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38588179242534776
2024-05-07 21:43:19,562 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38588179242534776
2024-05-07 21:43:19,593 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #218: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1320754716981132, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.2, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:43:19,593 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:19,594 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38588179242534776
2024-05-07 21:43:20,346 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #218: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.18}}
2024-05-07 21:43:20,346 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:20,347 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38588179242534776
2024-05-07 21:43:21,495 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #218: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22916666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.16, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-05-07 21:43:21,495 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:21,495 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38588179242534776
2024-05-07 21:43:26,206 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #218: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 3, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 8)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.15}}
2024-05-07 21:43:26,206 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:26,206 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38588179242534776
2024-05-07 21:43:26,286 - MainProcess - INFO - text_logger.py - 51 - Train epoch #218
2024-05-07 21:43:26,286 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.8002,  0.0000,  0.0000,  0.0000,  0.2510,  0.0000,  0.1773,  0.0097,
         0.2557,  0.0000,  0.0504,  0.0038,  0.0000,  0.0000,  0.0543,  0.0016,
         0.0000,  0.0000,  0.0465,  0.0015,  0.0000,  0.0000,  0.0436,  0.0000,
         0.0000,  0.0000,  0.0386,  0.0000,  0.0000,  0.0000,  0.0385,  0.0000,
         0.0000,  0.0000,  0.0219,  0.0000,  0.0000,  0.0000,  0.0047,  0.0000,
         0.0000,  0.0000,  0.0010,  0.0000,  0.0000])  tensor([1.8173, 0.0000, 0.0000, 0.0000, 0.1895, 0.0000, 0.1500, 0.0278, 0.1935,
        0.0000, 0.0563, 0.0131, 0.0000, 0.0000, 0.0641, 0.0102, 0.0000, 0.0000,
        0.0571, 0.0112, 0.0000, 0.0000, 0.0543, 0.0000, 0.0000, 0.0000, 0.0489,
        0.0000, 0.0000, 0.0000, 0.0497, 0.0000, 0.0000, 0.0000, 0.0292, 0.0000,
        0.0000, 0.0000, 0.0093, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000]) (500)
2024-05-07 21:43:26,319 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38476048188384343
2024-05-07 21:43:26,319 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:43:26,351 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #219: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.19, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-05-07 21:43:26,351 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:26,351 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #219: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 1, 0, 0),(rev, 4)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '4/4', 'revenue': 0.5319148936170213, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.31, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.03, '(rev, 5)': 0.01}}
2024-05-07 21:43:26,351 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:26,351 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38570271610196405
2024-05-07 21:43:26,351 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38570271610196405
2024-05-07 21:43:26,356 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #219: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.28205128205128205, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 3)': 0.03, '(min, 0)': 0.22, '(min, 1)': 0.41, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.03}}
2024-05-07 21:43:26,356 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #219: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.45, '(min, 0)': 0.55}}
2024-05-07 21:43:26,356 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:26,356 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:26,356 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38570271610196405
2024-05-07 21:43:26,356 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38570271610196405
2024-05-07 21:43:27,411 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #219: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0),(rev, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.625, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.23, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:43:27,411 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:27,411 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38570271610196405
2024-05-07 21:43:27,550 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #219: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.32, '(rev, 1)': 0.08, '(rev, 2)': 0.06}}
2024-05-07 21:43:27,558 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:27,558 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38570271610196405
2024-05-07 21:43:32,860 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #219: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7692307692307693, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 8)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.23, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:43:32,860 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:32,860 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38570271610196405
2024-05-07 21:43:32,941 - MainProcess - INFO - text_logger.py - 51 - Train epoch #219
2024-05-07 21:43:32,945 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.0052e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6744e-01, 0.0000e+00,
        1.5251e-01, 1.4553e-02, 3.8317e-01, 0.0000e+00, 1.6537e-02, 8.9985e-03,
        0.0000e+00, 0.0000e+00, 1.1385e-02, 7.4966e-03, 0.0000e+00, 0.0000e+00,
        8.7083e-03, 5.7059e-03, 0.0000e+00, 0.0000e+00, 7.6161e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.4793e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.7712e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2006e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.4872e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.6197e-05, 0.0000e+00, 0.0000e+00])  tensor([2.5959e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3071e-01, 0.0000e+00,
        1.5341e-01, 3.1452e-02, 1.3043e-01, 0.0000e+00, 4.0780e-02, 2.3422e-02,
        0.0000e+00, 0.0000e+00, 3.4376e-02, 3.3254e-02, 0.0000e+00, 0.0000e+00,
        2.9023e-02, 3.3583e-02, 0.0000e+00, 0.0000e+00, 2.6944e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.3722e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.2864e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3283e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.6140e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2036e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:43:32,975 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3845874784349537
2024-05-07 21:43:32,978 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.384620.38462
2024-05-07 21:43:33,016 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #220: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.022727272727272728, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.35, '(rev, 1)': 0.05, '(rev, 2)': 0.01}}
2024-05-07 21:43:33,016 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:33,016 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #220: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 0, 0, 0),(rev, 3)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.2553191489361702, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.13, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.03}}
2024-05-07 21:43:33,016 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #220: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.38095238095238093, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.41, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:43:33,016 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:33,016 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:33,016 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #220: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.02, '(min, 0)': 0.2, '(min, 1)': 0.44, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-05-07 21:43:33,016 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:33,016 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38476048188384343
2024-05-07 21:43:33,016 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #220: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(min, 0)': 0.51, '(min, 1)': 0.15, '(rev, 1)': 0.01}}
2024-05-07 21:43:33,016 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38476048188384343
2024-05-07 21:43:33,016 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38476048188384343
2024-05-07 21:43:33,016 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38476048188384343
2024-05-07 21:43:33,032 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:33,032 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38476048188384343
2024-05-07 21:43:33,107 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #220: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 3, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.475, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(min, 0)': 0.1, '(min, 1)': 0.51, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:43:33,107 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:33,108 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38476048188384343
2024-05-07 21:43:37,587 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #220: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5869565217391305, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(min, 0)': 0.21, '(min, 1)': 0.48, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.03}}
2024-05-07 21:43:37,587 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:37,587 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38476048188384343
2024-05-07 21:43:37,663 - MainProcess - INFO - text_logger.py - 51 - Train epoch #220
2024-05-07 21:43:37,663 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.2583e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2650e-01, 0.0000e+00,
        1.9467e-01, 1.2911e-02, 3.2777e-01, 0.0000e+00, 3.0509e-02, 8.7210e-03,
        0.0000e+00, 0.0000e+00, 2.1519e-02, 6.5537e-03, 0.0000e+00, 0.0000e+00,
        1.7167e-02, 5.7752e-03, 0.0000e+00, 0.0000e+00, 1.4822e-02, 6.6667e-05,
        0.0000e+00, 0.0000e+00, 1.3347e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1991e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0042e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.6522e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.9533e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6454e-01, 0.0000e+00,
        1.9028e-01, 3.2184e-02, 1.6367e-01, 0.0000e+00, 5.4796e-02, 2.4942e-02,
        0.0000e+00, 0.0000e+00, 4.5022e-02, 2.6554e-02, 0.0000e+00, 0.0000e+00,
        3.8947e-02, 3.0282e-02, 0.0000e+00, 0.0000e+00, 3.5350e-02, 1.4907e-03,
        0.0000e+00, 0.0000e+00, 3.2863e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.1179e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9771e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.0130e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:43:37,695 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3842322007385723
2024-05-07 21:43:37,695 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.293480.29348
2024-05-07 21:43:37,768 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #221: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(min, 0)': 0.46, '(min, 1)': 0.21}}
2024-05-07 21:43:37,768 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:37,768 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3845874784349537
2024-05-07 21:43:37,824 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #221: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.35, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(min, 0)': 0.36, '(min, 1)': 0.25, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-05-07 21:43:37,824 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:37,825 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3845874784349537
2024-05-07 21:43:38,068 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #221: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 3, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.25, '(rev, 1)': 0.07, '(rev, 2)': 0.03}}
2024-05-07 21:43:38,068 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:38,068 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3845874784349537
2024-05-07 21:43:38,181 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #221: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3877551020408163, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.24, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:43:38,181 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:38,182 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3845874784349537
2024-05-07 21:43:39,006 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #221: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6904761904761905, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.23, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 7)': 0.01}}
2024-05-07 21:43:39,007 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:39,008 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3845874784349537
2024-05-07 21:43:39,551 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #221: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.08, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.27, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:43:39,551 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:39,551 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3845874784349537
2024-05-07 21:43:41,848 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #221: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4878048780487805, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.03, '(min, 0)': 0.35, '(min, 1)': 0.29, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:43:41,848 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:41,856 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3845874784349537
2024-05-07 21:43:41,937 - MainProcess - INFO - text_logger.py - 51 - Train epoch #221
2024-05-07 21:43:41,937 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([0.3671, 0.0000, 0.0000, 0.0000, 0.3016, 0.0000, 0.1883, 0.0099, 0.3161,
        0.0000, 0.0335, 0.0071, 0.0000, 0.0000, 0.0296, 0.0053, 0.0000, 0.0000,
        0.0253, 0.0044, 0.0000, 0.0000, 0.0235, 0.0000, 0.0000, 0.0000, 0.0207,
        0.0000, 0.0000, 0.0000, 0.0196, 0.0000, 0.0000, 0.0000, 0.0121, 0.0000,
        0.0000, 0.0000, 0.0026, 0.0000, 0.0000, 0.0000, 0.0004, 0.0000, 0.0000])  tensor([2.0200, 0.0000, 0.0000, 0.0000, 0.1687, 0.0000, 0.1674, 0.0266, 0.1753,
        0.0000, 0.0522, 0.0210, 0.0000, 0.0000, 0.0522, 0.0236, 0.0000, 0.0000,
        0.0470, 0.0246, 0.0000, 0.0000, 0.0454, 0.0000, 0.0000, 0.0000, 0.0410,
        0.0000, 0.0000, 0.0000, 0.0405, 0.0000, 0.0000, 0.0000, 0.0261, 0.0000,
        0.0000, 0.0000, 0.0079, 0.0000, 0.0000, 0.0000, 0.0027, 0.0000, 0.0000]) (500)
2024-05-07 21:43:41,961 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38377777139850044
2024-05-07 21:43:41,970 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.243900.24390
2024-05-07 21:43:42,075 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #222: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5813953488372093, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(min, 0)': 0.28, '(min, 1)': 0.37, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 3)': 0.04, '(rev, 4)': 0.03}}
2024-05-07 21:43:42,075 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:42,075 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3842322007385723
2024-05-07 21:43:42,293 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #222: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.21818181818181817, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.35, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 4)': 0.01}}
2024-05-07 21:43:42,301 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:42,301 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3842322007385723
2024-05-07 21:43:43,496 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #222: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 8)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.14}}
2024-05-07 21:43:43,496 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:43,496 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3842322007385723
2024-05-07 21:43:44,178 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #222: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.425531914893617, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.3, '(rev, 1)': 0.03, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:43:44,178 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:44,178 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3842322007385723
2024-05-07 21:43:44,365 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #222: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7307692307692307, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.41, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:43:44,365 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:44,365 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3842322007385723
2024-05-07 21:43:44,879 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #222: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.24}}
2024-05-07 21:43:44,879 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:44,879 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3842322007385723
2024-05-07 21:43:46,291 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #222: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3673469387755102, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 3)': 0.04, '(min, 0)': 0.18, '(min, 1)': 0.46, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:43:46,291 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:46,291 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3842322007385723
2024-05-07 21:43:46,371 - MainProcess - INFO - text_logger.py - 51 - Train epoch #222
2024-05-07 21:43:46,371 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.6932e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1450e-01, 0.0000e+00,
        1.5386e-01, 1.2809e-02, 3.1443e-01, 0.0000e+00, 3.2493e-02, 7.4035e-03,
        0.0000e+00, 0.0000e+00, 3.3151e-02, 4.2758e-03, 0.0000e+00, 0.0000e+00,
        2.8933e-02, 3.0401e-03, 0.0000e+00, 0.0000e+00, 2.7616e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.3973e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.4189e-02, 2.2222e-04, 0.0000e+00, 0.0000e+00, 1.4885e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.4017e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.1578e-04, 0.0000e+00, 0.0000e+00])  tensor([2.2527, 0.0000, 0.0000, 0.0000, 0.1813, 0.0000, 0.1578, 0.0322, 0.1828,
        0.0000, 0.0507, 0.0208, 0.0000, 0.0000, 0.0565, 0.0167, 0.0000, 0.0000,
        0.0509, 0.0176, 0.0000, 0.0000, 0.0491, 0.0000, 0.0000, 0.0000, 0.0429,
        0.0000, 0.0000, 0.0000, 0.0437, 0.0029, 0.0000, 0.0000, 0.0275, 0.0000,
        0.0000, 0.0000, 0.0084, 0.0000, 0.0000, 0.0000, 0.0042, 0.0000, 0.0000]) (500)
2024-05-07 21:43:46,395 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3832028841191553
2024-05-07 21:43:46,404 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.183670.18367
2024-05-07 21:43:47,117 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #223: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.6428571428571429, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.47, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:43:47,117 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:47,117 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38377777139850044
2024-05-07 21:43:47,669 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #223: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.55, '(min, 1)': 0.08}}
2024-05-07 21:43:47,669 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:47,669 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38377777139850044
2024-05-07 21:43:48,630 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #223: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2978723404255319, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.44, '(rev, 1)': 0.11, '(rev, 3)': 0.03}}
2024-05-07 21:43:48,630 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:48,636 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38377777139850044
2024-05-07 21:43:49,848 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #223: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.21153846153846154, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.21, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-05-07 21:43:49,848 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #223: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.37, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:43:49,848 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:49,848 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:49,848 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38377777139850044
2024-05-07 21:43:49,848 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38377777139850044
2024-05-07 21:43:52,569 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #223: {'transition': '(exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 3, 5, 1, 1),(min, 0)->(exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 3, 6, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.5416666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 10)': 0.01, '(ado, 2)': 0.03, '(min, 0)': 0.33, '(min, 1)': 0.38, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 7)': 0.01}}
2024-05-07 21:43:52,569 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:52,569 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38377777139850044
2024-05-07 21:43:53,247 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #223: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 1.0454545454545454, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.26, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 5)': 0.01, '(rev, 6)': 0.01, '(rev, 9)': 0.01}}
2024-05-07 21:43:53,247 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:53,247 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38377777139850044
2024-05-07 21:43:53,335 - MainProcess - INFO - text_logger.py - 51 - Train epoch #223
2024-05-07 21:43:53,335 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0743e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3043e-01, 0.0000e+00,
        1.7721e-01, 1.2421e-02, 3.4808e-01, 0.0000e+00, 2.1957e-02, 1.1101e-02,
        0.0000e+00, 0.0000e+00, 1.8356e-02, 1.0427e-02, 0.0000e+00, 0.0000e+00,
        1.5052e-02, 1.0060e-02, 0.0000e+00, 0.0000e+00, 1.3774e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1697e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1495e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0398e-03, 7.1429e-05,
        0.0000e+00, 0.0000e+00, 7.0787e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1846e-04, 0.0000e+00, 0.0000e+00])  tensor([2.4582e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5164e-01, 0.0000e+00,
        1.7372e-01, 3.0079e-02, 1.5853e-01, 0.0000e+00, 4.5414e-02, 2.7213e-02,
        0.0000e+00, 0.0000e+00, 4.4073e-02, 3.6912e-02, 0.0000e+00, 0.0000e+00,
        3.7812e-02, 4.3009e-02, 0.0000e+00, 0.0000e+00, 3.5871e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.0931e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.1075e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9900e-02, 1.5972e-03,
        0.0000e+00, 0.0000e+00, 3.9873e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9833e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:43:53,368 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3833061044464894
2024-05-07 21:43:53,372 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.522730.52273
2024-05-07 21:43:53,399 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #224: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4878048780487805, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.13, '(min, 1)': 0.48, '(rev, 1)': 0.13, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:43:53,399 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
nsition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4418604651162791, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(min, 0)': 0.13, '(min, 1)': 0.5, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 5)': 0.01}}
2024-05-07 21:43:53,399 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:53,399 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #224: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.54, '(min, 1)': 0.05}}
2024-05-07 21:43:53,399 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
mation 0.3832028841191553
2024-05-07 21:43:53,402 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3832028841191553
2024-05-07 21:43:53,402 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3832028841191553
2024-05-07 21:43:54,986 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #224: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.23404255319148937, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.38, '(rev, 1)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:43:54,986 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:54,986 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3832028841191553
2024-05-07 21:43:55,585 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #224: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6444444444444445, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.05, '(min, 0)': 0.24, '(min, 1)': 0.42, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 5)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:43:55,585 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:55,585 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3832028841191553
2024-05-07 21:43:57,675 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #224: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.41, '(rev, 1)': 0.14, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:43:57,675 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:57,683 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3832028841191553
2024-05-07 21:43:59,124 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #224: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5957446808510638, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.37, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:43:59,124 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:59,124 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3832028841191553
2024-05-07 21:43:59,374 - MainProcess - INFO - text_logger.py - 51 - Train epoch #224
2024-05-07 21:43:59,375 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.1900e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5401e-01, 0.0000e+00,
        1.6985e-01, 1.3360e-02, 3.5223e-01, 0.0000e+00, 1.7177e-02, 1.1930e-02,
        0.0000e+00, 0.0000e+00, 1.4086e-02, 1.0062e-02, 0.0000e+00, 0.0000e+00,
        1.2167e-02, 7.7708e-03, 0.0000e+00, 0.0000e+00, 1.1204e-02, 4.2316e-04,
        0.0000e+00, 0.0000e+00, 9.5030e-03, 1.4381e-04, 0.0000e+00, 0.0000e+00,
        9.5853e-03, 7.1429e-05, 0.0000e+00, 0.0000e+00, 5.6197e-03, 7.1429e-05,
        0.0000e+00, 0.0000e+00, 6.6175e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.4099e-05, 0.0000e+00, 0.0000e+00])  tensor([2.8937e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4396e-01, 0.0000e+00,
        1.6613e-01, 3.0539e-02, 1.4498e-01, 0.0000e+00, 4.0142e-02, 2.5924e-02,
        0.0000e+00, 0.0000e+00, 3.9223e-02, 3.0969e-02, 0.0000e+00, 0.0000e+00,
        3.5380e-02, 2.9139e-02, 0.0000e+00, 0.0000e+00, 3.3301e-02, 3.5460e-03,
        0.0000e+00, 0.0000e+00, 2.8913e-02, 2.0193e-03, 0.0000e+00, 0.0000e+00,
        3.0194e-02, 1.5972e-03, 0.0000e+00, 0.0000e+00, 1.8256e-02, 1.5972e-03,
        0.0000e+00, 0.0000e+00, 3.8699e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1706e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:43:59,398 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38264958451408304
2024-05-07 21:43:59,398 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.142860.14286
2024-05-07 21:43:59,414 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #225: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(min, 0)': 0.45, '(min, 1)': 0.15, '(rev, 1)': 0.1, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-05-07 21:43:59,414 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:59,414 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3833061044464894
2024-05-07 21:43:59,431 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #225: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.02, '(min, 0)': 0.51, '(min, 1)': 0.06, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:43:59,431 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:59,431 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3833061044464894
2024-05-07 21:43:59,464 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #225: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.5, '(min, 1)': 0.09}}
2024-05-07 21:43:59,464 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:43:59,464 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3833061044464894
2024-05-07 21:44:00,117 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #225: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 8, 4, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 8, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(min, 0)': 0.53, '(min, 1)': 0.09, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:44:00,124 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:00,124 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3833061044464894
2024-05-07 21:44:01,575 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #225: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6458333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.31, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-05-07 21:44:01,583 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:01,583 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3833061044464894
2024-05-07 21:44:03,228 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #225: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.51, '(min, 1)': 0.13}}
2024-05-07 21:44:03,228 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:03,228 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3833061044464894
2024-05-07 21:44:04,018 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #225: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2127659574468085, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.04, '(min, 0)': 0.12, '(min, 1)': 0.44, '(rev, 1)': 0.07, '(rev, 2)': 0.04}}
2024-05-07 21:44:04,018 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:04,018 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3833061044464894
2024-05-07 21:44:04,284 - MainProcess - INFO - text_logger.py - 51 - Train epoch #225
2024-05-07 21:44:04,288 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.8025e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0704e-01, 0.0000e+00,
        1.2093e-01, 1.6723e-02, 4.3048e-01, 0.0000e+00, 4.3943e-03, 7.3716e-03,
        0.0000e+00, 0.0000e+00, 2.2534e-03, 3.6738e-03, 0.0000e+00, 0.0000e+00,
        1.4218e-03, 2.8495e-03, 0.0000e+00, 0.0000e+00, 1.1245e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.5127e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.5761e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1793e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.4226, 0.0000, 0.0000, 0.0000, 0.0866, 0.0000, 0.1380, 0.0345, 0.0919,
        0.0000, 0.0205, 0.0215, 0.0000, 0.0000, 0.0154, 0.0152, 0.0000, 0.0000,
        0.0102, 0.0155, 0.0000, 0.0000, 0.0088, 0.0000, 0.0000, 0.0000, 0.0073,
        0.0000, 0.0000, 0.0000, 0.0057, 0.0000, 0.0000, 0.0000, 0.0036, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-05-07 21:44:04,316 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3817073502959624
2024-05-07 21:44:04,316 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:44:04,645 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #226: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6341463414634146, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(min, 0)': 0.11, '(min, 1)': 0.5, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:44:04,645 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:04,645 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38264958451408304
2024-05-07 21:44:05,113 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #226: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.14285714285714285, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.25, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:44:05,113 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:05,117 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38264958451408304
2024-05-07 21:44:05,364 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #226: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6538461538461539, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.04, '(ado, 8)': 0.01, '(min, 0)': 0.14, '(min, 1)': 0.51, '(rev, 1)': 0.08, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:44:05,364 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:05,364 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38264958451408304
2024-05-07 21:44:05,412 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #226: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5208333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.53, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-05-07 21:44:05,412 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:05,412 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38264958451408304
2024-05-07 21:44:07,314 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #226: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(min, 0)': 0.06, '(min, 1)': 0.58, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:44:07,314 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:07,314 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38264958451408304
2024-05-07 21:44:08,226 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #226: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4318181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.07, '(min, 1)': 0.51, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-07 21:44:08,226 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:08,226 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38264958451408304
2024-05-07 21:44:08,846 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #226: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3137254901960784, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.04, '(ado, 8)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.31, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:44:08,846 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:08,846 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38264958451408304
2024-05-07 21:44:08,926 - MainProcess - INFO - text_logger.py - 51 - Train epoch #226
2024-05-07 21:44:08,926 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.2359e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4746e-01, 0.0000e+00,
        1.5301e-01, 1.3491e-02, 3.3960e-01, 0.0000e+00, 2.4826e-02, 8.1208e-03,
        0.0000e+00, 0.0000e+00, 2.3100e-02, 3.7529e-03, 0.0000e+00, 0.0000e+00,
        2.0379e-02, 3.2192e-03, 0.0000e+00, 0.0000e+00, 1.8469e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.5771e-02, 7.4074e-05, 0.0000e+00, 0.0000e+00,
        1.5916e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0295e-02, 7.1429e-05,
        0.0000e+00, 0.0000e+00, 2.0610e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.7955e-04, 0.0000e+00, 0.0000e+00])  tensor([2.1801e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6849e-01, 0.0000e+00,
        1.6927e-01, 3.1585e-02, 1.6567e-01, 0.0000e+00, 4.8829e-02, 2.0202e-02,
        0.0000e+00, 0.0000e+00, 4.9108e-02, 1.3092e-02, 0.0000e+00, 0.0000e+00,
        4.4682e-02, 1.6289e-02, 0.0000e+00, 0.0000e+00, 4.0854e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.5409e-02, 1.6563e-03, 0.0000e+00, 0.0000e+00,
        3.7444e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4383e-02, 1.5972e-03,
        0.0000e+00, 0.0000e+00, 6.8092e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5605e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:44:08,950 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38173268772188407
2024-05-07 21:44:08,960 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.483790.17006
2024-05-07 21:44:09,250 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #227: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 3, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.27906976744186046, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.37, '(min, 1)': 0.28, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:44:09,250 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:09,250 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3817073502959624
2024-05-07 21:44:09,508 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #227: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24489795918367346, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.4, '(min, 1)': 0.19, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:44:09,508 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:09,508 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3817073502959624
2024-05-07 21:44:12,577 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #227: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.05660377358490566, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.17, '(rev, 1)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:44:12,577 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:12,577 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3817073502959624
2024-05-07 21:44:13,238 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #227: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7142857142857143, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.24, '(rev, 1)': 0.01, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:44:13,238 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:13,238 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3817073502959624
2024-05-07 21:44:13,337 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #227: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.05, '(ado, 4)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.13, '(rev, 1)': 0.07, '(rev, 2)': 0.03}}
2024-05-07 21:44:13,337 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:13,337 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3817073502959624
2024-05-07 21:44:13,392 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #227: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.04, '(min, 0)': 0.46, '(min, 1)': 0.11, '(rev, 1)': 0.1, '(rev, 2)': 0.05}}
2024-05-07 21:44:13,393 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:13,393 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3817073502959624
2024-05-07 21:44:13,850 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #227: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.9574468085106383, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.03, '(min, 0)': 0.28, '(min, 1)': 0.35, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.05, '(rev, 4)': 0.01}}
2024-05-07 21:44:13,850 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:13,858 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3817073502959624
2024-05-07 21:44:14,125 - MainProcess - INFO - text_logger.py - 51 - Train epoch #227
2024-05-07 21:44:14,126 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-6.6432e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.2037e-01,
         0.0000e+00,  1.4215e-01,  1.3220e-02,  3.5120e-01,  0.0000e+00,
         2.8936e-02,  5.9162e-03,  0.0000e+00,  0.0000e+00,  2.8036e-02,
         2.5160e-03,  0.0000e+00,  0.0000e+00,  2.5550e-02,  1.4877e-03,
         0.0000e+00,  0.0000e+00,  2.3147e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  1.9973e-02,  5.0000e-05,  0.0000e+00,  0.0000e+00,
         2.1256e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.3102e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.5908e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  4.9508e-04,  0.0000e+00,  0.0000e+00])  tensor([2.2039e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6557e-01, 0.0000e+00,
        1.4380e-01, 3.3769e-02, 1.8313e-01, 0.0000e+00, 4.8263e-02, 1.9239e-02,
        0.0000e+00, 0.0000e+00, 5.1753e-02, 1.2014e-02, 0.0000e+00, 0.0000e+00,
        4.9155e-02, 8.4089e-03, 0.0000e+00, 0.0000e+00, 4.5390e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.9590e-02, 1.1180e-03, 0.0000e+00, 0.0000e+00,
        4.3118e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6838e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.4823e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.1346e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:44:14,149 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.38153535146294726
2024-05-07 21:44:14,157 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.372450.12755
2024-05-07 21:44:14,457 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #228: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 3, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.45652173913043476, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 4)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.54, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:44:14,457 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:14,457 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38173268772188407
2024-05-07 21:44:15,465 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #228: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.18, '(min, 1)': 0.45, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:44:15,465 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:15,473 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38173268772188407
2024-05-07 21:44:16,883 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #228: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.09, '(min, 1)': 0.5, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-05-07 21:44:16,883 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:16,883 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38173268772188407
2024-05-07 21:44:18,174 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #228: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.2727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.04, '(min, 0)': 0.13, '(min, 1)': 0.48, '(rev, 1)': 0.12, '(rev, 2)': 0.04}}
2024-05-07 21:44:18,174 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:18,182 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38173268772188407
2024-05-07 21:44:18,223 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #228: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2926829268292683, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.24, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:44:18,223 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:18,223 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38173268772188407
2024-05-07 21:44:18,319 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #228: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(min, 0)': 0.55, '(min, 1)': 0.1, '(rev, 1)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:44:18,319 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:18,319 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38173268772188407
2024-05-07 21:44:18,939 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #228: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5581395348837209, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.43, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-07 21:44:18,939 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:18,939 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38173268772188407
2024-05-07 21:44:19,212 - MainProcess - INFO - text_logger.py - 51 - Train epoch #228
2024-05-07 21:44:19,213 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.6364e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8434e-01, 0.0000e+00,
        1.5076e-01, 1.5784e-02, 3.7218e-01, 0.0000e+00, 1.4170e-02, 1.0084e-02,
        0.0000e+00, 0.0000e+00, 9.7262e-03, 6.2253e-03, 0.0000e+00, 0.0000e+00,
        8.3732e-03, 4.9204e-03, 0.0000e+00, 0.0000e+00, 7.2245e-03, 6.9881e-05,
        0.0000e+00, 0.0000e+00, 6.2279e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.7543e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7010e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.5751e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.9350e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3260e-01, 0.0000e+00,
        1.5361e-01, 3.4995e-02, 1.2811e-01, 0.0000e+00, 3.8789e-02, 2.9264e-02,
        0.0000e+00, 0.0000e+00, 3.0895e-02, 2.9292e-02, 0.0000e+00, 0.0000e+00,
        2.9284e-02, 2.9247e-02, 0.0000e+00, 0.0000e+00, 2.6536e-02, 1.1039e-03,
        0.0000e+00, 0.0000e+00, 2.3499e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3234e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5655e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.3066e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:44:19,236 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3812153394670489
2024-05-07 21:44:19,244 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.311110.20000
2024-05-07 21:44:19,599 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #229: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35714285714285715, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.31, '(rev, 1)': 0.13, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:44:19,599 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:19,599 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38153535146294726
2024-05-07 21:44:20,067 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #229: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 6, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 2, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43478260869565216, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.03, '(min, 0)': 0.4, '(min, 1)': 0.3, '(rev, 1)': 0.06, '(rev, 10)': 0.01, '(rev, 2)': 0.01, '(rev, 5)': 0.02}}
2024-05-07 21:44:20,067 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:20,067 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38153535146294726
2024-05-07 21:44:21,324 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #229: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.21, '(rev, 1)': 0.13, '(rev, 3)': 0.03}}
2024-05-07 21:44:21,324 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:21,324 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38153535146294726
2024-05-07 21:44:22,878 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #229: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.25, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:44:22,886 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:22,887 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38153535146294726
2024-05-07 21:44:23,070 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #229: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5348837209302325, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(min, 0)': 0.24, '(min, 1)': 0.41, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:44:23,078 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:23,078 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38153535146294726
2024-05-07 21:44:23,305 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #229: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.20454545454545456, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 3)': 0.03, '(min, 0)': 0.23, '(min, 1)': 0.36, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:44:23,305 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:23,305 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38153535146294726
2024-05-07 21:44:24,783 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #229: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 8)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.17}}
2024-05-07 21:44:24,783 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:24,783 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.38153535146294726
2024-05-07 21:44:24,864 - MainProcess - INFO - text_logger.py - 51 - Train epoch #229
2024-05-07 21:44:24,864 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.9976e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6383e-01, 0.0000e+00,
        1.8329e-01, 1.2868e-02, 3.9660e-01, 0.0000e+00, 1.0462e-02, 8.9242e-03,
        0.0000e+00, 0.0000e+00, 3.9340e-03, 6.0702e-03, 0.0000e+00, 0.0000e+00,
        2.6444e-03, 5.1621e-03, 0.0000e+00, 0.0000e+00, 1.9755e-03, 3.0769e-05,
        0.0000e+00, 0.0000e+00, 1.6879e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3699e-03, 6.8966e-05, 0.0000e+00, 0.0000e+00, 8.1245e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.9639e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.0000e-05, 0.0000e+00])  tensor([1.6876e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1712e-01, 0.0000e+00,
        1.9092e-01, 3.1175e-02, 1.2317e-01, 0.0000e+00, 2.9841e-02, 2.7154e-02,
        0.0000e+00, 0.0000e+00, 1.7842e-02, 2.5838e-02, 0.0000e+00, 0.0000e+00,
        1.5307e-02, 2.6892e-02, 0.0000e+00, 0.0000e+00, 1.3259e-02, 6.8802e-04,
        0.0000e+00, 0.0000e+00, 1.1953e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2208e-02, 1.5421e-03, 0.0000e+00, 0.0000e+00, 7.5713e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.5424e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.7889e-03, 0.0000e+00]) (500)
2024-05-07 21:44:24,897 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3806302481060711
2024-05-07 21:44:24,897 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.178570.17857
2024-05-07 21:44:25,002 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #230: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.17142857142857143, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(min, 0)': 0.5, '(min, 1)': 0.18, '(rev, 1)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:44:25,002 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:25,002 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3812153394670489
2024-05-07 21:44:26,408 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #230: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.08695652173913043, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.26, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:44:26,408 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:26,409 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3812153394670489
2024-05-07 21:44:26,626 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #230: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.03, '(ado, 6)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.33, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:44:26,634 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:26,635 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3812153394670489
2024-05-07 21:44:27,728 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #230: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 5, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4722222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.32, '(rev, 1)': 0.12, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-05-07 21:44:27,728 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:27,728 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3812153394670489
2024-05-07 21:44:27,889 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #230: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 3, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 6, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3170731707317073, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.16, '(min, 1)': 0.47, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:44:27,889 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:27,889 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3812153394670489
2024-05-07 21:44:28,099 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #230: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 3, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 4, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3235294117647059, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.19, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 6)': 0.02}}
2024-05-07 21:44:28,099 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:28,099 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3812153394670489
2024-05-07 21:44:29,413 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #230: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 8, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 9, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(min, 0)': 0.54, '(min, 1)': 0.13, '(rev, 1)': 0.01}}
2024-05-07 21:44:29,413 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:29,413 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3812153394670489
2024-05-07 21:44:29,486 - MainProcess - INFO - text_logger.py - 51 - Train epoch #230
2024-05-07 21:44:29,486 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.2350e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1312e-01, 0.0000e+00,
        2.1921e-01, 1.0954e-02, 3.0179e-01, 0.0000e+00, 3.6046e-02, 6.7532e-03,
        0.0000e+00, 0.0000e+00, 2.4818e-02, 3.7996e-03, 0.0000e+00, 0.0000e+00,
        2.1386e-02, 2.6794e-03, 0.0000e+00, 0.0000e+00, 1.7883e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.4766e-02, 1.5032e-04, 0.0000e+00, 0.0000e+00,
        1.4751e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.3823e-03, 8.0000e-05,
        0.0000e+00, 0.0000e+00, 2.2419e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9499e-04, 0.0000e+00, 0.0000e+00])  tensor([1.5966, 0.0000, 0.0000, 0.0000, 0.1678, 0.0000, 0.1913, 0.0302, 0.1596,
        0.0000, 0.0552, 0.0207, 0.0000, 0.0000, 0.0458, 0.0175, 0.0000, 0.0000,
        0.0425, 0.0154, 0.0000, 0.0000, 0.0380, 0.0000, 0.0000, 0.0000, 0.0335,
        0.0021, 0.0000, 0.0000, 0.0359, 0.0000, 0.0000, 0.0000, 0.0242, 0.0018,
        0.0000, 0.0000, 0.0080, 0.0000, 0.0000, 0.0000, 0.0018, 0.0000, 0.0000]) (500)
2024-05-07 21:44:29,511 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.37985944245937914
2024-05-07 21:44:29,519 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.085710.08571
2024-05-07 21:44:29,559 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #231: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.35, '(min, 1)': 0.24}}
2024-05-07 21:44:29,559 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:29,559 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3806302481060711
2024-05-07 21:44:31,780 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #231: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.022727272727272728, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.3, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:44:31,780 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:31,780 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3806302481060711
2024-05-07 21:44:32,368 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #231: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3191489361702128, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.22, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-07 21:44:32,368 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:32,368 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3806302481060711
2024-05-07 21:44:32,658 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #231: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.16, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:44:32,658 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:32,658 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3806302481060711
2024-05-07 21:44:32,901 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #231: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.46, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:44:32,901 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:32,901 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3806302481060711
2024-05-07 21:44:33,572 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #231: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 5, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4489795918367347, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 10)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.34, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:44:33,572 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:33,572 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3806302481060711
2024-05-07 21:44:33,711 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #231: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.37, '(min, 1)': 0.21}}
2024-05-07 21:44:33,711 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:33,711 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3806302481060711
2024-05-07 21:44:33,847 - MainProcess - INFO - text_logger.py - 51 - Train epoch #231
2024-05-07 21:44:33,847 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-5.2733e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7316e-01,
         0.0000e+00,  1.9188e-01,  1.0885e-02,  2.9836e-01,  0.0000e+00,
         4.2215e-02,  6.4646e-03,  0.0000e+00,  0.0000e+00,  3.6206e-02,
         3.1708e-03,  0.0000e+00,  0.0000e+00,  3.3110e-02,  2.6219e-03,
         0.0000e+00,  0.0000e+00,  2.9290e-02,  2.9851e-05,  0.0000e+00,
         0.0000e+00,  2.5763e-02,  8.0000e-05,  0.0000e+00,  0.0000e+00,
         2.5200e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.6998e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.1538e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  4.1269e-04,  0.0000e+00,  0.0000e+00])  tensor([1.9113e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7083e-01, 0.0000e+00,
        1.6961e-01, 2.9687e-02, 1.8425e-01, 0.0000e+00, 5.7571e-02, 1.9310e-02,
        0.0000e+00, 0.0000e+00, 5.4517e-02, 1.4944e-02, 0.0000e+00, 0.0000e+00,
        5.1881e-02, 1.7321e-02, 0.0000e+00, 0.0000e+00, 4.7279e-02, 6.6748e-04,
        0.0000e+00, 0.0000e+00, 4.2604e-02, 1.7889e-03, 0.0000e+00, 0.0000e+00,
        4.3754e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0165e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0616e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.6689e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:44:33,879 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3789172082412586
2024-05-07 21:44:33,880 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:44:35,267 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #232: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.25, '(rev, 1)': 0.02}}
2024-05-07 21:44:35,268 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:35,272 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37985944245937914
2024-05-07 21:44:37,706 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #232: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17073170731707318, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 7)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.28, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:44:37,706 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:37,714 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37985944245937914
2024-05-07 21:44:37,722 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #232: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 3, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.15, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(ado, 3)': 0.03, '(ado, 4)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.34, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:44:37,722 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:37,722 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37985944245937914
2024-05-07 21:44:37,933 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #232: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.39, '(min, 1)': 0.22}}
2024-05-07 21:44:37,933 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:37,933 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37985944245937914
2024-05-07 21:44:38,133 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #232: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5416666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.46, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 5)': 0.02, '(rev, 8)': 0.01, '(rev, 9)': 0.01}}
2024-05-07 21:44:38,133 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:38,133 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37985944245937914
2024-05-07 21:44:38,367 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #232: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 3, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6842105263157895, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.27, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-05-07 21:44:38,367 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:38,367 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37985944245937914
2024-05-07 21:44:39,088 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #232: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3584905660377358, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.18, '(min, 1)': 0.47, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:44:39,088 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:39,088 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37985944245937914
2024-05-07 21:44:39,378 - MainProcess - INFO - text_logger.py - 51 - Train epoch #232
2024-05-07 21:44:39,378 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.5976e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5882e-01, 0.0000e+00,
        2.1631e-01, 9.4991e-03, 2.6063e-01, 0.0000e+00, 4.9635e-02, 8.8432e-03,
        0.0000e+00, 0.0000e+00, 3.8223e-02, 9.7895e-03, 0.0000e+00, 0.0000e+00,
        3.5405e-02, 9.8425e-03, 0.0000e+00, 0.0000e+00, 3.0102e-02, 1.4924e-04,
        0.0000e+00, 0.0000e+00, 2.6017e-02, 1.5294e-04, 0.0000e+00, 0.0000e+00,
        2.5314e-02, 6.4516e-05, 0.0000e+00, 0.0000e+00, 1.6617e-02, 7.6923e-05,
        0.0000e+00, 0.0000e+00, 3.9504e-03, 8.0000e-05, 0.0000e+00, 0.0000e+00,
        4.9202e-04, 0.0000e+00, 0.0000e+00])  tensor([2.7788e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8054e-01, 0.0000e+00,
        1.9313e-01, 2.7610e-02, 1.7897e-01, 0.0000e+00, 6.2906e-02, 2.7899e-02,
        0.0000e+00, 0.0000e+00, 5.4206e-02, 3.6611e-02, 0.0000e+00, 0.0000e+00,
        5.2612e-02, 4.5968e-02, 0.0000e+00, 0.0000e+00, 4.6901e-02, 1.6696e-03,
        0.0000e+00, 0.0000e+00, 4.1867e-02, 1.8536e-03, 0.0000e+00, 0.0000e+00,
        4.3149e-02, 1.4426e-03, 0.0000e+00, 0.0000e+00, 2.9829e-02, 1.7201e-03,
        0.0000e+00, 0.0000e+00, 1.0302e-02, 1.7889e-03, 0.0000e+00, 0.0000e+00,
        2.9391e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:44:39,402 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.378224974023138
2024-05-07 21:44:39,411 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.125000.12500
2024-05-07 21:44:42,903 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #233: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.8695652173913043, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.44, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:44:42,903 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:42,903 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3789172082412586
2024-05-07 21:44:43,123 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #233: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.18421052631578946, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.42, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:44:43,123 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:43,129 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3789172082412586
2024-05-07 21:44:43,129 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #233: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.27, '(rev, 1)': 0.02, '(rev, 2)': 0.01}}
2024-05-07 21:44:43,129 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:43,129 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3789172082412586
2024-05-07 21:44:43,186 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #233: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3488372093023256, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.19, '(rev, 1)': 0.07, '(rev, 3)': 0.02, '(rev, 5)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:44:43,186 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:43,186 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3789172082412586
2024-05-07 21:44:43,259 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #233: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 8, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 9, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.26666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.28, '(rev, 1)': 0.02, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:44:43,259 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:43,265 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3789172082412586
2024-05-07 21:44:44,074 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #233: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.56, '(min, 1)': 0.07}}
2024-05-07 21:44:44,074 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:44,082 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3789172082412586
2024-05-07 21:44:44,139 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #233: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(ado, 9)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.14, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:44:44,139 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:44,139 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3789172082412586
2024-05-07 21:44:44,412 - MainProcess - INFO - text_logger.py - 51 - Train epoch #233
2024-05-07 21:44:44,412 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.4076e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6367e-01, 0.0000e+00,
        1.9832e-01, 9.1896e-03, 2.7420e-01, 0.0000e+00, 4.9824e-02, 8.2340e-03,
        0.0000e+00, 0.0000e+00, 3.8362e-02, 9.3516e-03, 0.0000e+00, 0.0000e+00,
        3.4827e-02, 9.1976e-03, 0.0000e+00, 0.0000e+00, 3.0755e-02, 2.9851e-05,
        0.0000e+00, 0.0000e+00, 2.6189e-02, 6.6667e-05, 0.0000e+00, 0.0000e+00,
        2.6374e-02, 8.0000e-05, 0.0000e+00, 0.0000e+00, 1.6849e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.0134e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.7179e-04, 0.0000e+00, 0.0000e+00])  tensor([2.4373e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7864e-01, 0.0000e+00,
        1.7499e-01, 2.7648e-02, 1.8259e-01, 0.0000e+00, 6.5522e-02, 2.5747e-02,
        0.0000e+00, 0.0000e+00, 5.4748e-02, 3.8534e-02, 0.0000e+00, 0.0000e+00,
        5.2019e-02, 4.1641e-02, 0.0000e+00, 0.0000e+00, 4.8314e-02, 6.6748e-04,
        0.0000e+00, 0.0000e+00, 4.1861e-02, 1.4907e-03, 0.0000e+00, 0.0000e+00,
        4.4339e-02, 1.7889e-03, 0.0000e+00, 0.0000e+00, 3.0285e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0294e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8204e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:44:44,436 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.37815230502240876
2024-05-07 21:44:44,444 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.434780.43478
2024-05-07 21:44:47,523 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #234: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0425531914893617, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.27, '(rev, 1)': 0.03, '(rev, 2)': 0.01}}
2024-05-07 21:44:47,523 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:47,523 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.378224974023138
2024-05-07 21:44:48,082 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #234: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.22, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:44:48,089 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:48,089 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.378224974023138
2024-05-07 21:44:48,212 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #234: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5217391304347826, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.03, '(min, 0)': 0.4, '(min, 1)': 0.24, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:44:48,212 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:48,212 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.378224974023138
2024-05-07 21:44:48,390 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #234: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.45098039215686275, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.33, '(rev, 1)': 0.04, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:44:48,390 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:48,390 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.378224974023138
2024-05-07 21:44:48,430 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #234: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46808510638297873, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.03, '(ado, 3)': 0.02, '(min, 0)': 0.32, '(min, 1)': 0.33, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-05-07 21:44:48,430 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:48,430 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.378224974023138
2024-05-07 21:44:48,495 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #234: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.38, '(min, 1)': 0.23}}
2024-05-07 21:44:48,495 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:48,495 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.378224974023138
2024-05-07 21:44:49,205 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #234: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 1),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 1, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.043478260869565216, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.18, '(rev, 1)': 0.03, '(rev, 2)': 0.01}}
2024-05-07 21:44:49,205 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:49,205 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.378224974023138
2024-05-07 21:44:49,294 - MainProcess - INFO - text_logger.py - 51 - Train epoch #234
2024-05-07 21:44:49,295 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.3888e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0491e-01, 0.0000e+00,
        1.9932e-01, 1.2737e-02, 3.1233e-01, 0.0000e+00, 2.9088e-02, 8.4620e-03,
        0.0000e+00, 0.0000e+00, 2.4778e-02, 8.0448e-03, 0.0000e+00, 0.0000e+00,
        2.2851e-02, 7.5593e-03, 0.0000e+00, 0.0000e+00, 2.0592e-02, 1.7471e-04,
        0.0000e+00, 0.0000e+00, 1.7937e-02, 3.0769e-05, 0.0000e+00, 0.0000e+00,
        1.7443e-02, 8.4823e-05, 0.0000e+00, 0.0000e+00, 1.1218e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.1734e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.6608e-04, 0.0000e+00, 0.0000e+00])  tensor([2.4908e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6054e-01, 0.0000e+00,
        1.8702e-01, 3.1455e-02, 1.6454e-01, 0.0000e+00, 4.8501e-02, 2.1268e-02,
        0.0000e+00, 0.0000e+00, 4.8435e-02, 2.9737e-02, 0.0000e+00, 0.0000e+00,
        4.6002e-02, 3.4241e-02, 0.0000e+00, 0.0000e+00, 4.2138e-02, 2.0059e-03,
        0.0000e+00, 0.0000e+00, 3.7255e-02, 6.8802e-04, 0.0000e+00, 0.0000e+00,
        3.6838e-02, 1.3896e-03, 0.0000e+00, 0.0000e+00, 2.5822e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.8136e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.1168e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:44:49,318 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3772535490651577
2024-05-07 21:44:49,326 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.021740.02174
2024-05-07 21:44:51,979 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #235: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.5, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:44:51,979 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:51,979 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37815230502240876
2024-05-07 21:44:52,621 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #235: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17391304347826086, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.14, '(min, 1)': 0.46, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:44:52,621 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:52,621 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37815230502240876
2024-05-07 21:44:53,202 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #235: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 10, 3, 0, 0),(rev, 4)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 6, 0, 0, 0)', 'reward_ratio': '4/4', 'revenue': 0.525, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.27, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.04, '(rev, 4)': 0.03}}
2024-05-07 21:44:53,210 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:53,211 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37815230502240876
2024-05-07 21:44:53,470 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #235: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 7, 4, 0, 0),(rev, 4)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 7, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3953488372093023, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.29, '(rev, 1)': 0.02, '(rev, 2)': 0.03, '(rev, 3)': 0.04, '(rev, 4)': 0.02}}
2024-05-07 21:44:53,470 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:53,470 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37815230502240876
2024-05-07 21:44:54,528 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #235: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.43, '(min, 1)': 0.17}}
2024-05-07 21:44:54,528 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:54,528 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37815230502240876
2024-05-07 21:44:55,004 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #235: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 8)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.15}}
2024-05-07 21:44:55,004 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:55,004 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37815230502240876
2024-05-07 21:44:55,296 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #235: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3617021276595745, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.03, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.46, '(rev, 1)': 0.11, '(rev, 2)': 0.01}}
2024-05-07 21:44:55,296 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:55,304 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37815230502240876
2024-05-07 21:44:55,578 - MainProcess - INFO - text_logger.py - 51 - Train epoch #235
2024-05-07 21:44:55,578 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.5818e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5098e-01, 0.0000e+00,
        1.7971e-01, 1.3268e-02, 3.5522e-01, 0.0000e+00, 1.4310e-02, 1.0752e-02,
        0.0000e+00, 0.0000e+00, 8.6075e-03, 1.4567e-02, 0.0000e+00, 0.0000e+00,
        7.1255e-03, 2.4235e-02, 0.0000e+00, 0.0000e+00, 5.8345e-03, 5.5700e-04,
        0.0000e+00, 0.0000e+00, 5.0249e-03, 5.5700e-04, 0.0000e+00, 0.0000e+00,
        4.8023e-03, 3.7294e-04, 0.0000e+00, 0.0000e+00, 2.7581e-03, 2.7701e-04,
        0.0000e+00, 0.0000e+00, 6.7252e-04, 1.9053e-04, 0.0000e+00, 0.0000e+00,
        1.4519e-04, 3.3898e-05, 0.0000e+00])  tensor([2.7881e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3476e-01, 0.0000e+00,
        1.6582e-01, 3.1268e-02, 1.3835e-01, 0.0000e+00, 3.6272e-02, 2.6252e-02,
        0.0000e+00, 0.0000e+00, 2.8712e-02, 4.4200e-02, 0.0000e+00, 0.0000e+00,
        2.6869e-02, 8.1558e-02, 0.0000e+00, 0.0000e+00, 2.3804e-02, 2.9217e-03,
        0.0000e+00, 0.0000e+00, 2.1164e-02, 2.9217e-03, 0.0000e+00, 0.0000e+00,
        2.1662e-02, 2.4139e-03, 0.0000e+00, 0.0000e+00, 1.3211e-02, 2.0740e-03,
        0.0000e+00, 0.0000e+00, 4.5479e-03, 1.7447e-03, 0.0000e+00, 0.0000e+00,
        2.0721e-03, 7.5799e-04, 0.0000e+00]) (500)
2024-05-07 21:44:55,610 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3763113148470371
2024-05-07 21:44:55,610 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:44:56,525 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #236: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2765957446808511, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.28, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:44:56,525 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:56,525 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3772535490651577
2024-05-07 21:44:58,197 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #236: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7272727272727273, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.36, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.04, '(rev, 4)': 0.02, '(rev, 7)': 0.01}}
2024-05-07 21:44:58,197 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:58,197 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3772535490651577
2024-05-07 21:44:58,527 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #236: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5319148936170213, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.03, '(min, 0)': 0.13, '(min, 1)': 0.5, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:44:58,527 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:58,527 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3772535490651577
2024-05-07 21:44:58,995 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #236: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 2, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.31, '(min, 1)': 0.26}}
2024-05-07 21:44:59,003 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:59,004 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3772535490651577
2024-05-07 21:44:59,212 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #236: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.9555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.03, '(min, 0)': 0.25, '(min, 1)': 0.36, '(rev, 1)': 0.11, '(rev, 2)': 0.08, '(rev, 4)': 0.01}}
2024-05-07 21:44:59,212 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:59,212 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3772535490651577
2024-05-07 21:44:59,333 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #236: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.37, '(min, 1)': 0.26}}
2024-05-07 21:44:59,333 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:59,333 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3772535490651577
2024-05-07 21:44:59,665 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #236: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(min, 0)': 0.27, '(min, 1)': 0.3, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:44:59,665 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:44:59,665 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3772535490651577
2024-05-07 21:44:59,939 - MainProcess - INFO - text_logger.py - 51 - Train epoch #236
2024-05-07 21:44:59,941 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.8134e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7665e-01, 0.0000e+00,
        1.6906e-01, 1.5222e-02, 3.9593e-01, 0.0000e+00, 3.1505e-03, 1.2002e-02,
        0.0000e+00, 0.0000e+00, 5.7698e-04, 1.2806e-02, 0.0000e+00, 0.0000e+00,
        6.2319e-05, 1.2338e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.5831e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2129e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.3664e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5999e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7037e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.6699e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0620e-01, 0.0000e+00,
        1.8230e-01, 3.2904e-02, 1.1193e-01, 0.0000e+00, 9.0570e-03, 2.4876e-02,
        0.0000e+00, 0.0000e+00, 3.1293e-03, 3.1581e-02, 0.0000e+00, 0.0000e+00,
        9.8676e-04, 3.2189e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5796e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5690e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.8114e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6160e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2817e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:44:59,963 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.37536908062891655
2024-05-07 21:44:59,971 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:45:01,119 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #237: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(min, 0)': 0.02, '(min, 1)': 0.57, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:45:01,119 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:01,119 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3763113148470371
2024-05-07 21:45:02,660 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #237: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.375, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.16, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 5)': 0.01}}
2024-05-07 21:45:02,660 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:02,663 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3763113148470371
2024-05-07 21:45:03,390 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #237: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(min, 0)': 0.34, '(min, 1)': 0.29, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:45:03,396 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:03,396 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3763113148470371
2024-05-07 21:45:03,646 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #237: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.58, '(min, 1)': 0.04}}
2024-05-07 21:45:03,646 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:03,646 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3763113148470371
2024-05-07 21:45:03,970 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #237: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 3, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 3, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24324324324324326, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.38, '(rev, 1)': 0.07, '(rev, 2)': 0.03}}
2024-05-07 21:45:03,970 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:03,970 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3763113148470371
2024-05-07 21:45:05,333 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #237: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 3, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 4, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 7)': 0.01, '(min, 0)': 0.56, '(min, 1)': 0.07}}
2024-05-07 21:45:05,341 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:05,341 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3763113148470371
2024-05-07 21:45:06,337 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #237: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.04, '(min, 0)': 0.29, '(min, 1)': 0.35, '(rev, 1)': 0.06, '(rev, 2)': 0.07, '(rev, 7)': 0.01}}
2024-05-07 21:45:06,337 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:06,337 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3763113148470371
2024-05-07 21:45:06,611 - MainProcess - INFO - text_logger.py - 51 - Train epoch #237
2024-05-07 21:45:06,611 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.5811e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8239e-01, 0.0000e+00,
        1.3973e-01, 1.6163e-02, 3.8190e-01, 0.0000e+00, 1.2911e-02, 5.8682e-03,
        0.0000e+00, 0.0000e+00, 9.2981e-03, 5.8462e-03, 0.0000e+00, 0.0000e+00,
        8.8288e-03, 1.2022e-02, 0.0000e+00, 0.0000e+00, 7.6100e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.6522e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.2590e-03, 1.4359e-04, 0.0000e+00, 0.0000e+00, 3.8300e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.8160e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.1728e-05, 0.0000e+00, 0.0000e+00])  tensor([2.6740e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3084e-01, 0.0000e+00,
        1.5526e-01, 3.5516e-02, 1.3051e-01, 0.0000e+00, 3.6301e-02, 1.7855e-02,
        0.0000e+00, 0.0000e+00, 3.1857e-02, 2.5278e-02, 0.0000e+00, 0.0000e+00,
        3.1668e-02, 5.8587e-02, 0.0000e+00, 0.0000e+00, 2.7844e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.4890e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.4659e-02, 2.2739e-03, 0.0000e+00, 0.0000e+00, 1.5574e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.4576e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.9442e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:45:06,635 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.374426846410796
2024-05-07 21:45:06,644 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:45:07,120 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #238: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.45652173913043476, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.02, '(ado, 9)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.25, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:45:07,120 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:07,120 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37536908062891655
2024-05-07 21:45:07,597 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #238: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.03, '(min, 0)': 0.45, '(min, 1)': 0.1, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:45:07,597 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:07,597 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37536908062891655
2024-05-07 21:45:07,928 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #238: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.49, '(min, 1)': 0.11}}
2024-05-07 21:45:07,928 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:07,928 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37536908062891655
2024-05-07 21:45:09,178 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #238: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4230769230769231, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.18, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:45:09,178 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:09,178 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37536908062891655
2024-05-07 21:45:09,339 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #238: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.7954545454545454, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.29, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 7)': 0.01}}
2024-05-07 21:45:09,339 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:09,339 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37536908062891655
2024-05-07 21:45:09,873 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #238: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.4, '(min, 1)': 0.2}}
2024-05-07 21:45:09,873 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:09,873 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37536908062891655
2024-05-07 21:45:10,964 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #238: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4489795918367347, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(min, 0)': 0.41, '(min, 1)': 0.21, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 5)': 0.02}}
2024-05-07 21:45:10,964 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:10,972 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37536908062891655
2024-05-07 21:45:11,228 - MainProcess - INFO - text_logger.py - 51 - Train epoch #238
2024-05-07 21:45:11,228 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.7078e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4514e-01, 0.0000e+00,
        1.3564e-01, 1.5797e-02, 3.7921e-01, 0.0000e+00, 1.5450e-02, 1.0667e-02,
        0.0000e+00, 0.0000e+00, 1.4319e-02, 1.2880e-02, 0.0000e+00, 0.0000e+00,
        1.3759e-02, 1.4317e-02, 0.0000e+00, 0.0000e+00, 1.1636e-02, 5.8856e-04,
        0.0000e+00, 0.0000e+00, 1.0425e-02, 4.1425e-04, 0.0000e+00, 0.0000e+00,
        1.0773e-02, 4.6525e-04, 0.0000e+00, 0.0000e+00, 6.7554e-03, 2.1926e-04,
        0.0000e+00, 0.0000e+00, 1.2852e-03, 8.4112e-05, 0.0000e+00, 0.0000e+00,
        1.6851e-04, 0.0000e+00, 0.0000e+00])  tensor([3.3151e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4501e-01, 0.0000e+00,
        1.5950e-01, 3.3842e-02, 1.5227e-01, 0.0000e+00, 3.6423e-02, 2.4787e-02,
        0.0000e+00, 0.0000e+00, 3.9806e-02, 3.7664e-02, 0.0000e+00, 0.0000e+00,
        3.9788e-02, 5.1680e-02, 0.0000e+00, 0.0000e+00, 3.4093e-02, 3.2541e-03,
        0.0000e+00, 0.0000e+00, 3.1082e-02, 2.5658e-03, 0.0000e+00, 0.0000e+00,
        3.2652e-02, 3.1952e-03, 0.0000e+00, 0.0000e+00, 2.0534e-02, 1.8641e-03,
        0.0000e+00, 0.0000e+00, 5.5964e-03, 1.0863e-03, 0.0000e+00, 0.0000e+00,
        1.7045e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:45:11,252 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3734846121926754
2024-05-07 21:45:11,260 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:45:11,952 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #239: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36363636363636365, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(min, 0)': 0.14, '(min, 1)': 0.46, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:45:11,952 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:11,952 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.374426846410796
2024-05-07 21:45:12,107 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #239: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.5, '(min, 1)': 0.1}}
2024-05-07 21:45:12,107 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:12,115 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.374426846410796
2024-05-07 21:45:13,287 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #239: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40816326530612246, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.39, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 4)': 0.01}}
2024-05-07 21:45:13,287 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:13,287 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.374426846410796
2024-05-07 21:45:13,488 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #239: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 4, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.39, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 5)': 0.01}}
2024-05-07 21:45:13,488 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:13,488 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.374426846410796
2024-05-07 21:45:14,510 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #239: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.04, '(min, 0)': 0.1, '(min, 1)': 0.47, '(rev, 1)': 0.1, '(rev, 2)': 0.06}}
2024-05-07 21:45:14,518 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:14,518 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.374426846410796
2024-05-07 21:45:15,333 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #239: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.53, '(min, 1)': 0.09}}
2024-05-07 21:45:15,333 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:15,333 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.374426846410796
2024-05-07 21:45:15,834 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #239: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(rev, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.625, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.38, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 4)': 0.01}}
2024-05-07 21:45:15,834 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:15,834 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.374426846410796
2024-05-07 21:45:16,134 - MainProcess - INFO - text_logger.py - 51 - Train epoch #239
2024-05-07 21:45:16,134 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.0402e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.2193e-01,
         0.0000e+00,  1.2496e-01,  2.1713e-02,  4.0612e-01,  0.0000e+00,
         5.5606e-03,  6.8506e-03,  0.0000e+00,  0.0000e+00,  2.7365e-03,
         3.2470e-03,  0.0000e+00,  0.0000e+00,  1.4511e-03,  3.2416e-03,
         0.0000e+00,  0.0000e+00,  8.2914e-04,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  6.7221e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         4.5973e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.3385e-04,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00])  tensor([1.3090, 0.0000, 0.0000, 0.0000, 0.0930, 0.0000, 0.1432, 0.0445, 0.0904,
        0.0000, 0.0233, 0.0213, 0.0000, 0.0000, 0.0173, 0.0207, 0.0000, 0.0000,
        0.0122, 0.0240, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.0066,
        0.0000, 0.0000, 0.0000, 0.0048, 0.0000, 0.0000, 0.0000, 0.0030, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-05-07 21:45:16,166 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3725423779745548
2024-05-07 21:45:16,166 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:45:16,630 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #240: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.16, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.03}}
2024-05-07 21:45:16,630 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:16,636 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3734846121926754
2024-05-07 21:45:16,636 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #240: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.35, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 5)': 0.01}}
2024-05-07 21:45:16,636 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:16,636 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3734846121926754
2024-05-07 21:45:17,603 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #240: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.30434782608695654, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.05, '(min, 0)': 0.52, '(min, 1)': 0.1, '(rev, 1)': 0.11, '(rev, 2)': 0.05}}
2024-05-07 21:45:17,603 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:17,606 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3734846121926754
2024-05-07 21:45:18,947 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #240: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.18604651162790697, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.52, '(min, 1)': 0.12, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:45:18,947 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:18,947 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3734846121926754
2024-05-07 21:45:19,062 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #240: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5957446808510638, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(min, 0)': 0.48, '(min, 1)': 0.1, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.03}}
2024-05-07 21:45:19,062 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:19,062 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3734846121926754
2024-05-07 21:45:20,695 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #240: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.29, '(rev, 1)': 0.06, '(rev, 2)': 0.07, '(rev, 3)': 0.03}}
2024-05-07 21:45:20,695 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:20,695 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3734846121926754
2024-05-07 21:45:22,089 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #240: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7115384615384616, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 9)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.18, '(rev, 1)': 0.05, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-07 21:45:22,089 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:22,089 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3734846121926754
2024-05-07 21:45:22,355 - MainProcess - INFO - text_logger.py - 51 - Train epoch #240
2024-05-07 21:45:22,355 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-8.3122e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.4696e-01,
         0.0000e+00,  1.3058e-01,  1.4054e-02,  3.8604e-01,  0.0000e+00,
         2.1927e-02,  3.5375e-03,  0.0000e+00,  0.0000e+00,  2.0074e-02,
         9.1025e-04,  0.0000e+00,  0.0000e+00,  1.9039e-02,  3.3706e-04,
         0.0000e+00,  0.0000e+00,  1.6735e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  1.4487e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         1.4576e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.3016e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2705e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  1.6876e-04,  0.0000e+00,  0.0000e+00])  tensor([1.6359, 0.0000, 0.0000, 0.0000, 0.1461, 0.0000, 0.1298, 0.0320, 0.1621,
        0.0000, 0.0423, 0.0110, 0.0000, 0.0000, 0.0435, 0.0052, 0.0000, 0.0000,
        0.0440, 0.0035, 0.0000, 0.0000, 0.0397, 0.0000, 0.0000, 0.0000, 0.0351,
        0.0000, 0.0000, 0.0000, 0.0365, 0.0000, 0.0000, 0.0000, 0.0241, 0.0000,
        0.0000, 0.0000, 0.0055, 0.0000, 0.0000, 0.0000, 0.0017, 0.0000, 0.0000]) (500)
2024-05-07 21:45:22,379 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3727740567999125
2024-05-07 21:45:22,389 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.586960.17391
2024-05-07 21:45:22,396 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #241: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.044444444444444446, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 7)': 0.02, '(min, 0)': 0.24, '(min, 1)': 0.44, '(rev, 1)': 0.06}}
2024-05-07 21:45:22,396 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:22,396 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3725423779745548
2024-05-07 21:45:22,429 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #241: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.02, '(min, 0)': 0.12, '(min, 1)': 0.52, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:45:22,429 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #241: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5531914893617021, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 3)': 0.02, '(min, 0)': 0.22, '(min, 1)': 0.49, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 7)': 0.01, '(rev, 9)': 0.01}}
2024-05-07 21:45:22,429 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:22,429 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:22,429 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3725423779745548
2024-05-07 21:45:22,429 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3725423779745548
2024-05-07 21:45:23,209 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #241: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.14285714285714285, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.03, '(min, 0)': 0.4, '(min, 1)': 0.22, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-05-07 21:45:23,209 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:23,209 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3725423779745548
2024-05-07 21:45:24,804 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #241: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.43478260869565216, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.02, '(min, 0)': 0.07, '(min, 1)': 0.56, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:45:24,804 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:24,804 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3725423779745548
2024-05-07 21:45:25,465 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #241: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.23, '(rev, 1)': 0.01}}
2024-05-07 21:45:25,465 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:25,465 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3725423779745548
2024-05-07 21:45:26,344 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #241: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5217391304347826, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 3)': 0.01, '(min, 0)': 0.08, '(min, 1)': 0.56, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:45:26,344 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:26,352 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3725423779745548
2024-05-07 21:45:26,626 - MainProcess - INFO - text_logger.py - 51 - Train epoch #241
2024-05-07 21:45:26,627 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-8.5891e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.1138e-01,
         0.0000e+00,  1.6999e-01,  1.4455e-02,  2.8993e-01,  0.0000e+00,
         3.7115e-02,  6.2474e-03,  0.0000e+00,  0.0000e+00,  3.3014e-02,
         2.7199e-03,  0.0000e+00,  0.0000e+00,  3.1818e-02,  1.3960e-03,
         0.0000e+00,  0.0000e+00,  2.8904e-02,  3.6364e-05,  0.0000e+00,
         0.0000e+00,  2.5952e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.6325e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.7247e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.0468e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  4.2363e-04,  0.0000e+00,  0.0000e+00])  tensor([1.3275e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8334e-01, 0.0000e+00,
        1.5050e-01, 3.9581e-02, 1.7042e-01, 0.0000e+00, 5.3052e-02, 1.8915e-02,
        0.0000e+00, 0.0000e+00, 5.2513e-02, 1.2259e-02, 0.0000e+00, 0.0000e+00,
        5.3427e-02, 7.2136e-03, 0.0000e+00, 0.0000e+00, 4.9799e-02, 8.1312e-04,
        0.0000e+00, 0.0000e+00, 4.5632e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.7493e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1851e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.7214e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.6316e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:45:26,659 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3728197966798493
2024-05-07 21:45:26,659 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.493990.05920
2024-05-07 21:45:26,692 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #242: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 4, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.54, '(min, 1)': 0.09, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-05-07 21:45:26,692 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:26,692 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3727740567999125
2024-05-07 21:45:26,708 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #242: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.38636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.44, '(rev, 1)': 0.12, '(rev, 2)': 0.03, '(rev, 5)': 0.01}}
2024-05-07 21:45:26,708 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:26,708 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3727740567999125
2024-05-07 21:45:27,071 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #242: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6521739130434783, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 3)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.24, '(rev, 1)': 0.12, '(rev, 2)': 0.03, '(rev, 3)': 0.04}}
2024-05-07 21:45:27,071 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:27,071 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3727740567999125
2024-05-07 21:45:27,424 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #242: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 9)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.19, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-05-07 21:45:27,432 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:27,433 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3727740567999125
2024-05-07 21:45:30,030 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #242: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.375, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.33, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 6)': 0.01}}
2024-05-07 21:45:30,030 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:30,030 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3727740567999125
2024-05-07 21:45:30,531 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #242: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8292682926829268, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 3)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.18, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.04, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:45:30,531 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:30,531 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3727740567999125
2024-05-07 21:45:31,027 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #242: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.36, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.05, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:45:31,027 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:31,027 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3727740567999125
2024-05-07 21:45:31,292 - MainProcess - INFO - text_logger.py - 51 - Train epoch #242
2024-05-07 21:45:31,292 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.7164e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1664e-01, 0.0000e+00,
        1.9287e-01, 1.3890e-02, 3.4749e-01, 0.0000e+00, 1.8383e-02, 1.3949e-02,
        0.0000e+00, 0.0000e+00, 1.2351e-02, 1.6044e-02, 0.0000e+00, 0.0000e+00,
        1.2491e-02, 1.4362e-02, 0.0000e+00, 0.0000e+00, 1.0648e-02, 6.0113e-04,
        0.0000e+00, 0.0000e+00, 9.8471e-03, 4.2758e-04, 0.0000e+00, 0.0000e+00,
        1.0416e-02, 1.7467e-04, 0.0000e+00, 0.0000e+00, 6.8260e-03, 1.7467e-04,
        0.0000e+00, 0.0000e+00, 2.0792e-03, 1.0387e-04, 0.0000e+00, 0.0000e+00,
        2.3721e-04, 0.0000e+00, 0.0000e+00])  tensor([2.2660e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4208e-01, 0.0000e+00,
        1.6993e-01, 3.4505e-02, 1.5402e-01, 0.0000e+00, 3.7935e-02, 3.2580e-02,
        0.0000e+00, 0.0000e+00, 3.4169e-02, 5.3232e-02, 0.0000e+00, 0.0000e+00,
        3.8373e-02, 5.7327e-02, 0.0000e+00, 0.0000e+00, 3.3557e-02, 3.7483e-03,
        0.0000e+00, 0.0000e+00, 3.1550e-02, 2.9922e-03, 0.0000e+00, 0.0000e+00,
        3.3822e-02, 1.7419e-03, 0.0000e+00, 0.0000e+00, 2.2357e-02, 1.7419e-03,
        0.0000e+00, 0.0000e+00, 7.9255e-03, 1.3410e-03, 0.0000e+00, 0.0000e+00,
        2.0168e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:45:31,316 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.37270683075441163
2024-05-07 21:45:31,324 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.414630.41463
2024-05-07 21:45:31,372 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #243: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.48, '(min, 1)': 0.12}}
2024-05-07 21:45:31,372 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:31,372 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3728197966798493
2024-05-07 21:45:31,518 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #243: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.33, '(min, 1)': 0.24, '(rev, 1)': 0.11, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:45:31,518 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:31,518 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3728197966798493
2024-05-07 21:45:31,743 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #243: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 3, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.5813953488372093, 'length': 100, 'actions': {'(ado, 1)': 0.06, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.5, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.05, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:45:31,743 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:31,743 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3728197966798493
2024-05-07 21:45:32,506 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #243: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7391304347826086, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 3)': 0.03, '(min, 0)': 0.32, '(min, 1)': 0.3, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:45:32,506 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:32,514 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3728197966798493
2024-05-07 21:45:33,949 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #243: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.18, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.2, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:45:33,949 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:33,949 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3728197966798493
2024-05-07 21:45:35,291 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #243: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.34375, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.44, '(min, 1)': 0.26, '(rev, 1)': 0.03, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:45:35,291 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:35,291 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3728197966798493
2024-05-07 21:45:36,916 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #243: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 5, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7941176470588235, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.29, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.04, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:45:36,916 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:36,916 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3728197966798493
2024-05-07 21:45:37,174 - MainProcess - INFO - text_logger.py - 51 - Train epoch #243
2024-05-07 21:45:37,174 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0887e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5262e-01, 0.0000e+00,
        1.8079e-01, 1.4314e-02, 3.5513e-01, 0.0000e+00, 1.9212e-02, 1.3322e-02,
        0.0000e+00, 0.0000e+00, 1.0715e-02, 1.1749e-02, 0.0000e+00, 0.0000e+00,
        9.0167e-03, 6.8392e-03, 0.0000e+00, 0.0000e+00, 7.8421e-03, 4.1291e-04,
        0.0000e+00, 0.0000e+00, 6.7552e-03, 7.4074e-05, 0.0000e+00, 0.0000e+00,
        6.3235e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7909e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0238e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.9994e-05, 0.0000e+00, 0.0000e+00])  tensor([2.1714e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3678e-01, 0.0000e+00,
        1.7017e-01, 3.5773e-02, 1.3979e-01, 0.0000e+00, 4.3664e-02, 3.2689e-02,
        0.0000e+00, 0.0000e+00, 3.0607e-02, 4.1021e-02, 0.0000e+00, 0.0000e+00,
        3.0237e-02, 3.7511e-02, 0.0000e+00, 0.0000e+00, 2.7581e-02, 3.7571e-03,
        0.0000e+00, 0.0000e+00, 2.4874e-02, 1.6563e-03, 0.0000e+00, 0.0000e+00,
        2.5248e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6352e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.7532e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1090e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:45:37,198 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3721083465362911
2024-05-07 21:45:37,198 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.171880.17187
2024-05-07 21:45:37,214 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #244: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.41, '(min, 1)': 0.13, '(rev, 1)': 0.07, '(rev, 2)': 0.02}}
2024-05-07 21:45:37,214 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:37,214 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37270683075441163
2024-05-07 21:45:37,246 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #244: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.48, '(min, 1)': 0.11}}
2024-05-07 21:45:37,246 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #244: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.02040816326530612, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.15, '(rev, 1)': 0.04}}
2024-05-07 21:45:37,246 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:37,246 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:37,246 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37270683075441163
2024-05-07 21:45:37,246 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37270683075441163
2024-05-07 21:45:37,786 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #244: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 0, 1, 0)', 'reward_ratio': '0/0', 'revenue': 0.1702127659574468, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.03, '(ado, 8)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.29, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:45:37,786 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:37,786 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37270683075441163
2024-05-07 21:45:38,376 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #244: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 3, 8, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 4, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.21951219512195122, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.26, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:45:38,376 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:38,376 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37270683075441163
2024-05-07 21:45:39,321 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #244: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.56, '(min, 1)': 0.03}}
2024-05-07 21:45:39,321 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:39,321 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37270683075441163
2024-05-07 21:45:41,649 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #244: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1346153846153846, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.26, '(rev, 1)': 0.05, '(rev, 5)': 0.01}}
2024-05-07 21:45:41,657 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:41,657 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37270683075441163
2024-05-07 21:45:41,923 - MainProcess - INFO - text_logger.py - 51 - Train epoch #244
2024-05-07 21:45:41,923 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.1150e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0354e-01, 0.0000e+00,
        1.6496e-01, 1.0267e-02, 3.1409e-01, 0.0000e+00, 3.7482e-02, 4.0499e-03,
        0.0000e+00, 0.0000e+00, 3.2066e-02, 2.6138e-03, 0.0000e+00, 0.0000e+00,
        3.0675e-02, 1.7487e-03, 0.0000e+00, 0.0000e+00, 2.7843e-02, 3.1381e-04,
        0.0000e+00, 0.0000e+00, 2.4117e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.4844e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5415e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.3155e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.5201e-04, 0.0000e+00, 0.0000e+00])  tensor([1.5707, 0.0000, 0.0000, 0.0000, 0.1736, 0.0000, 0.1419, 0.0289, 0.1809,
        0.0000, 0.0541, 0.0157, 0.0000, 0.0000, 0.0498, 0.0141, 0.0000, 0.0000,
        0.0510, 0.0124, 0.0000, 0.0000, 0.0479, 0.0029, 0.0000, 0.0000, 0.0433,
        0.0000, 0.0000, 0.0000, 0.0466, 0.0000, 0.0000, 0.0000, 0.0303, 0.0000,
        0.0000, 0.0000, 0.0126, 0.0000, 0.0000, 0.0000, 0.0034, 0.0000, 0.0000]) (500)
2024-05-07 21:45:41,948 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.37116611231817054
2024-05-07 21:45:41,956 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:45:41,980 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #245: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.52, '(min, 1)': 0.07}}
2024-05-07 21:45:41,980 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #245: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.04878048780487805, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.17, '(rev, 1)': 0.02, '(rev, 2)': 0.01}}
2024-05-07 21:45:41,980 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:41,980 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:41,980 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3721083465362911
2024-05-07 21:45:41,980 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3721083465362911
2024-05-07 21:45:41,989 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #245: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22448979591836735, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.36, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:45:41,989 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:41,989 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3721083465362911
2024-05-07 21:45:42,495 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #245: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 3, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.9, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(min, 0)': 0.48, '(min, 1)': 0.2, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:45:42,495 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:42,495 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3721083465362911
2024-05-07 21:45:42,885 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #245: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.05454545454545454, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 5)': 0.01, '(ado, 8)': 0.02, '(min, 0)': 0.49, '(min, 1)': 0.13, '(rev, 1)': 0.03, '(rev, 2)': 0.01}}
2024-05-07 21:45:42,885 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:42,890 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3721083465362911
2024-05-07 21:45:43,553 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #245: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.44, '(min, 1)': 0.14}}
2024-05-07 21:45:43,553 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:43,553 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3721083465362911
2024-05-07 21:45:45,997 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #245: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.075, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.25, '(rev, 1)': 0.04}}
2024-05-07 21:45:45,997 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:45,997 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3721083465362911
2024-05-07 21:45:46,280 - MainProcess - INFO - text_logger.py - 51 - Train epoch #245
2024-05-07 21:45:46,281 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-4.1355e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.1068e-01,
         0.0000e+00,  1.8405e-01,  8.0533e-03,  2.1792e-01,  0.0000e+00,
         6.8597e-02,  3.7278e-03,  0.0000e+00,  0.0000e+00,  6.2090e-02,
         1.8874e-03,  0.0000e+00,  0.0000e+00,  5.7562e-02,  1.6454e-03,
         0.0000e+00,  0.0000e+00,  5.2311e-02,  1.4304e-04,  0.0000e+00,
         0.0000e+00,  4.7407e-02,  6.8966e-05,  0.0000e+00,  0.0000e+00,
         4.6472e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8532e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  7.8596e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  9.9615e-04,  0.0000e+00,  0.0000e+00])  tensor([1.7179e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7716e-01, 0.0000e+00,
        1.3891e-01, 2.6579e-02, 1.8345e-01, 0.0000e+00, 6.1303e-02, 1.5400e-02,
        0.0000e+00, 0.0000e+00, 5.8373e-02, 1.0975e-02, 0.0000e+00, 0.0000e+00,
        5.7583e-02, 9.7832e-03, 0.0000e+00, 0.0000e+00, 5.3904e-02, 2.2608e-03,
        0.0000e+00, 0.0000e+00, 5.0446e-02, 1.5421e-03, 0.0000e+00, 0.0000e+00,
        5.2405e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5556e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.3806e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.0834e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:45:46,304 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3702238781000499
2024-05-07 21:45:46,312 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:45:46,328 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #246: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.55, '(min, 1)': 0.07}}
2024-05-07 21:45:46,328 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:46,328 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37116611231817054
2024-05-07 21:45:46,660 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #246: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.375, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.02, '(min, 0)': 0.49, '(min, 1)': 0.1, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-05-07 21:45:46,660 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:46,660 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37116611231817054
2024-05-07 21:45:47,074 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #246: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7954545454545454, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.35, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 7)': 0.01}}
2024-05-07 21:45:47,074 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:47,074 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37116611231817054
2024-05-07 21:45:47,276 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #246: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.56, '(min, 1)': 0.05}}
2024-05-07 21:45:47,276 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:47,276 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37116611231817054
2024-05-07 21:45:48,761 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #246: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6346153846153846, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 10)': 0.01, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(min, 0)': 0.07, '(min, 1)': 0.55, '(rev, 1)': 0.1, '(rev, 2)': 0.04}}
2024-05-07 21:45:48,761 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:48,761 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37116611231817054
2024-05-07 21:45:49,310 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #246: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.03278688524590164, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(ado, 5)': 0.03, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.25, '(rev, 2)': 0.01}}
2024-05-07 21:45:49,310 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:49,310 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37116611231817054
2024-05-07 21:45:49,850 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #246: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2608695652173913, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 3)': 0.02, '(min, 0)': 0.43, '(min, 1)': 0.15, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:45:49,850 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:49,858 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.37116611231817054
2024-05-07 21:45:50,132 - MainProcess - INFO - text_logger.py - 51 - Train epoch #246
2024-05-07 21:45:50,132 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.6491e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5350e-01, 0.0000e+00,
        1.4417e-01, 1.5504e-02, 3.6038e-01, 0.0000e+00, 2.2681e-02, 8.2646e-03,
        0.0000e+00, 0.0000e+00, 1.8866e-02, 7.2562e-03, 0.0000e+00, 0.0000e+00,
        1.6533e-02, 3.9048e-03, 0.0000e+00, 0.0000e+00, 1.4417e-02, 1.1146e-04,
        0.0000e+00, 0.0000e+00, 1.2629e-02, 6.8966e-05, 0.0000e+00, 0.0000e+00,
        1.2207e-02, 6.6667e-05, 0.0000e+00, 0.0000e+00, 7.5330e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.7357e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6646e-04, 0.0000e+00, 0.0000e+00])  tensor([2.3257e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4537e-01, 0.0000e+00,
        1.4106e-01, 3.6233e-02, 1.5157e-01, 0.0000e+00, 4.6109e-02, 2.4075e-02,
        0.0000e+00, 0.0000e+00, 4.3354e-02, 3.6051e-02, 0.0000e+00, 0.0000e+00,
        3.9852e-02, 2.7536e-02, 0.0000e+00, 0.0000e+00, 3.5621e-02, 1.7632e-03,
        0.0000e+00, 0.0000e+00, 3.2084e-02, 1.5421e-03, 0.0000e+00, 0.0000e+00,
        3.2761e-02, 1.4907e-03, 0.0000e+00, 0.0000e+00, 2.1697e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.2127e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.1109e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:45:50,156 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3692816438819293
2024-05-07 21:45:50,164 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:45:50,472 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #247: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.56, '(min, 1)': 0.04}}
2024-05-07 21:45:50,472 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:50,472 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3702238781000499
2024-05-07 21:45:51,133 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #247: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.03, '(ado, 3)': 0.03, '(min, 0)': 0.39, '(min, 1)': 0.24, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:45:51,133 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:51,133 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3702238781000499
2024-05-07 21:45:51,180 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #247: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 3)': 0.03, '(min, 0)': 0.4, '(min, 1)': 0.28, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.03}}
2024-05-07 21:45:51,180 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:51,180 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3702238781000499
2024-05-07 21:45:51,412 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #247: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 3, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.52, '(min, 1)': 0.09}}
2024-05-07 21:45:51,412 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:51,412 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3702238781000499
2024-05-07 21:45:52,852 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #247: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.17, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 4)': 0.01}}
2024-05-07 21:45:52,852 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:52,852 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3702238781000499
2024-05-07 21:45:53,642 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #247: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1794871794871795, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.27, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:45:53,642 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:53,642 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3702238781000499
2024-05-07 21:45:54,625 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #247: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.14634146341463414, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.25, '(rev, 1)': 0.04, '(rev, 2)': 0.03}}
2024-05-07 21:45:54,625 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:54,625 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3702238781000499
2024-05-07 21:45:54,898 - MainProcess - INFO - text_logger.py - 51 - Train epoch #247
2024-05-07 21:45:54,898 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.9912e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4058e-01, 0.0000e+00,
        1.6941e-01, 1.5522e-02, 3.5431e-01, 0.0000e+00, 2.1508e-02, 9.0937e-03,
        0.0000e+00, 0.0000e+00, 1.6123e-02, 8.5838e-03, 0.0000e+00, 0.0000e+00,
        1.4474e-02, 4.5981e-03, 0.0000e+00, 0.0000e+00, 1.3380e-02, 1.3209e-04,
        0.0000e+00, 0.0000e+00, 1.1964e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1392e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0461e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.8206e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.2736e-05, 0.0000e+00, 0.0000e+00])  tensor([1.6480e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4342e-01, 0.0000e+00,
        1.5779e-01, 3.5855e-02, 1.4986e-01, 0.0000e+00, 4.4893e-02, 2.5953e-02,
        0.0000e+00, 0.0000e+00, 3.8767e-02, 3.1676e-02, 0.0000e+00, 0.0000e+00,
        3.8119e-02, 1.7959e-02, 0.0000e+00, 0.0000e+00, 3.5976e-02, 1.7182e-03,
        0.0000e+00, 0.0000e+00, 3.2934e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2656e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1315e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.6166e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0112e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:45:54,922 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3683394096638088
2024-05-07 21:45:54,930 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:45:54,938 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #248: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3673469387755102, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(min, 0)': 0.37, '(min, 1)': 0.22, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:45:54,938 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:54,938 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3692816438819293
2024-05-07 21:45:54,947 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #248: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.57, '(min, 1)': 0.05}}
2024-05-07 21:45:54,947 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:54,947 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3692816438819293
2024-05-07 21:45:57,080 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #248: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32558139534883723, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 3)': 0.02, '(min, 0)': 0.44, '(min, 1)': 0.18, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 4)': 0.01}}
2024-05-07 21:45:57,080 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:57,088 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3692816438819293
2024-05-07 21:45:57,218 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #248: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 3, 0, 1),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 2, 3, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(ado, 7)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.21}}
2024-05-07 21:45:57,218 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:57,218 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3692816438819293
2024-05-07 21:45:57,670 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #248: {'transition': '(exi, not, exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 2, 3, 9, 1, 1),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.15555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.23, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:45:57,670 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:57,670 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3692816438819293
2024-05-07 21:45:58,050 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #248: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.14545454545454545, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.06, '(rev, 1)': 0.04, '(rev, 2)': 0.04}}
2024-05-07 21:45:58,050 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:45:58,051 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3692816438819293
2024-05-07 21:46:01,535 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #248: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.22}}
2024-05-07 21:46:01,535 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:01,535 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3692816438819293
2024-05-07 21:46:01,802 - MainProcess - INFO - text_logger.py - 51 - Train epoch #248
2024-05-07 21:46:01,802 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([0.2415, 0.0000, 0.0000, 0.0000, 0.3130, 0.0000, 0.1464, 0.0126, 0.3155,
        0.0000, 0.0392, 0.0047, 0.0000, 0.0000, 0.0332, 0.0014, 0.0000, 0.0000,
        0.0307, 0.0007, 0.0000, 0.0000, 0.0283, 0.0000, 0.0000, 0.0000, 0.0266,
        0.0000, 0.0000, 0.0000, 0.0251, 0.0000, 0.0000, 0.0000, 0.0164, 0.0000,
        0.0000, 0.0000, 0.0054, 0.0000, 0.0000, 0.0000, 0.0007, 0.0000, 0.0000])  tensor([1.8380, 0.0000, 0.0000, 0.0000, 0.1792, 0.0000, 0.1393, 0.0330, 0.1827,
        0.0000, 0.0584, 0.0170, 0.0000, 0.0000, 0.0525, 0.0107, 0.0000, 0.0000,
        0.0513, 0.0056, 0.0000, 0.0000, 0.0486, 0.0000, 0.0000, 0.0000, 0.0463,
        0.0000, 0.0000, 0.0000, 0.0456, 0.0000, 0.0000, 0.0000, 0.0302, 0.0000,
        0.0000, 0.0000, 0.0125, 0.0000, 0.0000, 0.0000, 0.0035, 0.0000, 0.0000]) (500)
2024-05-07 21:46:01,826 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3673971754456882
2024-05-07 21:46:01,834 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:46:01,862 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #249: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.27, '(rev, 1)': 0.08, '(rev, 2)': 0.08}}
2024-05-07 21:46:01,862 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:01,862 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3683394096638088
2024-05-07 21:46:01,874 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #249: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.11904761904761904, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.19, '(rev, 1)': 0.05, '(rev, 2)': 0.02}}
2024-05-07 21:46:01,874 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:01,874 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3683394096638088
2024-05-07 21:46:01,996 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #249: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.33, '(min, 1)': 0.31}}
2024-05-07 21:46:01,996 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:01,996 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3683394096638088
2024-05-07 21:46:02,221 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #249: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2894736842105263, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.24, '(rev, 1)': 0.02}}
2024-05-07 21:46:02,221 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:02,229 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3683394096638088
2024-05-07 21:46:02,486 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #249: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.18, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.19, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:46:02,486 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:02,486 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3683394096638088
2024-05-07 21:46:04,930 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #249: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.45098039215686275, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 6)': 0.02, '(min, 0)': 0.37, '(min, 1)': 0.26, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-07 21:46:04,930 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:04,938 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3683394096638088
2024-05-07 21:46:06,022 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #249: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.39215686274509803, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.03, '(ado, 8)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.24, '(rev, 1)': 0.11, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-05-07 21:46:06,022 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:06,022 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3683394096638088
2024-05-07 21:46:06,272 - MainProcess - INFO - text_logger.py - 51 - Train epoch #249
2024-05-07 21:46:06,273 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([0.2215, 0.0000, 0.0000, 0.0000, 0.3225, 0.0000, 0.1596, 0.0142, 0.3331,
        0.0000, 0.0334, 0.0055, 0.0000, 0.0000, 0.0268, 0.0023, 0.0000, 0.0000,
        0.0243, 0.0004, 0.0000, 0.0000, 0.0219, 0.0000, 0.0000, 0.0000, 0.0202,
        0.0000, 0.0000, 0.0000, 0.0195, 0.0000, 0.0000, 0.0000, 0.0123, 0.0000,
        0.0000, 0.0000, 0.0035, 0.0000, 0.0000, 0.0000, 0.0003, 0.0000, 0.0000])  tensor([1.7055, 0.0000, 0.0000, 0.0000, 0.1617, 0.0000, 0.1395, 0.0344, 0.1692,
        0.0000, 0.0574, 0.0172, 0.0000, 0.0000, 0.0490, 0.0133, 0.0000, 0.0000,
        0.0473, 0.0053, 0.0000, 0.0000, 0.0436, 0.0000, 0.0000, 0.0000, 0.0413,
        0.0000, 0.0000, 0.0000, 0.0417, 0.0000, 0.0000, 0.0000, 0.0267, 0.0000,
        0.0000, 0.0000, 0.0099, 0.0000, 0.0000, 0.0000, 0.0024, 0.0000, 0.0000]) (500)
2024-05-07 21:46:06,296 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.36674441491177817
2024-05-07 21:46:06,296 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.144740.14474
2024-05-07 21:46:06,320 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #250: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.27906976744186046, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.22, '(min, 1)': 0.35, '(rev, 1)': 0.09, '(rev, 2)': 0.03}}
2024-05-07 21:46:06,320 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:06,320 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3673971754456882
2024-05-07 21:46:06,361 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #250: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40425531914893614, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.02, '(min, 0)': 0.49, '(min, 1)': 0.12, '(rev, 1)': 0.06, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-05-07 21:46:06,361 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:06,361 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3673971754456882
2024-05-07 21:46:07,070 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #250: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.30434782608695654, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.28, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-05-07 21:46:07,070 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:07,070 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3673971754456882
2024-05-07 21:46:07,840 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #250: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10526315789473684, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(min, 0)': 0.5, '(min, 1)': 0.12, '(rev, 1)': 0.02, '(rev, 2)': 0.02}}
2024-05-07 21:46:07,840 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:07,840 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3673971754456882
2024-05-07 21:46:08,221 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #250: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.15625, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(min, 0)': 0.41, '(min, 1)': 0.27, '(rev, 1)': 0.03, '(rev, 2)': 0.02}}
2024-05-07 21:46:08,221 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:08,221 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3673971754456882
2024-05-07 21:46:09,599 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #250: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.06666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.18, '(rev, 1)': 0.04, '(rev, 2)': 0.01}}
2024-05-07 21:46:09,599 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:09,599 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3673971754456882
2024-05-07 21:46:10,215 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #250: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2553191489361702, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 3)': 0.04, '(min, 0)': 0.39, '(min, 1)': 0.2, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-07 21:46:10,215 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:10,215 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3673971754456882
2024-05-07 21:46:10,497 - MainProcess - INFO - text_logger.py - 51 - Train epoch #250
2024-05-07 21:46:10,497 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([0.2121, 0.0000, 0.0000, 0.0000, 0.3548, 0.0000, 0.1433, 0.0158, 0.3581,
        0.0000, 0.0249, 0.0046, 0.0000, 0.0000, 0.0191, 0.0013, 0.0000, 0.0000,
        0.0184, 0.0000, 0.0000, 0.0000, 0.0162, 0.0000, 0.0000, 0.0000, 0.0158,
        0.0000, 0.0000, 0.0000, 0.0144, 0.0000, 0.0000, 0.0000, 0.0095, 0.0000,
        0.0000, 0.0000, 0.0032, 0.0000, 0.0000, 0.0000, 0.0005, 0.0000, 0.0000])  tensor([1.1813, 0.0000, 0.0000, 0.0000, 0.1527, 0.0000, 0.1376, 0.0376, 0.1563,
        0.0000, 0.0503, 0.0152, 0.0000, 0.0000, 0.0422, 0.0070, 0.0000, 0.0000,
        0.0431, 0.0000, 0.0000, 0.0000, 0.0387, 0.0000, 0.0000, 0.0000, 0.0385,
        0.0000, 0.0000, 0.0000, 0.0363, 0.0000, 0.0000, 0.0000, 0.0246, 0.0000,
        0.0000, 0.0000, 0.0096, 0.0000, 0.0000, 0.0000, 0.0029, 0.0000, 0.0000]) (500)
2024-05-07 21:46:10,521 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.36606369385155235
2024-05-07 21:46:10,529 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.130760.02549
2024-05-07 21:46:10,988 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #251: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36585365853658536, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.28, '(rev, 1)': 0.11, '(rev, 2)': 0.05}}
2024-05-07 21:46:10,988 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:10,988 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36674441491177817
2024-05-07 21:46:11,366 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #251: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4583333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(ado, 4)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.45, '(rev, 1)': 0.09, '(rev, 2)': 0.08, '(rev, 3)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:46:11,366 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:11,366 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36674441491177817
2024-05-07 21:46:14,329 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #251: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.29545454545454547, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.17, '(min, 1)': 0.44, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:46:14,329 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:14,329 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36674441491177817
2024-05-07 21:46:14,772 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #251: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.14}}
2024-05-07 21:46:14,772 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:14,772 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36674441491177817
2024-05-07 21:46:14,828 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #251: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.43478260869565216, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.41, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:46:14,828 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:14,828 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36674441491177817
2024-05-07 21:46:15,012 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #251: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8913043478260869, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 3)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.24, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.02}}
2024-05-07 21:46:15,012 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:15,012 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36674441491177817
2024-05-07 21:46:16,053 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #251: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36363636363636365, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.25, '(rev, 1)': 0.02, '(rev, 3)': 0.02}}
2024-05-07 21:46:16,053 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:16,053 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36674441491177817
2024-05-07 21:46:16,142 - MainProcess - INFO - text_logger.py - 51 - Train epoch #251
2024-05-07 21:46:16,142 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.9797e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6359e-01, 0.0000e+00,
        1.6182e-01, 2.3600e-02, 3.7992e-01, 0.0000e+00, 9.3934e-03, 1.4298e-02,
        0.0000e+00, 0.0000e+00, 4.1480e-03, 2.1495e-02, 0.0000e+00, 0.0000e+00,
        3.0011e-03, 1.1321e-02, 0.0000e+00, 0.0000e+00, 2.2529e-03, 4.9723e-04,
        0.0000e+00, 0.0000e+00, 1.8738e-03, 6.4516e-05, 0.0000e+00, 0.0000e+00,
        1.5004e-03, 7.1429e-05, 0.0000e+00, 0.0000e+00, 8.6426e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.9139e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([3.7653e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1732e-01, 0.0000e+00,
        1.7258e-01, 4.5320e-02, 1.1259e-01, 0.0000e+00, 2.8822e-02, 3.1231e-02,
        0.0000e+00, 0.0000e+00, 1.8217e-02, 6.3836e-02, 0.0000e+00, 0.0000e+00,
        1.6696e-02, 3.6256e-02, 0.0000e+00, 0.0000e+00, 1.4088e-02, 3.7232e-03,
        0.0000e+00, 0.0000e+00, 1.3518e-02, 1.4426e-03, 0.0000e+00, 0.0000e+00,
        1.2749e-02, 1.5972e-03, 0.0000e+00, 0.0000e+00, 7.8590e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2508e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:46:16,170 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.36548509599706813
2024-05-07 21:46:16,174 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.181820.18182
2024-05-07 21:46:17,755 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #252: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8292682926829268, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.43, '(min, 1)': 0.23, '(rev, 1)': 0.06, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:46:17,755 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:17,755 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36606369385155235
2024-05-07 21:46:17,771 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #252: {'transition': '(exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 3, 6, 1, 1),(min, 0)->(exi, wit, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 4, 6, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.24, '(rev, 1)': 0.03, '(rev, 2)': 0.05}}
2024-05-07 21:46:17,771 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:17,771 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36606369385155235
2024-05-07 21:46:18,891 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #252: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 4, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.48, '(min, 1)': 0.17}}
2024-05-07 21:46:18,891 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:18,900 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36606369385155235
2024-05-07 21:46:19,287 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #252: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2608695652173913, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.04, '(ado, 7)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.27, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:46:19,287 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:19,295 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36606369385155235
2024-05-07 21:46:19,787 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #252: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.08108108108108109, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.09, '(rev, 1)': 0.03, '(rev, 2)': 0.02}}
2024-05-07 21:46:19,787 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:19,787 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36606369385155235
2024-05-07 21:46:21,744 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #252: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43137254901960786, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.16, '(rev, 1)': 0.07, '(rev, 2)': 0.04}}
2024-05-07 21:46:21,744 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:21,744 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36606369385155235
2024-05-07 21:46:22,728 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #252: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3023255813953488, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.46, '(min, 1)': 0.23, '(rev, 1)': 0.02, '(rev, 2)': 0.01}}
2024-05-07 21:46:22,728 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:22,728 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36606369385155235
2024-05-07 21:46:22,993 - MainProcess - INFO - text_logger.py - 51 - Train epoch #252
2024-05-07 21:46:22,993 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.2239e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8450e-01, 0.0000e+00,
        1.7230e-01, 1.2914e-02, 2.9997e-01, 0.0000e+00, 4.5090e-02, 7.9307e-03,
        0.0000e+00, 0.0000e+00, 3.6582e-02, 6.4435e-03, 0.0000e+00, 0.0000e+00,
        3.2331e-02, 4.4080e-03, 0.0000e+00, 0.0000e+00, 2.8385e-02, 5.3833e-04,
        0.0000e+00, 0.0000e+00, 2.6143e-02, 2.0686e-04, 0.0000e+00, 0.0000e+00,
        2.2740e-02, 1.4100e-04, 0.0000e+00, 0.0000e+00, 1.4550e-02, 7.0802e-05,
        0.0000e+00, 0.0000e+00, 4.2573e-03, 3.5088e-05, 0.0000e+00, 0.0000e+00,
        4.6395e-04, 0.0000e+00, 0.0000e+00])  tensor([2.6364e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7405e-01, 0.0000e+00,
        1.6082e-01, 3.5539e-02, 1.8493e-01, 0.0000e+00, 6.4938e-02, 2.4297e-02,
        0.0000e+00, 0.0000e+00, 5.4684e-02, 2.5612e-02, 0.0000e+00, 0.0000e+00,
        5.0857e-02, 1.6043e-02, 0.0000e+00, 0.0000e+00, 4.5988e-02, 3.6872e-03,
        0.0000e+00, 0.0000e+00, 4.4027e-02, 1.8881e-03, 0.0000e+00, 0.0000e+00,
        4.1218e-02, 1.5718e-03, 0.0000e+00, 0.0000e+00, 2.8777e-02, 1.1184e-03,
        0.0000e+00, 0.0000e+00, 1.1478e-02, 7.8459e-04, 0.0000e+00, 0.0000e+00,
        2.7706e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:46:23,017 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3649742343279671
2024-05-07 21:46:23,025 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.215690.21569
2024-05-07 21:46:23,041 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #253: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 0, 1, 0)', 'reward_ratio': '0/0', 'revenue': 0.7307692307692307, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.12, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:46:23,041 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
nsition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2564102564102564, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(min, 0)': 0.36, '(min, 1)': 0.29, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:46:23,041 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:23,041 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36548509599706813
2024-05-07 21:46:23,041 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36548509599706813
2024-05-07 21:46:24,604 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #253: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.03, '(ado, 7)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.21, '(rev, 1)': 0.03, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:46:24,604 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:24,604 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36548509599706813
2024-05-07 21:46:24,757 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #253: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.5106382978723404, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.25, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:46:24,757 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:24,765 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36548509599706813
2024-05-07 21:46:25,448 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #253: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(ado, 7)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.24}}
2024-05-07 21:46:25,448 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:25,448 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36548509599706813
2024-05-07 21:46:26,246 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #253: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5227272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.2, '(rev, 1)': 0.06, '(rev, 2)': 0.06, '(rev, 3)': 0.05, '(rev, 4)': 0.01}}
2024-05-07 21:46:26,246 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:26,246 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36548509599706813
2024-05-07 21:46:27,332 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #253: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 6, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.05128205128205128, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 3)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.14, '(rev, 1)': 0.03, '(rev, 2)': 0.01}}
2024-05-07 21:46:27,332 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:27,332 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36548509599706813
2024-05-07 21:46:27,605 - MainProcess - INFO - text_logger.py - 51 - Train epoch #253
2024-05-07 21:46:27,605 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-2.5234e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.4819e-01,
         0.0000e+00,  1.7813e-01,  1.4713e-02,  2.5497e-01,  0.0000e+00,
         5.9280e-02,  6.0053e-03,  0.0000e+00,  0.0000e+00,  5.1116e-02,
         2.8948e-03,  0.0000e+00,  0.0000e+00,  4.6295e-02,  1.0395e-03,
         0.0000e+00,  0.0000e+00,  3.9652e-02,  6.4516e-05,  0.0000e+00,
         0.0000e+00,  3.8070e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.2662e-02,  7.1429e-05,  0.0000e+00,  0.0000e+00,  2.0676e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  5.8437e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.1918e-04,  0.0000e+00,  0.0000e+00])  tensor([1.9499e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7948e-01, 0.0000e+00,
        1.5355e-01, 4.0435e-02, 1.8352e-01, 0.0000e+00, 6.5248e-02, 1.8840e-02,
        0.0000e+00, 0.0000e+00, 6.0188e-02, 1.1618e-02, 0.0000e+00, 0.0000e+00,
        5.7207e-02, 5.4997e-03, 0.0000e+00, 0.0000e+00, 5.0112e-02, 1.4426e-03,
        0.0000e+00, 0.0000e+00, 4.9645e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.5364e-02, 1.5972e-03, 0.0000e+00, 0.0000e+00, 3.2393e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.3247e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.2695e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:46:27,638 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.36455472738257383
2024-05-07 21:46:27,638 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.261360.26136
2024-05-07 21:46:28,000 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #254: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.02, '(min, 0)': 0.47, '(min, 1)': 0.13, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 5)': 0.01}}
2024-05-07 21:46:28,000 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:28,000 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3649742343279671
2024-05-07 21:46:28,555 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #254: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 0, 1, 0),(rev, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '11/1', 'revenue': 0.2391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.28, '(rev, 1)': 0.01}}
2024-05-07 21:46:28,555 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:28,555 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3649742343279671
2024-05-07 21:46:28,974 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #254: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1590909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.17, '(rev, 1)': 0.07, '(rev, 2)': 0.01}}
2024-05-07 21:46:28,974 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:28,974 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3649742343279671
2024-05-07 21:46:29,642 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #254: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 0, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.18, '(rev, 1)': 0.06, '(rev, 2)': 0.04}}
2024-05-07 21:46:29,642 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:29,642 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3649742343279671
2024-05-07 21:46:30,302 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #254: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.14893617021276595, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 3)': 0.04, '(min, 0)': 0.41, '(min, 1)': 0.15, '(rev, 1)': 0.1, '(rev, 2)': 0.02}}
2024-05-07 21:46:30,302 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:30,302 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3649742343279671
2024-05-07 21:46:31,446 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #254: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 4)': 0.01, '(min, 0)': 0.54, '(min, 1)': 0.1}}
2024-05-07 21:46:31,446 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:31,446 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3649742343279671
2024-05-07 21:46:31,575 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #254: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.3, '(rev, 1)': 0.04, '(rev, 2)': 0.01}}
2024-05-07 21:46:31,575 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:31,575 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3649742343279671
2024-05-07 21:46:31,713 - MainProcess - INFO - text_logger.py - 51 - Train epoch #254
2024-05-07 21:46:31,713 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.2881e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.9560e-01,
         0.0000e+00,  1.4925e-01,  9.3507e-03,  2.0210e-01,  0.0000e+00,
         7.9209e-02,  2.2590e-03,  0.0000e+00,  0.0000e+00,  7.2886e-02,
         4.6419e-04,  0.0000e+00,  0.0000e+00,  6.8081e-02,  2.6440e-04,
         0.0000e+00,  0.0000e+00,  6.1838e-02,  5.5556e-05,  0.0000e+00,
         0.0000e+00,  5.8014e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         5.3042e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.4141e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2100e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  1.3431e-03,  0.0000e+00,  0.0000e+00])  tensor([1.8611e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8782e-01, 0.0000e+00,
        1.0948e-01, 3.0846e-02, 1.9446e-01, 0.0000e+00, 6.4524e-02, 1.0008e-02,
        0.0000e+00, 0.0000e+00, 6.0287e-02, 4.4838e-03, 0.0000e+00, 0.0000e+00,
        5.8250e-02, 2.6710e-03, 0.0000e+00, 0.0000e+00, 5.4201e-02, 1.2423e-03,
        0.0000e+00, 0.0000e+00, 5.2183e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.0117e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5854e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.6331e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.5648e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:46:31,737 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3642947626679994
2024-05-07 21:46:31,745 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.341130.19220
2024-05-07 21:46:32,382 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #255: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.4, '(min, 1)': 0.2, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-07 21:46:32,382 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:32,382 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36455472738257383
2024-05-07 21:46:34,226 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #255: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.54, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(ado, 6)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.28, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.03}}
2024-05-07 21:46:34,226 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:34,226 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36455472738257383
2024-05-07 21:46:34,651 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #255: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2127659574468085, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.16, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:46:34,659 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:34,660 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36455472738257383
2024-05-07 21:46:35,627 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #255: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.32, '(min, 1)': 0.27}}
2024-05-07 21:46:35,627 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:35,627 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36455472738257383
2024-05-07 21:46:36,110 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #255: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.625, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(min, 0)': 0.43, '(min, 1)': 0.29, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.04, '(rev, 4)': 0.01, '(rev, 8)': 0.01}}
2024-05-07 21:46:36,110 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:36,118 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36455472738257383
2024-05-07 21:46:36,465 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #255: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 4, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.021739130434782608, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.18, '(rev, 1)': 0.03, '(rev, 2)': 0.01}}
2024-05-07 21:46:36,465 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:36,465 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36455472738257383
2024-05-07 21:46:36,981 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #255: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 2, 3, 0, 1),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 2, 4, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.4897959183673469, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.35, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-07 21:46:36,981 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:36,981 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36455472738257383
2024-05-07 21:46:37,068 - MainProcess - INFO - text_logger.py - 51 - Train epoch #255
2024-05-07 21:46:37,068 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-6.7808e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8583e-01,
         0.0000e+00,  1.6812e-01,  1.6175e-02,  2.9765e-01,  0.0000e+00,
         4.2712e-02,  6.9215e-03,  0.0000e+00,  0.0000e+00,  3.4242e-02,
         5.1429e-03,  0.0000e+00,  0.0000e+00,  3.3977e-02,  3.6339e-03,
         0.0000e+00,  0.0000e+00,  2.9456e-02,  1.1513e-04,  0.0000e+00,
         0.0000e+00,  2.8887e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.4892e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.6254e-02,
         7.4074e-05,  0.0000e+00,  0.0000e+00,  5.5463e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.7090e-04,  0.0000e+00,  0.0000e+00])  tensor([2.3696e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7201e-01, 0.0000e+00,
        1.4712e-01, 4.2559e-02, 1.7757e-01, 0.0000e+00, 6.0141e-02, 2.0627e-02,
        0.0000e+00, 0.0000e+00, 5.1928e-02, 3.3265e-02, 0.0000e+00, 0.0000e+00,
        5.4386e-02, 3.0004e-02, 0.0000e+00, 0.0000e+00, 4.8773e-02, 1.8253e-03,
        0.0000e+00, 0.0000e+00, 4.9212e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.4390e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0120e-02, 1.6563e-03,
        0.0000e+00, 0.0000e+00, 1.2799e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.4118e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:46:37,109 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3638423243682462
2024-05-07 21:46:37,109 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.244900.24490
2024-05-07 21:46:37,157 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #256: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0),(ado, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/3', 'revenue': 0.3695652173913043, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.3, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-07 21:46:37,157 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:37,157 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3642947626679994
2024-05-07 21:46:38,953 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #256: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.2}}
2024-05-07 21:46:38,953 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:38,953 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3642947626679994
2024-05-07 21:46:39,755 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #256: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 4, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.48, '(min, 1)': 0.17}}
2024-05-07 21:46:39,755 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:39,763 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3642947626679994
2024-05-07 21:46:40,197 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #256: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.525, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.26, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:46:40,197 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:40,197 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3642947626679994
2024-05-07 21:46:40,813 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #256: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 4, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.30434782608695654, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.03, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.3, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:46:40,813 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:40,813 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3642947626679994
2024-05-07 21:46:40,813 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #256: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 4, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '4/4', 'revenue': 0.2916666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.27, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-05-07 21:46:40,813 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:40,821 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3642947626679994
2024-05-07 21:46:42,452 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #256: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 3, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 3, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(min, 0)': 0.53, '(min, 1)': 0.13}}
2024-05-07 21:46:42,452 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:42,452 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3642947626679994
2024-05-07 21:46:42,524 - MainProcess - INFO - text_logger.py - 51 - Train epoch #256
2024-05-07 21:46:42,524 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.3433e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4601e-01, 0.0000e+00,
        1.9576e-01, 1.1287e-02, 2.5347e-01, 0.0000e+00, 5.7232e-02, 7.6676e-03,
        0.0000e+00, 0.0000e+00, 4.6267e-02, 3.9737e-03, 0.0000e+00, 0.0000e+00,
        4.1369e-02, 1.4888e-03, 0.0000e+00, 0.0000e+00, 3.8189e-02, 1.5100e-04,
        0.0000e+00, 0.0000e+00, 3.4745e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.1305e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1498e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.6201e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.7405e-04, 0.0000e+00, 0.0000e+00])  tensor([2.2329, 0.0000, 0.0000, 0.0000, 0.1758, 0.0000, 0.1619, 0.0350, 0.1815,
        0.0000, 0.0660, 0.0224, 0.0000, 0.0000, 0.0585, 0.0189, 0.0000, 0.0000,
        0.0554, 0.0094, 0.0000, 0.0000, 0.0530, 0.0024, 0.0000, 0.0000, 0.0490,
        0.0000, 0.0000, 0.0000, 0.0466, 0.0000, 0.0000, 0.0000, 0.0330, 0.0000,
        0.0000, 0.0000, 0.0165, 0.0000, 0.0000, 0.0000, 0.0041, 0.0000, 0.0000]) (500)
2024-05-07 21:46:42,548 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3629000901501256
2024-05-07 21:46:42,548 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:46:42,583 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #257: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 3, 0, 0),(rev, 3)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4358974358974359, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.27, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:46:42,583 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:42,583 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3638423243682462
2024-05-07 21:46:44,129 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #257: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.49, '(min, 1)': 0.08}}
2024-05-07 21:46:44,129 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:44,129 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3638423243682462
2024-05-07 21:46:44,144 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #257: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.15384615384615385, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.26, '(rev, 1)': 0.04, '(rev, 6)': 0.01}}
2024-05-07 21:46:44,144 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:46:44,144 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3638423243682462
2024-05-07 21:47:30,358 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #257: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0625, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.21, '(rev, 1)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:47:30,358 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:47:30,359 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3638423243682462
2024-05-07 21:59:20,599 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #257: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.43, '(min, 1)': 0.14}}
2024-05-07 21:59:20,599 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:20,600 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3638423243682462
2024-05-07 21:59:20,921 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #257: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 1, 7, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 6, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6756756756756757, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.45, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-05-07 21:59:20,921 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:20,921 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3638423243682462
2024-05-07 21:59:23,842 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #257: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(rev, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5882352941176471, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(ado, 3)': 0.04, '(ado, 8)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.36, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:59:23,843 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:23,844 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3638423243682462
2024-05-07 21:59:24,108 - MainProcess - INFO - text_logger.py - 51 - Train epoch #257
2024-05-07 21:59:24,111 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([9.7664e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5466e-01, 0.0000e+00,
        1.8974e-01, 1.1428e-02, 2.6762e-01, 0.0000e+00, 5.3722e-02, 7.4617e-03,
        0.0000e+00, 0.0000e+00, 4.3037e-02, 9.0054e-03, 0.0000e+00, 0.0000e+00,
        3.9400e-02, 5.6934e-03, 0.0000e+00, 0.0000e+00, 3.4487e-02, 7.1429e-05,
        0.0000e+00, 0.0000e+00, 3.2059e-02, 1.4835e-04, 0.0000e+00, 0.0000e+00,
        2.7764e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7173e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.0448e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.8443e-04, 0.0000e+00, 0.0000e+00])  tensor([3.0795e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7092e-01, 0.0000e+00,
        1.5967e-01, 3.3725e-02, 1.8125e-01, 0.0000e+00, 6.3634e-02, 2.3536e-02,
        0.0000e+00, 0.0000e+00, 5.6068e-02, 3.6497e-02, 0.0000e+00, 0.0000e+00,
        5.4890e-02, 2.8783e-02, 0.0000e+00, 0.0000e+00, 4.9565e-02, 1.5972e-03,
        0.0000e+00, 0.0000e+00, 4.7563e-02, 2.3449e-03, 0.0000e+00, 0.0000e+00,
        4.4467e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0133e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.4080e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9944e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:59:24,138 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.361957855932005
2024-05-07 21:59:24,142 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-07 21:59:24,189 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #258: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 4, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.36585365853658536, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.03, '(min, 0)': 0.23, '(min, 1)': 0.44, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:59:24,190 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:24,190 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3629000901501256
2024-05-07 21:59:24,196 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #258: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.28, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-07 21:59:24,196 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:24,197 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3629000901501256
2024-05-07 21:59:24,203 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #258: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.40476190476190477, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.38, '(min, 1)': 0.23, '(rev, 1)': 0.13, '(rev, 2)': 0.03, '(rev, 3)': 0.03}}
2024-05-07 21:59:24,204 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:24,206 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3629000901501256
2024-05-07 21:59:24,757 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #258: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5319148936170213, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.03, '(ado, 7)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.3, '(rev, 1)': 0.11, '(rev, 2)': 0.01, '(rev, 4)': 0.02}}
2024-05-07 21:59:24,757 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:24,759 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3629000901501256
2024-05-07 21:59:26,194 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #258: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 3, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.24390243902439024, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.34, '(rev, 1)': 0.14, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:59:26,195 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:26,195 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3629000901501256
2024-05-07 21:59:28,034 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #258: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.38636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.31, '(min, 1)': 0.34, '(rev, 1)': 0.13, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-05-07 21:59:28,035 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:28,036 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3629000901501256
2024-05-07 21:59:28,456 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #258: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.14814814814814814, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 5)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.19, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:59:28,456 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:28,457 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3629000901501256
2024-05-07 21:59:28,541 - MainProcess - INFO - text_logger.py - 51 - Train epoch #258
2024-05-07 21:59:28,544 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.6790e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5953e-01, 0.0000e+00,
        2.0528e-01, 1.8278e-02, 3.6597e-01, 0.0000e+00, 1.3276e-02, 1.1185e-02,
        0.0000e+00, 0.0000e+00, 5.3490e-03, 7.3494e-03, 0.0000e+00, 0.0000e+00,
        3.2383e-03, 3.7373e-03, 0.0000e+00, 0.0000e+00, 2.4482e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.9135e-03, 6.4516e-05, 0.0000e+00, 0.0000e+00,
        1.2682e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.1807e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.9915e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5242e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1062e-01, 0.0000e+00,
        1.7646e-01, 4.0250e-02, 1.1781e-01, 0.0000e+00, 3.4963e-02, 2.5037e-02,
        0.0000e+00, 0.0000e+00, 1.9665e-02, 2.5250e-02, 0.0000e+00, 0.0000e+00,
        1.6375e-02, 1.8962e-02, 0.0000e+00, 0.0000e+00, 1.3677e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2925e-02, 1.4426e-03, 0.0000e+00, 0.0000e+00,
        1.0596e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.5739e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.3349e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:59:28,570 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.36151793652869924
2024-05-07 21:59:28,573 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.251160.10301
2024-05-07 21:59:28,604 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #259: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24390243902439024, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.1, '(min, 1)': 0.49, '(rev, 1)': 0.13, '(rev, 2)': 0.02}}
2024-05-07 21:59:28,604 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:28,605 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.361957855932005
2024-05-07 21:59:28,636 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #259: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.02, '(min, 0)': 0.36, '(min, 1)': 0.22, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:59:28,636 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:28,637 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.361957855932005
2024-05-07 21:59:29,474 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #259: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 1, 3, 2, 0, 1),(min, 1)->(exi, not, exi, not, exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 1, 4, 2, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.125, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 10)': 0.01, '(ado, 2)': 0.02, '(min, 0)': 0.12, '(min, 1)': 0.46, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:59:29,474 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:29,475 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.361957855932005
2024-05-07 21:59:30,552 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #259: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 1, 0, 1)', 'reward_ratio': '0/0', 'revenue': 1.0, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 5)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.39, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 7)': 0.01}}
2024-05-07 21:59:30,552 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:30,553 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.361957855932005
2024-05-07 21:59:30,564 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #259: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.12, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 10)': 0.01, '(ado, 2)': 0.04, '(ado, 4)': 0.02, '(min, 0)': 0.29, '(min, 1)': 0.33, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:59:30,564 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:30,565 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.361957855932005
2024-05-07 21:59:32,590 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #259: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.21428571428571427, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.04, '(ado, 4)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.23, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:59:32,590 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:32,592 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.361957855932005
2024-05-07 21:59:37,317 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #259: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 6, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 1.5135135135135136, 'length': 100, 'actions': {'(ado, 1)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.47, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.06, '(rev, 4)': 0.04, '(rev, 8)': 0.01}}
2024-05-07 21:59:37,317 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:37,317 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.361957855932005
2024-05-07 21:59:37,391 - MainProcess - INFO - text_logger.py - 51 - Train epoch #259
2024-05-07 21:59:37,393 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.1423e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6106e-01, 0.0000e+00,
        1.4391e-01, 1.8655e-02, 3.6726e-01, 0.0000e+00, 1.5991e-02, 7.7142e-03,
        0.0000e+00, 0.0000e+00, 1.4286e-02, 3.2603e-03, 0.0000e+00, 0.0000e+00,
        1.5094e-02, 5.3581e-04, 0.0000e+00, 0.0000e+00, 1.3304e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2959e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2864e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.5447e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.0103e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.5311e-04, 0.0000e+00, 0.0000e+00])  tensor([1.6664, 0.0000, 0.0000, 0.0000, 0.1393, 0.0000, 0.1418, 0.0419, 0.1468,
        0.0000, 0.0375, 0.0222, 0.0000, 0.0000, 0.0384, 0.0159, 0.0000, 0.0000,
        0.0419, 0.0061, 0.0000, 0.0000, 0.0374, 0.0000, 0.0000, 0.0000, 0.0367,
        0.0000, 0.0000, 0.0000, 0.0367, 0.0000, 0.0000, 0.0000, 0.0242, 0.0000,
        0.0000, 0.0000, 0.0116, 0.0000, 0.0000, 0.0000, 0.0033, 0.0000, 0.0000]) (500)
2024-05-07 21:59:37,406 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.36308921582409215
2024-05-07 21:59:37,412 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 1.256760.25676
2024-05-07 21:59:37,438 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #260: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.30434782608695654, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.03, '(min, 0)': 0.44, '(min, 1)': 0.13, '(rev, 1)': 0.08, '(rev, 2)': 0.06}}
2024-05-07 21:59:37,439 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:37,440 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36151793652869924
2024-05-07 21:59:37,455 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #260: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.03, '(min, 0)': 0.42, '(min, 1)': 0.14, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:59:37,455 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:37,455 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #260: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.6, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.11, '(rev, 1)': 0.1, '(rev, 2)': 0.11, '(rev, 3)': 0.02}}
2024-05-07 21:59:37,455 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
ansition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6739130434782609, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.1, '(rev, 1)': 0.07, '(rev, 2)': 0.09, '(rev, 3)': 0.01}}
2024-05-07 21:59:37,455 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #260: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2916666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.43, '(rev, 1)': 0.09, '(rev, 2)': 0.04}}
2024-05-07 21:59:37,455 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:37,456 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #260: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4375, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.03, '(ado, 5)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.2, '(rev, 1)': 0.06, '(rev, 2)': 0.05}}
2024-05-07 21:59:37,456 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36151793652869924
2024-05-07 21:59:37,456 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36151793652869924
2024-05-07 21:59:37,457 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36151793652869924
2024-05-07 21:59:37,457 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36151793652869924
2024-05-07 21:59:37,460 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:37,468 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36151793652869924
2024-05-07 21:59:39,318 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #260: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2926829268292683, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(min, 0)': 0.42, '(min, 1)': 0.2, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:59:39,318 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:39,319 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36151793652869924
2024-05-07 21:59:39,389 - MainProcess - INFO - text_logger.py - 51 - Train epoch #260
2024-05-07 21:59:39,391 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0251e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2133e-01, 0.0000e+00,
        1.1617e-01, 1.9185e-02, 4.3462e-01, 0.0000e+00, 1.6544e-03, 5.1622e-03,
        0.0000e+00, 0.0000e+00, 3.8213e-04, 1.0134e-03, 0.0000e+00, 0.0000e+00,
        2.0121e-04, 2.4368e-04, 0.0000e+00, 0.0000e+00, 5.0000e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.6485e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5010e-02, 0.0000e+00,
        1.2948e-01, 4.2259e-02, 7.5266e-02, 0.0000e+00, 8.3666e-03, 1.5532e-02,
        0.0000e+00, 0.0000e+00, 3.8297e-03, 6.4826e-03, 0.0000e+00, 0.0000e+00,
        2.3334e-03, 2.7479e-03, 0.0000e+00, 0.0000e+00, 1.1180e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:59:39,403 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.36303966453280084
2024-05-07 21:59:39,405 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.446340.15366
2024-05-07 21:59:39,435 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #261: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(min, 0)': 0.41, '(min, 1)': 0.18, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-05-07 21:59:39,436 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:39,436 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #261: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.16, '(rev, 1)': 0.06, '(rev, 2)': 0.07, '(rev, 3)': 0.03}}
2024-05-07 21:59:39,436 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:39,436 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36308921582409215
2024-05-07 21:59:39,436 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36308921582409215
2024-05-07 21:59:39,451 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #261: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.06, '(min, 0)': 0.41, '(min, 1)': 0.21, '(rev, 1)': 0.09, '(rev, 2)': 0.06}}
2024-05-07 21:59:39,451 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #261: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.18181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.3, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:59:39,452 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:39,452 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:39,452 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36308921582409215
2024-05-07 21:59:39,452 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36308921582409215
2024-05-07 21:59:39,466 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #261: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(ado, 3)': 0.03, '(min, 0)': 0.41, '(min, 1)': 0.22, '(rev, 1)': 0.05, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-05-07 21:59:39,466 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #261: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.30612244897959184, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.07, '(rev, 1)': 0.06, '(rev, 2)': 0.06}}
2024-05-07 21:59:39,466 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:39,466 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:39,467 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36308921582409215
2024-05-07 21:59:39,468 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36308921582409215
2024-05-07 21:59:40,830 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #261: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0392156862745098, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(ado, 7)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.24, '(rev, 1)': 0.02}}
2024-05-07 21:59:40,830 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:40,831 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36308921582409215
2024-05-07 21:59:40,900 - MainProcess - INFO - text_logger.py - 51 - Train epoch #261
2024-05-07 21:59:40,903 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.1017e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9619e-01, 0.0000e+00,
        1.3650e-01, 2.3564e-02, 4.0366e-01, 0.0000e+00, 9.4683e-03, 7.1734e-03,
        0.0000e+00, 0.0000e+00, 4.9014e-03, 2.0685e-03, 0.0000e+00, 0.0000e+00,
        4.3197e-03, 2.2768e-04, 0.0000e+00, 0.0000e+00, 3.3152e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2571e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8784e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9365e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.3223e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.1324, 0.0000, 0.0000, 0.0000, 0.1018, 0.0000, 0.1454, 0.0485, 0.1071,
        0.0000, 0.0333, 0.0196, 0.0000, 0.0000, 0.0225, 0.0091, 0.0000, 0.0000,
        0.0235, 0.0026, 0.0000, 0.0000, 0.0190, 0.0000, 0.0000, 0.0000, 0.0187,
        0.0000, 0.0000, 0.0000, 0.0167, 0.0000, 0.0000, 0.0000, 0.0115, 0.0000,
        0.0000, 0.0000, 0.0042, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-05-07 21:59:40,914 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.36261490687051995
2024-05-07 21:59:40,917 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.258740.21952
2024-05-07 21:59:41,091 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #262: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5681818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.2, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 4)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:59:41,091 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:41,092 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36303966453280084
2024-05-07 21:59:41,098 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #262: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.26, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-05-07 21:59:41,098 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:41,099 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36303966453280084
2024-05-07 21:59:41,124 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #262: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3829787234042553, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.16, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-07 21:59:41,125 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:41,125 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36303966453280084
2024-05-07 21:59:41,171 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #262: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.45, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:59:41,171 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:41,171 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36303966453280084
2024-05-07 21:59:41,317 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #262: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5434782608695652, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.52, '(min, 1)': 0.07, '(rev, 1)': 0.07, '(rev, 2)': 0.07}}
2024-05-07 21:59:41,317 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:41,318 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36303966453280084
2024-05-07 21:59:41,843 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #262: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.15555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 6)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.15, '(rev, 1)': 0.02, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-07 21:59:41,843 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:41,844 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36303966453280084
2024-05-07 21:59:42,539 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #262: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.38636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.33, '(min, 1)': 0.32, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 8)': 0.01}}
2024-05-07 21:59:42,539 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:42,540 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36303966453280084
2024-05-07 21:59:42,675 - MainProcess - INFO - text_logger.py - 51 - Train epoch #262
2024-05-07 21:59:42,677 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.6202e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0156e-01, 0.0000e+00,
        1.4531e-01, 2.4729e-02, 4.0976e-01, 0.0000e+00, 3.4489e-03, 8.9436e-03,
        0.0000e+00, 0.0000e+00, 4.8218e-04, 3.6557e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.9571e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.5692e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.4025, 0.0000, 0.0000, 0.0000, 0.0897, 0.0000, 0.1665, 0.0514, 0.0928,
        0.0000, 0.0119, 0.0239, 0.0000, 0.0000, 0.0040, 0.0139, 0.0000, 0.0000,
        0.0000, 0.0079, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0025, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-05-07 21:59:42,692 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3622145918443186
2024-05-07 21:59:42,693 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.270960.11540
2024-05-07 21:59:42,706 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #263: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.2978723404255319, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.55, '(min, 1)': 0.03, '(rev, 1)': 0.08, '(rev, 2)': 0.05}}
2024-05-07 21:59:42,707 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:42,707 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36261490687051995
2024-05-07 21:59:42,751 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #263: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(min, 0)': 0.36, '(min, 1)': 0.23, '(rev, 1)': 0.11, '(rev, 2)': 0.06}}
2024-05-07 21:59:42,751 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:42,752 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36261490687051995
2024-05-07 21:59:42,839 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #263: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5434782608695652, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.03, '(min, 0)': 0.35, '(min, 1)': 0.22, '(rev, 1)': 0.1, '(rev, 2)': 0.05}}
2024-05-07 21:59:42,839 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:42,840 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36261490687051995
2024-05-07 21:59:43,394 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #263: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 9, 3, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 1, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.5813953488372093, 'length': 100, 'actions': {'(ado, 1)': 0.08, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(min, 0)': 0.37, '(min, 1)': 0.36, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 8)': 0.01}}
2024-05-07 21:59:43,394 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:43,396 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36261490687051995
2024-05-07 21:59:43,460 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #263: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.8636363636363636, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.49, '(rev, 1)': 0.08, '(rev, 2)': 0.09, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:59:43,460 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:43,461 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36261490687051995
2024-05-07 21:59:43,580 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #263: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.36, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:59:43,580 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:43,581 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36261490687051995
2024-05-07 21:59:44,140 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #263: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.723404255319149, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.16, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:59:44,141 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:44,141 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.36261490687051995
2024-05-07 21:59:44,201 - MainProcess - INFO - text_logger.py - 51 - Train epoch #263
2024-05-07 21:59:44,202 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.1809e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9555e-01, 0.0000e+00,
        1.4998e-01, 2.1982e-02, 4.0746e-01, 0.0000e+00, 5.3782e-03, 9.6736e-03,
        0.0000e+00, 0.0000e+00, 1.8136e-03, 3.9900e-03, 0.0000e+00, 0.0000e+00,
        1.1578e-03, 1.5661e-03, 0.0000e+00, 0.0000e+00, 5.9667e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.8919e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8608e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.0000e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.9877e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.7923e-02, 0.0000e+00,
        1.4991e-01, 4.6365e-02, 9.0812e-02, 0.0000e+00, 2.3871e-02, 2.5708e-02,
        0.0000e+00, 0.0000e+00, 1.1733e-02, 1.7064e-02, 0.0000e+00, 0.0000e+00,
        9.4152e-03, 7.0902e-03, 0.0000e+00, 0.0000e+00, 5.8585e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.6016e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.8662e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7889e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:59:44,218 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3624179841037394
2024-05-07 21:59:44,220 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.572810.15059
2024-05-07 21:59:44,257 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #264: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.21739130434782608, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.03, '(min, 0)': 0.39, '(min, 1)': 0.18, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-07 21:59:44,257 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:44,257 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3622145918443186
2024-05-07 21:59:44,405 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #264: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5434782608695652, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.41, '(min, 1)': 0.16, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-07 21:59:44,405 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:44,406 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3622145918443186
2024-05-07 21:59:44,451 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #264: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(min, 0)': 0.35, '(min, 1)': 0.21, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-07 21:59:44,451 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:44,452 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3622145918443186
2024-05-07 21:59:45,132 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #264: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.35, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 6)': 0.02, '(rev, 7)': 0.01}}
2024-05-07 21:59:45,132 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:45,132 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3622145918443186
2024-05-07 21:59:45,485 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #264: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.48936170212765956, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.17, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-07 21:59:45,485 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:45,486 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3622145918443186
2024-05-07 21:59:45,683 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #264: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6818181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.26, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 7)': 0.01}}
2024-05-07 21:59:45,683 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:45,683 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3622145918443186
2024-05-07 21:59:46,116 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #264: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.36, '(rev, 1)': 0.06, '(rev, 2)': 0.05}}
2024-05-07 21:59:46,116 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:46,116 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3622145918443186
2024-05-07 21:59:46,187 - MainProcess - INFO - text_logger.py - 51 - Train epoch #264
2024-05-07 21:59:46,190 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([9.4695e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9310e-01, 0.0000e+00,
        1.4875e-01, 2.2048e-02, 4.0755e-01, 0.0000e+00, 2.3293e-03, 1.2359e-02,
        0.0000e+00, 0.0000e+00, 2.3913e-04, 8.7148e-03, 0.0000e+00, 0.0000e+00,
        7.0370e-05, 3.9385e-03, 0.0000e+00, 0.0000e+00, 7.0370e-05, 1.9757e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3707e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.8670e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0370e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7037e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.6517e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0396e-01, 0.0000e+00,
        1.8007e-01, 4.9755e-02, 9.9073e-02, 0.0000e+00, 8.9230e-03, 3.6834e-02,
        0.0000e+00, 0.0000e+00, 2.5630e-03, 2.9503e-02, 0.0000e+00, 0.0000e+00,
        1.1131e-03, 1.3460e-02, 0.0000e+00, 0.0000e+00, 1.1131e-03, 2.1052e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2968e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.8431e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1131e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2817e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:59:46,204 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3622042420225291
2024-05-07 21:59:46,206 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.364250.12512
2024-05-07 21:59:46,235 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #265: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.27450980392156865, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.47, '(rev, 1)': 0.03, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-05-07 21:59:46,235 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:46,235 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3624179841037394
2024-05-07 21:59:46,250 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #265: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.36, '(min, 1)': 0.24, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-05-07 21:59:46,251 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:46,251 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3624179841037394
2024-05-07 21:59:46,263 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #265: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5813953488372093, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.25, '(min, 1)': 0.36, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-07 21:59:46,263 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:46,264 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3624179841037394
2024-05-07 21:59:46,619 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #265: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.45454545454545453, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.12, '(min, 1)': 0.51, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:59:46,619 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:46,620 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3624179841037394
2024-05-07 21:59:47,010 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #265: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(min, 0)': 0.31, '(min, 1)': 0.3, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-07 21:59:47,010 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:47,010 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3624179841037394
2024-05-07 21:59:47,118 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #265: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17391304347826086, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 3)': 0.03, '(min, 0)': 0.06, '(min, 1)': 0.53, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-07 21:59:47,118 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:47,118 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3624179841037394
2024-05-07 21:59:47,850 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #265: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(min, 0)': 0.39, '(min, 1)': 0.21, '(rev, 1)': 0.09, '(rev, 2)': 0.06}}
2024-05-07 21:59:47,851 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:47,852 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3624179841037394
2024-05-07 21:59:47,927 - MainProcess - INFO - text_logger.py - 51 - Train epoch #265
2024-05-07 21:59:47,929 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.4754e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8681e-01, 0.0000e+00,
        1.6528e-01, 1.8177e-02, 3.9483e-01, 0.0000e+00, 8.9181e-03, 7.1964e-03,
        0.0000e+00, 0.0000e+00, 4.3036e-03, 3.3000e-03, 0.0000e+00, 0.0000e+00,
        3.0530e-03, 1.2333e-03, 0.0000e+00, 0.0000e+00, 2.0317e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.0028e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.5102e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.6135e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.6518e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.7736e-05, 0.0000e+00, 0.0000e+00])  tensor([1.4084e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0071e-01, 0.0000e+00,
        1.5504e-01, 4.3306e-02, 1.0321e-01, 0.0000e+00, 2.9324e-02, 2.1096e-02,
        0.0000e+00, 0.0000e+00, 1.9056e-02, 1.3094e-02, 0.0000e+00, 0.0000e+00,
        1.8066e-02, 6.3501e-03, 0.0000e+00, 0.0000e+00, 1.3302e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.3569e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1935e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.8529e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.6449e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.4380e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-07 21:59:47,942 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.3623508966932974
2024-05-07 21:59:47,944 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.544440.07778
2024-05-07 21:59:48,029 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #266: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 4)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.35, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 5)': 0.01, '(rev, 8)': 0.01, '(rev, 9)': 0.01}}
2024-05-07 21:59:48,030 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:48,030 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3622042420225291
2024-05-07 21:59:48,264 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #266: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.32, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 5)': 0.01}}
2024-05-07 21:59:48,265 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:48,265 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3622042420225291
2024-05-07 21:59:48,346 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #266: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.36, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.02, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-07 21:59:48,347 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:48,347 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3622042420225291
2024-05-07 21:59:48,538 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #266: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5897435897435898, 'length': 100, 'actions': {'(ado, 1)': 0.08, '(ado, 4)': 0.02, '(min, 0)': 0.11, '(min, 1)': 0.54, '(rev, 1)': 0.13, '(rev, 2)': 0.07, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-05-07 21:59:48,538 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:48,538 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3622042420225291
2024-05-07 21:59:48,619 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #266: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5833333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.29, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-07 21:59:48,619 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:48,620 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3622042420225291
2024-05-07 21:59:48,755 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #266: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2978723404255319, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.29, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-07 21:59:48,755 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-07 21:59:48,756 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.3622042420225291
2024-05-07 21:59:49,328 - Train Agent 1 - INFO - util.py - 54 - process shutting down22024-05-07 21:59:49,328 - Train Agent 2 - INFO - util.py - 54 - process shutting down
2024-05-07 21:59:49,328 - Train Agent 5 - INFO - util.py - 54 - process shutting down
2024-05-07 21:59:49,328 - Train Agent 4 - INFO - util.py - 54 - process shutting down
2024-05-07 21:59:49,443 - MainProcess - INFO - util.py - 54 - sending shutdown message to manager
2024-05-07 21:59:49,670 - MainProcess - INFO - util.py - 54 - process shutting down
