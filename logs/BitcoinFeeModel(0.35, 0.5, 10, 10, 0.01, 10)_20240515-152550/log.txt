2024-05-15 15:25:57,856 - MainProcess - INFO - text_logger.py - 51 - Starting to train trainer:
instance(SynchronizedMultiProcessOrchestrator):
  Type: typing.Literal['single_process', 'multi_process', 'synced_multi_process'],
  agent: {'type': 'MCTSAgent', 'exploration_mechanism': {'type': 'EpsilonGreedyExploration', 'epsilon_schedule': {'type': 'ParameterSchedule', 'starting_parameter': 0.05, 'step_change': 0, 'end_parameter': 0}}, 'depth': 5, 'simulations': 25, 'ground_initial_state': False, 'value_clip': 0, 'nn_factor': 0.0001},
  algorithm: instance(MCTSAlgorithm):
    agent: {'type': 'MCTSAgent', 'exploration_mechanism': {'type': 'EpsilonGreedyExploration', 'epsilon_schedule': {'type': 'ParameterSchedule', 'starting_parameter': 0.05, 'step_change': 0, 'end_parameter': 0}}, 'depth': 5, 'simulations': 25, 'ground_initial_state': False, 'value_clip': 0, 'nn_factor': 0.0001},
    approximator: MCTSApproximator(
  (model): Sequential(
    (0): Linear(in_features=46, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=88, bias=True)
  )
),
    blockchain_model: BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01, 10),
    creation_args: {
      'batch_size': 100,
      'bind_all': False,
      'build_info': None,
      'bva_smart_init': 0.47111710906028753,
      'depth': 5,
      'dropout': 0,
      'epoch_shuffles': 2,
      'epsilon_step': 0,
      'evaluate_episode_length': 100,
      'ground_initial_state': False,
      'learning_rate': 0.0002,
      'length_factor': 10,
      'lower_priority': True,
      'lr_decay_epoch': 1000,
      'mc_simulations': 25,
      'nn_factor': 0.0001,
      'normalize_target_values': True,
      'num_of_episodes_for_average': 1000,
      'num_of_epochs': 5001,
      'number_of_evaluation_agents': 2,
      'number_of_training_agents': 5,
      'output_profile': False,
      'output_root': None,
      'prune_tree_rate': 250,
      'starting_epsilon': 0.05,
      'train_episode_length': 100,
      'use_base_approximation': True,
      'use_cached_values': False,
    },
    device: device(type='cpu'),
    loss_fn: MCTSLossFunction(
  (approximator): MCTSApproximator(
    (model): Sequential(
      (0): Linear(in_features=46, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=88, bias=True)
    )
  )
),
    lr_scheduler: instance(StepLR):
      base_lrs: [0.0002],
      gamma: 0.1,
      last_epoch: 0,
      optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0002
    lr: 0.0002
    weight_decay: 0
),
      step_size: 1000,
      verbose: False,
    optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0002
    lr: 0.0002
    weight_decay: 0
),
    simulator: instance(MDPBlockchainSimulator):
      action_space: instance(MultiDimensionalDiscreteSpace):
        dimension: 2,
        intervals: [
          instance(Interval):
            boundaries: (0, 3),
            enum: class(Action):
              Adopt: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Adopt',
                numerator: 1,
                real: 1,
                value: 1,
              Illegal: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Illegal',
                numerator: 0,
                real: 0,
                value: 0,
              Mine: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Mine',
                numerator: 3,
                real: 3,
                value: 3,
              Reveal: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Reveal',
                numerator: 2,
                real: 2,
                value: 2,
            size: 4
          instance(Interval):
            boundaries: (0, 10),
            enum: None,
            size: 11
        ],
        size: 44,
      check_valid_states: False,
      device: device(type='cpu'),
      expected_horizon: 10000,
      final_state: (
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Fork):
          denominator: 1,
          imag: 0,
          name: 'Irrelevant',
          numerator: 0,
          real: 0,
          value: 0
        -1,
        -1,
        -1,
        -1,
        -1,
      ),
      include_transition_info: True,
      initial_state: (
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Fork):
          denominator: 1,
          imag: 0,
          name: 'Irrelevant',
          numerator: 0,
          real: 0,
          value: 0
        0,
        0,
        0,
        0,
        0,
      ),
      num_of_actions: 44,
      num_of_states: 531232341494857729,
      state_space: instance(DefaultValueSpace):
        default_value: (
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Fork):
            denominator: 1,
            imag: 0,
            name: 'Irrelevant',
            numerator: 0,
            real: 0,
            value: 0
          -1,
          -1,
          -1,
          -1,
          -1,
        ),
        dimension: 46,
        size: 531232341494857729,
        underlying_space: instance(MultiDimensionalDiscreteSpace):
          dimension: 46,
          intervals: [
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 2),
              enum: class(Fork):
                Active: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Active',
                  numerator: 2,
                  real: 2,
                  value: 2,
                Irrelevant: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Irrelevant',
                  numerator: 0,
                  real: 0,
                  value: 0,
                Relevant: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Relevant',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 3
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
          ],
          size: 531232341494857728,
      state_space_dim: 46,
  approximator: MCTSApproximator(
  (model): Sequential(
    (0): Linear(in_features=46, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=88, bias=True)
  )
),
  batch_size: 100,
  bind_all: False,
  blockchain_model: BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01, 10),
  build_info: None,
  callback: instance(CompositionCallback):
    callbacks: (
      instance(CompositionCallback):
        callbacks: (
          instance(TextLoggingCallback):
            logger: instance(TextLogger):
              file_name: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                          10)_20240515-152550\\log.txt',
              logger: <Logger multiprocessing (INFO)>,
              output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                           10)_20240515-152550',
            logger_name: 'text',
            orchestrator: <Recursion on instance(SynchronizedMultiProcessOrchestrator) with id=2586489128032>,
            output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                         10)_20240515-152550'
          instance(TensorboardLoggingCallback):
            bind_all: False,
            logger: None,
            logger_name: 'tensorboard',
            max_num_of_agents: 5,
            max_number_of_actions: 3,
            num_of_q_values_in_approximator: 0,
            orchestrator: None,
            tensorboard_popen: None
          instance(BVACallback):
            agent: None,
            episode_values: deque([], maxlen=1000),
            episode_values_synchronizer: None,
            epoch_history: [],
            num_of_episodes_for_average: 1000,
            own_sync_manager: False,
            smart_init: 0.47111710906028753,
            sort_episodes: True,
            stop_goal: None,
            sync_dict: None,
            sync_manager: None
          instance(BVATextLoggingCallback):
            agent: None,
            bva_callback: instance(BVACallback):
              agent: None,
              episode_values: deque([], maxlen=1000),
              episode_values_synchronizer: None,
              epoch_history: [],
              num_of_episodes_for_average: 1000,
              own_sync_manager: False,
              smart_init: 0.47111710906028753,
              sort_episodes: True,
              stop_goal: None,
              sync_dict: None,
              sync_manager: None,
            logger: None,
            logger_name: 'text'
          instance(BVATensorboardLoggingCallback):
            bva_callback: instance(BVACallback):
              agent: None,
              episode_values: deque([], maxlen=1000),
              episode_values_synchronizer: None,
              epoch_history: [],
              num_of_episodes_for_average: 1000,
              own_sync_manager: False,
              smart_init: 0.47111710906028753,
              sort_episodes: True,
              stop_goal: None,
              sync_dict: None,
              sync_manager: None,
            logger: None,
            logger_name: 'tensorboard'
          instance(CheckpointCallback):
            bva_before: 0,
            bva_callback: instance(BVACallback):
              agent: None,
              episode_values: deque([], maxlen=1000),
              episode_values_synchronizer: None,
              epoch_history: [],
              num_of_episodes_for_average: 1000,
              own_sync_manager: False,
              smart_init: 0.47111710906028753,
              sort_episodes: True,
              stop_goal: None,
              sync_dict: None,
              sync_manager: None,
            latest_approximator: None,
            load_epoch: None,
            load_experiment: None,
            load_seed: True,
            nn_state_before: None,
            orchestrator: None,
            output_dir: None,
            own_sync_manager: False,
            random_seed_dict: None,
            save_rate: 100,
            sync_dict: None,
            sync_manager: None
          instance(PolicyRevenueCallback):
            agent: None,
            confidence: 0.99,
            dump_path: '',
            dump_trajectories: False,
            episode_values: None,
            episode_values_synchronizer: None,
            length_factor: 10,
            long_simulation_rate: 100,
            num_of_agents: 0,
            num_of_evaluation_agents: 0,
            orchestrator: None,
            own_sync_manager: False,
            policy_revenue: 0,
            policy_revenue_confidence_radius: 0,
            policy_test_revenue: 0,
            policy_test_revenue_confidence_radius: 0,
            repeats: 1,
            sync_dict: None,
            sync_manager: None,
            test_episode_values: None,
            test_episode_values_synchronizer: None
          instance(PolicyRevenueTextLoggingCallback):
            logger: None,
            logger_name: 'text',
            policy_revenue_callback: instance(PolicyRevenueCallback):
              agent: None,
              confidence: 0.99,
              dump_path: '',
              dump_trajectories: False,
              episode_values: None,
              episode_values_synchronizer: None,
              length_factor: 10,
              long_simulation_rate: 100,
              num_of_agents: 0,
              num_of_evaluation_agents: 0,
              orchestrator: None,
              own_sync_manager: False,
              policy_revenue: 0,
              policy_revenue_confidence_radius: 0,
              policy_test_revenue: 0,
              policy_test_revenue_confidence_radius: 0,
              repeats: 1,
              sync_dict: None,
              sync_manager: None,
              test_episode_values: None,
              test_episode_values_synchronizer: None
          instance(PolicyRevenueTensorboardLoggingCallback):
            logger: None,
            logger_name: 'tensorboard',
            policy_revenue_callback: instance(PolicyRevenueCallback):
              agent: None,
              confidence: 0.99,
              dump_path: '',
              dump_trajectories: False,
              episode_values: None,
              episode_values_synchronizer: None,
              length_factor: 10,
              long_simulation_rate: 100,
              num_of_agents: 0,
              num_of_evaluation_agents: 0,
              orchestrator: None,
              own_sync_manager: False,
              policy_revenue: 0,
              policy_revenue_confidence_radius: 0,
              policy_test_revenue: 0,
              policy_test_revenue_confidence_radius: 0,
              repeats: 1,
              sync_dict: None,
              sync_manager: None,
              test_episode_values: None,
              test_episode_values_synchronizer: None
        )
      instance(MCTSTensorboardLoggingCallback):
        agent: None,
        logger: None,
        logger_name: 'tensorboard',
        max_num_of_agents: 5,
        orchestrator: None
    ),
  creation_args: {
    'bva_smart_init': 0.47111710906028753,
    'depth': 5,
    'device': device(type='cpu')
    'dropout': 0,
    'epsilon_step': 0,
    'ground_initial_state': False,
    'length_factor': 10,
    'lr_decay_epoch': 1000,
    'mc_simulations': 25,
    'nn_factor': 0.0001,
    'normalize_target_values': True,
    'num_of_episodes_for_average': 1000,
    'prune_tree_rate': 250,
    'simulator': instance(MDPBlockchainSimulator):
      action_space: instance(MultiDimensionalDiscreteSpace):
        dimension: 2,
        intervals: [
          instance(Interval):
            boundaries: (0, 3),
            enum: class(Action):
              Adopt: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Adopt',
                numerator: 1,
                real: 1,
                value: 1,
              Illegal: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Illegal',
                numerator: 0,
                real: 0,
                value: 0,
              Mine: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Mine',
                numerator: 3,
                real: 3,
                value: 3,
              Reveal: class(Action):
                denominator: 1,
                imag: 0,
                name: 'Reveal',
                numerator: 2,
                real: 2,
                value: 2,
            size: 4
          instance(Interval):
            boundaries: (0, 10),
            enum: None,
            size: 11
        ],
        size: 44,
      check_valid_states: False,
      device: device(type='cpu'),
      expected_horizon: 10000,
      final_state: (
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Fork):
          denominator: 1,
          imag: 0,
          name: 'Irrelevant',
          numerator: 0,
          real: 0,
          value: 0
        -1,
        -1,
        -1,
        -1,
        -1,
      ),
      include_transition_info: True,
      initial_state: (
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Block):
          denominator: 1,
          imag: 0,
          name: 'NoBlock',
          numerator: 0,
          real: 0,
          value: 0
        class(Transaction):
          denominator: 1,
          imag: 0,
          name: 'NoTransaction',
          numerator: 0,
          real: 0,
          value: 0
        class(Fork):
          denominator: 1,
          imag: 0,
          name: 'Irrelevant',
          numerator: 0,
          real: 0,
          value: 0
        0,
        0,
        0,
        0,
        0,
      ),
      num_of_actions: 44,
      num_of_states: 531232341494857729,
      state_space: instance(DefaultValueSpace):
        default_value: (
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Block):
            denominator: 1,
            imag: 0,
            name: 'NoBlock',
            numerator: 0,
            real: 0,
            value: 0
          class(Transaction):
            denominator: 1,
            imag: 0,
            name: 'NoTransaction',
            numerator: 0,
            real: 0,
            value: 0
          class(Fork):
            denominator: 1,
            imag: 0,
            name: 'Irrelevant',
            numerator: 0,
            real: 0,
            value: 0
          -1,
          -1,
          -1,
          -1,
          -1,
        ),
        dimension: 46,
        size: 531232341494857729,
        underlying_space: instance(MultiDimensionalDiscreteSpace):
          dimension: 46,
          intervals: [
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Block):
                Exists: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'Exists',
                  numerator: 1,
                  real: 1,
                  value: 1,
                NoBlock: class(Block):
                  denominator: 1,
                  imag: 0,
                  name: 'NoBlock',
                  numerator: 0,
                  real: 0,
                  value: 0,
              size: 2
            instance(Interval):
              boundaries: (0, 1),
              enum: class(Transaction):
                NoTransaction: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'NoTransaction',
                  numerator: 0,
                  real: 0,
                  value: 0,
                With: class(Transaction):
                  denominator: 1,
                  imag: 0,
                  name: 'With',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 2
            instance(Interval):
              boundaries: (0, 2),
              enum: class(Fork):
                Active: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Active',
                  numerator: 2,
                  real: 2,
                  value: 2,
                Irrelevant: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Irrelevant',
                  numerator: 0,
                  real: 0,
                  value: 0,
                Relevant: class(Fork):
                  denominator: 1,
                  imag: 0,
                  name: 'Relevant',
                  numerator: 1,
                  real: 1,
                  value: 1,
              size: 3
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
            instance(Interval):
              boundaries: (0, 10),
              enum: None,
              size: 11
          ],
          size: 531232341494857728,
      state_space_dim: 46
    'starting_epsilon': 0.05,
    'use_base_approximation': True,
    'use_cached_values': False,
  },
  episode_reset_rate: 10,
  episode_synchronizer: {'type': 'BufferSynchronizer', 'target_buffer': <reinforcement_learning.base.utility.dummy_buffer.DummyBuffer object at 0x0000025A36D81FD0>},
  epoch_length: 1000,
  epoch_size: 2000,
  evaluate_episode_length: 100,
  expected_horizon: 10000,
  experiment_name: 'BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                    10)_20240515-152550',
  learning_rate: 0.0002,
  loggers: {
    'tensorboard': instance(SynchronizedLogger):
      base_logger: instance(TensorboardLogger):
        flush_secs: 15,
        hparam_dict: {
        },
        hparam_domain_discrete: {
        },
        layout: {
        },
        metric_dict: {
        },
        output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                     10)_20240515-152550',
        started_logging: False,
        tensorboard_writer: instance(SummaryWriter):
          all_writers: {
            'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01, 10)_20240515-152550': instance(FileWriter):
              event_writer: instance(EventFileWriter)
          },
          default_bins: [-9.920775621859783e+19, -9.018886928963438e+19, -8.198988117239489e+19, -7.453625561126807e+19, -6.776023237388005e+19, -6.160021124898186e+19, -5.600019204452896e+19, -5.090926549502632e+19, -4.628115045002392e+19, -4.2073773136385384e+19, -3.824888466944125e+19, -3.477171333585568e+19, -3.1610648487141528e+19, -2.873695317012866e+19, -2.6124502881935143e+19, -2.3749548074486493e+19, -2.1590498249533174e+19, -1.962772568139379e+19, -1.7843386983085265e+19, -1.6221260893713875e+19, -1.4746600812467157e+19, -1.3406000738606506e+19, -1.2187273398733187e+19, -1.1079339453393805e+19, -1.0072126775812549e+19, -9.156478887102316e+18, -8.324071715547559e+18, -7.567337923225053e+18, -6.879398112022775e+18, -6.253998283657068e+18, -5.685452985142788e+18, -5.16859362285708e+18, -4.698721475324618e+18, -4.271564977567834e+18, -3.8832408886980306e+18, -3.530218989725482e+18, -3.2092899906595287e+18, -2.917536355145026e+18, -2.652305777404569e+18, -2.41118707036779e+18, -2.1919882457888998e+18, -1.992716587080818e+18, -1.8115605337098342e+18, -1.6468732124634854e+18, -1.4971574658758958e+18, -1.3610522417053596e+18, -1.237320219732145e+18, -1.1248365633928589e+18, -1.022578693993508e+18, -9.296169945395526e+17, -8.451063586723205e+17, -7.682785078839277e+17, -6.984350071672069e+17, -6.349409156065517e+17, -5.772190141877742e+17, -5.247445583525219e+17, -4.770405075932017e+17, -4.336731887210924e+17, -3.9424835338281126e+17, -3.584075939843738e+17, -3.2582508544033984e+17, -2.9620462312758163e+17, -2.6927693011598326e+17, -2.447972091963484e+17, -2.2254291745122582e+17, -2.02311743137478e+17, -1.8391976648861635e+17, -1.6719978771692394e+17, -1.5199980701538538e+17, -1.3818164274125942e+17, -1.2561967521932674e+17, -1.1419970474484248e+17, -1.0381791340440224e+17, -9.43799212767293e+16, -8.579992843339026e+16, -7.799993493944568e+16, -7.090903176313243e+16, -6.446275614830221e+16, -5.860250558936564e+16, -5.327500508124149e+16, -4.843182280112862e+16, -4.402892981920784e+16, -4.002629983564349e+16, -3.638754530513044e+16, -3.3079586641027668e+16, -3.0072351491843332e+16, -2.733850135622121e+16, -2.4853183051110188e+16, -2.2593802773736532e+16, -2.0539820703396844e+16, -1.867256427581531e+16, -1.6975058432559372e+16, -1.54318713023267e+16, -1.402897391120609e+16, -1.275361264655099e+16, -1.1594193315046354e+16, -1.054017574095123e+16, -9581977946319300.0, -8710889042108454.0, -7918990038280412.0, -7199081852982192.0, -6544619866347447.0, -5949654423952224.0, -5408776749047476.0, -4917069771861341.0, -4470063428964855.0, -4063694026331686.0, -3694267296665169.0, -3358424815150153.5, -3053113468318321.0, -2775557698471200.5, -2523234271337455.0, -2293849337579504.5, -2085317579617731.2, -1895743254197937.2, -1723402958361761.0, -1566729962147055.2, -1424299965588232.0, -1294818150534756.2, -1177107409577051.0, -1070097645070046.2, -972816040972769.2, -884378219066153.8, -803980199151048.8, -730891090137317.0, -664446445579379.0, -604042223253980.9, -549129293867255.25, -499208448970232.0, -453825862700210.9, -412568966091100.75, -375062696446455.2, -340966087678595.6, -309969170616905.06, -281790155106277.3, -256172868278433.9, -232884425707667.16, -211713114279697.4, -192466467526997.62, -174969515933634.2, -159063196303303.78, -144602905730276.16, -131457187027523.78, -119506533661385.25, -108642303328532.03, -98765730298665.47, -89787027544241.33, -81624570494764.84, -74204154995240.77, -67458322722946.15, -61325747929951.04, -55750679936319.125, -50682436305744.66, -46074942096131.5, -41886310996483.18, -38078464542257.43, -34616785947506.754, -31469805406824.32, -28608914006203.926, -26008103642003.566, -23643730583639.605, -21494300530581.457, -19540273209619.504, -17763884736017.73, -16148986123652.482, -14680896476047.71, -13346269523679.736, -12132972294254.305, -11029974812958.457, -10027249829962.232, -9115681663602.03, -8286983330547.298, -7533621209588.452, -6848746554171.319, -6226133231064.835, -5660121119149.85, -5145564653772.59, -4677786048884.172, -4252532771712.8833, -3865938883375.348, -3514489893977.589, -3194990812706.899, -2904537102460.817, -2640488274964.379, -2400443886331.2534, -2182221714846.594, -1983837922587.8125, -1803489020534.3748, -1639535473213.0679, -1490486793830.0615, -1354987994390.9648, -1231807267628.1497, -1119824788752.8633, -1018022535229.8757, -925475032027.1597, -841340938206.5087, -764855398369.5532, -695323089426.8665, -632111899478.9695, -574647181344.5177, -522406528495.01605, -474915025904.56, -431740932640.50903, -392491756945.9173, -356810688132.65204, -324373352847.8655, -294884866225.3322, -268077151113.93835, -243706501012.6712, -221551364556.97382, -201410331415.43073, -183100301286.7552, -166454819351.5956, -151322563046.9051, -137565966406.27734, -125059969460.25212, -113690881327.50192, -103355346661.36537, -93959406055.7867, -85417641868.89699, -77652401698.99725, -70593092453.63387, -64175538594.21259, -58341398722.011444, -53037635201.82858, -48216032001.662346, -43832756365.14758, -39847960331.95235, -36225418483.59304, -32932198621.448215, -29938362383.13474, -27216693075.577034, -24742448250.524574, -22493134773.204155, -20448304339.276505, -18589367581.160458, -16899425073.782234, -15363113703.438393, -13966467003.12581, -12696788184.659826, -11542534713.327114, -10493213375.75192, -9539284887.0472, -8672077170.042908, -7883706518.220825, -7167005925.655295, -6515459932.413904, -5923145393.103549, -5384677630.094135, -4895161481.903759, -4450146801.73069, -4045588001.5733542, -3677807274.1575947, -3343461158.3250856, -3039510143.9318957, -2763191039.938087, -2511991854.4891696, -2283628958.626518, -2076026326.0241067, -1887296660.021915, -1715724236.383559, -1559749305.8032353, -1417953914.3665774, -1289049013.0605247, -1171862739.1459315, -1065329762.8599375, -968481602.5999432, -880437820.5454028, -800398018.6776388, -727634562.434217, -661485965.8492881, -601350878.0448073, -546682616.4043702, -496984196.7312456, -451803815.2102232, -410730741.10020286, -373391582.8183662, -339446893.471242, -308588084.97385633, -280534622.70350575, -255031475.1850052, -231846795.62273198, -210769814.2024836, -191608922.0022578, -174189929.0929616, -158354480.99360144, -143958619.08509222, -130871471.89553836, -118974065.35958032, -108158241.2359821, -98325673.85089281, -89386976.22808437, -81260887.4800767, -73873534.072797, -67157758.24799727, -61052507.49817933, -55502279.543799385, -50456617.76709034, -45869652.51553667, -41699684.10503334, -37908803.731848486, -34462548.847134985, -31329589.861031804, -28481445.32821073, -25892223.025646117, -23538384.568769194, -21398531.426153813, -19453210.387412556, -17684736.715829596, -16077033.378026905, -14615484.889115367, -13286804.444650333, -12078913.131500302, -10980830.119545728, -9982572.835950661, -9075066.2145006, -8250060.195000546, -7500054.722727768, -6818231.566116152, -6198392.332832865, -5634902.1207571495, -5122638.291597408, -4656943.901452189, -4233585.364956535, -3848713.9681423046, -3498830.8801293676, -3180755.345572152, -2891595.768701956, -2628723.426092687, -2389748.56917517, -2172498.699250154, -1974998.81750014, -1795453.4704546726, -1632230.427686066, -1483845.8433509688, -1348950.7666826989, -1226318.8788024534, -1114835.3443658666, -1013486.6766962423, -921351.5242693111, -837592.2947902827, -761447.5407184388, -692225.0370167625, -629295.4881970568, -572086.8074518698, -520078.91586533614, -472799.0144230328, -429817.2858391207, -390742.98712647334, -355220.897387703, -322928.0885342754, -293570.989576614, -266882.7177969218, -242620.65254265617, -220564.22958423287, -200512.93598566623, -182284.48725969656, -165713.17023608775, -150648.33657826157, -136953.03325296505, -124502.75750269549, -113184.32500245044, -102894.84091131858, -93540.76446483507, -85037.05860439551, -77306.41691308682, -70278.56083007893, -63889.60075461721, -58081.45523147019, -52801.32293770016, -48001.20267063651, -43637.45697330591, -39670.415430278095, -36064.01402752554, -32785.46729775049, -29804.97027068226, -27095.427518802055, -24632.206835274592, -22392.915304795082, -20357.19573163189, -18506.54157421081, -16824.128703828006, -15294.66245802546, -13904.238598204962, -12640.216907459055, -11491.10627950823, -10446.46025409839, -9496.782049180354, -8633.438226527594, -7848.580205934176, -7135.072914485614, -6486.429922259648, -5896.754474781498, -5360.685886164998, -4873.350805604543, -4430.3189141859475, -4027.5626492599517, -3661.4205902363196, -3328.5641729421086, -3025.9674299473713, -2750.8794817703374, -2500.799528882125, -2273.454117165568, -2066.776470150516, -1878.8877001368326, -1708.0797273971205, -1552.7997521792004, -1411.6361383447274, -1283.3055803133884, -1166.6414366485349, -1060.5831242259408, -964.166476569037, -876.5149786991244, -796.8317988173858, -724.3925443794416, -658.5386767085832, -598.6715242805302, -544.2468402550275, -494.76985477729767, -449.79077707027056, -408.9007064275187, -371.72791493410784, -337.9344681219162, -307.2131528381056, -279.2846843982778, -253.89516763479799, -230.81378875890724, -209.830717053552, -190.7551973214109, -173.41381574673716, -157.64892340612468, -143.31720309647696, -130.28836645134268, -118.44396950122061, -107.67633591020055, -97.88757810018231, -88.98870736380209, -80.89882487618371, -73.54438625107609, -66.85853295552371, -60.78048450502155, -55.25498591365595, -50.23180537605086, -45.66527761459169, -41.513888740537894, -37.73989885503445, -34.30899895912222, -31.18999905374747, -28.35454459431588, -25.77685872210534, -23.43350792918667, -21.303189026533335, -19.366535478666666, -17.60594134424242, -16.005401222038564, -14.550364747307786, -13.22760431573435, -12.025094832485772, -10.931904393168884, -9.938094902880803, -9.034631729891638, -8.213301572628762, -7.466637793298873, -6.7878525393626115, -6.1707750357841915, -5.609795487076537, -5.099814079160488, -4.636194617418625, -4.214722379471477, -3.8315657995195243, -3.48324163592684, -3.1665833053880363, -2.8787120958073054, -2.6170109961884593, -2.379100905625872, -2.1628190051144287, -1.9661990955585713, -1.7874537232350647, -1.624957930213695, -1.47723448201245, -1.3429404381931362, -1.220854943811942, -1.109868130738129, -1.0089710279437536, -0.917246389039776, -0.8338603536725235, -0.7580548669750213, -0.6891407881591103, -0.6264916255991911, -0.56953784145381, -0.5177616740489182, -0.47069243095356195, -0.42790220995778355, -0.38900200905253046, -0.35363819004775493, -0.3214892636797772, -0.29226296698161564, -0.2656936063469233, -0.24153964213356663, -0.2195814928486969, -0.19961953895336082, -0.18147230813941892, -0.16497482558128992, -0.14997711416480902, -0.13634283105891729, -0.12394802823537933, -0.11268002566852665, -0.10243638697138786, -0.09312398815580714, -0.08465817105073375, -0.07696197368248522, -0.06996543062044111, -0.06360493692767373, -0.057822669934248845, -0.052566063576589855, -0.04778733052417259, -0.043443027749247805, -0.03949366159022527, -0.035903328718386605, -0.03263938974398782, -0.02967217249453438, -0.026974702267758523, -0.0245224566070532, -0.022293142370048362, -0.02026649306368033, -0.018424084603345752, -0.01674916782122341, -0.01522651620111219, -0.013842287455556535, -0.012583897686869577, -0.01143990698806325, -0.010399915443693864, -0.00945446858517624, -0.008594971441069308, -0.007813610400972098, -0.007103282182701907, -0.006457529257001733, -0.005870481142728848, -0.005336801038844407, -0.00485163730804037, -0.00441057937094579, -0.004009617609950718, -0.0036451069181370156, -0.003313733561942741, -0.0030124850563115826, -0.002738622778465075, -0.0024896570713318863, -0.0022633246103017147, -0.0020575678275470133, -0.001870516206860921, -0.0017004692789644735, -0.0015458811626949758, -0.001405346511540887, -0.0012775877377644426, -0.001161443397967675, -0.001055857634516068, -0.0009598705768327891, -0.0008726096153025355, -0.0007932814684568504, -0.0007211649713244094, -0.0006556045193858267, -0.0005960041085325697, -0.0005418219168477906, -0.0004925653789525368, -0.0004477867081386698, -0.0004070788255806089, -0.0003700716596187353, -0.00033642878147157755, -0.0003058443467923432, -0.0002780403152657665, -0.00025276392296887866, -0.0002297853845171624, -0.00020889580410651126, -0.00018990527646046477, -0.00017264116041860433, -0.00015694650947145847, -0.00014267864497405315, -0.00012970785906732103, -0.00011791623551574639, -0.00010719657774158762, -9.745143431053419e-05, -8.859221300957652e-05, -8.053837546325138e-05, -7.321670496659217e-05, -6.656064087872014e-05, -6.050967352610922e-05, -5.500879411464474e-05, -5.000799464967703e-05, -4.546181331788821e-05, -4.132892119808019e-05, -3.757174654370926e-05, -3.415613322155387e-05, -3.1051030201412604e-05, -2.822820927401146e-05, -2.5662008430919505e-05, -2.3329098573563184e-05, -2.1208271430511985e-05, -1.9280246755010893e-05, -1.7527497050009902e-05, -1.593408822728173e-05, -1.44855347520743e-05, -1.316866795643118e-05, -1.1971516324028345e-05, -1.0883196658207586e-05, -9.893815143825077e-06, -8.994377403477343e-06, -8.176706730433948e-06, -7.4333697549399525e-06, -6.757608868127229e-06, -6.143280789206572e-06, -5.584800717460519e-06, -5.077091561327744e-06, -4.615537783025222e-06, -4.1959434391138375e-06, -3.8144940355580335e-06, -3.467721850507303e-06, -3.1524744095520932e-06, -2.865885826865539e-06, -2.605350751695944e-06, -2.368500683359949e-06, -2.153182439418135e-06, -1.9574385812892137e-06, -1.7794896193538304e-06, -1.6177178357762093e-06, -1.470652577978372e-06, -1.3369568890712472e-06, -1.2154153537011338e-06, -1.1049230488192125e-06, -1.0044754989265568e-06, -9.131595444786879e-07, -8.301450404351707e-07, -7.546773094865188e-07, -6.860702813513807e-07, -6.237002557739824e-07, -5.670002325218022e-07, -5.15454756838002e-07, -4.6859523348909267e-07, -4.2599566680826603e-07, -3.8726878800751456e-07, -3.5206253455228594e-07, -3.200568495929872e-07, -2.909607723572611e-07, -2.645097930520555e-07, -2.4046344822914135e-07, -2.1860313475376482e-07, -1.9873012250342254e-07, -1.8066374773038411e-07, -1.6423977066398553e-07, -1.4930888242180502e-07, -1.3573534765618637e-07, -1.2339577059653305e-07, -1.1217797326957548e-07, -1.0197997569961407e-07, -9.270906881783097e-08, -8.42809716525736e-08, -7.661906513870326e-08, -6.965369558063933e-08, -6.332154143694484e-08, -5.756503766994985e-08, -5.2331852427227134e-08, -4.757441129747921e-08, -4.324946481589019e-08, -3.9317695287172896e-08, -3.574335935197536e-08, -3.249396304725032e-08, -2.95399664065912e-08, -2.6854514915082908e-08, -2.4413195377348097e-08, -2.219381397940736e-08, -2.017619452673396e-08, -1.83419950243036e-08, -1.667454093118509e-08, -1.5158673573804625e-08, -1.3780612339822385e-08, -1.2527829399838531e-08, -1.1388935818035027e-08, -1.0353578016395478e-08, -9.412343651268615e-09, -8.556676046607832e-09, -7.778796406007119e-09, -7.071633096370107e-09, -6.428757360336461e-09, -5.8443248730331455e-09, -5.313022611848313e-09, -4.830020556225739e-09, -4.390927778387036e-09, -3.991752525806396e-09, -3.628865932551268e-09, -3.2989690295920617e-09, -2.9990627541746013e-09, -2.7264206856132736e-09, -2.47856425964843e-09, -2.253240236044027e-09, -2.048400214585479e-09, -1.8621820132595262e-09, -1.6928927393268418e-09, -1.5389933993880379e-09, -1.3990849085345797e-09, -1.2718953713950723e-09, -1.1562685194500657e-09, -1.0511531995000597e-09, -9.55593817727327e-10, -8.68721652479388e-10, -7.897469567994436e-10, -7.179517789085851e-10, -6.52683435371441e-10, -5.933485776104008e-10, -5.394077978276371e-10, -4.903707252978519e-10, -4.4579156845259254e-10, -4.0526506222962957e-10, -3.684227838451178e-10, -3.349298034955616e-10, -3.0448163954141963e-10, -2.7680149049219964e-10, -2.516377186292724e-10, -2.287615623902476e-10, -2.079650567184069e-10, -1.89059142471279e-10, -1.718719477011627e-10, -1.5624722518287518e-10, -1.4204293198443196e-10, -1.291299381676654e-10, -1.173908528796958e-10, -1.067189571633598e-10, -9.701723378487254e-11, -8.819748525897503e-11, -8.017953205361366e-11, -7.289048368510333e-11, -6.626407607736665e-11, -6.02400691612424e-11, -5.4763699237493095e-11, -4.978518112499372e-11, -4.5259255568176104e-11, -4.1144777789251e-11, -3.7404343444773633e-11, -3.400394858615785e-11, -3.091268053287077e-11, -2.8102436848064334e-11, -2.5547669861876665e-11, -2.3225154419887876e-11, -2.111377674535261e-11, -1.91943424957751e-11, -1.7449402268886454e-11, -1.5863092971714956e-11, -1.4420993610649957e-11, -1.310999419149996e-11, -1.1918176537727236e-11, -1.0834705943388396e-11, -9.849732675807632e-12, -8.954302432552392e-12, -8.140274938683992e-12, -7.400249944258175e-12, -6.727499949325613e-12, -6.115909044841466e-12, -5.559917313492241e-12, -5.054470284992946e-12, -4.594972986357223e-12, -4.177248169415657e-12, -3.797498335832415e-12, -3.452271214393104e-12, -3.1384283767210032e-12, -2.8531167061100027e-12, -2.593742460100002e-12, -2.357947691000002e-12, -2.1435888100000016e-12, -1.9487171000000014e-12, -1.771561000000001e-12, -1.6105100000000008e-12, -1.4641000000000006e-12, -1.3310000000000005e-12, -1.2100000000000003e-12, -1.1000000000000002e-12, -1e-12, 0, 1e-12, 1.1000000000000002e-12, 1.2100000000000003e-12, 1.3310000000000005e-12, 1.4641000000000006e-12, 1.6105100000000008e-12, 1.771561000000001e-12, 1.9487171000000014e-12, 2.1435888100000016e-12, 2.357947691000002e-12, 2.593742460100002e-12, 2.8531167061100027e-12, 3.1384283767210032e-12, 3.452271214393104e-12, 3.797498335832415e-12, 4.177248169415657e-12, 4.594972986357223e-12, 5.054470284992946e-12, 5.559917313492241e-12, 6.115909044841466e-12, 6.727499949325613e-12, 7.400249944258175e-12, 8.140274938683992e-12, 8.954302432552392e-12, 9.849732675807632e-12, 1.0834705943388396e-11, 1.1918176537727236e-11, 1.310999419149996e-11, 1.4420993610649957e-11, 1.5863092971714956e-11, 1.7449402268886454e-11, 1.91943424957751e-11, 2.111377674535261e-11, 2.3225154419887876e-11, 2.5547669861876665e-11, 2.8102436848064334e-11, 3.091268053287077e-11, 3.400394858615785e-11, 3.7404343444773633e-11, 4.1144777789251e-11, 4.5259255568176104e-11, 4.978518112499372e-11, 5.4763699237493095e-11, 6.02400691612424e-11, 6.626407607736665e-11, 7.289048368510333e-11, 8.017953205361366e-11, 8.819748525897503e-11, 9.701723378487254e-11, 1.067189571633598e-10, 1.173908528796958e-10, 1.291299381676654e-10, 1.4204293198443196e-10, 1.5624722518287518e-10, 1.718719477011627e-10, 1.89059142471279e-10, 2.079650567184069e-10, 2.287615623902476e-10, 2.516377186292724e-10, 2.7680149049219964e-10, 3.0448163954141963e-10, 3.349298034955616e-10, 3.684227838451178e-10, 4.0526506222962957e-10, 4.4579156845259254e-10, 4.903707252978519e-10, 5.394077978276371e-10, 5.933485776104008e-10, 6.52683435371441e-10, 7.179517789085851e-10, 7.897469567994436e-10, 8.68721652479388e-10, 9.55593817727327e-10, 1.0511531995000597e-09, 1.1562685194500657e-09, 1.2718953713950723e-09, 1.3990849085345797e-09, 1.5389933993880379e-09, 1.6928927393268418e-09, 1.8621820132595262e-09, 2.048400214585479e-09, 2.253240236044027e-09, 2.47856425964843e-09, 2.7264206856132736e-09, 2.9990627541746013e-09, 3.2989690295920617e-09, 3.628865932551268e-09, 3.991752525806396e-09, 4.390927778387036e-09, 4.830020556225739e-09, 5.313022611848313e-09, 5.8443248730331455e-09, 6.428757360336461e-09, 7.071633096370107e-09, 7.778796406007119e-09, 8.556676046607832e-09, 9.412343651268615e-09, 1.0353578016395478e-08, 1.1388935818035027e-08, 1.2527829399838531e-08, 1.3780612339822385e-08, 1.5158673573804625e-08, 1.667454093118509e-08, 1.83419950243036e-08, 2.017619452673396e-08, 2.219381397940736e-08, 2.4413195377348097e-08, 2.6854514915082908e-08, 2.95399664065912e-08, 3.249396304725032e-08, 3.574335935197536e-08, 3.9317695287172896e-08, 4.324946481589019e-08, 4.757441129747921e-08, 5.2331852427227134e-08, 5.756503766994985e-08, 6.332154143694484e-08, 6.965369558063933e-08, 7.661906513870326e-08, 8.42809716525736e-08, 9.270906881783097e-08, 1.0197997569961407e-07, 1.1217797326957548e-07, 1.2339577059653305e-07, 1.3573534765618637e-07, 1.4930888242180502e-07, 1.6423977066398553e-07, 1.8066374773038411e-07, 1.9873012250342254e-07, 2.1860313475376482e-07, 2.4046344822914135e-07, 2.645097930520555e-07, 2.909607723572611e-07, 3.200568495929872e-07, 3.5206253455228594e-07, 3.8726878800751456e-07, 4.2599566680826603e-07, 4.6859523348909267e-07, 5.15454756838002e-07, 5.670002325218022e-07, 6.237002557739824e-07, 6.860702813513807e-07, 7.546773094865188e-07, 8.301450404351707e-07, 9.131595444786879e-07, 1.0044754989265568e-06, 1.1049230488192125e-06, 1.2154153537011338e-06, 1.3369568890712472e-06, 1.470652577978372e-06, 1.6177178357762093e-06, 1.7794896193538304e-06, 1.9574385812892137e-06, 2.153182439418135e-06, 2.368500683359949e-06, 2.605350751695944e-06, 2.865885826865539e-06, 3.1524744095520932e-06, 3.467721850507303e-06, 3.8144940355580335e-06, 4.1959434391138375e-06, 4.615537783025222e-06, 5.077091561327744e-06, 5.584800717460519e-06, 6.143280789206572e-06, 6.757608868127229e-06, 7.4333697549399525e-06, 8.176706730433948e-06, 8.994377403477343e-06, 9.893815143825077e-06, 1.0883196658207586e-05, 1.1971516324028345e-05, 1.316866795643118e-05, 1.44855347520743e-05, 1.593408822728173e-05, 1.7527497050009902e-05, 1.9280246755010893e-05, 2.1208271430511985e-05, 2.3329098573563184e-05, 2.5662008430919505e-05, 2.822820927401146e-05, 3.1051030201412604e-05, 3.415613322155387e-05, 3.757174654370926e-05, 4.132892119808019e-05, 4.546181331788821e-05, 5.000799464967703e-05, 5.500879411464474e-05, 6.050967352610922e-05, 6.656064087872014e-05, 7.321670496659217e-05, 8.053837546325138e-05, 8.859221300957652e-05, 9.745143431053419e-05, 0.00010719657774158762, 0.00011791623551574639, 0.00012970785906732103, 0.00014267864497405315, 0.00015694650947145847, 0.00017264116041860433, 0.00018990527646046477, 0.00020889580410651126, 0.0002297853845171624, 0.00025276392296887866, 0.0002780403152657665, 0.0003058443467923432, 0.00033642878147157755, 0.0003700716596187353, 0.0004070788255806089, 0.0004477867081386698, 0.0004925653789525368, 0.0005418219168477906, 0.0005960041085325697, 0.0006556045193858267, 0.0007211649713244094, 0.0007932814684568504, 0.0008726096153025355, 0.0009598705768327891, 0.001055857634516068, 0.001161443397967675, 0.0012775877377644426, 0.001405346511540887, 0.0015458811626949758, 0.0017004692789644735, 0.001870516206860921, 0.0020575678275470133, 0.0022633246103017147, 0.0024896570713318863, 0.002738622778465075, 0.0030124850563115826, 0.003313733561942741, 0.0036451069181370156, 0.004009617609950718, 0.00441057937094579, 0.00485163730804037, 0.005336801038844407, 0.005870481142728848, 0.006457529257001733, 0.007103282182701907, 0.007813610400972098, 0.008594971441069308, 0.00945446858517624, 0.010399915443693864, 0.01143990698806325, 0.012583897686869577, 0.013842287455556535, 0.01522651620111219, 0.01674916782122341, 0.018424084603345752, 0.02026649306368033, 0.022293142370048362, 0.0245224566070532, 0.026974702267758523, 0.02967217249453438, 0.03263938974398782, 0.035903328718386605, 0.03949366159022527, 0.043443027749247805, 0.04778733052417259, 0.052566063576589855, 0.057822669934248845, 0.06360493692767373, 0.06996543062044111, 0.07696197368248522, 0.08465817105073375, 0.09312398815580714, 0.10243638697138786, 0.11268002566852665, 0.12394802823537933, 0.13634283105891729, 0.14997711416480902, 0.16497482558128992, 0.18147230813941892, 0.19961953895336082, 0.2195814928486969, 0.24153964213356663, 0.2656936063469233, 0.29226296698161564, 0.3214892636797772, 0.35363819004775493, 0.38900200905253046, 0.42790220995778355, 0.47069243095356195, 0.5177616740489182, 0.56953784145381, 0.6264916255991911, 0.6891407881591103, 0.7580548669750213, 0.8338603536725235, 0.917246389039776, 1.0089710279437536, 1.109868130738129, 1.220854943811942, 1.3429404381931362, 1.47723448201245, 1.624957930213695, 1.7874537232350647, 1.9661990955585713, 2.1628190051144287, 2.379100905625872, 2.6170109961884593, 2.8787120958073054, 3.1665833053880363, 3.48324163592684, 3.8315657995195243, 4.214722379471477, 4.636194617418625, 5.099814079160488, 5.609795487076537, 6.1707750357841915, 6.7878525393626115, 7.466637793298873, 8.213301572628762, 9.034631729891638, 9.938094902880803, 10.931904393168884, 12.025094832485772, 13.22760431573435, 14.550364747307786, 16.005401222038564, 17.60594134424242, 19.366535478666666, 21.303189026533335, 23.43350792918667, 25.77685872210534, 28.35454459431588, 31.18999905374747, 34.30899895912222, 37.73989885503445, 41.513888740537894, 45.66527761459169, 50.23180537605086, 55.25498591365595, 60.78048450502155, 66.85853295552371, 73.54438625107609, 80.89882487618371, 88.98870736380209, 97.88757810018231, 107.67633591020055, 118.44396950122061, 130.28836645134268, 143.31720309647696, 157.64892340612468, 173.41381574673716, 190.7551973214109, 209.830717053552, 230.81378875890724, 253.89516763479799, 279.2846843982778, 307.2131528381056, 337.9344681219162, 371.72791493410784, 408.9007064275187, 449.79077707027056, 494.76985477729767, 544.2468402550275, 598.6715242805302, 658.5386767085832, 724.3925443794416, 796.8317988173858, 876.5149786991244, 964.166476569037, 1060.5831242259408, 1166.6414366485349, 1283.3055803133884, 1411.6361383447274, 1552.7997521792004, 1708.0797273971205, 1878.8877001368326, 2066.776470150516, 2273.454117165568, 2500.799528882125, 2750.8794817703374, 3025.9674299473713, 3328.5641729421086, 3661.4205902363196, 4027.5626492599517, 4430.3189141859475, 4873.350805604543, 5360.685886164998, 5896.754474781498, 6486.429922259648, 7135.072914485614, 7848.580205934176, 8633.438226527594, 9496.782049180354, 10446.46025409839, 11491.10627950823, 12640.216907459055, 13904.238598204962, 15294.66245802546, 16824.128703828006, 18506.54157421081, 20357.19573163189, 22392.915304795082, 24632.206835274592, 27095.427518802055, 29804.97027068226, 32785.46729775049, 36064.01402752554, 39670.415430278095, 43637.45697330591, 48001.20267063651, 52801.32293770016, 58081.45523147019, 63889.60075461721, 70278.56083007893, 77306.41691308682, 85037.05860439551, 93540.76446483507, 102894.84091131858, 113184.32500245044, 124502.75750269549, 136953.03325296505, 150648.33657826157, 165713.17023608775, 182284.48725969656, 200512.93598566623, 220564.22958423287, 242620.65254265617, 266882.7177969218, 293570.989576614, 322928.0885342754, 355220.897387703, 390742.98712647334, 429817.2858391207, 472799.0144230328, 520078.91586533614, 572086.8074518698, 629295.4881970568, 692225.0370167625, 761447.5407184388, 837592.2947902827, 921351.5242693111, 1013486.6766962423, 1114835.3443658666, 1226318.8788024534, 1348950.7666826989, 1483845.8433509688, 1632230.427686066, 1795453.4704546726, 1974998.81750014, 2172498.699250154, 2389748.56917517, 2628723.426092687, 2891595.768701956, 3180755.345572152, 3498830.8801293676, 3848713.9681423046, 4233585.364956535, 4656943.901452189, 5122638.291597408, 5634902.1207571495, 6198392.332832865, 6818231.566116152, 7500054.722727768, 8250060.195000546, 9075066.2145006, 9982572.835950661, 10980830.119545728, 12078913.131500302, 13286804.444650333, 14615484.889115367, 16077033.378026905, 17684736.715829596, 19453210.387412556, 21398531.426153813, 23538384.568769194, 25892223.025646117, 28481445.32821073, 31329589.861031804, 34462548.847134985, 37908803.731848486, 41699684.10503334, 45869652.51553667, 50456617.76709034, 55502279.543799385, 61052507.49817933, 67157758.24799727, 73873534.072797, 81260887.4800767, 89386976.22808437, 98325673.85089281, 108158241.2359821, 118974065.35958032, 130871471.89553836, 143958619.08509222, 158354480.99360144, 174189929.0929616, 191608922.0022578, 210769814.2024836, 231846795.62273198, 255031475.1850052, 280534622.70350575, 308588084.97385633, 339446893.471242, 373391582.8183662, 410730741.10020286, 451803815.2102232, 496984196.7312456, 546682616.4043702, 601350878.0448073, 661485965.8492881, 727634562.434217, 800398018.6776388, 880437820.5454028, 968481602.5999432, 1065329762.8599375, 1171862739.1459315, 1289049013.0605247, 1417953914.3665774, 1559749305.8032353, 1715724236.383559, 1887296660.021915, 2076026326.0241067, 2283628958.626518, 2511991854.4891696, 2763191039.938087, 3039510143.9318957, 3343461158.3250856, 3677807274.1575947, 4045588001.5733542, 4450146801.73069, 4895161481.903759, 5384677630.094135, 5923145393.103549, 6515459932.413904, 7167005925.655295, 7883706518.220825, 8672077170.042908, 9539284887.0472, 10493213375.75192, 11542534713.327114, 12696788184.659826, 13966467003.12581, 15363113703.438393, 16899425073.782234, 18589367581.160458, 20448304339.276505, 22493134773.204155, 24742448250.524574, 27216693075.577034, 29938362383.13474, 32932198621.448215, 36225418483.59304, 39847960331.95235, 43832756365.14758, 48216032001.662346, 53037635201.82858, 58341398722.011444, 64175538594.21259, 70593092453.63387, 77652401698.99725, 85417641868.89699, 93959406055.7867, 103355346661.36537, 113690881327.50192, 125059969460.25212, 137565966406.27734, 151322563046.9051, 166454819351.5956, 183100301286.7552, 201410331415.43073, 221551364556.97382, 243706501012.6712, 268077151113.93835, 294884866225.3322, 324373352847.8655, 356810688132.65204, 392491756945.9173, 431740932640.50903, 474915025904.56, 522406528495.01605, 574647181344.5177, 632111899478.9695, 695323089426.8665, 764855398369.5532, 841340938206.5087, 925475032027.1597, 1018022535229.8757, 1119824788752.8633, 1231807267628.1497, 1354987994390.9648, 1490486793830.0615, 1639535473213.0679, 1803489020534.3748, 1983837922587.8125, 2182221714846.594, 2400443886331.2534, 2640488274964.379, 2904537102460.817, 3194990812706.899, 3514489893977.589, 3865938883375.348, 4252532771712.8833, 4677786048884.172, 5145564653772.59, 5660121119149.85, 6226133231064.835, 6848746554171.319, 7533621209588.452, 8286983330547.298, 9115681663602.03, 10027249829962.232, 11029974812958.457, 12132972294254.305, 13346269523679.736, 14680896476047.71, 16148986123652.482, 17763884736017.73, 19540273209619.504, 21494300530581.457, 23643730583639.605, 26008103642003.566, 28608914006203.926, 31469805406824.32, 34616785947506.754, 38078464542257.43, 41886310996483.18, 46074942096131.5, 50682436305744.66, 55750679936319.125, 61325747929951.04, 67458322722946.15, 74204154995240.77, 81624570494764.84, 89787027544241.33, 98765730298665.47, 108642303328532.03, 119506533661385.25, 131457187027523.78, 144602905730276.16, 159063196303303.78, 174969515933634.2, 192466467526997.62, 211713114279697.4, 232884425707667.16, 256172868278433.9, 281790155106277.3, 309969170616905.06, 340966087678595.6, 375062696446455.2, 412568966091100.75, 453825862700210.9, 499208448970232.0, 549129293867255.25, 604042223253980.9, 664446445579379.0, 730891090137317.0, 803980199151048.8, 884378219066153.8, 972816040972769.2, 1070097645070046.2, 1177107409577051.0, 1294818150534756.2, 1424299965588232.0, 1566729962147055.2, 1723402958361761.0, 1895743254197937.2, 2085317579617731.2, 2293849337579504.5, 2523234271337455.0, 2775557698471200.5, 3053113468318321.0, 3358424815150153.5, 3694267296665169.0, 4063694026331686.0, 4470063428964855.0, 4917069771861341.0, 5408776749047476.0, 5949654423952224.0, 6544619866347447.0, 7199081852982192.0, 7918990038280412.0, 8710889042108454.0, 9581977946319300.0, 1.054017574095123e+16, 1.1594193315046354e+16, 1.275361264655099e+16, 1.402897391120609e+16, 1.54318713023267e+16, 1.6975058432559372e+16, 1.867256427581531e+16, 2.0539820703396844e+16, 2.2593802773736532e+16, 2.4853183051110188e+16, 2.733850135622121e+16, 3.0072351491843332e+16, 3.3079586641027668e+16, 3.638754530513044e+16, 4.002629983564349e+16, 4.402892981920784e+16, 4.843182280112862e+16, 5.327500508124149e+16, 5.860250558936564e+16, 6.446275614830221e+16, 7.090903176313243e+16, 7.799993493944568e+16, 8.579992843339026e+16, 9.43799212767293e+16, 1.0381791340440224e+17, 1.1419970474484248e+17, 1.2561967521932674e+17, 1.3818164274125942e+17, 1.5199980701538538e+17, 1.6719978771692394e+17, 1.8391976648861635e+17, 2.02311743137478e+17, 2.2254291745122582e+17, 2.447972091963484e+17, 2.6927693011598326e+17, 2.9620462312758163e+17, 3.2582508544033984e+17, 3.584075939843738e+17, 3.9424835338281126e+17, 4.336731887210924e+17, 4.770405075932017e+17, 5.247445583525219e+17, 5.772190141877742e+17, 6.349409156065517e+17, 6.984350071672069e+17, 7.682785078839277e+17, 8.451063586723205e+17, 9.296169945395526e+17, 1.022578693993508e+18, 1.1248365633928589e+18, 1.237320219732145e+18, 1.3610522417053596e+18, 1.4971574658758958e+18, 1.6468732124634854e+18, 1.8115605337098342e+18, 1.992716587080818e+18, 2.1919882457888998e+18, 2.41118707036779e+18, 2.652305777404569e+18, 2.917536355145026e+18, 3.2092899906595287e+18, 3.530218989725482e+18, 3.8832408886980306e+18, 4.271564977567834e+18, 4.698721475324618e+18, 5.16859362285708e+18, 5.685452985142788e+18, 6.253998283657068e+18, 6.879398112022775e+18, 7.567337923225053e+18, 8.324071715547559e+18, 9.156478887102316e+18, 1.0072126775812549e+19, 1.1079339453393805e+19, 1.2187273398733187e+19, 1.3406000738606506e+19, 1.4746600812467157e+19, 1.6221260893713875e+19, 1.7843386983085265e+19, 1.962772568139379e+19, 2.1590498249533174e+19, 2.3749548074486493e+19, 2.6124502881935143e+19, 2.873695317012866e+19, 3.1610648487141528e+19, 3.477171333585568e+19, 3.824888466944125e+19, 4.2073773136385384e+19, 4.628115045002392e+19, 5.090926549502632e+19, 5.600019204452896e+19, 6.160021124898186e+19, 6.776023237388005e+19, 7.453625561126807e+19, 8.198988117239489e+19, 9.018886928963438e+19, 9.920775621859783e+19],
          file_writer: instance(FileWriter):
            event_writer: instance(EventFileWriter),
          filename_suffix: '',
          flush_secs: 15,
          log_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                    10)_20240515-152550',
          max_queue: 10,
          purge_step: None,
      buffer_synchronizer: {'type': 'BufferSynchronizer', 'target_buffer': <reinforcement_learning.base.utility.deque_buffer_wrapper.DequeBufferWrapper object at 0x0000025A36D8F5E0>},
      output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                   10)_20240515-152550',
      own_sync_manager: False,
      sync_manager: instance(SyncManager):
        address: '\\\\.\\pipe\\pyc-29232-0-pn4v_5x9',
        shutdown: <Finalize object, callback=_finalize_manager, args=(<SpawnProcess name='SyncManager-1' pid=29232 parent=27256 started>, '\\\\.\\pipe\\pyc-29232-0-pn4v_5x9', b'\x1b\x11\x9a2\x08\x9d\xbe\x0f\xc1\x90E\xdd\xfc\xd1\x81\x1e\xf5\xf1\xcfTS\xb4\xbc\x83\xd7\xbf\x10J\x88\xb9\x90=', <multiprocessing.managers.State object at 0x0000025A36C40B50>, <function Client at 0x0000025A363E2940>), exitpriority=0>,
      writing_buffer: deque([], maxlen=5000)
    'text': instance(TextLogger):
      file_name: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                  10)_20240515-152550\\log.txt',
      logger: <Logger multiprocessing (INFO)>,
      output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
                   10)_20240515-152550'
  },
  loss_fn: MCTSLossFunction(
  (approximator): MCTSApproximator(
    (model): Sequential(
      (0): Linear(in_features=46, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=88, bias=True)
    )
  )
),
  lower_priority: True,
  lr_scheduler: instance(StepLR):
    base_lrs: [0.0002],
    gamma: 0.1,
    last_epoch: 0,
    optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0002
    lr: 0.0002
    weight_decay: 0
),
    step_size: 1000,
    verbose: False,
  num_of_epochs: 5001,
  number_of_evaluation_agents: 2,
  number_of_training_agents: 5,
  optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0002
    lr: 0.0002
    weight_decay: 0
),
  original_affinity: None,
  output_dir: 'logs\\BitcoinFeeModel(0.35, 0.5, 10, 10, 0.01,
               10)_20240515-152550',
  output_profile: False,
  output_root: 'logs/',
  processes: [],
  random_seed: 0,
  replay_buffer: {'type': 'ShuffleReplayBuffer', 'batch_size': 100, 'buffer_size': 0},
  replay_buffer_agent_queue: {'type': 'SequentialReplayBuffer', 'batch_size': 100, 'buffer_size': 100},
  replay_buffer_queue: None,
  replay_buffer_size: 1000,
  replay_buffer_synchronizer: {'type': 'BufferSynchronizer', 'target_buffer': {'type': 'ShuffleReplayBuffer', 'batch_size': 100, 'buffer_size': 0}},
  sync_dict: <DictProxy object, typeid 'dict' at 0x25a36c40c40>,
  sync_manager: instance(SyncManager):
    address: '\\\\.\\pipe\\pyc-29232-0-pn4v_5x9',
    shutdown: <Finalize object, callback=_finalize_manager, args=(<SpawnProcess name='SyncManager-1' pid=29232 parent=27256 started>, '\\\\.\\pipe\\pyc-29232-0-pn4v_5x9', b'\x1b\x11\x9a2\x08\x9d\xbe\x0f\xc1\x90E\xdd\xfc\xd1\x81\x1e\xf5\xf1\xcfTS\xb4\xbc\x83\xd7\xbf\x10J\x88\xb9\x90=', <multiprocessing.managers.State object at 0x0000025A36C40B50>, <function Client at 0x0000025A363E2940>), exitpriority=0>,
  train_episode_length: 100,
  weight_decay: 0

2024-05-15 15:26:12,999 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #0: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 5, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.42, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(r2024-05-15 15:26:12,999 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:13,000 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:13,000 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #0: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.029411764705882353, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(min, 0)': 0.42, '(min, 1)': 0.24, '(rev, 1)': 0.01}}
2024-05-15 15:26:13,000 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:13,000 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-15 15:26:13,001 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-15 15:26:13,001 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-15 15:26:13,014 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #0: {'transition': '(exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, rel, 1, 6, 10, 1, 1),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, nob, not, irr, 1, 0, 9, 0, 1)', 'reward_ratio': '0/1', 'revenue': 0.11627906976744186, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 10)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.44, '(rev, 1)': 0.02, '(rev, 3)': 0.01}}
2024-05-15 15:26:13,014 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:13,015 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-15 15:26:13,031 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #0: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, rel, 1, 2, 10, 0, 1),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, nob, not, irr, 1, 0, 9, 0, 1)', 'reward_ratio': '0/1', 'revenue': 0.11764705882352941, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.32, '(min, 1)': 0.34, '(rev, 1)': 0.04}}
2024-05-15 15:26:13,031 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:13,032 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #0: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.025, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.26, '(rev, 1)': 0.01}}
2024-05-15 15:26:13,032 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:13,032 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-15 15:26:13,033 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-15 15:26:14,172 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #0: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.02631578947368421, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.36, '(rev, 1)': 0.01}}
2024-05-15 15:26:14,173 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:14,173 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-15 15:26:26,152 - MainProcess - INFO - text_logger.py - 51 - Train epoch #0
2024-05-15 15:26:26,157 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.0509,  0.0000,  0.0000,  0.0000,  0.1385,  0.0000,  0.1335,  0.0083,
         0.1518,  0.0000,  0.1096,  0.0032,  0.0000,  0.0000,  0.0756,  0.0021,
         0.0000,  0.0000,  0.0836,  0.0000,  0.0000,  0.0000,  0.0665,  0.0003,
         0.0000,  0.0000,  0.0628,  0.0000,  0.0000,  0.0000,  0.0472,  0.0000,
         0.0000,  0.0000,  0.0551,  0.0000,  0.0000,  0.0000,  0.0454,  0.0000,
         0.0000,  0.0000,  0.0165,  0.0000,  0.0000])  tensor([0.6359, 0.0000, 0.0000, 0.0000, 0.1162, 0.0000, 0.0713, 0.0498, 0.1125,
        0.0000, 0.0601, 0.0275, 0.0000, 0.0000, 0.0446, 0.0208, 0.0000, 0.0000,
        0.0502, 0.0000, 0.0000, 0.0000, 0.0443, 0.0072, 0.0000, 0.0000, 0.0450,
        0.0000, 0.0000, 0.0000, 0.0380, 0.0000, 0.0000, 0.0000, 0.0471, 0.0000,
        0.0000, 0.0000, 0.0498, 0.0000, 0.0000, 0.0000, 0.0397, 0.0000, 0.0000]) (500)
2024-05-15 15:26:26,281 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4703219336656964
2024-05-15 15:26:26,303 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.073530.04412
2024-05-15 15:26:26,303 - MainProcess - INFO - text_logger.py - 51 - Simulated Policy Revenue 0.017740.01269
2024-05-15 15:26:26,311 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #1: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.32, '(min, 1)': 0.29}}
2024-05-15 15:26:26,312 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:26,312 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-15 15:26:26,359 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #1: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 5, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.21}}
2024-05-15 15:26:26,359 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:26,360 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-15 15:26:26,466 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #1: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.14893617021276595, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.34, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:26:26,466 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:26,467 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-15 15:26:26,559 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #1: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 4, 0, 0),(ado, 4)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/4', 'revenue': 0.05263157894736842, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.01, '(ado, 4)': 0.03, '(ado, 7)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.36, '(rev, 1)': 0.01, '(rev, 2)': 0.01}}
2024-05-15 15:26:26,559 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:26,559 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-15 15:26:26,905 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #1: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.32, '(min, 1)': 0.32}}
2024-05-15 15:26:26,906 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:26,907 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-15 15:26:27,663 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #1: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.02, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.33}}
2024-05-15 15:26:27,663 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:27,664 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-15 15:26:27,971 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #1: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, nob, not, irr, 1, 0, 9, 0, 1),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, rel, 1, 0, 10, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.022222222222222223, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 10)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.31, '(rev, 1)': 0.01}}
2024-05-15 15:26:27,971 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:27,972 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.47111710906028753
2024-05-15 15:26:28,107 - MainProcess - INFO - text_logger.py - 51 - Train epoch #1
2024-05-15 15:26:28,110 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.2491,  0.0000,  0.0000,  0.0000,  0.1124,  0.0000,  0.1309,  0.0014,
         0.1275,  0.0000,  0.1132,  0.0005,  0.0000,  0.0000,  0.0836,  0.0008,
         0.0000,  0.0000,  0.0929,  0.0004,  0.0000,  0.0000,  0.0774,  0.0000,
         0.0000,  0.0000,  0.0719,  0.0000,  0.0000,  0.0000,  0.0549,  0.0000,
         0.0000,  0.0000,  0.0623,  0.0000,  0.0000,  0.0000,  0.0508,  0.0000,
         0.0000,  0.0000,  0.0191,  0.0000,  0.0000])  tensor([0.6798, 0.0000, 0.0000, 0.0000, 0.0901, 0.0000, 0.0566, 0.0215, 0.0906,
        0.0000, 0.0469, 0.0118, 0.0000, 0.0000, 0.0367, 0.0122, 0.0000, 0.0000,
        0.0422, 0.0084, 0.0000, 0.0000, 0.0388, 0.0000, 0.0000, 0.0000, 0.0406,
        0.0000, 0.0000, 0.0000, 0.0358, 0.0000, 0.0000, 0.0000, 0.0455, 0.0000,
        0.0000, 0.0000, 0.0499, 0.0000, 0.0000, 0.0000, 0.0421, 0.0000, 0.0000]) (500)
2024-05-15 15:26:28,126 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46937969944757585
2024-05-15 15:26:28,129 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-15 15:26:28,155 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #2: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 3)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.22}}
2024-05-15 15:26:28,155 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:28,156 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-05-15 15:26:28,188 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #2: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.41, '(min, 1)': 0.2}}
2024-05-15 15:26:28,188 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:28,189 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-05-15 15:26:28,225 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #2: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.41, '(min, 1)': 0.27}}
2024-05-15 15:26:28,225 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:28,226 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-05-15 15:26:28,231 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #2: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 5, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 4)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.21, '(rev, 1)': 0.04, '(rev, 2)': 0.02}}
2024-05-15 15:26:28,231 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:28,233 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-05-15 15:26:28,487 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #2: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.57, '(min, 1)': 0.03}}
2024-05-15 15:26:28,487 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:28,488 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-05-15 15:26:30,495 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #2: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.36585365853658536, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.45, '(rev, 1)': 0.01, '(rev, 2)': 0.02}}
2024-05-15 15:26:30,495 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:30,495 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-05-15 15:26:30,764 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #2: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.29}}
2024-05-15 15:26:30,764 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:30,765 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4703219336656964
2024-05-15 15:26:30,909 - MainProcess - INFO - text_logger.py - 51 - Train epoch #2
2024-05-15 15:26:30,913 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.2749,  0.0000,  0.0000,  0.0000,  0.1084,  0.0000,  0.1138,  0.0048,
         0.1192,  0.0000,  0.1043,  0.0024,  0.0000,  0.0000,  0.0860,  0.0000,
         0.0000,  0.0000,  0.0872,  0.0000,  0.0000,  0.0000,  0.0770,  0.0000,
         0.0000,  0.0000,  0.0825,  0.0000,  0.0000,  0.0000,  0.0593,  0.0000,
         0.0000,  0.0000,  0.0723,  0.0000,  0.0000,  0.0000,  0.0616,  0.0000,
         0.0000,  0.0000,  0.0212,  0.0000,  0.0000])  tensor([0.7598, 0.0000, 0.0000, 0.0000, 0.1003, 0.0000, 0.0513, 0.0379, 0.0988,
        0.0000, 0.0411, 0.0236, 0.0000, 0.0000, 0.0345, 0.0000, 0.0000, 0.0000,
        0.0360, 0.0000, 0.0000, 0.0000, 0.0336, 0.0000, 0.0000, 0.0000, 0.0381,
        0.0000, 0.0000, 0.0000, 0.0305, 0.0000, 0.0000, 0.0000, 0.0403, 0.0000,
        0.0000, 0.0000, 0.0503, 0.0000, 0.0000, 0.0000, 0.0408, 0.0000, 0.0000]) (500)
2024-05-15 15:26:30,929 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46843746522945523
2024-05-15 15:26:30,931 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-15 15:26:30,957 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #3: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.51, '(min, 1)': 0.11}}
2024-05-15 15:26:30,957 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:30,957 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #3: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 0, 8, 0, 1),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 1, 8, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.02, '(min, 0)': 0.45, '(min, 1)': 0.26}}
2024-05-15 15:26:30,958 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
ition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.32, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(ado, 8)': 0.02, '(min, 0)': 0.47, '(min, 1)': 0.25, '(rev, 1)': 0.02, '(rev, 2)': 0.02}}
2024-05-15 15:26:30,958 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:30,958 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-05-15 15:26:30,958 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-05-15 15:26:30,959 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-05-15 15:26:30,973 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #3: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.29}}
2024-05-15 15:26:30,973 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:30,974 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-05-15 15:26:30,974 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #3: {'transition': '(exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 2, 9, 1, 1),(min, 0)->(exi, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 3, 9, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.29, '(min, 1)': 0.3}}
2024-05-15 15:26:30,974 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:30,975 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-05-15 15:26:31,864 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #3: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 7)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.29}}
2024-05-15 15:26:31,864 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:31,865 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-05-15 15:26:32,157 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #3: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.43, '(min, 1)': 0.21}}
2024-05-15 15:26:32,158 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:32,158 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46937969944757585
2024-05-15 15:26:32,300 - MainProcess - INFO - text_logger.py - 51 - Train epoch #3
2024-05-15 15:26:32,303 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.4370,  0.0000,  0.0000,  0.0000,  0.0995,  0.0000,  0.1134,  0.0012,
         0.1097,  0.0000,  0.1071,  0.0009,  0.0000,  0.0000,  0.0948,  0.0006,
         0.0000,  0.0000,  0.0875,  0.0000,  0.0000,  0.0000,  0.0875,  0.0000,
         0.0000,  0.0000,  0.0897,  0.0000,  0.0000,  0.0000,  0.0554,  0.0000,
         0.0000,  0.0000,  0.0753,  0.0000,  0.0000,  0.0000,  0.0595,  0.0000,
         0.0000,  0.0000,  0.0181,  0.0000,  0.0000])  tensor([0.7811, 0.0000, 0.0000, 0.0000, 0.0834, 0.0000, 0.0437, 0.0196, 0.0840,
        0.0000, 0.0341, 0.0141, 0.0000, 0.0000, 0.0304, 0.0089, 0.0000, 0.0000,
        0.0297, 0.0000, 0.0000, 0.0000, 0.0321, 0.0000, 0.0000, 0.0000, 0.0368,
        0.0000, 0.0000, 0.0000, 0.0260, 0.0000, 0.0000, 0.0000, 0.0410, 0.0000,
        0.0000, 0.0000, 0.0460, 0.0000, 0.0000, 0.0000, 0.0339, 0.0000, 0.0000]) (500)
2024-05-15 15:26:32,322 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46749523101133467
2024-05-15 15:26:32,325 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-15 15:26:32,506 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #4: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.21, '(min, 1)': 0.39}}
2024-05-15 15:26:32,506 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:32,507 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-05-15 15:26:32,685 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #4: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 4, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.44, '(min, 1)': 0.19}}
2024-05-15 15:26:32,685 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:32,686 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-05-15 15:26:33,214 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #4: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 4)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.32}}
2024-05-15 15:26:33,214 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:33,214 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-05-15 15:26:33,553 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #4: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.29, '(min, 1)': 0.33}}
2024-05-15 15:26:33,553 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:33,554 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-05-15 15:26:33,656 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #4: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 6, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.020833333333333332, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.27, '(rev, 1)': 0.01}}
2024-05-15 15:26:33,656 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:33,657 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-05-15 15:26:33,681 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #4: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.23}}
2024-05-15 15:26:33,682 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:33,683 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-05-15 15:26:33,715 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #4: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 1, 1, 10, 1, 1),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 0, 9, 0, 1)', 'reward_ratio': '0/1', 'revenue': 0.20454545454545456, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 10)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.27, '(rev, 1)': 0.01, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:26:33,715 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:33,716 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46843746522945523
2024-05-15 15:26:33,851 - MainProcess - INFO - text_logger.py - 51 - Train epoch #4
2024-05-15 15:26:33,854 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.7685e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1046e-01,
         0.0000e+00,  1.2044e-01,  1.1654e-03,  1.1943e-01,  0.0000e+00,
         1.1254e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.5067e-02,
         2.4242e-04,  0.0000e+00,  0.0000e+00,  8.1553e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  8.9473e-02,  1.4815e-04,  0.0000e+00,
         0.0000e+00,  8.9990e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         4.7644e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  7.4368e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.8004e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  9.4771e-03,  0.0000e+00,  0.0000e+00])  tensor([0.6829, 0.0000, 0.0000, 0.0000, 0.0853, 0.0000, 0.0451, 0.0184, 0.0836,
        0.0000, 0.0378, 0.0000, 0.0000, 0.0000, 0.0326, 0.0054, 0.0000, 0.0000,
        0.0307, 0.0000, 0.0000, 0.0000, 0.0358, 0.0033, 0.0000, 0.0000, 0.0405,
        0.0000, 0.0000, 0.0000, 0.0244, 0.0000, 0.0000, 0.0000, 0.0409, 0.0000,
        0.0000, 0.0000, 0.0403, 0.0000, 0.0000, 0.0000, 0.0219, 0.0000, 0.0000]) (500)
2024-05-15 15:26:33,873 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4665529967932141
2024-05-15 15:26:33,875 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-15 15:26:34,027 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #5: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.24390243902439024, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.46, '(min, 1)': 0.22, '(rev, 10)': 0.01}}
2024-05-15 15:26:34,028 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:34,029 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-05-15 15:26:34,164 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #5: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.34, '(min, 1)': 0.29}}
2024-05-15 15:26:34,165 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:34,166 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-05-15 15:26:35,147 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #5: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, nob, not, nob, not, rel, 1, 1, 8, 0, 1),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, nob, not, nob, not, irr, 1, 2, 8, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.22641509433962265, 'length': 100, 'actions': {'(ado, 1)': 0.06, '(ado, 2)': 0.03, '(ado, 4)': 0.02, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.42, '(rev, 1)': 0.04, '(rev, 4)': 0.02}}
2024-05-15 15:26:35,148 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:35,148 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-05-15 15:26:35,564 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #5: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 4, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 10)': 0.01, '(ado, 3)': 0.02, '(ado, 9)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.25}}
2024-05-15 15:26:35,564 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:35,565 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-05-15 15:26:36,282 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #5: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.03508771929824561, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 7)': 0.01, '(ado, 9)': 0.02, '(min, 0)': 0.32, '(min, 1)': 0.38, '(rev, 1)': 0.02}}
2024-05-15 15:26:36,282 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:36,282 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-05-15 15:26:36,598 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #5: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.31}}
2024-05-15 15:26:36,598 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:36,599 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-05-15 15:26:36,652 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #5: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, rel, 1, 0, 10, 0, 1),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, wit, exi, not, exi, not, nob, not, irr, 1, 0, 9, 0, 1)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.35, '(min, 1)': 0.29}}
2024-05-15 15:26:36,652 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:36,652 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46749523101133467
2024-05-15 15:26:36,784 - MainProcess - INFO - text_logger.py - 51 - Train epoch #5
2024-05-15 15:26:36,787 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.3213e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2581e-01,
         0.0000e+00,  1.3036e-01,  3.2301e-03,  1.2873e-01,  0.0000e+00,
         1.1640e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.9801e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  7.7022e-02,  2.5714e-04,
         0.0000e+00,  0.0000e+00,  8.6918e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  9.1935e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.5495e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.1368e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.6515e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.1547e-03,  0.0000e+00,  0.0000e+00])  tensor([0.7028, 0.0000, 0.0000, 0.0000, 0.1011, 0.0000, 0.0541, 0.0293, 0.0961,
        0.0000, 0.0464, 0.0000, 0.0000, 0.0000, 0.0419, 0.0000, 0.0000, 0.0000,
        0.0373, 0.0041, 0.0000, 0.0000, 0.0441, 0.0000, 0.0000, 0.0000, 0.0523,
        0.0000, 0.0000, 0.0000, 0.0254, 0.0000, 0.0000, 0.0000, 0.0467, 0.0000,
        0.0000, 0.0000, 0.0384, 0.0000, 0.0000, 0.0000, 0.0140, 0.0000, 0.0000]) (500)
2024-05-15 15:26:36,803 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46585466501411793
2024-05-15 15:26:36,805 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.121950.12195
2024-05-15 15:26:36,814 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.26, '(rev, 1)': 0.01}}
2024-05-15 15:26:36,815 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:36,816 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-05-15 15:26:36,829 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.44, '(min, 1)': 0.16}}
2024-05-15 15:26:36,830 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:36,831 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-05-15 15:26:36,908 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 4, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.038461538461538464, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.27, '(rev, 2)': 0.01}}
2024-05-15 15:26:36,908 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:36,909 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-05-15 15:26:37,757 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.38, '(rev, 6)': 0.01}}
2024-05-15 15:26:37,757 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:37,757 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-05-15 15:26:37,836 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #6: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 4)': 0.01, '(ado, 6)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.37}}
2024-05-15 15:26:37,836 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:37,837 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-05-15 15:26:37,990 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 2, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.29}}
2024-05-15 15:26:37,990 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:37,991 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-05-15 15:26:38,878 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #6: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2653061224489796, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.37, '(rev, 1)': 0.03}}
2024-05-15 15:26:38,878 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:38,878 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4665529967932141
2024-05-15 15:26:39,021 - MainProcess - INFO - text_logger.py - 51 - Train epoch #6
2024-05-15 15:26:39,024 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.1305e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2509e-01,
         0.0000e+00,  1.3462e-01,  1.4188e-03,  1.2737e-01,  0.0000e+00,
         1.1998e-01,  2.6667e-04,  0.0000e+00,  0.0000e+00,  1.0545e-01,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  7.6159e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  9.0372e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  9.2950e-02,  7.4074e-05,  0.0000e+00,  0.0000e+00,
         3.2772e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.2706e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8623e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  2.1467e-03,  0.0000e+00,  0.0000e+00])  tensor([0.8490, 0.0000, 0.0000, 0.0000, 0.0861, 0.0000, 0.0498, 0.0183, 0.0814,
        0.0000, 0.0433, 0.0060, 0.0000, 0.0000, 0.0401, 0.0000, 0.0000, 0.0000,
        0.0340, 0.0000, 0.0000, 0.0000, 0.0427, 0.0000, 0.0000, 0.0000, 0.0522,
        0.0017, 0.0000, 0.0000, 0.0216, 0.0000, 0.0000, 0.0000, 0.0457, 0.0000,
        0.0000, 0.0000, 0.0330, 0.0000, 0.0000, 0.0000, 0.0074, 0.0000, 0.0000]) (500)
2024-05-15 15:26:39,041 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46515687524044175
2024-05-15 15:26:39,044 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.122220.12222
2024-05-15 15:26:39,052 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #7: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 5, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.21}}
2024-05-15 15:26:39,052 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:39,053 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-05-15 15:26:39,099 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #7: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5116279069767442, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 7)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.37, '(rev, 1)': 0.03, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-15 15:26:39,100 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:39,101 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-05-15 15:26:39,415 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #7: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.28, '(min, 1)': 0.33}}
2024-05-15 15:26:39,415 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:39,416 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-05-15 15:26:39,964 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #7: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.020833333333333332, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 4)': 0.02, '(ado, 5)': 0.01, '(ado, 7)': 0.02, '(min, 0)': 0.3, '(min, 1)': 0.45, '(rev, 1)': 0.01}}
2024-05-15 15:26:39,964 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:39,965 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-05-15 15:26:40,349 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #7: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(ado, 4)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.16}}
2024-05-15 15:26:40,350 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:40,350 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-05-15 15:26:40,355 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #7: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 5, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.36}}
2024-05-15 15:26:40,355 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:40,355 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-05-15 15:26:40,365 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #7: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.09302325581395349, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.42, '(rev, 2)': 0.02}}
2024-05-15 15:26:40,365 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:40,366 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46585466501411793
2024-05-15 15:26:40,505 - MainProcess - INFO - text_logger.py - 51 - Train epoch #7
2024-05-15 15:26:40,507 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.2760,  0.0000,  0.0000,  0.0000,  0.1087,  0.0000,  0.1350,  0.0004,
         0.1081,  0.0000,  0.1192,  0.0005,  0.0000,  0.0000,  0.1132,  0.0000,
         0.0000,  0.0000,  0.0839,  0.0000,  0.0000,  0.0000,  0.0997,  0.0000,
         0.0000,  0.0000,  0.1038,  0.0000,  0.0000,  0.0000,  0.0356,  0.0000,
         0.0000,  0.0000,  0.0653,  0.0000,  0.0000,  0.0000,  0.0253,  0.0000,
         0.0000,  0.0000,  0.0012,  0.0000,  0.0000])  tensor([0.7433, 0.0000, 0.0000, 0.0000, 0.0722, 0.0000, 0.0370, 0.0097, 0.0669,
        0.0000, 0.0313, 0.0067, 0.0000, 0.0000, 0.0301, 0.0000, 0.0000, 0.0000,
        0.0256, 0.0000, 0.0000, 0.0000, 0.0320, 0.0000, 0.0000, 0.0000, 0.0400,
        0.0000, 0.0000, 0.0000, 0.0171, 0.0000, 0.0000, 0.0000, 0.0390, 0.0000,
        0.0000, 0.0000, 0.0277, 0.0000, 0.0000, 0.0000, 0.0047, 0.0000, 0.0000]) (500)
2024-05-15 15:26:40,535 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4647262689292979
2024-05-15 15:26:40,537 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.255810.25581
2024-05-15 15:26:40,651 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #8: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 3, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.02, '(min, 0)': 0.42, '(min, 1)': 0.31}}
2024-05-15 15:26:40,651 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:40,652 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-05-15 15:26:40,656 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #8: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.44, '(min, 0)': 0.41, '(min, 1)': 0.15}}
2024-05-15 15:26:40,656 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:40,657 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-05-15 15:26:40,855 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #8: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.46, '(min, 1)': 0.16}}
2024-05-15 15:26:40,856 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:40,857 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-05-15 15:26:41,626 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #8: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.38636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.43, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-05-15 15:26:41,626 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:41,627 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-05-15 15:26:41,943 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #8: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(ado, 9)': 0.02, '(min, 0)': 0.25, '(min, 1)': 0.44}}
2024-05-15 15:26:41,943 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:41,944 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-05-15 15:26:42,031 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #8: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.31}}
2024-05-15 15:26:42,031 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:42,032 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-05-15 15:26:42,272 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #8: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.34, '(rev, 1)': 0.03, '(rev, 4)': 0.01}}
2024-05-15 15:26:42,272 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:42,272 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46515687524044175
2024-05-15 15:26:42,402 - MainProcess - INFO - text_logger.py - 51 - Train epoch #8
2024-05-15 15:26:42,405 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.2338e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4610e-01,
         0.0000e+00,  1.4827e-01,  2.2367e-03,  1.4067e-01,  0.0000e+00,
         1.2631e-01,  1.6514e-04,  0.0000e+00,  0.0000e+00,  1.1219e-01,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  7.5760e-02,  1.3118e-04,
         0.0000e+00,  0.0000e+00,  8.3356e-02,  7.1429e-05,  0.0000e+00,
         0.0000e+00,  8.3329e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.6762e-02,  6.6667e-05,  0.0000e+00,  0.0000e+00,  4.2627e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1608e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.4037e-04,  0.0000e+00,  0.0000e+00])  tensor([0.9523, 0.0000, 0.0000, 0.0000, 0.1022, 0.0000, 0.0551, 0.0203, 0.0916,
        0.0000, 0.0482, 0.0037, 0.0000, 0.0000, 0.0473, 0.0000, 0.0000, 0.0000,
        0.0381, 0.0021, 0.0000, 0.0000, 0.0474, 0.0016, 0.0000, 0.0000, 0.0520,
        0.0000, 0.0000, 0.0000, 0.0198, 0.0015, 0.0000, 0.0000, 0.0387, 0.0000,
        0.0000, 0.0000, 0.0183, 0.0000, 0.0000, 0.0000, 0.0024, 0.0000, 0.0000]) (500)
2024-05-15 15:26:42,418 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46378403471117735
2024-05-15 15:26:42,420 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-15 15:26:42,433 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #9: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.47, '(min, 0)': 0.44, '(min, 1)': 0.09}}
2024-05-15 15:26:42,434 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:42,434 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-05-15 15:26:42,449 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #9: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 4)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.28}}
2024-05-15 15:26:42,449 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:42,450 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-05-15 15:26:42,481 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #9: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.26, '(min, 1)': 0.31}}
2024-05-15 15:26:42,481 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:42,482 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-05-15 15:26:43,174 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #9: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.04081632653061224, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.28, '(rev, 1)': 0.02}}
2024-05-15 15:26:43,174 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:43,175 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-05-15 15:26:43,754 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #9: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.19047619047619047, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.31, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:26:43,754 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:43,755 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-05-15 15:26:44,293 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #9: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 2, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 5)': 0.02, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.3}}
2024-05-15 15:26:44,294 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:44,294 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-05-15 15:26:44,598 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #9: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.38, '(min, 1)': 0.36, '(rev, 1)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:26:44,599 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:44,599 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4647262689292979
2024-05-15 15:26:44,757 - MainProcess - INFO - text_logger.py - 51 - Train epoch #9
2024-05-15 15:26:44,759 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.0845e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3351e-01, 0.0000e+00,
        1.5016e-01, 1.7154e-03, 1.2747e-01, 0.0000e+00, 1.2825e-01, 1.2903e-04,
        0.0000e+00, 0.0000e+00, 1.1680e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.0408e-02, 1.1765e-04, 0.0000e+00, 0.0000e+00, 9.0740e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.8899e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9282e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2512e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.5814e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.1614e-04, 0.0000e+00, 0.0000e+00])  tensor([0.7108, 0.0000, 0.0000, 0.0000, 0.0945, 0.0000, 0.0492, 0.0171, 0.0830,
        0.0000, 0.0425, 0.0029, 0.0000, 0.0000, 0.0429, 0.0000, 0.0000, 0.0000,
        0.0355, 0.0019, 0.0000, 0.0000, 0.0438, 0.0000, 0.0000, 0.0000, 0.0495,
        0.0000, 0.0000, 0.0000, 0.0190, 0.0000, 0.0000, 0.0000, 0.0377, 0.0000,
        0.0000, 0.0000, 0.0156, 0.0000, 0.0000, 0.0000, 0.0025, 0.0000, 0.0000]) (500)
2024-05-15 15:26:44,775 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4628418004930568
2024-05-15 15:26:44,778 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-15 15:26:44,788 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #10: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 5, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.08695652173913043, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.54, '(min, 1)': 0.23, '(rev, 4)': 0.01}}
2024-05-15 15:26:44,788 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:44,789 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-05-15 15:26:44,804 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.52, '(min, 1)': 0.17}}
2024-05-15 15:26:44,804 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:44,805 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-05-15 15:26:44,834 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.027777777777777776, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.41, '(min, 1)': 0.23, '(rev, 1)': 0.01}}
2024-05-15 15:26:44,835 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:44,835 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-05-15 15:26:45,547 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3684210526315789, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.42, '(rev, 1)': 0.01, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-15 15:26:45,547 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:45,548 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-05-15 15:26:45,715 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.48, '(min, 1)': 0.15}}
2024-05-15 15:26:45,715 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:45,715 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-05-15 15:26:45,726 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.15789473684210525, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(ado, 5)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.35, '(rev, 2)': 0.03}}
2024-05-15 15:26:45,727 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:45,727 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-05-15 15:26:46,725 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #10: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.11627906976744186, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.33, '(rev, 5)': 0.01}}
2024-05-15 15:26:46,726 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:46,726 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46378403471117735
2024-05-15 15:26:46,867 - MainProcess - INFO - text_logger.py - 51 - Train epoch #10
2024-05-15 15:26:46,870 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.6141e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4978e-01,
         0.0000e+00,  1.6110e-01,  8.4094e-04,  1.3691e-01,  0.0000e+00,
         1.2972e-01,  7.2803e-04,  0.0000e+00,  0.0000e+00,  1.1509e-01,
         2.5941e-04,  0.0000e+00,  0.0000e+00,  7.5663e-02,  6.6667e-05,
         0.0000e+00,  0.0000e+00,  7.9413e-02,  6.6667e-05,  0.0000e+00,
         0.0000e+00,  7.7207e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.6002e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.7472e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  9.0707e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.2120e-04,  0.0000e+00,  0.0000e+00])  tensor([1.0480, 0.0000, 0.0000, 0.0000, 0.1091, 0.0000, 0.0564, 0.0095, 0.0934,
        0.0000, 0.0495, 0.0065, 0.0000, 0.0000, 0.0509, 0.0031, 0.0000, 0.0000,
        0.0395, 0.0015, 0.0000, 0.0000, 0.0457, 0.0015, 0.0000, 0.0000, 0.0489,
        0.0000, 0.0000, 0.0000, 0.0187, 0.0000, 0.0000, 0.0000, 0.0314, 0.0000,
        0.0000, 0.0000, 0.0139, 0.0000, 0.0000, 0.0000, 0.0031, 0.0000, 0.0000]) (500)
2024-05-15 15:26:46,882 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4619273440527139
2024-05-15 15:26:46,885 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.013890.01389
2024-05-15 15:26:46,899 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #11: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 4, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.39, '(min, 1)': 0.26}}
2024-05-15 15:26:46,899 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:46,900 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-05-15 15:26:46,929 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #11: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.49, '(min, 1)': 0.11}}
2024-05-15 15:26:46,929 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:46,930 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-05-15 15:26:47,012 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #11: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 5, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8043478260869565, 'length': 100, 'actions': {'(ado, 1)': 0.05, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.48, '(rev, 1)': 0.04, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.03}}
2024-05-15 15:26:47,013 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:47,013 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-05-15 15:26:47,492 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #11: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 4, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 9)': 0.02, '(min, 0)': 0.37, '(min, 1)': 0.3}}
2024-05-15 15:26:47,492 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:47,493 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-05-15 15:26:48,315 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #11: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.37}}
2024-05-15 15:26:48,315 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:48,316 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-05-15 15:26:48,377 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #11: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.18181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.42, '(min, 1)': 0.28, '(rev, 8)': 0.01}}
2024-05-15 15:26:48,377 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:48,378 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-05-15 15:26:48,426 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #11: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 6, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 5, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0425531914893617, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 3)': 0.01, '(ado, 5)': 0.02, '(ado, 6)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.27, '(rev, 2)': 0.01}}
2024-05-15 15:26:48,427 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:48,427 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4628418004930568
2024-05-15 15:26:48,567 - MainProcess - INFO - text_logger.py - 51 - Train epoch #11
2024-05-15 15:26:48,571 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.2525e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7271e-01, 0.0000e+00,
        1.6679e-01, 3.3844e-03, 1.4920e-01, 0.0000e+00, 1.2736e-01, 1.9751e-03,
        0.0000e+00, 0.0000e+00, 1.1377e-01, 1.6745e-03, 0.0000e+00, 0.0000e+00,
        7.0703e-02, 9.9183e-04, 0.0000e+00, 0.0000e+00, 7.5141e-02, 5.7477e-04,
        0.0000e+00, 0.0000e+00, 6.5990e-02, 8.3464e-05, 0.0000e+00, 0.0000e+00,
        2.1871e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3034e-02, 6.2500e-05,
        0.0000e+00, 0.0000e+00, 4.3102e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.6525e-04, 0.0000e+00, 0.0000e+00])  tensor([1.4961e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2454e-01, 0.0000e+00,
        5.9621e-02, 1.6888e-02, 9.3327e-02, 0.0000e+00, 5.2142e-02, 8.7547e-03,
        0.0000e+00, 0.0000e+00, 5.3971e-02, 7.0405e-03, 0.0000e+00, 0.0000e+00,
        3.9460e-02, 4.5704e-03, 0.0000e+00, 0.0000e+00, 4.7493e-02, 3.5879e-03,
        0.0000e+00, 0.0000e+00, 4.8140e-02, 1.0814e-03, 0.0000e+00, 0.0000e+00,
        1.8439e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4696e-02, 1.3975e-03,
        0.0000e+00, 0.0000e+00, 9.5567e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3669e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:26:48,590 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.46098510983459334
2024-05-15 15:26:48,593 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-15 15:26:48,629 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #12: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.39, '(min, 1)': 0.18}}
2024-05-15 15:26:48,630 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:48,631 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-05-15 15:26:49,617 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #12: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.46, '(min, 1)': 0.16}}
2024-05-15 15:26:49,617 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:49,618 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-05-15 15:26:49,889 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #12: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.55, '(min, 1)': 0.14}}
2024-05-15 15:26:49,889 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:49,890 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-05-15 15:26:49,909 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #12: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.04878048780487805, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 8)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.17, '(rev, 2)': 0.01}}
2024-05-15 15:26:49,909 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:49,910 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-05-15 15:26:49,957 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #12: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.23}}
2024-05-15 15:26:49,958 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:49,958 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-05-15 15:26:49,976 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #12: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17391304347826086, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.28, '(rev, 1)': 0.01, '(rev, 7)': 0.01}}
2024-05-15 15:26:49,976 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:49,977 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-05-15 15:26:50,108 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #12: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 6)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.2}}
2024-05-15 15:26:50,108 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:50,108 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4619273440527139
2024-05-15 15:26:50,247 - MainProcess - INFO - text_logger.py - 51 - Train epoch #12
2024-05-15 15:26:50,250 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-4.5656e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1426e-01,
         0.0000e+00,  1.5901e-01,  2.1495e-04,  1.0502e-01,  0.0000e+00,
         1.3796e-01,  7.1429e-05,  0.0000e+00,  0.0000e+00,  1.3043e-01,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  8.9096e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  9.1562e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  9.2157e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.0433e-02,  6.6667e-05,  0.0000e+00,  0.0000e+00,  4.0114e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  8.2744e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  1.3347e-03,  0.0000e+00,  0.0000e+00])  tensor([0.7962, 0.0000, 0.0000, 0.0000, 0.0875, 0.0000, 0.0399, 0.0048, 0.0737,
        0.0000, 0.0332, 0.0016, 0.0000, 0.0000, 0.0359, 0.0000, 0.0000, 0.0000,
        0.0312, 0.0000, 0.0000, 0.0000, 0.0367, 0.0000, 0.0000, 0.0000, 0.0414,
        0.0000, 0.0000, 0.0000, 0.0162, 0.0015, 0.0000, 0.0000, 0.0262, 0.0000,
        0.0000, 0.0000, 0.0113, 0.0000, 0.0000, 0.0000, 0.0044, 0.0000, 0.0000]) (500)
2024-05-15 15:26:50,266 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4600428756164728
2024-05-15 15:26:50,269 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-15 15:26:50,434 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #13: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 0, 8, 0, 0),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 1, 8, 1, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.45, '(min, 1)': 0.16}}
2024-05-15 15:26:50,435 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:50,435 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-05-15 15:26:51,435 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #13: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.18}}
2024-05-15 15:26:51,435 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:51,436 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-05-15 15:26:51,525 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #13: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 3, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36585365853658536, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 7)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.24, '(rev, 5)': 0.01}}
2024-05-15 15:26:51,525 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:51,527 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-05-15 15:26:51,806 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #13: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.28}}
2024-05-15 15:26:51,807 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:51,807 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-05-15 15:26:51,970 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #13: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 3, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.29}}
2024-05-15 15:26:51,970 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:51,970 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-05-15 15:26:52,240 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #13: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2982456140350877, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 4)': 0.02, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.38, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-15 15:26:52,240 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:52,240 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-05-15 15:26:52,412 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #13: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 1, 1, 9, 1, 1),(min, 0)->(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 2, 9, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.36}}
2024-05-15 15:26:52,412 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:52,412 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.46098510983459334
2024-05-15 15:26:52,553 - MainProcess - INFO - text_logger.py - 51 - Train epoch #13
2024-05-15 15:26:52,555 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([9.0063e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5436e-01, 0.0000e+00,
        1.8150e-01, 6.1104e-04, 1.4030e-01, 0.0000e+00, 1.3727e-01, 6.0606e-05,
        0.0000e+00, 0.0000e+00, 1.1722e-01, 4.3478e-05, 0.0000e+00, 0.0000e+00,
        7.4198e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7105e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.3506e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5802e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4387e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2449e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.9423e-04, 0.0000e+00, 0.0000e+00])  tensor([1.1919e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0242e-01, 0.0000e+00,
        4.7654e-02, 6.4607e-03, 7.9749e-02, 0.0000e+00, 3.9105e-02, 1.3552e-03,
        0.0000e+00, 0.0000e+00, 4.2390e-02, 9.7220e-04, 0.0000e+00, 0.0000e+00,
        3.2807e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9199e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.6444e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7838e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2314e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.5063e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3684e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:26:52,571 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4594664950568888
2024-05-15 15:26:52,573 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.182930.18293
2024-05-15 15:26:52,923 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #14: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.61, '(min, 1)': 0.02}}
2024-05-15 15:26:52,923 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:52,924 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-05-15 15:26:52,995 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #14: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 5, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 8)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.34, '(rev, 3)': 0.01}}
2024-05-15 15:26:52,996 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:52,996 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-05-15 15:26:53,189 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #14: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 4)': 0.01, '(ado, 5)': 0.03, '(min, 0)': 0.53, '(min, 1)': 0.13}}
2024-05-15 15:26:53,189 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:53,189 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-05-15 15:26:53,240 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #14: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 6)': 0.02, '(min, 0)': 0.53, '(min, 1)': 0.16}}
2024-05-15 15:26:53,240 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:53,241 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-05-15 15:26:53,465 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #14: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2127659574468085, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.19, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:26:53,465 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:53,465 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-05-15 15:26:54,056 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #14: {'transition': '(exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 1, 3, 8, 1, 1),(min, 0)->(exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 1, 3, 9, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.38636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.08, '(ado, 3)': 0.02, '(ado, 4)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.32, '(rev, 1)': 0.03, '(rev, 10)': 0.01, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:26:54,056 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:54,056 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-05-15 15:26:54,671 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #14: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 0, 9, 0, 1),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 1, 9, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.31}}
2024-05-15 15:26:54,672 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:54,672 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4600428756164728
2024-05-15 15:26:54,812 - MainProcess - INFO - text_logger.py - 51 - Train epoch #14
2024-05-15 15:26:54,815 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-4.8173e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2343e-01,
         0.0000e+00,  1.5561e-01,  1.0693e-03,  1.0808e-01,  0.0000e+00,
         1.3823e-01,  6.1929e-04,  0.0000e+00,  0.0000e+00,  1.3190e-01,
         2.6391e-04,  0.0000e+00,  0.0000e+00,  9.1785e-02,  1.0833e-04,
         0.0000e+00,  0.0000e+00,  9.0953e-02,  7.6923e-05,  0.0000e+00,
         0.0000e+00,  8.7833e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.8796e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.3285e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  6.7302e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  1.1562e-03,  6.4516e-05,  0.0000e+00])  tensor([1.1898, 0.0000, 0.0000, 0.0000, 0.1192, 0.0000, 0.0486, 0.0080, 0.0882,
        0.0000, 0.0428, 0.0040, 0.0000, 0.0000, 0.0467, 0.0025, 0.0000, 0.0000,
        0.0406, 0.0018, 0.0000, 0.0000, 0.0470, 0.0017, 0.0000, 0.0000, 0.0534,
        0.0000, 0.0000, 0.0000, 0.0200, 0.0000, 0.0000, 0.0000, 0.0256, 0.0000,
        0.0000, 0.0000, 0.0104, 0.0000, 0.0000, 0.0000, 0.0042, 0.0014, 0.0000]) (500)
2024-05-15 15:26:54,828 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.45880686953442046
2024-05-15 15:26:54,830 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.141300.14130
2024-05-15 15:26:54,844 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #15: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 6, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.34, '(min, 1)': 0.24}}
2024-05-15 15:26:54,844 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:54,844 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #15: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 1, 7, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 2, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.27}}
2024-05-15 15:26:54,844 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #15: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 4, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.23, '(rev, 10)': 0.01}}
2024-05-15 15:26:54,844 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:54,844 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:54,845 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-05-15 15:26:54,845 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-05-15 15:26:54,845 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-05-15 15:26:54,892 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #15: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 6, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.44, '(min, 1)': 0.15}}
2024-05-15 15:26:54,893 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:54,893 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-05-15 15:26:55,690 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #15: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 2, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.038461538461538464, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.34, '(rev, 2)': 0.01}}
2024-05-15 15:26:55,691 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:55,691 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-05-15 15:26:56,289 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #15: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.17}}
2024-05-15 15:26:56,290 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:56,291 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-05-15 15:26:56,458 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #15: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 3, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.06382978723404255, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 8)': 0.02, '(min, 0)': 0.4, '(min, 1)': 0.33, '(rev, 3)': 0.01}}
2024-05-15 15:26:56,458 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:56,459 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4594664950568888
2024-05-15 15:26:56,599 - MainProcess - INFO - text_logger.py - 51 - Train epoch #15
2024-05-15 15:26:56,602 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.1737e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5253e-01, 0.0000e+00,
        1.9077e-01, 0.0000e+00, 1.3914e-01, 0.0000e+00, 1.4270e-01, 4.4444e-05,
        0.0000e+00, 0.0000e+00, 1.1073e-01, 6.0606e-05, 0.0000e+00, 0.0000e+00,
        7.7842e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0702e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.4214e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8052e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0754e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.2048e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8350e-04, 6.6667e-05, 0.0000e+00])  tensor([0.9119, 0.0000, 0.0000, 0.0000, 0.0906, 0.0000, 0.0489, 0.0000, 0.0682,
        0.0000, 0.0330, 0.0010, 0.0000, 0.0000, 0.0336, 0.0014, 0.0000, 0.0000,
        0.0304, 0.0000, 0.0000, 0.0000, 0.0315, 0.0000, 0.0000, 0.0000, 0.0325,
        0.0000, 0.0000, 0.0000, 0.0194, 0.0000, 0.0000, 0.0000, 0.0219, 0.0000,
        0.0000, 0.0000, 0.0063, 0.0000, 0.0000, 0.0000, 0.0017, 0.0015, 0.0000]) (500)
2024-05-15 15:26:56,616 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4578646353162999
2024-05-15 15:26:56,619 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-15 15:26:56,631 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #16: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.37, '(min, 1)': 0.25}}
2024-05-15 15:26:56,631 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:56,633 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-05-15 15:26:56,678 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #16: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.12195121951219512, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.28, '(rev, 5)': 0.01}}
2024-05-15 15:26:56,678 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:56,679 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-05-15 15:26:56,842 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #16: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.21, '(rev, 1)': 0.02, '(rev, 3)': 0.01}}
2024-05-15 15:26:56,843 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:56,843 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-05-15 15:26:57,311 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #16: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.11904761904761904, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.54, '(min, 1)': 0.22, '(rev, 5)': 0.01}}
2024-05-15 15:26:57,311 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:57,312 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-05-15 15:26:57,428 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #16: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 5, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.25, '(rev, 1)': 0.01, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-05-15 15:26:57,428 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:57,430 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-05-15 15:26:57,983 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #16: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.15}}
2024-05-15 15:26:57,983 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:57,983 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-05-15 15:26:58,667 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #16: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 2, 7, 0, 0),(ado, 5)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 2, 0, 0)', 'reward_ratio': '0/5', 'revenue': 0.17777777777777778, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 5)': 0.02, '(min, 0)': 0.35, '(min, 1)': 0.31, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-05-15 15:26:58,667 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:58,668 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45880686953442046
2024-05-15 15:26:58,819 - MainProcess - INFO - text_logger.py - 51 - Train epoch #16
2024-05-15 15:26:58,822 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.7100e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.3308e-01,
         0.0000e+00,  1.6258e-01,  8.4530e-04,  1.1135e-01,  0.0000e+00,
         1.3481e-01,  5.3282e-04,  0.0000e+00,  0.0000e+00,  1.4233e-01,
         3.1351e-04,  0.0000e+00,  0.0000e+00,  8.8484e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  8.8593e-02,  1.4039e-04,  0.0000e+00,
         0.0000e+00,  7.4482e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.0433e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7011e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.4145e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.0313e-04,  0.0000e+00,  0.0000e+00])  tensor([1.2383, 0.0000, 0.0000, 0.0000, 0.1239, 0.0000, 0.0480, 0.0062, 0.0889,
        0.0000, 0.0424, 0.0038, 0.0000, 0.0000, 0.0532, 0.0029, 0.0000, 0.0000,
        0.0396, 0.0000, 0.0000, 0.0000, 0.0466, 0.0022, 0.0000, 0.0000, 0.0448,
        0.0000, 0.0000, 0.0000, 0.0205, 0.0000, 0.0000, 0.0000, 0.0238, 0.0000,
        0.0000, 0.0000, 0.0086, 0.0000, 0.0000, 0.0000, 0.0031, 0.0000, 0.0000]) (500)
2024-05-15 15:26:58,836 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4572335122092904
2024-05-15 15:26:58,838 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.155560.15556
2024-05-15 15:26:58,850 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #17: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.36, '(min, 1)': 0.26}}
2024-05-15 15:26:58,850 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:58,851 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-05-15 15:26:58,882 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #17: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.2}}
2024-05-15 15:26:58,882 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:58,883 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-05-15 15:26:58,899 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #17: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.2}}
2024-05-15 15:26:58,899 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:58,899 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-05-15 15:26:59,449 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #17: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 1, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4634146341463415, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.34, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:26:59,449 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:59,449 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-05-15 15:26:59,456 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #17: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 2)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.33}}
2024-05-15 15:26:59,456 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:59,457 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-05-15 15:26:59,586 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #17: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 5, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.29, '(rev, 1)': 0.02, '(rev, 3)': 0.02}}
2024-05-15 15:26:59,586 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:26:59,587 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-05-15 15:27:00,767 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #17: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.34, '(rev, 2)': 0.03}}
2024-05-15 15:27:00,768 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:00,769 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4578646353162999
2024-05-15 15:27:00,913 - MainProcess - INFO - text_logger.py - 51 - Train epoch #17
2024-05-15 15:27:00,916 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.7991e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.5350e-01,
         0.0000e+00,  1.7855e-01,  1.2574e-03,  1.3368e-01,  0.0000e+00,
         1.3968e-01,  5.6514e-04,  0.0000e+00,  0.0000e+00,  9.8124e-02,
         2.2545e-04,  0.0000e+00,  0.0000e+00,  8.3203e-02,  6.2500e-05,
         0.0000e+00,  0.0000e+00,  7.6752e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  7.0627e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.0236e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.6986e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  5.6122e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  9.3345e-04,  0.0000e+00,  0.0000e+00])  tensor([1.4616e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3930e-01, 0.0000e+00,
        4.9965e-02, 7.0712e-03, 9.6386e-02, 0.0000e+00, 5.0532e-02, 3.7166e-03,
        0.0000e+00, 0.0000e+00, 4.1614e-02, 2.5866e-03, 0.0000e+00, 0.0000e+00,
        4.0820e-02, 1.3975e-03, 0.0000e+00, 0.0000e+00, 4.1001e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.0731e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9307e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1327e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.0653e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.7552e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:00,932 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.45629127799116986
2024-05-15 15:27:00,934 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-15 15:27:00,978 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #18: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.49, '(min, 1)': 0.13}}
2024-05-15 15:27:00,978 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:00,978 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-05-15 15:27:00,979 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #18: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 3, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.15}}
2024-05-15 15:27:00,979 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:00,980 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-05-15 15:27:00,993 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #18: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.46, '(min, 1)': 0.11}}
2024-05-15 15:27:00,994 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:00,994 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-05-15 15:27:01,152 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #18: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 2, 7, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.06521739130434782, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 5)': 0.01, '(ado, 8)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.24, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-15 15:27:01,153 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:01,153 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-05-15 15:27:01,180 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #18: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.03, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.02, '(min, 0)': 0.44, '(min, 1)': 0.28, '(rev, 1)': 0.04, '(rev, 2)': 0.02}}
2024-05-15 15:27:01,180 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:01,181 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-05-15 15:27:01,276 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #18: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41509433962264153, 'length': 100, 'actions': {'(ado, 1)': 0.09, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(ado, 8)': 0.02, '(min, 0)': 0.48, '(min, 1)': 0.3, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:27:01,277 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:01,278 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-05-15 15:27:03,212 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #18: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 5)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.26, '(rev, 1)': 0.03, '(rev, 2)': 0.01}}
2024-05-15 15:27:03,213 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:03,213 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4572335122092904
2024-05-15 15:27:03,360 - MainProcess - INFO - text_logger.py - 51 - Train epoch #18
2024-05-15 15:27:03,364 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.9235e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7915e-01, 0.0000e+00,
        1.7294e-01, 1.2256e-03, 1.4055e-01, 0.0000e+00, 1.1973e-01, 5.8509e-04,
        0.0000e+00, 0.0000e+00, 1.2395e-01, 2.0944e-04, 0.0000e+00, 0.0000e+00,
        7.6187e-02, 1.0283e-04, 0.0000e+00, 0.0000e+00, 6.8480e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.2147e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7703e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1067e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.8828e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0870e-03, 0.0000e+00, 0.0000e+00])  tensor([1.9406e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6032e-01, 0.0000e+00,
        5.5797e-02, 6.5797e-03, 1.0801e-01, 0.0000e+00, 4.9980e-02, 3.4701e-03,
        0.0000e+00, 0.0000e+00, 6.4711e-02, 2.4346e-03, 0.0000e+00, 0.0000e+00,
        4.6433e-02, 1.6265e-03, 0.0000e+00, 0.0000e+00, 4.6390e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.4709e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.2355e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0970e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.6863e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.2116e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:03,377 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4553490437730493
2024-05-15 15:27:03,379 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-15 15:27:03,408 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #19: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 3)': 0.01, '(ado, 6)': 0.03, '(min, 0)': 0.4, '(min, 1)': 0.28}}
2024-05-15 15:27:03,408 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #19: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.56, '(min, 1)': 0.14, '(rev, 1)': 0.01}}
2024-05-15 15:27:03,408 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:03,408 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:03,409 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-05-15 15:27:03,409 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-05-15 15:27:03,440 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #19: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 8)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/8', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 3)': 0.02, '(ado, 5)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.22}}
2)': 0.01}}
2024-05-15 15:27:03,440 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:03,440 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:03,441 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:03,441 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-05-15 15:27:03,441 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-05-15 15:27:03,442 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-05-15 15:27:03,558 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #19: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.27, '(min, 1)': 0.3}}
2024-05-15 15:27:03,558 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:03,559 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-05-15 15:27:05,352 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #19: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 5)': 0.01, '(ado, 7)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.29, '(rev, 5)': 0.01}}
2024-05-15 15:27:05,352 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:05,353 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45629127799116986
2024-05-15 15:27:05,482 - MainProcess - INFO - text_logger.py - 51 - Train epoch #19
2024-05-15 15:27:05,484 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-4.6106e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1721e-01,
         0.0000e+00,  1.7649e-01,  1.2163e-04,  9.9133e-02,  0.0000e+00,
         1.5055e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2480e-01,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  9.3461e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  8.7925e-02,  1.0760e-04,  0.0000e+00,
         0.0000e+00,  7.7047e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         3.6330e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.9080e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  6.4165e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  1.3210e-03,  0.0000e+00,  0.0000e+00])  tensor([1.1902, 0.0000, 0.0000, 0.0000, 0.1058, 0.0000, 0.0392, 0.0020, 0.0738,
        0.0000, 0.0307, 0.0000, 0.0000, 0.0000, 0.0320, 0.0000, 0.0000, 0.0000,
        0.0346, 0.0000, 0.0000, 0.0000, 0.0382, 0.0017, 0.0000, 0.0000, 0.0371,
        0.0000, 0.0000, 0.0000, 0.0207, 0.0000, 0.0000, 0.0000, 0.0207, 0.0000,
        0.0000, 0.0000, 0.0094, 0.0000, 0.0000, 0.0000, 0.0044, 0.0000, 0.0000]) (500)
2024-05-15 15:27:05,497 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.454709135136324
2024-05-15 15:27:05,499 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.151160.15116
2024-05-15 15:27:05,514 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #20: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.31, '(min, 1)': 0.34}}
2024-05-15 15:27:05,514 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:05,515 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-05-15 15:27:05,530 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #20: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.19047619047619047, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 5)': 0.02, '(min, 0)': 0.36, '(min, 1)': 0.33, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:27:05,530 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:05,530 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-05-15 15:27:05,545 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #20: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 1, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 1, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.24324324324324326, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.51, '(min, 1)': 0.16, '(rev, 1)': 0.02, '(rev, 2)': 0.02, '(rev, 5)': 0.01}}
2024-05-15 15:27:05,546 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:05,546 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #20: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3191489361702128, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.02, '(min, 0)': 0.39, '(min, 1)': 0.34, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-15 15:27:05,546 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:05,546 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-05-15 15:27:05,546 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-05-15 15:27:05,966 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #20: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.22}}
2024-05-15 15:27:05,967 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:05,967 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-05-15 15:27:06,137 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #20: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.27, '(rev, 1)': 0.01}}
2024-05-15 15:27:06,137 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:06,138 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-05-15 15:27:06,853 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #20: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.08888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.22, '(rev, 4)': 0.01}}
2024-05-15 15:27:06,853 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:06,854 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4553490437730493
2024-05-15 15:27:06,988 - MainProcess - INFO - text_logger.py - 51 - Train epoch #20
2024-05-15 15:27:06,990 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-0.0282,  0.0000,  0.0000,  0.0000,  0.1648,  0.0000,  0.1780,  0.0009,
         0.1290,  0.0000,  0.1231,  0.0005,  0.0000,  0.0000,  0.1083,  0.0003,
         0.0000,  0.0000,  0.0846,  0.0002,  0.0000,  0.0000,  0.0763,  0.0000,
         0.0000,  0.0000,  0.0675,  0.0000,  0.0000,  0.0000,  0.0325,  0.0000,
         0.0000,  0.0000,  0.0277,  0.0000,  0.0000,  0.0000,  0.0053,  0.0000,
         0.0000,  0.0000,  0.0009,  0.0000,  0.0000])  tensor([1.6133, 0.0000, 0.0000, 0.0000, 0.1692, 0.0000, 0.0548, 0.0050, 0.1076,
        0.0000, 0.0492, 0.0030, 0.0000, 0.0000, 0.0514, 0.0025, 0.0000, 0.0000,
        0.0462, 0.0021, 0.0000, 0.0000, 0.0442, 0.0000, 0.0000, 0.0000, 0.0424,
        0.0000, 0.0000, 0.0000, 0.0226, 0.0000, 0.0000, 0.0000, 0.0209, 0.0000,
        0.0000, 0.0000, 0.0089, 0.0000, 0.0000, 0.0000, 0.0037, 0.0000, 0.0000]) (500)
2024-05-15 15:27:07,004 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.45401014416144664
2024-05-15 15:27:07,006 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.121620.12162
2024-05-15 15:27:07,036 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #21: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.54, '(min, 1)': 0.06}}
2024-05-15 15:27:07,036 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:07,037 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-05-15 15:27:07,259 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #21: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5217391304347826, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(min, 0)': 0.4, '(min, 1)': 0.23, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 5)': 0.03}}
2024-05-15 15:27:07,259 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:07,260 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-05-15 15:27:07,382 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #21: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2682926829268293, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 8)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.15, '(rev, 1)': 0.01}}
2024-05-15 15:27:07,383 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:07,383 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-05-15 15:27:07,585 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #21: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1891891891891892, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.41, '(min, 1)': 0.23, '(rev, 1)': 0.05, '(rev, 4)': 0.01}}
2024-05-15 15:27:07,585 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:07,586 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-05-15 15:27:07,779 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #21: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 3, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.20408163265306123, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.35, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-15 15:27:07,779 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:07,780 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-05-15 15:27:07,850 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #21: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.42857142857142855, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.24, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:27:07,851 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:07,851 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-05-15 15:27:09,317 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #21: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 1, 1, 9, 1, 1),(min, 0)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 1, 1, 10, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.43902439024390244, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.41, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-15 15:27:09,317 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:09,318 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.454709135136324
2024-05-15 15:27:09,457 - MainProcess - INFO - text_logger.py - 51 - Train epoch #21
2024-05-15 15:27:09,460 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.8018e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4530e-01, 0.0000e+00,
        1.4065e-01, 2.7679e-03, 2.1790e-01, 0.0000e+00, 7.2675e-02, 2.0853e-03,
        0.0000e+00, 0.0000e+00, 6.1899e-02, 1.4161e-03, 0.0000e+00, 0.0000e+00,
        4.3624e-02, 4.3635e-04, 0.0000e+00, 0.0000e+00, 3.8836e-02, 3.1539e-04,
        0.0000e+00, 0.0000e+00, 3.5302e-02, 1.7770e-04, 0.0000e+00, 0.0000e+00,
        1.8082e-02, 3.1000e-04, 0.0000e+00, 0.0000e+00, 1.4688e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.0309e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.0104e-04, 0.0000e+00, 0.0000e+00])  tensor([2.7306e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2768e-01, 0.0000e+00,
        7.4961e-02, 7.9999e-03, 1.3474e-01, 0.0000e+00, 7.4017e-02, 6.0368e-03,
        0.0000e+00, 0.0000e+00, 6.9627e-02, 5.2797e-03, 0.0000e+00, 0.0000e+00,
        5.3412e-02, 2.8535e-03, 0.0000e+00, 0.0000e+00, 4.9822e-02, 2.5392e-03,
        0.0000e+00, 0.0000e+00, 4.6564e-02, 1.7829e-03, 0.0000e+00, 0.0000e+00,
        2.5110e-02, 2.9522e-03, 0.0000e+00, 0.0000e+00, 2.1445e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.3779e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8020e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:09,476 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.45333620262625296
2024-05-15 15:27:09,479 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.134150.13415
2024-05-15 15:27:09,505 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #22: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.09523809523809523, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.27, '(rev, 1)': 0.02, '(rev, 2)': 0.02, '(rev, 4)': 0.01}}
2024-05-15 15:27:09,505 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #22: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.54, '(min, 1)': 0.1}}
2024-05-15 15:27:09,506 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:09,505 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:09,506 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #22: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17777777777777778, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.38, '(rev, 1)': 0.05, '(rev, 5)': 0.01}}
2024-05-15 15:27:09,506 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:09,507 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-05-15 15:27:09,507 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-05-15 15:27:09,507 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-05-15 15:27:09,522 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #22: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.4782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(min, 0)': 0.21, '(min, 1)': 0.39, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 5)': 0.01}}
2024-05-15 15:27:09,522 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:09,523 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-05-15 15:27:09,537 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #22: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.018518518518518517, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.2, '(rev, 1)': 0.03}}
2024-05-15 15:27:09,537 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:09,537 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #22: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.45, '(min, 1)': 0.16}}
2024-05-15 15:27:09,537 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:09,538 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-05-15 15:27:09,538 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-05-15 15:27:10,895 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #22: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.04081632653061224, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.26, '(rev, 1)': 0.03}}
2024-05-15 15:27:10,895 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:10,895 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45401014416144664
2024-05-15 15:27:11,040 - MainProcess - INFO - text_logger.py - 51 - Train epoch #22
2024-05-15 15:27:11,043 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.4632e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1447e-01, 0.0000e+00,
        1.5425e-01, 2.1787e-03, 2.0707e-01, 0.0000e+00, 7.6371e-02, 1.3469e-03,
        0.0000e+00, 0.0000e+00, 6.3872e-02, 4.8771e-04, 0.0000e+00, 0.0000e+00,
        5.0829e-02, 2.3888e-04, 0.0000e+00, 0.0000e+00, 4.6539e-02, 1.6226e-04,
        0.0000e+00, 0.0000e+00, 3.9333e-02, 9.9755e-05, 0.0000e+00, 0.0000e+00,
        2.1156e-02, 9.9755e-05, 0.0000e+00, 0.0000e+00, 1.7088e-02, 9.9755e-05,
        0.0000e+00, 0.0000e+00, 3.6039e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.0032e-04, 0.0000e+00, 0.0000e+00])  tensor([2.3033e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3506e-01, 0.0000e+00,
        8.4181e-02, 6.8400e-03, 1.4124e-01, 0.0000e+00, 7.0722e-02, 4.6505e-03,
        0.0000e+00, 0.0000e+00, 6.2738e-02, 2.7259e-03, 0.0000e+00, 0.0000e+00,
        5.3606e-02, 2.0898e-03, 0.0000e+00, 0.0000e+00, 5.1064e-02, 1.8994e-03,
        0.0000e+00, 0.0000e+00, 4.4847e-02, 1.2911e-03, 0.0000e+00, 0.0000e+00,
        2.5339e-02, 1.2911e-03, 0.0000e+00, 0.0000e+00, 2.2429e-02, 1.2911e-03,
        0.0000e+00, 0.0000e+00, 7.8437e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2382e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:11,060 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4523939684081324
2024-05-15 15:27:11,062 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-15 15:27:11,089 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #23: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 5, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24489795918367346, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.4, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:27:11,089 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:11,090 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-05-15 15:27:11,104 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #23: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.54, '(min, 1)': 0.08}}
2024-05-15 15:27:11,105 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:11,106 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-05-15 15:27:11,288 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #23: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 1, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13043478260869565, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.25, '(rev, 1)': 0.05, '(rev, 4)': 0.01}}
2024-05-15 15:27:11,289 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:11,289 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-05-15 15:27:11,325 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #23: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.475, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.18, '(min, 1)': 0.46, '(rev, 1)': 0.12, '(rev, 2)': 0.06, '(rev, 3)': 0.03}}
2024-05-15 15:27:11,325 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:11,326 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-05-15 15:27:11,682 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #23: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 3, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6764705882352942, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.31, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.03}}
2024-05-15 15:27:11,682 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:11,683 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-05-15 15:27:12,041 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #23: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32558139534883723, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.18, '(rev, 4)': 0.01}}
2024-05-15 15:27:12,041 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:12,042 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-05-15 15:27:12,669 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #23: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.06666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.27, '(rev, 1)': 0.03}}
2024-05-15 15:27:12,669 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:12,670 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45333620262625296
2024-05-15 15:27:12,821 - MainProcess - INFO - text_logger.py - 51 - Train epoch #23
2024-05-15 15:27:12,825 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.8448e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5889e-01, 0.0000e+00,
        1.3408e-01, 2.8890e-03, 2.3884e-01, 0.0000e+00, 5.6281e-02, 2.0893e-03,
        0.0000e+00, 0.0000e+00, 5.2573e-02, 1.4899e-03, 0.0000e+00, 0.0000e+00,
        4.2420e-02, 2.8371e-04, 0.0000e+00, 0.0000e+00, 3.8530e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.3171e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9449e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5104e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2930e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.1231e-04, 0.0000e+00, 0.0000e+00])  tensor([2.1605, 0.0000, 0.0000, 0.0000, 0.2294, 0.0000, 0.0795, 0.0076, 0.1406,
        0.0000, 0.0610, 0.0056, 0.0000, 0.0000, 0.0641, 0.0049, 0.0000, 0.0000,
        0.0564, 0.0025, 0.0000, 0.0000, 0.0531, 0.0000, 0.0000, 0.0000, 0.0468,
        0.0000, 0.0000, 0.0000, 0.0286, 0.0000, 0.0000, 0.0000, 0.0237, 0.0000,
        0.0000, 0.0000, 0.0079, 0.0000, 0.0000, 0.0000, 0.0031, 0.0000, 0.0000]) (500)
2024-05-15 15:27:12,843 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4517773155853606
2024-05-15 15:27:12,846 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.162790.16279
2024-05-15 15:27:13,411 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #24: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2549019607843137, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.15, '(rev, 1)': 0.02, '(rev, 2)': 0.01}}
2024-05-15 15:27:13,412 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:13,412 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-05-15 15:27:13,431 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #24: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.23076923076923078, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.26, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-15 15:27:13,431 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:13,432 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-05-15 15:27:13,740 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #24: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.31, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-15 15:27:13,741 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:13,741 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-05-15 15:27:13,744 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #24: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 3, 0, 0),(rev, 3)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5853658536585366, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.09, '(min, 1)': 0.55, '(rev, 1)': 0.08, '(rev, 3)': 0.05, '(rev, 4)': 0.01}}
2024-05-15 15:27:13,744 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:13,745 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-05-15 15:27:13,916 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #24: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.58, '(min, 1)': 0.04}}
2024-05-15 15:27:13,917 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:13,917 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-05-15 15:27:14,811 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #24: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5576923076923077, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.37, '(rev, 1)': 0.04, '(rev, 10)': 0.01, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-15 15:27:14,812 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:14,812 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-05-15 15:27:15,114 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #24: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.02, '(ado, 8)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.33, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-05-15 15:27:15,114 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:15,115 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4523939684081324
2024-05-15 15:27:15,252 - MainProcess - INFO - text_logger.py - 51 - Train epoch #24
2024-05-15 15:27:15,254 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.5762e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8608e-01, 0.0000e+00,
        1.3146e-01, 3.3479e-03, 2.5035e-01, 0.0000e+00, 5.1753e-02, 2.2375e-03,
        0.0000e+00, 0.0000e+00, 4.8291e-02, 1.2717e-03, 0.0000e+00, 0.0000e+00,
        3.4475e-02, 6.0214e-04, 0.0000e+00, 0.0000e+00, 2.9547e-02, 2.6845e-04,
        0.0000e+00, 0.0000e+00, 2.8603e-02, 6.6120e-05, 0.0000e+00, 0.0000e+00,
        1.5746e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2549e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.7353e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.4919e-04, 6.0606e-05, 0.0000e+00])  tensor([2.1048e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2140e-01, 0.0000e+00,
        9.3938e-02, 8.0175e-03, 1.4063e-01, 0.0000e+00, 6.0955e-02, 5.8768e-03,
        0.0000e+00, 0.0000e+00, 6.4502e-02, 5.1054e-03, 0.0000e+00, 0.0000e+00,
        5.1423e-02, 3.5376e-03, 0.0000e+00, 0.0000e+00, 4.5621e-02, 2.1282e-03,
        0.0000e+00, 0.0000e+00, 4.5297e-02, 1.0444e-03, 0.0000e+00, 0.0000e+00,
        2.7113e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3462e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.6663e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9597e-03, 1.3552e-03, 0.0000e+00]) (500)
2024-05-15 15:27:15,270 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.45108998332802436
2024-05-15 15:27:15,272 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.127450.12745
2024-05-15 15:27:15,329 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #25: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(min, 0)': 0.08, '(min, 1)': 0.5, '(rev, 1)': 0.08, '(rev, 2)': 0.02}}
2024-05-15 15:27:15,329 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:15,329 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-05-15 15:27:15,333 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #25: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.11428571428571428, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.49, '(min, 1)': 0.14, '(rev, 1)': 0.04, '(rev, 2)': 0.02}}
2024-05-15 15:27:15,333 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:15,334 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-05-15 15:27:15,416 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #25: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 5, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.44, '(min, 1)': 0.18}}
2024-05-15 15:27:15,416 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:15,417 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-05-15 15:27:15,448 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #25: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.2653061224489796, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.29, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:27:15,448 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:15,449 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-05-15 15:27:15,604 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #25: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.2}}
2024-05-15 15:27:15,604 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:15,604 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-05-15 15:27:16,719 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #25: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.08823529411764706, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.2, '(rev, 1)': 0.04, '(rev, 2)': 0.01}}
2024-05-15 15:27:16,719 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:16,720 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-05-15 15:27:17,252 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #25: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.04, '(ado, 6)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.24, '(rev, 1)': 0.1, '(rev, 2)': 0.04}}
2024-05-15 15:27:17,252 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:17,252 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4517773155853606
2024-05-15 15:27:17,390 - MainProcess - INFO - text_logger.py - 51 - Train epoch #25
2024-05-15 15:27:17,393 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.2163e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7688e-01, 0.0000e+00,
        1.2395e-01, 2.9064e-03, 2.5882e-01, 0.0000e+00, 4.9168e-02, 1.4598e-03,
        0.0000e+00, 0.0000e+00, 4.5478e-02, 4.9162e-04, 0.0000e+00, 0.0000e+00,
        3.7302e-02, 2.8999e-04, 0.0000e+00, 0.0000e+00, 3.3436e-02, 6.4516e-05,
        0.0000e+00, 0.0000e+00, 3.0910e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8125e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6236e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.9369e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.4076e-04, 0.0000e+00, 0.0000e+00])  tensor([1.7014e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2795e-01, 0.0000e+00,
        8.1275e-02, 7.5326e-03, 1.4822e-01, 0.0000e+00, 6.3215e-02, 4.7677e-03,
        0.0000e+00, 0.0000e+00, 6.2690e-02, 2.8286e-03, 0.0000e+00, 0.0000e+00,
        5.2487e-02, 2.3002e-03, 0.0000e+00, 0.0000e+00, 4.7823e-02, 1.4426e-03,
        0.0000e+00, 0.0000e+00, 4.4558e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7178e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4837e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.8680e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8344e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:17,404 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4502620348241895
2024-05-15 15:27:17,406 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.057140.05714
2024-05-15 15:27:17,437 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #26: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 3, 0, 1),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 4, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(ado, 7)': 0.01, '(min, 0)': 0.52, '(min, 1)': 0.1}}
2024-05-15 15:27:17,437 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:17,437 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-05-15 15:27:17,452 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #26: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46511627906976744, 'length': 100, 'actions': {'(ado, 1)': 0.09, '(ado, 2)': 0.01, '(ado, 3)': 0.04, '(min, 0)': 0.44, '(min, 1)': 0.24, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 6)': 0.01}}
2024-05-15 15:27:17,452 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:17,453 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-05-15 15:27:17,469 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #26: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 6)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.09, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-15 15:27:17,469 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:17,469 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-05-15 15:27:17,653 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #26: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3953488372093023, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 9)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.2, '(rev, 1)': 0.07, '(rev, 3)': 0.01}}
2024-05-15 15:27:17,653 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:17,654 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-05-15 15:27:17,957 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #26: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.55, '(min, 1)': 0.07}}
2024-05-15 15:27:17,957 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:17,958 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-05-15 15:27:18,219 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #26: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.30612244897959184, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.21, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-05-15 15:27:18,219 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:18,220 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-05-15 15:27:19,595 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #26: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7659574468085106, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.46, '(rev, 1)': 0.05, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 7)': 0.01}}
2024-05-15 15:27:19,596 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:19,596 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.45108998332802436
2024-05-15 15:27:19,747 - MainProcess - INFO - text_logger.py - 51 - Train epoch #26
2024-05-15 15:27:19,750 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.4639e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8509e-01, 0.0000e+00,
        1.0326e-01, 4.2181e-03, 3.2732e-01, 0.0000e+00, 2.4460e-02, 2.5664e-03,
        0.0000e+00, 0.0000e+00, 1.5954e-02, 1.9792e-03, 0.0000e+00, 0.0000e+00,
        1.0588e-02, 6.1553e-04, 0.0000e+00, 0.0000e+00, 9.1967e-03, 4.0794e-04,
        0.0000e+00, 0.0000e+00, 6.7605e-03, 1.0387e-04, 0.0000e+00, 0.0000e+00,
        3.8038e-03, 1.2239e-04, 0.0000e+00, 0.0000e+00, 3.1235e-03, 6.6834e-05,
        0.0000e+00, 0.0000e+00, 3.2429e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.7736e-05, 0.0000e+00, 0.0000e+00])  tensor([1.8234e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4765e-01, 0.0000e+00,
        8.3586e-02, 8.8118e-03, 9.4388e-02, 0.0000e+00, 4.6317e-02, 6.2231e-03,
        0.0000e+00, 0.0000e+00, 3.9640e-02, 6.1664e-03, 0.0000e+00, 0.0000e+00,
        3.1976e-02, 3.3545e-03, 0.0000e+00, 0.0000e+00, 2.9514e-02, 2.7471e-03,
        0.0000e+00, 0.0000e+00, 2.4082e-02, 1.3410e-03, 0.0000e+00, 0.0000e+00,
        1.4588e-02, 1.6288e-03, 0.0000e+00, 0.0000e+00, 1.2543e-02, 1.0570e-03,
        0.0000e+00, 0.0000e+00, 2.6220e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.4380e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:19,764 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.44931980060606896
2024-05-15 15:27:19,766 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-15 15:27:19,810 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #27: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.28, '(min, 1)': 0.38, '(rev, 1)': 0.05, '(rev, 2)': 0.09, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-05-15 15:27:19,810 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:19,810 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #27: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.07894736842105263, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 4)': 0.01, '(min, 0)': 0.58, '(min, 1)': 0.08, '(rev, 1)': 0.01, '(rev, 3)': 0.01}}
2024-05-15 15:27:19,810 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:19,811 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-05-15 15:27:19,812 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-05-15 15:27:19,825 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #27: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24489795918367346, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.21, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-15 15:27:19,826 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:19,826 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #27: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 2, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.44, '(min, 1)': 0.16}}
2024-05-15 15:27:19,826 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:19,826 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-05-15 15:27:19,826 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-05-15 15:27:19,837 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #27: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.25}}
2024-05-15 15:27:19,837 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:19,837 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-05-15 15:27:20,514 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #27: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 1.1111111111111112, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.02, '(min, 0)': 0.11, '(min, 1)': 0.53, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.05, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:27:20,514 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:20,515 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-05-15 15:27:21,275 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #27: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5581395348837209, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.47, '(rev, 1)': 0.11, '(rev, 2)': 0.05, '(rev, 3)': 0.04, '(rev, 5)': 0.01}}
2024-05-15 15:27:21,275 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:21,276 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4502620348241895
2024-05-15 15:27:21,418 - MainProcess - INFO - text_logger.py - 51 - Train epoch #27
2024-05-15 15:27:21,421 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.1840e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3622e-01, 0.0000e+00,
        1.0180e-01, 5.1427e-03, 2.8042e-01, 0.0000e+00, 3.8356e-02, 3.4036e-03,
        0.0000e+00, 0.0000e+00, 3.3745e-02, 1.6356e-03, 0.0000e+00, 0.0000e+00,
        2.7329e-02, 9.1489e-04, 0.0000e+00, 0.0000e+00, 2.3399e-02, 7.2711e-04,
        0.0000e+00, 0.0000e+00, 2.0532e-02, 3.0629e-04, 0.0000e+00, 0.0000e+00,
        1.2660e-02, 3.2787e-05, 0.0000e+00, 0.0000e+00, 1.0266e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.5739e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.4658e-04, 0.0000e+00, 0.0000e+00])  tensor([2.8414e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1567e-01, 0.0000e+00,
        9.0628e-02, 9.4945e-03, 1.3073e-01, 0.0000e+00, 5.6505e-02, 7.4274e-03,
        0.0000e+00, 0.0000e+00, 5.5996e-02, 5.7543e-03, 0.0000e+00, 0.0000e+00,
        4.7566e-02, 4.5518e-03, 0.0000e+00, 0.0000e+00, 4.2814e-02, 4.0686e-03,
        0.0000e+00, 0.0000e+00, 3.8844e-02, 2.7552e-03, 0.0000e+00, 0.0000e+00,
        2.5235e-02, 7.3314e-04, 0.0000e+00, 0.0000e+00, 2.1797e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.6515e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9495e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:21,442 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4483775663879484
2024-05-15 15:27:21,445 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-15 15:27:21,449 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #28: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 3, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.53, '(min, 1)': 0.06}}
2024-05-15 15:27:21,449 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:21,450 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-05-15 15:27:21,482 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #28: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.47, '(min, 1)': 0.11}}
2024-05-15 15:27:21,483 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:21,485 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-05-15 15:27:22,053 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #28: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3137254901960784, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 7)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.2, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-15 15:27:22,053 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:22,054 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-05-15 15:27:22,125 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #28: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.15789473684210525, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 6)': 0.01, '(min, 0)': 0.56, '(min, 1)': 0.13, '(rev, 1)': 0.03, '(rev, 3)': 0.01}}
2024-05-15 15:27:22,125 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:22,126 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-05-15 15:27:22,226 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #28: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46938775510204084, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.33, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:27:22,227 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:22,227 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-05-15 15:27:22,253 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #28: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3023255813953488, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 8)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.29, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 4)': 0.01}}
2024-05-15 15:27:22,254 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:22,254 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-05-15 15:27:22,822 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #28: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.11904761904761904, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.27, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-15 15:27:22,822 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:22,822 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44931980060606896
2024-05-15 15:27:22,963 - MainProcess - INFO - text_logger.py - 51 - Train epoch #28
2024-05-15 15:27:22,966 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.2922e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.0455e-01,
         0.0000e+00,  1.4960e-01,  2.4424e-03,  2.1049e-01,  0.0000e+00,
         7.3082e-02,  1.5450e-03,  0.0000e+00,  0.0000e+00,  6.6095e-02,
         5.5574e-04,  0.0000e+00,  0.0000e+00,  5.1940e-02,  4.3512e-04,
         0.0000e+00,  0.0000e+00,  4.5993e-02,  9.1847e-05,  0.0000e+00,
         0.0000e+00,  4.2696e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.5036e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.0903e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.0616e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  4.8304e-04,  0.0000e+00,  0.0000e+00])  tensor([1.8604e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2621e-01, 0.0000e+00,
        8.7464e-02, 6.8842e-03, 1.3470e-01, 0.0000e+00, 5.7375e-02, 5.2099e-03,
        0.0000e+00, 0.0000e+00, 5.6781e-02, 2.9388e-03, 0.0000e+00, 0.0000e+00,
        4.8320e-02, 3.0446e-03, 0.0000e+00, 0.0000e+00, 4.4906e-02, 1.4662e-03,
        0.0000e+00, 0.0000e+00, 4.3466e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7660e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5715e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.7403e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7830e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:22,981 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4474353321698278
2024-05-15 15:27:22,983 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-15 15:27:23,009 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #29: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 4, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.55, '(min, 1)': 0.08}}
2024-05-15 15:27:23,010 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:23,012 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-05-15 15:27:23,040 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #29: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.53, '(min, 1)': 0.08}}
2024-05-15 15:27:23,040 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:23,042 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-05-15 15:27:23,647 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #29: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 5, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17391304347826086, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.15, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-15 15:27:23,647 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:23,647 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-05-15 15:27:23,665 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #29: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1276595744680851, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 5)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.14, '(rev, 1)': 0.05, '(rev, 3)': 0.01}}
2024-05-15 15:27:23,665 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:23,666 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-05-15 15:27:24,300 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #29: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 6, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 0, 5, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.9024390243902439, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 3)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.46, '(rev, 1)': 0.12, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-15 15:27:24,300 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:24,301 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-05-15 15:27:24,420 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #29: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 4, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10256410256410256, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(ado, 5)': 0.02, '(min, 0)': 0.62, '(min, 1)': 0.13, '(rev, 1)': 0.02, '(rev, 2)': 0.02}}
2024-05-15 15:27:24,420 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:24,421 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-05-15 15:27:25,508 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #29: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2894736842105263, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.34, '(rev, 1)': 0.04, '(rev, 9)': 0.01}}
2024-05-15 15:27:25,509 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:25,509 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4483775663879484
2024-05-15 15:27:25,643 - MainProcess - INFO - text_logger.py - 51 - Train epoch #29
2024-05-15 15:27:25,646 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.0570e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6026e-01, 0.0000e+00,
        1.3872e-01, 2.5162e-03, 2.5938e-01, 0.0000e+00, 5.5983e-02, 1.3172e-03,
        0.0000e+00, 0.0000e+00, 4.8970e-02, 8.0481e-04, 0.0000e+00, 0.0000e+00,
        3.6416e-02, 3.7067e-04, 0.0000e+00, 0.0000e+00, 3.1473e-02, 2.2070e-04,
        0.0000e+00, 0.0000e+00, 2.8553e-02, 6.8765e-05, 0.0000e+00, 0.0000e+00,
        1.7496e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4620e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.4258e-03, 5.2632e-05, 0.0000e+00, 0.0000e+00,
        3.5388e-04, 0.0000e+00, 0.0000e+00])  tensor([1.8385e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1610e-01, 0.0000e+00,
        9.3295e-02, 6.9465e-03, 1.3719e-01, 0.0000e+00, 5.8372e-02, 4.6119e-03,
        0.0000e+00, 0.0000e+00, 5.6103e-02, 3.7532e-03, 0.0000e+00, 0.0000e+00,
        4.5034e-02, 2.7978e-03, 0.0000e+00, 0.0000e+00, 4.1332e-02, 2.0358e-03,
        0.0000e+00, 0.0000e+00, 3.8711e-02, 1.0938e-03, 0.0000e+00, 0.0000e+00,
        2.5472e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2121e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.0205e-03, 1.1769e-03, 0.0000e+00, 0.0000e+00,
        2.3896e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:25,675 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4464930979517072
2024-05-15 15:27:25,678 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-15 15:27:25,705 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #30: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.3157894736842105, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 2)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.09, '(rev, 1)': 0.03}}
2024-05-15 15:27:25,706 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:25,706 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:25,706 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-05-15 15:27:25,706 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-05-15 15:27:25,713 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #30: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 1, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.21621621621621623, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.35, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-15 15:27:25,713 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:25,714 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-05-15 15:27:25,721 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #30: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40540540540540543, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(min, 0)': 0.37, '(min, 1)': 0.28, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.03}}
2024-05-15 15:27:25,721 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:25,722 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-05-15 15:27:26,040 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #30: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.4, '(rev, 1)': 0.04, '(rev, 2)': 0.06, '(rev, 3)': 0.03}}
2024-05-15 15:27:26,041 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:26,041 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-05-15 15:27:26,231 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #30: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.41, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 5)': 0.01}}
2024-05-15 15:27:26,231 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:26,232 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-05-15 15:27:27,764 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #30: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.07692307692307693, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.05, '(ado, 3)': 0.02, '(ado, 4)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.29, '(rev, 1)': 0.02, '(rev, 4)': 0.01}}
2024-05-15 15:27:27,764 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:27,765 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4474353321698278
2024-05-15 15:27:27,906 - MainProcess - INFO - text_logger.py - 51 - Train epoch #30
2024-05-15 15:27:27,908 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.7532e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6311e-01, 0.0000e+00,
        1.2593e-01, 2.5290e-03, 2.6211e-01, 0.0000e+00, 5.5797e-02, 1.3070e-03,
        0.0000e+00, 0.0000e+00, 4.6264e-02, 5.6427e-04, 0.0000e+00, 0.0000e+00,
        3.9344e-02, 1.8476e-04, 0.0000e+00, 0.0000e+00, 3.5042e-02, 3.0303e-05,
        0.0000e+00, 0.0000e+00, 3.1175e-02, 3.0303e-05, 0.0000e+00, 0.0000e+00,
        1.9243e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4506e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.4759e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5609e-04, 0.0000e+00, 0.0000e+00])  tensor([1.9831e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2236e-01, 0.0000e+00,
        8.9290e-02, 7.0529e-03, 1.4228e-01, 0.0000e+00, 6.2259e-02, 4.8008e-03,
        0.0000e+00, 0.0000e+00, 5.4958e-02, 3.3656e-03, 0.0000e+00, 0.0000e+00,
        5.0090e-02, 1.8508e-03, 0.0000e+00, 0.0000e+00, 4.6462e-02, 6.7760e-04,
        0.0000e+00, 0.0000e+00, 4.2285e-02, 6.7760e-04, 0.0000e+00, 0.0000e+00,
        2.7780e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3807e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.1104e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.4065e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:27,920 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.44595626913899206
2024-05-15 15:27:27,922 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.202700.20270
2024-05-15 15:27:27,938 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #31: {'transition': '(exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 1, 5, 8, 1, 1),(min, 0)->(exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 1, 5, 9, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 8)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.2}}
2024-05-15 15:27:27,938 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:27,938 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-05-15 15:27:27,970 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #31: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 5, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 6, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.35, '(min, 1)': 0.25}}
2024-05-15 15:27:27,970 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #31: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.2, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-15 15:27:27,970 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:27,971 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-05-15 15:27:27,971 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-05-15 15:27:27,995 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #31: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 1, 7, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.047619047619047616, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 4)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.17, '(rev, 1)': 0.04}}
2024-05-15 15:27:27,995 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:27,996 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-05-15 15:27:28,113 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #31: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 10)': 0.01, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.22, '(rev, 1)': 0.03, '(rev, 3)': 0.01, '(rev, 7)': 0.01}}
2024-05-15 15:27:28,113 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:28,114 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-05-15 15:27:28,296 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #31: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0425531914893617, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.18, '(rev, 1)': 0.03}}
2024-05-15 15:27:28,296 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:28,297 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-05-15 15:27:29,718 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #31: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.075, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.22, '(rev, 1)': 0.04}}
2024-05-15 15:27:29,718 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:29,718 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4464930979517072
2024-05-15 15:27:29,852 - MainProcess - INFO - text_logger.py - 51 - Train epoch #31
2024-05-15 15:27:29,855 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-2.7033e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.3465e-01,
         0.0000e+00,  1.4433e-01,  1.7652e-03,  2.4880e-01,  0.0000e+00,
         6.2395e-02,  4.8541e-04,  0.0000e+00,  0.0000e+00,  5.2590e-02,
         2.1400e-04,  0.0000e+00,  0.0000e+00,  4.3628e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.8027e-02,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  3.4583e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.0476e-02,  5.4054e-05,  0.0000e+00,  0.0000e+00,  1.5401e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.2866e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.2234e-04,  0.0000e+00,  0.0000e+00])  tensor([1.6936e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1740e-01, 0.0000e+00,
        8.8082e-02, 6.0241e-03, 1.4142e-01, 0.0000e+00, 5.9984e-02, 2.9068e-03,
        0.0000e+00, 0.0000e+00, 5.4355e-02, 2.3392e-03, 0.0000e+00, 0.0000e+00,
        4.9184e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5958e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.3724e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7722e-02, 1.2087e-03, 0.0000e+00, 0.0000e+00, 2.4159e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.9994e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.6278e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:29,868 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4450140349208715
2024-05-15 15:27:29,871 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-15 15:27:29,900 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #32: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.06666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.29, '(rev, 1)': 0.04, '(rev, 2)': 0.02}}
2024-05-15 15:27:29,900 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:29,900 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-05-15 15:27:29,932 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #32: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.021739130434782608, 'length': 100, 'actions': {'(ado, 1)': 0.45, '(min, 0)': 0.41, '(min, 1)': 0.13, '(rev, 1)': 0.01}}
min, 0)': 0.43, '(min, 1)': 0.16, '(rev, 1)': 0.07, '(rev, 2)': 0.01}}
2024-05-15 15:27:29,932 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:29,932 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:29,932 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #32: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.18604651162790697, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 8)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.3, '(rev, 1)': 0.1}}
2024-05-15 15:27:29,932 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:29,932 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-05-15 15:27:29,932 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #32: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1590909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.31, '(min, 1)': 0.26, '(rev, 1)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:27:29,932 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:29,932 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-05-15 15:27:29,933 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-05-15 15:27:30,091 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #32: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 4)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.33, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 4)': 0.01}}
2024-05-15 15:27:30,091 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:30,092 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-05-15 15:27:31,550 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #32: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.673469387755102, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.5, '(rev, 1)': 0.13, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-15 15:27:31,550 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:31,551 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44595626913899206
2024-05-15 15:27:31,685 - MainProcess - INFO - text_logger.py - 51 - Train epoch #32
2024-05-15 15:27:31,687 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.7473e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2942e-01, 0.0000e+00,
        1.0267e-01, 3.3771e-03, 2.8620e-01, 0.0000e+00, 3.8527e-02, 2.6509e-03,
        0.0000e+00, 0.0000e+00, 3.4417e-02, 1.0354e-03, 0.0000e+00, 0.0000e+00,
        2.7638e-02, 4.6464e-04, 0.0000e+00, 0.0000e+00, 2.4567e-02, 1.5421e-04,
        0.0000e+00, 0.0000e+00, 2.1907e-02, 5.4143e-05, 0.0000e+00, 0.0000e+00,
        1.4664e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0558e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.5290e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6321e-04, 0.0000e+00, 0.0000e+00])  tensor([2.0453e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1956e-01, 0.0000e+00,
        8.7934e-02, 7.6739e-03, 1.3261e-01, 0.0000e+00, 5.7518e-02, 6.3132e-03,
        0.0000e+00, 0.0000e+00, 5.4034e-02, 4.0784e-03, 0.0000e+00, 0.0000e+00,
        4.5335e-02, 2.6953e-03, 0.0000e+00, 0.0000e+00, 4.0995e-02, 1.5475e-03,
        0.0000e+00, 0.0000e+00, 3.6991e-02, 8.5592e-04, 0.0000e+00, 0.0000e+00,
        2.5300e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9965e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.5251e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6437e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:31,704 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.44425263074227656
2024-05-15 15:27:31,706 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.090420.06868
2024-05-15 15:27:31,724 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #33: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 7)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.37, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:27:31,724 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:31,724 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-05-15 15:27:31,749 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #33: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.45, '(rev, 1)': 0.13, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:27:31,749 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:31,750 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-05-15 15:27:31,959 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #33: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 8, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3611111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 3)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.42, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.02}}
2024-05-15 15:27:31,959 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:31,960 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-05-15 15:27:32,048 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #33: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.65, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.47, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-15 15:27:32,048 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:32,049 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-05-15 15:27:32,069 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #33: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.9333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 3)': 0.03, '(min, 0)': 0.21, '(min, 1)': 0.46, '(rev, 1)': 0.11, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.03}}
2024-05-15 15:27:32,069 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:32,070 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-05-15 15:27:32,082 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #33: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 8)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.41, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-15 15:27:32,082 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:32,083 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-05-15 15:27:33,403 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #33: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46153846153846156, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.16, '(min, 1)': 0.49, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-15 15:27:33,403 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:33,404 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4450140349208715
2024-05-15 15:27:33,537 - MainProcess - INFO - text_logger.py - 51 - Train epoch #33
2024-05-15 15:27:33,540 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.7745e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5310e-01, 0.0000e+00,
        5.4962e-02, 4.5035e-03, 3.5012e-01, 0.0000e+00, 9.8829e-03, 3.7582e-03,
        0.0000e+00, 0.0000e+00, 6.5385e-03, 2.2386e-03, 0.0000e+00, 0.0000e+00,
        4.1994e-03, 1.2557e-03, 0.0000e+00, 0.0000e+00, 3.5443e-03, 4.9375e-05,
        0.0000e+00, 0.0000e+00, 2.7762e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8191e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1763e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.9482e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.9291e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1101e-01, 0.0000e+00,
        5.9400e-02, 8.4329e-03, 6.8257e-02, 0.0000e+00, 2.8972e-02, 7.2873e-03,
        0.0000e+00, 0.0000e+00, 2.4829e-02, 5.7743e-03, 0.0000e+00, 0.0000e+00,
        2.0111e-02, 4.8777e-03, 0.0000e+00, 0.0000e+00, 1.8135e-02, 7.8461e-04,
        0.0000e+00, 0.0000e+00, 1.4630e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0142e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0861e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1016e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:33,553 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4438671598091802
2024-05-15 15:27:33,555 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.278380.08273
2024-05-15 15:27:33,567 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #34: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 3)': 0.02, '(min, 0)': 0.02, '(min, 1)': 0.59, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:27:33,567 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:33,568 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-05-15 15:27:33,598 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #34: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.4, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-15 15:27:33,598 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:33,599 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-05-15 15:27:33,634 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #34: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 2, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 1, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.14583333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.14, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-15 15:27:33,634 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:33,635 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-05-15 15:27:34,062 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #34: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.41, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-05-15 15:27:34,062 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:34,063 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-05-15 15:27:34,233 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #34: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8536585365853658, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 3)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.38, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.05, '(rev, 4)': 0.01}}
2024-05-15 15:27:34,233 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:34,234 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-05-15 15:27:34,646 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #34: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.13636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.39, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:27:34,646 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:34,647 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-05-15 15:27:34,904 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #34: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.42, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-15 15:27:34,904 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:34,905 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44425263074227656
2024-05-15 15:27:35,052 - MainProcess - INFO - text_logger.py - 51 - Train epoch #34
2024-05-15 15:27:35,054 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.6787e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3925e-01, 0.0000e+00,
        5.7046e-02, 3.5841e-03, 3.5119e-01, 0.0000e+00, 1.1492e-02, 2.5135e-03,
        0.0000e+00, 0.0000e+00, 8.6446e-03, 1.7342e-03, 0.0000e+00, 0.0000e+00,
        6.5222e-03, 7.7687e-04, 0.0000e+00, 0.0000e+00, 5.6638e-03, 2.8676e-04,
        0.0000e+00, 0.0000e+00, 5.0297e-03, 2.0236e-04, 0.0000e+00, 0.0000e+00,
        3.2860e-03, 8.5497e-05, 0.0000e+00, 0.0000e+00, 2.3248e-03, 2.9412e-05,
        0.0000e+00, 0.0000e+00, 3.4415e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.0733e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3376e-01, 0.0000e+00,
        7.7735e-02, 7.7528e-03, 8.3435e-02, 0.0000e+00, 3.1336e-02, 6.2321e-03,
        0.0000e+00, 0.0000e+00, 2.8509e-02, 5.6695e-03, 0.0000e+00, 0.0000e+00,
        2.4309e-02, 3.7455e-03, 0.0000e+00, 0.0000e+00, 2.2033e-02, 2.0189e-03,
        0.0000e+00, 0.0000e+00, 2.0216e-02, 1.7100e-03, 0.0000e+00, 0.0000e+00,
        1.3457e-02, 1.1052e-03, 0.0000e+00, 0.0000e+00, 1.0048e-02, 6.5767e-04,
        0.0000e+00, 0.0000e+00, 2.5658e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:35,074 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4433968458809146
2024-05-15 15:27:35,076 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.235960.09013
2024-05-15 15:27:35,184 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #35: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36363636363636365, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.21, '(min, 1)': 0.38, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-15 15:27:35,185 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:35,186 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-05-15 15:27:35,242 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #35: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5853658536585366, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.5, '(min, 1)': 0.15, '(rev, 1)': 0.13, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 7)': 0.01}}
2024-05-15 15:27:35,243 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:35,243 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-05-15 15:27:35,682 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #35: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.875, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.13, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-15 15:27:35,683 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:35,683 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-05-15 15:27:36,318 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #35: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.022222222222222223, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.16, '(rev, 1)': 0.02}}
2024-05-15 15:27:36,319 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:36,320 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-05-15 15:27:36,421 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #35: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3611111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.43, '(min, 1)': 0.24, '(rev, 1)': 0.03, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-15 15:27:36,421 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:36,422 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-05-15 15:27:36,510 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #35: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.03, '(ado, 3)': 0.02, '(min, 0)': 0.16, '(min, 1)': 0.43, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-15 15:27:36,511 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:36,511 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-05-15 15:27:36,564 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #35: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0),(ado, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/3', 'revenue': 0.22727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.32, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-15 15:27:36,564 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:36,564 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4438671598091802
2024-05-15 15:27:36,699 - MainProcess - INFO - text_logger.py - 51 - Train epoch #35
2024-05-15 15:27:36,701 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.5027e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6094e-01, 0.0000e+00,
        9.1682e-02, 3.1678e-03, 3.2056e-01, 0.0000e+00, 2.8251e-02, 1.7722e-03,
        0.0000e+00, 0.0000e+00, 2.3475e-02, 8.5122e-04, 0.0000e+00, 0.0000e+00,
        1.9432e-02, 4.5675e-04, 0.0000e+00, 0.0000e+00, 1.6489e-02, 2.1472e-04,
        0.0000e+00, 0.0000e+00, 1.4705e-02, 5.5787e-05, 0.0000e+00, 0.0000e+00,
        9.9476e-03, 3.2258e-05, 0.0000e+00, 0.0000e+00, 6.5854e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2015e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7739e-04, 0.0000e+00, 0.0000e+00])  tensor([1.9334e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9373e-01, 0.0000e+00,
        9.0088e-02, 7.5665e-03, 1.2169e-01, 0.0000e+00, 4.9270e-02, 5.4956e-03,
        0.0000e+00, 0.0000e+00, 4.5964e-02, 4.2107e-03, 0.0000e+00, 0.0000e+00,
        4.0440e-02, 3.1279e-03, 0.0000e+00, 0.0000e+00, 3.5775e-02, 2.2166e-03,
        0.0000e+00, 0.0000e+00, 3.2249e-02, 8.9196e-04, 0.0000e+00, 0.0000e+00,
        2.2950e-02, 7.2131e-04, 0.0000e+00, 0.0000e+00, 1.5986e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.6793e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6406e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:36,712 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.443403613880089
2024-05-15 15:27:36,714 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.474500.11086
2024-05-15 15:27:36,853 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #36: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3404255319148936, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.42, '(min, 1)': 0.13, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 4)': 0.01}}
2024-05-15 15:27:36,853 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:36,854 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-05-15 15:27:37,417 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #36: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.5, '(min, 1)': 0.12, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-15 15:27:37,417 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:37,418 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-05-15 15:27:37,502 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #36: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0975609756097561, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.5, '(min, 1)': 0.1, '(rev, 1)': 0.01, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-15 15:27:37,502 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:37,503 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-05-15 15:27:37,758 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #36: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(min, 0)': 0.37, '(min, 1)': 0.19, '(rev, 1)': 0.12, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-15 15:27:37,758 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:37,759 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-05-15 15:27:37,923 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #36: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.42, '(min, 1)': 0.17, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 6)': 0.01}}
2024-05-15 15:27:37,923 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:37,923 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-05-15 15:27:37,950 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #36: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3958333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 5)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.19, '(rev, 1)': 0.1, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-05-15 15:27:37,950 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:37,951 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-05-15 15:27:38,193 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #36: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 7, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.675, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.38, '(min, 1)': 0.25, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-05-15 15:27:38,193 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:38,194 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4433968458809146
2024-05-15 15:27:38,333 - MainProcess - INFO - text_logger.py - 51 - Train epoch #36
2024-05-15 15:27:38,335 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.6275e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4567e-01, 0.0000e+00,
        5.9283e-02, 5.7920e-03, 3.7365e-01, 0.0000e+00, 5.6156e-03, 2.9363e-03,
        0.0000e+00, 0.0000e+00, 2.5923e-03, 8.3475e-04, 0.0000e+00, 0.0000e+00,
        1.0488e-03, 4.4797e-04, 0.0000e+00, 0.0000e+00, 6.9893e-04, 2.1204e-04,
        0.0000e+00, 0.0000e+00, 4.7149e-04, 5.5556e-05, 0.0000e+00, 0.0000e+00,
        4.3759e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5269e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.1984, 0.0000, 0.0000, 0.0000, 0.0729, 0.0000, 0.0638, 0.0097, 0.0418,
        0.0000, 0.0198, 0.0071, 0.0000, 0.0000, 0.0141, 0.0038, 0.0000, 0.0000,
        0.0097, 0.0029, 0.0000, 0.0000, 0.0085, 0.0023, 0.0000, 0.0000, 0.0061,
        0.0012, 0.0000, 0.0000, 0.0056, 0.0000, 0.0000, 0.0000, 0.0033, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-05-15 15:27:38,353 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4428993661694931
2024-05-15 15:27:38,355 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.218990.12143
2024-05-15 15:27:38,773 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #37: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.05, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.44, '(min, 1)': 0.16, '(rev, 1)': 0.02}}
2024-05-15 15:27:38,773 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:38,774 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-05-15 15:27:38,806 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #37: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.39, '(min, 0)': 0.53, '(min, 1)': 0.08}}
2024-05-15 15:27:38,808 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:38,808 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-05-15 15:27:38,814 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #37: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 2, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.47, '(min, 1)': 0.07, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-15 15:27:38,814 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:38,815 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-05-15 15:27:39,296 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #37: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.30434782608695654, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.23, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:27:39,297 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:39,297 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-05-15 15:27:39,499 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #37: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7045454545454546, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.27, '(rev, 1)': 0.09, '(rev, 2)': 0.08, '(rev, 3)': 0.02}}
2024-05-15 15:27:39,499 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:39,499 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-05-15 15:27:39,512 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #37: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5909090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(min, 0)': 0.39, '(min, 1)': 0.23, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-15 15:27:39,512 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:39,513 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-05-15 15:27:39,807 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #37: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.46808510638297873, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.4, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-05-15 15:27:39,807 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:39,808 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.443403613880089
2024-05-15 15:27:39,946 - MainProcess - INFO - text_logger.py - 51 - Train epoch #37
2024-05-15 15:27:39,949 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.0497e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5267e-01, 0.0000e+00,
        5.7198e-02, 5.0781e-03, 3.7242e-01, 0.0000e+00, 4.8975e-03, 2.8911e-03,
        0.0000e+00, 0.0000e+00, 1.6209e-03, 1.1614e-03, 0.0000e+00, 0.0000e+00,
        2.1440e-04, 7.0649e-04, 0.0000e+00, 0.0000e+00, 5.4444e-05, 3.3365e-04,
        0.0000e+00, 0.0000e+00, 2.7778e-05, 2.9238e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.1545e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2525e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0159e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5787e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.1285e-02, 0.0000e+00,
        7.2278e-02, 9.3626e-03, 4.3856e-02, 0.0000e+00, 1.7571e-02, 7.2379e-03,
        0.0000e+00, 0.0000e+00, 1.0143e-02, 4.5829e-03, 0.0000e+00, 0.0000e+00,
        2.4562e-03, 4.0358e-03, 0.0000e+00, 0.0000e+00, 8.6016e-04, 2.6658e-03,
        0.0000e+00, 0.0000e+00, 6.2113e-04, 2.5146e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.8434e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4082e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1721e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:39,971 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4420071319513725
2024-05-15 15:27:39,973 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.025000.02500
2024-05-15 15:27:40,127 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #38: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.52, '(min, 1)': 0.07}}
2024-05-15 15:27:40,127 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:40,128 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-05-15 15:27:40,129 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #38: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 3, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.56, '(min, 1)': 0.02}}
2024-05-15 15:27:40,129 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:40,129 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-05-15 15:27:40,319 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #38: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 6)': 0.01, '(min, 0)': 0.52, '(min, 1)': 0.06, '(rev, 1)': 0.09, '(rev, 2)': 0.05}}
2024-05-15 15:27:40,319 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:40,320 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-05-15 15:27:40,616 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #38: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35714285714285715, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(min, 0)': 0.45, '(min, 1)': 0.1, '(rev, 1)': 0.13, '(rev, 2)': 0.05}}
2024-05-15 15:27:40,616 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:40,616 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-05-15 15:27:41,235 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #38: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10869565217391304, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.16, '(rev, 1)': 0.04, '(rev, 2)': 0.01}}
2024-05-15 15:27:41,235 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:41,236 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-05-15 15:27:41,360 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #38: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.2, '(rev, 1)': 0.08, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-15 15:27:41,360 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:41,360 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-05-15 15:27:41,742 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #38: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.23, '(rev, 1)': 0.07, '(rev, 2)': 0.03}}
2024-05-15 15:27:41,742 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:41,743 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4428993661694931
2024-05-15 15:27:41,886 - MainProcess - INFO - text_logger.py - 51 - Train epoch #38
2024-05-15 15:27:41,889 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.3554e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1297e-01, 0.0000e+00,
        7.1020e-02, 4.5371e-03, 3.5940e-01, 0.0000e+00, 1.3672e-02, 2.0646e-03,
        0.0000e+00, 0.0000e+00, 1.0424e-02, 5.5125e-04, 0.0000e+00, 0.0000e+00,
        7.5413e-03, 4.2356e-04, 0.0000e+00, 0.0000e+00, 6.1637e-03, 1.6311e-04,
        0.0000e+00, 0.0000e+00, 5.0178e-03, 1.0477e-04, 0.0000e+00, 0.0000e+00,
        3.2647e-03, 7.6197e-05, 0.0000e+00, 0.0000e+00, 2.2205e-03, 3.7736e-05,
        0.0000e+00, 0.0000e+00, 3.1624e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9412e-05, 0.0000e+00, 0.0000e+00])  tensor([1.2837e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3079e-01, 0.0000e+00,
        7.6764e-02, 8.9754e-03, 7.9060e-02, 0.0000e+00, 3.3122e-02, 6.0420e-03,
        0.0000e+00, 0.0000e+00, 3.0915e-02, 3.2128e-03, 0.0000e+00, 0.0000e+00,
        2.5148e-02, 3.0364e-03, 0.0000e+00, 0.0000e+00, 2.1439e-02, 1.6557e-03,
        0.0000e+00, 0.0000e+00, 1.8482e-02, 1.3611e-03, 0.0000e+00, 0.0000e+00,
        1.3349e-02, 1.2036e-03, 0.0000e+00, 0.0000e+00, 9.2802e-03, 8.4380e-04,
        0.0000e+00, 0.0000e+00, 2.3659e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.5767e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:41,909 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.44106489773325186
2024-05-15 15:27:41,911 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-15 15:27:41,917 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #39: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 4, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(min, 0)': 0.58, '(min, 1)': 0.04}}
2024-05-15 15:27:41,917 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:41,918 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-05-15 15:27:41,933 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #39: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.44, '(min, 1)': 0.14, '(rev, 1)': 0.12, '(rev, 2)': 0.05}}
2024-05-15 15:27:41,934 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:41,935 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-05-15 15:27:42,235 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #39: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4318181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.49, '(min, 1)': 0.1, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 4)': 0.02}}
2024-05-15 15:27:42,236 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:42,236 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-05-15 15:27:42,784 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #39: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.1, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-15 15:27:42,784 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:42,784 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-05-15 15:27:42,796 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #39: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3023255813953488, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.42, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-15 15:27:42,796 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:42,797 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-05-15 15:27:42,898 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #39: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.51, '(min, 1)': 0.06}}
2024-05-15 15:27:42,898 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:42,899 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-05-15 15:27:43,156 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #39: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 4, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4883720930232558, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(min, 0)': 0.48, '(min, 1)': 0.11, '(rev, 1)': 0.12, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:27:43,156 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:43,156 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4420071319513725
2024-05-15 15:27:43,296 - MainProcess - INFO - text_logger.py - 51 - Train epoch #39
2024-05-15 15:27:43,299 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.1386e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5382e-01, 0.0000e+00,
        4.7238e-02, 5.6896e-03, 3.8523e-01, 0.0000e+00, 3.1374e-03, 2.5391e-03,
        0.0000e+00, 0.0000e+00, 1.1484e-03, 6.3202e-04, 0.0000e+00, 0.0000e+00,
        1.9520e-04, 2.2575e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2219e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4483e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.4483e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([9.6098e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0373e-02, 0.0000e+00,
        5.2764e-02, 9.6935e-03, 2.7179e-02, 0.0000e+00, 1.2418e-02, 6.6354e-03,
        0.0000e+00, 0.0000e+00, 7.7827e-03, 3.3695e-03, 0.0000e+00, 0.0000e+00,
        3.1085e-03, 1.9123e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1419e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7106e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.7106e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:43,314 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4401226635151313
2024-05-15 15:27:43,316 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-15 15:27:43,508 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #40: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1282051282051282, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(min, 0)': 0.48, '(min, 1)': 0.11, '(rev, 1)': 0.04, '(rev, 2)': 0.03}}
2024-05-15 15:27:43,508 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:43,509 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-05-15 15:27:43,884 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #40: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.375, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 5)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.22, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-15 15:27:43,884 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:43,884 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-05-15 15:27:44,323 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #40: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.8541666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 7)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-05-15 15:27:44,323 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:44,324 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-05-15 15:27:44,441 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #40: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.41, '(min, 1)': 0.21, '(rev, 1)': 0.06, '(rev, 2)': 0.07, '(rev, 3)': 0.02}}
2024-05-15 15:27:44,442 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:44,442 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-05-15 15:27:44,446 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #40: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.17, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-05-15 15:27:44,446 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:44,447 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-05-15 15:27:44,848 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #40: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46808510638297873, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.28, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:27:44,848 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:44,848 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-05-15 15:27:45,144 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #40: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5434782608695652, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 7)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.19, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-05-15 15:27:45,144 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:45,145 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.44106489773325186
2024-05-15 15:27:45,206 - MainProcess - INFO - text_logger.py - 51 - Train epoch #40
2024-05-15 15:27:45,209 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-6.5838e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  5.0324e-01,
         0.0000e+00,  7.4070e-02,  4.4900e-03,  3.5479e-01,  0.0000e+00,
         1.5824e-02,  2.0706e-03,  0.0000e+00,  0.0000e+00,  1.3075e-02,
         8.2001e-04,  0.0000e+00,  0.0000e+00,  8.9763e-03,  3.6859e-04,
         0.0000e+00,  0.0000e+00,  7.8520e-03,  1.2269e-04,  0.0000e+00,
         0.0000e+00,  6.6181e-03,  7.9216e-05,  0.0000e+00,  0.0000e+00,
         4.2282e-03,  4.0000e-05,  0.0000e+00,  0.0000e+00,  2.8986e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.8957e-04,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  5.2303e-05,  0.0000e+00,  0.0000e+00])  tensor([1.6946e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4118e-01, 0.0000e+00,
        8.6325e-02, 8.8986e-03, 8.2653e-02, 0.0000e+00, 3.2707e-02, 6.0398e-03,
        0.0000e+00, 0.0000e+00, 3.1210e-02, 4.0749e-03, 0.0000e+00, 0.0000e+00,
        2.3238e-02, 2.7199e-03, 0.0000e+00, 0.0000e+00, 2.1577e-02, 1.5824e-03,
        0.0000e+00, 0.0000e+00, 1.9371e-02, 1.2513e-03, 0.0000e+00, 0.0000e+00,
        1.3257e-02, 8.9443e-04, 0.0000e+00, 0.0000e+00, 9.9011e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.6633e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.4177e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:45,223 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.440578074224547
2024-05-15 15:27:45,225 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.698820.15534
2024-05-15 15:27:45,285 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #41: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.023255813953488372, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 6)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.1, '(rev, 1)': 0.02}}
2024-05-15 15:27:45,285 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:45,286 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-05-15 15:27:45,546 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #41: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 6)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.16, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-15 15:27:45,546 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:45,547 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-05-15 15:27:45,923 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #41: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.52, '(min, 1)': 0.08, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-15 15:27:45,923 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:45,924 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-05-15 15:27:46,202 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #41: {'transition': '(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 2, 5, 1, 1),(min, 0)->(exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 3, 5, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.41, '(min, 1)': 0.19, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-15 15:27:46,202 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:46,203 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-05-15 15:27:46,213 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #41: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 0, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 6, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40476190476190477, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.43, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-15 15:27:46,213 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:46,214 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-05-15 15:27:46,401 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #41: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5869565217391305, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(min, 0)': 0.29, '(min, 1)': 0.26, '(rev, 1)': 0.11, '(rev, 2)': 0.05}}
2024-05-15 15:27:46,401 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:46,402 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-05-15 15:27:46,899 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #41: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6428571428571429, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(min, 0)': 0.27, '(min, 1)': 0.36, '(rev, 1)': 0.11, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-15 15:27:46,899 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:46,900 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4401226635151313
2024-05-15 15:27:46,975 - MainProcess - INFO - text_logger.py - 51 - Train epoch #41
2024-05-15 15:27:46,979 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-2.4780e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.8062e-01,
         0.0000e+00,  8.2155e-02,  4.1523e-03,  3.3818e-01,  0.0000e+00,
         2.0960e-02,  1.6970e-03,  0.0000e+00,  0.0000e+00,  1.7971e-02,
         6.1111e-04,  0.0000e+00,  0.0000e+00,  1.3415e-02,  5.1597e-04,
         0.0000e+00,  0.0000e+00,  1.2301e-02,  3.4116e-04,  0.0000e+00,
         0.0000e+00,  1.0902e-02,  3.7958e-04,  0.0000e+00,  0.0000e+00,
         7.9294e-03,  1.3486e-04,  0.0000e+00,  0.0000e+00,  6.2985e-03,
         3.5714e-05,  0.0000e+00,  0.0000e+00,  1.2318e-03,  3.5714e-05,
         0.0000e+00,  0.0000e+00,  1.3438e-04,  0.0000e+00,  0.0000e+00])  tensor([1.8187e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7119e-01, 0.0000e+00,
        1.0330e-01, 8.6674e-03, 1.0216e-01, 0.0000e+00, 3.8422e-02, 5.4138e-03,
        0.0000e+00, 0.0000e+00, 3.5712e-02, 3.4326e-03, 0.0000e+00, 0.0000e+00,
        2.7495e-02, 3.1188e-03, 0.0000e+00, 0.0000e+00, 2.5936e-02, 2.4066e-03,
        0.0000e+00, 0.0000e+00, 2.3552e-02, 2.9703e-03, 0.0000e+00, 0.0000e+00,
        1.7384e-02, 1.5086e-03, 0.0000e+00, 0.0000e+00, 1.4009e-02, 7.9860e-04,
        0.0000e+00, 0.0000e+00, 4.6836e-03, 7.9860e-04, 0.0000e+00, 0.0000e+00,
        1.5078e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:46,993 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4405786971492836
2024-05-15 15:27:46,996 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.471430.17143
2024-05-15 15:27:47,023 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2692307692307692, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 7)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.18, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-15 15:27:47,024 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:47,024 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-05-15 15:27:47,271 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.48, '(min, 1)': 0.11}}
2024-05-15 15:27:47,271 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:47,272 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-05-15 15:27:47,672 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5294117647058824, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.17, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-15 15:27:47,672 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:47,672 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-05-15 15:27:48,038 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.045454545454545456, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.23, '(rev, 1)': 0.04}}
2024-05-15 15:27:48,038 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:48,039 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-05-15 15:27:48,144 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 8)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.31, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-05-15 15:27:48,145 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:48,145 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-05-15 15:27:48,167 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7555555555555555, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(min, 0)': 0.37, '(min, 1)': 0.28, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.07, '(rev, 4)': 0.04}}
2024-05-15 15:27:48,167 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:48,167 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-05-15 15:27:48,327 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #42: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.36, '(min, 1)': 0.2, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-15 15:27:48,327 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:48,328 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.440578074224547
2024-05-15 15:27:48,396 - MainProcess - INFO - text_logger.py - 51 - Train epoch #42
2024-05-15 15:27:48,398 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.1348e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0159e-01, 0.0000e+00,
        6.9313e-02, 4.0843e-03, 3.4256e-01, 0.0000e+00, 1.8941e-02, 2.8893e-03,
        0.0000e+00, 0.0000e+00, 1.4575e-02, 2.1868e-03, 0.0000e+00, 0.0000e+00,
        1.0242e-02, 1.5799e-03, 0.0000e+00, 0.0000e+00, 9.8714e-03, 4.8663e-04,
        0.0000e+00, 0.0000e+00, 8.6144e-03, 3.6796e-04, 0.0000e+00, 0.0000e+00,
        6.2385e-03, 3.0907e-04, 0.0000e+00, 0.0000e+00, 4.9592e-03, 3.6364e-05,
        0.0000e+00, 0.0000e+00, 1.0056e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4532e-04, 0.0000e+00, 0.0000e+00])  tensor([2.0738e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6112e-01, 0.0000e+00,
        9.5430e-02, 8.2663e-03, 9.4860e-02, 0.0000e+00, 3.6711e-02, 6.6710e-03,
        0.0000e+00, 0.0000e+00, 3.2343e-02, 6.0066e-03, 0.0000e+00, 0.0000e+00,
        2.4618e-02, 5.4076e-03, 0.0000e+00, 0.0000e+00, 2.4410e-02, 2.8956e-03,
        0.0000e+00, 0.0000e+00, 2.1474e-02, 2.4863e-03, 0.0000e+00, 0.0000e+00,
        1.5873e-02, 2.2999e-03, 0.0000e+00, 0.0000e+00, 1.2975e-02, 8.1312e-04,
        0.0000e+00, 0.0000e+00, 4.2118e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4692e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:48,414 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43994757404227414
2024-05-15 15:27:48,416 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.155560.15556
2024-05-15 15:27:48,957 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #43: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 4, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 5, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 7)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.16, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-15 15:27:48,957 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:48,958 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-05-15 15:27:49,579 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #43: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 9, 3, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 9, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4594594594594595, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.21, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.04, '(rev, 5)': 0.01}}
2024-05-15 15:27:49,579 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:49,579 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-05-15 15:27:49,621 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #43: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 4, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 6)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.3}}
2024-05-15 15:27:49,621 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:49,622 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-05-15 15:27:49,974 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #43: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.23404255319148937, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.4, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-15 15:27:49,974 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:49,974 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-05-15 15:27:50,052 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #43: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 10)': 0.01, '(ado, 2)': 0.02, '(min, 0)': 0.45, '(min, 1)': 0.2, '(rev, 1)': 0.08, '(rev, 2)': 0.03}}
2024-05-15 15:27:50,052 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:50,052 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-05-15 15:27:50,523 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #43: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.08108108108108109, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(min, 0)': 0.43, '(min, 1)': 0.21, '(rev, 1)': 0.01, '(rev, 3)': 0.01}}
2024-05-15 15:27:50,523 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:50,524 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-05-15 15:27:50,716 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #43: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 1),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 2, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.375, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.3, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-15 15:27:50,716 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:50,717 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4405786971492836
2024-05-15 15:27:50,860 - MainProcess - INFO - text_logger.py - 51 - Train epoch #43
2024-05-15 15:27:50,863 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.5734e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0649e-01, 0.0000e+00,
        7.2479e-02, 3.5302e-03, 3.4712e-01, 0.0000e+00, 1.7472e-02, 2.4893e-03,
        0.0000e+00, 0.0000e+00, 1.3313e-02, 1.6546e-03, 0.0000e+00, 0.0000e+00,
        8.9788e-03, 1.1303e-03, 0.0000e+00, 0.0000e+00, 8.2597e-03, 7.3222e-04,
        0.0000e+00, 0.0000e+00, 6.8963e-03, 5.7088e-04, 0.0000e+00, 0.0000e+00,
        4.1819e-03, 5.1313e-04, 0.0000e+00, 0.0000e+00, 3.2299e-03, 2.3399e-04,
        0.0000e+00, 0.0000e+00, 6.0997e-04, 3.6364e-05, 0.0000e+00, 0.0000e+00,
        8.2695e-05, 0.0000e+00, 0.0000e+00])  tensor([2.2182e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5520e-01, 0.0000e+00,
        9.5556e-02, 7.6240e-03, 9.0552e-02, 0.0000e+00, 3.5798e-02, 5.9175e-03,
        0.0000e+00, 0.0000e+00, 3.0487e-02, 5.0662e-03, 0.0000e+00, 0.0000e+00,
        2.1931e-02, 4.0308e-03, 0.0000e+00, 0.0000e+00, 2.2472e-02, 3.2606e-03,
        0.0000e+00, 0.0000e+00, 1.9894e-02, 2.8554e-03, 0.0000e+00, 0.0000e+00,
        1.3785e-02, 2.7135e-03, 0.0000e+00, 0.0000e+00, 1.1265e-02, 1.8800e-03,
        0.0000e+00, 0.0000e+00, 3.4288e-03, 8.1312e-04, 0.0000e+00, 0.0000e+00,
        1.0798e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:50,878 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4390864209052346
2024-05-15 15:27:50,881 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.040540.04054
2024-05-15 15:27:51,148 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.36, '(min, 1)': 0.27}}
2024-05-15 15:27:51,149 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:51,149 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-05-15 15:27:51,726 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #44: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.07692307692307693, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.31, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-15 15:27:51,726 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:51,727 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-05-15 15:27:51,741 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 4)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.23, '(rev, 1)': 0.02, '(rev, 2)': 0.02, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-15 15:27:51,742 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:51,742 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-05-15 15:27:52,103 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.36, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 3)': 0.03, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.4, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:27:52,103 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:52,104 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-05-15 15:27:52,113 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.29, '(rev, 1)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:27:52,113 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:52,114 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-05-15 15:27:52,141 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.42, '(min, 0)': 0.38, '(min, 1)': 0.2}}
2024-05-15 15:27:52,141 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:52,143 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-05-15 15:27:53,304 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #44: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 5)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.22}}
2024-05-15 15:27:53,304 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:53,305 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43994757404227414
2024-05-15 15:27:53,445 - MainProcess - INFO - text_logger.py - 51 - Train epoch #44
2024-05-15 15:27:53,447 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-7.1114e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.1395e-01,
         0.0000e+00,  1.7042e-01,  2.1033e-03,  2.4171e-01,  0.0000e+00,
         6.2073e-02,  1.4011e-03,  0.0000e+00,  0.0000e+00,  4.9834e-02,
         5.9143e-04,  0.0000e+00,  0.0000e+00,  3.8661e-02,  2.3694e-04,
         0.0000e+00,  0.0000e+00,  3.7497e-02,  5.2094e-04,  0.0000e+00,
         0.0000e+00,  3.4201e-02,  3.2258e-05,  0.0000e+00,  0.0000e+00,
         2.4427e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.8936e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.0899e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.0639e-04,  0.0000e+00,  0.0000e+00])  tensor([1.9727e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2199e-01, 0.0000e+00,
        1.2899e-01, 6.2317e-03, 1.3389e-01, 0.0000e+00, 5.1817e-02, 4.7689e-03,
        0.0000e+00, 0.0000e+00, 4.3491e-02, 3.4349e-03, 0.0000e+00, 0.0000e+00,
        3.5122e-02, 2.0167e-03, 0.0000e+00, 0.0000e+00, 3.5539e-02, 3.9136e-03,
        0.0000e+00, 0.0000e+00, 3.3385e-02, 7.2131e-04, 0.0000e+00, 0.0000e+00,
        2.5788e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1859e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.2711e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.1669e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:53,463 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.438144186687114
2024-05-15 15:27:53,465 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-15 15:27:54,411 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #45: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(min, 0)': 0.3, '(min, 1)': 0.33}}
2024-05-15 15:27:54,412 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:54,414 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-05-15 15:27:54,538 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #45: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 7)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.1}}
2024-05-15 15:27:54,539 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:54,539 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-05-15 15:27:55,037 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #45: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43137254901960786, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.32, '(rev, 1)': 0.03, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-15 15:27:55,037 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:55,038 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-05-15 15:27:55,429 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #45: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3673469387755102, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 9)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.42, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 5)': 0.02}}
2024-05-15 15:27:55,429 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:55,431 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-05-15 15:27:55,884 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #45: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7435897435897436, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 8)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.33, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 5)': 0.02}}
2024-05-15 15:27:55,884 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:55,885 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-05-15 15:27:55,920 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #45: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.52, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 6)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.3, '(rev, 1)': 0.05, '(rev, 5)': 0.01, '(rev, 6)': 0.02}}
2024-05-15 15:27:55,921 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:55,922 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-05-15 15:27:56,863 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #45: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.16326530612244897, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 5)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.14, '(rev, 1)': 0.04, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-15 15:27:56,863 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:56,864 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4390864209052346
2024-05-15 15:27:57,045 - MainProcess - INFO - text_logger.py - 51 - Train epoch #45
2024-05-15 15:27:57,052 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.3675e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3078e-01, 0.0000e+00,
        1.1235e-01, 3.0676e-03, 3.0306e-01, 0.0000e+00, 3.4429e-02, 2.0275e-03,
        0.0000e+00, 0.0000e+00, 2.8253e-02, 1.2080e-03, 0.0000e+00, 0.0000e+00,
        2.1168e-02, 6.7340e-04, 0.0000e+00, 0.0000e+00, 1.9589e-02, 6.9373e-04,
        0.0000e+00, 0.0000e+00, 1.7652e-02, 3.6722e-04, 0.0000e+00, 0.0000e+00,
        1.2531e-02, 1.0588e-04, 0.0000e+00, 0.0000e+00, 9.8324e-03, 3.6364e-05,
        0.0000e+00, 0.0000e+00, 1.8835e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.0031e-04, 0.0000e+00, 0.0000e+00])  tensor([2.4719e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1266e-01, 0.0000e+00,
        1.2858e-01, 7.3583e-03, 1.3013e-01, 0.0000e+00, 4.8757e-02, 5.7518e-03,
        0.0000e+00, 0.0000e+00, 4.3061e-02, 4.6920e-03, 0.0000e+00, 0.0000e+00,
        3.3662e-02, 3.3071e-03, 0.0000e+00, 0.0000e+00, 3.2548e-02, 3.5140e-03,
        0.0000e+00, 0.0000e+00, 2.9749e-02, 2.8631e-03, 0.0000e+00, 0.0000e+00,
        2.2139e-02, 1.3718e-03, 0.0000e+00, 0.0000e+00, 1.8016e-02, 8.1312e-04,
        0.0000e+00, 0.0000e+00, 5.8310e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.1417e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:27:57,075 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43720195246899346
2024-05-15 15:27:57,080 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-15 15:27:57,676 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #46: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.41, '(min, 0)': 0.22, '(min, 1)': 0.37}}
2024-05-15 15:27:57,677 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:57,679 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-05-15 15:27:57,898 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #46: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.22, '(min, 1)': 0.38}}
2024-05-15 15:27:57,899 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:57,900 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-05-15 15:27:59,839 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #46: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3125, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 8)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.25, '(rev, 1)': 0.08, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-15 15:27:59,840 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:27:59,842 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-05-15 15:28:00,569 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #46: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 3, 1, 1),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 4, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.46, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 4)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.26, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.04, '(rev, 4)': 0.01}}
2024-05-15 15:28:00,569 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:00,570 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-05-15 15:28:01,005 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #46: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.48, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-05-15 15:28:01,005 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:01,006 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-05-15 15:28:01,063 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #46: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.09803921568627451, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.53, '(min, 1)': 0.19, '(rev, 1)': 0.01, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-15 15:28:01,063 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:01,064 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-05-15 15:28:01,482 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #46: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.44680851063829785, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.34, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-05-15 15:28:01,482 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:01,482 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.438144186687114
2024-05-15 15:28:01,620 - MainProcess - INFO - text_logger.py - 51 - Train epoch #46
2024-05-15 15:28:01,622 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.0413e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4966e-01, 0.0000e+00,
        9.3711e-02, 3.7625e-03, 3.2611e-01, 0.0000e+00, 3.0168e-02, 1.8121e-03,
        0.0000e+00, 0.0000e+00, 2.3568e-02, 1.3860e-03, 0.0000e+00, 0.0000e+00,
        1.6806e-02, 7.8657e-04, 0.0000e+00, 0.0000e+00, 1.6378e-02, 5.8606e-04,
        0.0000e+00, 0.0000e+00, 1.4641e-02, 3.4387e-04, 0.0000e+00, 0.0000e+00,
        1.0562e-02, 3.0613e-04, 0.0000e+00, 0.0000e+00, 7.7868e-03, 3.6364e-05,
        0.0000e+00, 0.0000e+00, 1.3372e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5569e-04, 0.0000e+00, 0.0000e+00])  tensor([2.2195e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9413e-01, 0.0000e+00,
        1.1056e-01, 8.3025e-03, 1.2154e-01, 0.0000e+00, 4.8304e-02, 5.4450e-03,
        0.0000e+00, 0.0000e+00, 4.0956e-02, 4.6998e-03, 0.0000e+00, 0.0000e+00,
        3.0773e-02, 3.6647e-03, 0.0000e+00, 0.0000e+00, 3.1686e-02, 3.1721e-03,
        0.0000e+00, 0.0000e+00, 2.8886e-02, 2.4388e-03, 0.0000e+00, 0.0000e+00,
        2.2189e-02, 2.2932e-03, 0.0000e+00, 0.0000e+00, 1.7071e-02, 8.1312e-04,
        0.0000e+00, 0.0000e+00, 4.9609e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.0261e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:01,636 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4362597182508729
2024-05-15 15:28:01,638 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-15 15:28:01,700 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #47: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2708333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(min, 0)': 0.19, '(min, 1)': 0.42, '(rev, 1)': 0.03, '(rev, 10)': 0.01}}
2024-05-15 15:28:01,701 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:01,702 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-05-15 15:28:01,753 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #47: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.37, '(ado, 8)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.19}}
2024-05-15 15:28:01,754 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:01,755 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-05-15 15:28:02,641 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #47: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.33, '(min, 1)': 0.29, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-05-15 15:28:02,642 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:02,642 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-05-15 15:28:03,661 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #47: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1875, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 3)': 0.03, '(ado, 8)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.24, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:28:03,662 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:03,663 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-05-15 15:28:04,372 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #47: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 3, 0, 0),(rev, 3)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.27, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-15 15:28:04,372 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:04,373 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-05-15 15:28:05,248 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #47: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 3, 9, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.2}}
2024-05-15 15:28:05,248 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:05,249 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-05-15 15:28:05,766 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #47: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 2, 1, 1),(min, 0)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 3, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.19047619047619047, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 5)': 0.01, '(ado, 6)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.39, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:28:05,766 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:05,767 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43720195246899346
2024-05-15 15:28:05,920 - MainProcess - INFO - text_logger.py - 51 - Train epoch #47
2024-05-15 15:28:05,923 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-1.3567e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.5587e-01,
         0.0000e+00,  1.5011e-01,  1.9760e-03,  2.6737e-01,  0.0000e+00,
         5.0904e-02,  1.4587e-03,  0.0000e+00,  0.0000e+00,  4.1269e-02,
         8.2454e-04,  0.0000e+00,  0.0000e+00,  3.1219e-02,  5.9187e-04,
         0.0000e+00,  0.0000e+00,  3.0360e-02,  2.3752e-04,  0.0000e+00,
         0.0000e+00,  2.8039e-02,  4.0816e-05,  0.0000e+00,  0.0000e+00,
         2.0783e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.5226e-02,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.1162e-03,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.0773e-04,  0.0000e+00,  0.0000e+00])  tensor([2.2636e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2690e-01, 0.0000e+00,
        1.3079e-01, 6.2641e-03, 1.4596e-01, 0.0000e+00, 5.4243e-02, 4.8474e-03,
        0.0000e+00, 0.0000e+00, 4.6247e-02, 3.7843e-03, 0.0000e+00, 0.0000e+00,
        3.7190e-02, 3.3883e-03, 0.0000e+00, 0.0000e+00, 3.7975e-02, 2.0146e-03,
        0.0000e+00, 0.0000e+00, 3.5814e-02, 9.1268e-04, 0.0000e+00, 0.0000e+00,
        2.8133e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2301e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.5571e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.0905e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:05,941 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43558831736608566
2024-05-15 15:28:05,944 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.135420.13542
2024-05-15 15:28:05,968 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #48: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 6, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 3)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.26, '(rev, 1)': 0.04, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:28:05,968 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:05,969 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729
2024-05-15 15:28:05,984 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #48: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.05263157894736842, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(min, 0)': 0.37, '(min, 1)': 0.24, '(rev, 1)': 0.02, '(rev, 2)': 0.01}}
2024-05-15 15:28:05,985 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:05,986 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729
2024-05-15 15:28:05,999 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #48: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.24, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 5)': 0.01}}
2024-05-15 15:28:06,000 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:06,001 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729
2024-05-15 15:28:07,093 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #48: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0),(rev, 2)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5714285714285714, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(min, 0)': 0.3, '(min, 1)': 0.29, '(rev, 1)': 0.12, '(rev, 2)': 0.07, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-05-15 15:28:07,094 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:07,094 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729
2024-05-15 15:28:07,745 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #48: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 2, 0, 1),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 1, 0, 1)', 'reward_ratio': '0/1', 'revenue': 0.23404255319148937, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.03, '(ado, 5)': 0.02, '(min, 0)': 0.39, '(min, 1)': 0.29, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-15 15:28:07,746 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:07,747 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729
2024-05-15 15:28:08,669 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #48: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.4074074074074074, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.15, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-15 15:28:08,669 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:08,669 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729
2024-05-15 15:28:08,932 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #48: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 8)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.35, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-05-15 15:28:08,932 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:08,933 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4362597182508729
2024-05-15 15:28:09,072 - MainProcess - INFO - text_logger.py - 51 - Train epoch #48
2024-05-15 15:28:09,075 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.8644e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8341e-01, 0.0000e+00,
        8.0020e-02, 3.8365e-03, 3.5160e-01, 0.0000e+00, 1.9837e-02, 2.8473e-03,
        0.0000e+00, 0.0000e+00, 1.4915e-02, 1.9913e-03, 0.0000e+00, 0.0000e+00,
        1.0716e-02, 9.7278e-04, 0.0000e+00, 0.0000e+00, 9.4654e-03, 5.9830e-04,
        0.0000e+00, 0.0000e+00, 8.0379e-03, 2.0826e-04, 0.0000e+00, 0.0000e+00,
        6.4292e-03, 7.4773e-05, 0.0000e+00, 0.0000e+00, 4.4028e-03, 7.4773e-05,
        0.0000e+00, 0.0000e+00, 5.6576e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.0909e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5989e-01, 0.0000e+00,
        1.0039e-01, 8.4677e-03, 1.0190e-01, 0.0000e+00, 3.8609e-02, 6.9654e-03,
        0.0000e+00, 0.0000e+00, 3.3519e-02, 5.7357e-03, 0.0000e+00, 0.0000e+00,
        2.6686e-02, 4.0771e-03, 0.0000e+00, 0.0000e+00, 2.5305e-02, 3.3263e-03,
        0.0000e+00, 0.0000e+00, 2.2419e-02, 2.2779e-03, 0.0000e+00, 0.0000e+00,
        1.8722e-02, 1.1811e-03, 0.0000e+00, 0.0000e+00, 1.3333e-02, 1.1811e-03,
        0.0000e+00, 0.0000e+00, 3.5065e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:09,091 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4350987147269124
2024-05-15 15:28:09,093 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.226320.17368
2024-05-15 15:28:09,104 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #49: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.02, '(min, 0)': 0.14, '(min, 1)': 0.43, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-15 15:28:09,104 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:09,105 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43558831736608566
2024-05-15 15:28:09,152 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #49: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 3, 9, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 4, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.4, '(min, 0)': 0.48, '(min, 1)': 0.12}}
2024-05-15 15:28:09,152 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:09,153 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43558831736608566
2024-05-15 15:28:09,177 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #49: {'transition': '(exi, wit, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 4, 9, 1, 1),(min, 0)->(exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 1, 5, 9, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.36, '(ado, 7)': 0.01, '(min, 0)': 0.43, '(min, 1)': 0.2}}
2024-05-15 15:28:09,177 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:09,178 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43558831736608566
2024-05-15 15:28:09,520 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #49: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4523809523809524, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.02, '(min, 0)': 0.31, '(min, 1)': 0.32, '(rev, 1)': 0.04, '(rev, 3)': 0.02}}
2024-05-15 15:28:09,520 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:09,521 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43558831736608566
2024-05-15 15:28:10,061 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #49: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.34, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:28:10,061 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:10,061 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43558831736608566
2024-05-15 15:28:10,607 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #49: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.28, '(min, 1)': 0.33, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-05-15 15:28:10,608 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:10,608 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43558831736608566
2024-05-15 15:28:10,731 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #49: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.275, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.04, '(min, 0)': 0.26, '(min, 1)': 0.35, '(rev, 1)': 0.1, '(rev, 2)': 0.04}}
2024-05-15 15:28:10,731 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:10,732 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43558831736608566
2024-05-15 15:28:10,866 - MainProcess - INFO - text_logger.py - 51 - Train epoch #49
2024-05-15 15:28:10,869 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.7844e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2157e-01, 0.0000e+00,
        5.4320e-02, 4.9637e-03, 3.7244e-01, 0.0000e+00, 1.1496e-02, 3.3140e-03,
        0.0000e+00, 0.0000e+00, 7.9989e-03, 1.8463e-03, 0.0000e+00, 0.0000e+00,
        5.7487e-03, 4.6123e-04, 0.0000e+00, 0.0000e+00, 4.7484e-03, 1.0131e-04,
        0.0000e+00, 0.0000e+00, 4.6222e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4616e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4700e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.0578e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.1250e-05, 0.0000e+00, 0.0000e+00])  tensor([1.5525e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2212e-01, 0.0000e+00,
        7.0607e-02, 9.3715e-03, 7.6340e-02, 0.0000e+00, 3.1169e-02, 7.2097e-03,
        0.0000e+00, 0.0000e+00, 2.5902e-02, 5.9269e-03, 0.0000e+00, 0.0000e+00,
        2.1061e-02, 2.7484e-03, 0.0000e+00, 0.0000e+00, 1.8780e-02, 1.3064e-03,
        0.0000e+00, 0.0000e+00, 1.8274e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4250e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0725e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.9071e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.9877e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:10,885 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43415648050879185
2024-05-15 15:28:10,886 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.000000.00000
2024-05-15 15:28:11,040 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #50: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0967741935483871, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.56, '(min, 1)': 0.11, '(rev, 1)': 0.03, '(rev, 2)': 0.02}}
2024-05-15 15:28:11,040 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:11,041 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4350987147269124
2024-05-15 15:28:11,188 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #50: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32558139534883723, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.33, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-15 15:28:11,188 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:11,189 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4350987147269124
2024-05-15 15:28:11,545 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #50: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 0, 8, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 0, 0, 7, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.13157894736842105, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.19, '(rev, 1)': 0.05, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-15 15:28:11,546 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:11,547 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4350987147269124
2024-05-15 15:28:12,077 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #50: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.03, '(min, 0)': 0.24, '(min, 1)': 0.41, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-15 15:28:12,077 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:12,078 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4350987147269124
2024-05-15 15:28:12,088 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #50: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0),(rev, 2)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43243243243243246, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.2, '(min, 1)': 0.41, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-15 15:28:12,088 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:12,089 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4350987147269124
2024-05-15 15:28:12,747 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #50: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.06521739130434782, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(ado, 9)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.28, '(rev, 1)': 0.03, '(rev, 2)': 0.03}}
2024-05-15 15:28:12,747 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:12,748 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4350987147269124
2024-05-15 15:28:12,924 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #50: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.23684210526315788, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 3)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.42, '(min, 1)': 0.28, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-15 15:28:12,924 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:12,925 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4350987147269124
2024-05-15 15:28:13,063 - MainProcess - INFO - text_logger.py - 51 - Train epoch #50
2024-05-15 15:28:13,066 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.7318e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7669e-01, 0.0000e+00,
        8.8320e-02, 3.9829e-03, 3.5464e-01, 0.0000e+00, 2.0432e-02, 2.9770e-03,
        0.0000e+00, 0.0000e+00, 1.4041e-02, 2.1318e-03, 0.0000e+00, 0.0000e+00,
        9.8043e-03, 6.4910e-04, 0.0000e+00, 0.0000e+00, 8.2357e-03, 2.2072e-04,
        0.0000e+00, 0.0000e+00, 8.2472e-03, 2.7397e-05, 0.0000e+00, 0.0000e+00,
        5.6174e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6024e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.8572e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.8686e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6113e-01, 0.0000e+00,
        1.1699e-01, 8.5795e-03, 1.0229e-01, 0.0000e+00, 4.0138e-02, 6.7260e-03,
        0.0000e+00, 0.0000e+00, 3.1683e-02, 6.2419e-03, 0.0000e+00, 0.0000e+00,
        2.4432e-02, 3.1691e-03, 0.0000e+00, 0.0000e+00, 2.1624e-02, 1.7611e-03,
        0.0000e+00, 0.0000e+00, 2.2469e-02, 6.1262e-04, 0.0000e+00, 0.0000e+00,
        1.6901e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1979e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.8873e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:13,083 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4334425994315881
2024-05-15 15:28:13,085 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.114180.01740
2024-05-15 15:28:13,143 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #51: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.09090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.28, '(rev, 1)': 0.05, '(rev, 2)': 0.02}}
2024-05-15 15:28:13,143 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:13,144 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43415648050879185
2024-05-15 15:28:13,978 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #51: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5098039215686274, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 8)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.3, '(rev, 1)': 0.05, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-05-15 15:28:13,979 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:13,981 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43415648050879185
2024-05-15 15:28:13,989 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #51: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(min, 0)': 0.12, '(min, 1)': 0.44, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-15 15:28:13,989 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:13,990 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43415648050879185
2024-05-15 15:28:14,824 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #51: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 1, 9, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 2, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.57, '(min, 1)': 0.1}}
2024-05-15 15:28:14,824 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:14,825 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43415648050879185
2024-05-15 15:28:15,123 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #51: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.42, 'length': 100, 'actions': {'(ado, 1)': 0.34, '(ado, 5)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.25, '(rev, 1)': 0.03, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:28:15,123 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:15,124 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43415648050879185
2024-05-15 15:28:15,250 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #51: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7021276595744681, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(min, 0)': 0.34, '(min, 1)': 0.36, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 6)': 0.01, '(rev, 8)': 0.01}}
2024-05-15 15:28:15,250 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:15,251 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43415648050879185
2024-05-15 15:28:15,431 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #51: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.39215686274509803, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(ado, 7)': 0.02, '(min, 0)': 0.2, '(min, 1)': 0.41, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-15 15:28:15,432 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:15,434 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43415648050879185
2024-05-15 15:28:15,596 - MainProcess - INFO - text_logger.py - 51 - Train epoch #51
2024-05-15 15:28:15,600 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.0092e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4926e-01, 0.0000e+00,
        9.5926e-02, 4.5311e-03, 3.2863e-01, 0.0000e+00, 2.7861e-02, 2.2772e-03,
        0.0000e+00, 0.0000e+00, 2.2054e-02, 1.1543e-03, 0.0000e+00, 0.0000e+00,
        1.7267e-02, 8.6356e-04, 0.0000e+00, 0.0000e+00, 1.5041e-02, 3.5569e-04,
        0.0000e+00, 0.0000e+00, 1.3989e-02, 6.0400e-04, 0.0000e+00, 0.0000e+00,
        1.1777e-02, 3.8462e-05, 0.0000e+00, 0.0000e+00, 7.0973e-03, 6.0606e-05,
        0.0000e+00, 0.0000e+00, 9.9993e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.0914e-04, 0.0000e+00, 0.0000e+00])  tensor([2.7567e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9100e-01, 0.0000e+00,
        1.0712e-01, 9.3869e-03, 1.2441e-01, 0.0000e+00, 4.7908e-02, 6.2216e-03,
        0.0000e+00, 0.0000e+00, 4.1487e-02, 4.5771e-03, 0.0000e+00, 0.0000e+00,
        3.4284e-02, 4.0533e-03, 0.0000e+00, 0.0000e+00, 3.1003e-02, 2.4089e-03,
        0.0000e+00, 0.0000e+00, 2.9316e-02, 4.1196e-03, 0.0000e+00, 0.0000e+00,
        2.5103e-02, 8.6003e-04, 0.0000e+00, 0.0000e+00, 1.7098e-02, 1.3552e-03,
        0.0000e+00, 0.0000e+00, 4.3303e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7938e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:15,620 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4330101691350361
2024-05-15 15:28:15,624 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.254900.25490
2024-05-15 15:28:15,645 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #52: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3617021276595745, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.25, '(min, 1)': 0.3, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 4)': 0.01}}
2024-05-15 15:28:15,646 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:15,646 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4334425994315881
2024-05-15 15:28:16,331 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #52: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5217391304347826, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.51, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 7)': 0.01}}
2024-05-15 15:28:16,331 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:16,332 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4334425994315881
2024-05-15 15:28:16,833 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #52: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8095238095238095, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(min, 0)': 0.42, '(min, 1)': 0.19, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-15 15:28:16,833 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:16,834 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4334425994315881
2024-05-15 15:28:17,249 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #52: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5416666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(min, 0)': 0.34, '(min, 1)': 0.21, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-15 15:28:17,249 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:17,250 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4334425994315881
2024-05-15 15:28:17,671 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #52: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 4, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.27, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-15 15:28:17,671 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:17,672 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4334425994315881
2024-05-15 15:28:17,737 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #52: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2608695652173913, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.15, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-15 15:28:17,738 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:17,739 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4334425994315881
2024-05-15 15:28:18,010 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #52: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6585365853658537, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(min, 0)': 0.27, '(min, 1)': 0.4, '(rev, 1)': 0.11, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-05-15 15:28:18,010 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:18,011 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4334425994315881
2024-05-15 15:28:18,182 - MainProcess - INFO - text_logger.py - 51 - Train epoch #52
2024-05-15 15:28:18,187 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.9688e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1647e-01, 0.0000e+00,
        6.1197e-02, 5.3188e-03, 3.7817e-01, 0.0000e+00, 1.1213e-02, 3.0371e-03,
        0.0000e+00, 0.0000e+00, 6.8769e-03, 1.7143e-03, 0.0000e+00, 0.0000e+00,
        4.2821e-03, 9.0427e-04, 0.0000e+00, 0.0000e+00, 3.3658e-03, 3.1769e-04,
        0.0000e+00, 0.0000e+00, 3.1542e-03, 2.5696e-04, 0.0000e+00, 0.0000e+00,
        2.2226e-03, 1.5060e-04, 0.0000e+00, 0.0000e+00, 1.1751e-03, 2.7778e-05,
        0.0000e+00, 0.0000e+00, 1.1316e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4483e-05, 0.0000e+00, 0.0000e+00])  tensor([1.6400e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1254e-01, 0.0000e+00,
        7.9106e-02, 9.7767e-03, 6.7764e-02, 0.0000e+00, 2.9021e-02, 7.0918e-03,
        0.0000e+00, 0.0000e+00, 2.2897e-02, 5.3889e-03, 0.0000e+00, 0.0000e+00,
        1.7412e-02, 3.8467e-03, 0.0000e+00, 0.0000e+00, 1.4939e-02, 2.1409e-03,
        0.0000e+00, 0.0000e+00, 1.4528e-02, 1.9138e-03, 0.0000e+00, 0.0000e+00,
        1.0967e-02, 1.7986e-03, 0.0000e+00, 0.0000e+00, 7.1421e-03, 6.2113e-04,
        0.0000e+00, 0.0000e+00, 1.5088e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.7106e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:18,207 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.433419125393106
2024-05-15 15:28:18,210 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.675600.13393
2024-05-15 15:28:19,029 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #53: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 7, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 7, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.9285714285714286, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.02, '(min, 0)': 0.21, '(min, 1)': 0.45, '(rev, 1)': 0.09, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 6)': 0.01}}
2024-05-15 15:28:19,029 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:19,030 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4330101691350361
2024-05-15 15:28:19,846 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #53: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.43902439024390244, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.49, '(rev, 1)': 0.12, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-05-15 15:28:19,846 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:19,847 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4330101691350361
2024-05-15 15:28:20,300 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #53: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 7)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.25, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.01, '(rev, 7)': 0.01}}
2024-05-15 15:28:20,300 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:20,301 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4330101691350361
2024-05-15 15:28:20,569 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #53: {'transition': '(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 2, 4, 1, 1),(min, 0)->(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 2, 5, 1, 1)', 'reward_ratio': '0/0', 'revenue': 1.3095238095238095, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.51, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 4)': 0.01, '(rev, 8)': 0.01}}
2024-05-15 15:28:20,570 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:20,570 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4330101691350361
2024-05-15 15:28:20,611 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #53: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.4444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 3)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.34, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-15 15:28:20,612 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:20,613 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4330101691350361
2024-05-15 15:28:20,968 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #53: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2708333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.38, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-15 15:28:20,968 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:20,969 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4330101691350361
2024-05-15 15:28:22,279 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #53: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6585365853658537, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.29, '(min, 1)': 0.42, '(rev, 1)': 0.06, '(rev, 3)': 0.04, '(rev, 4)': 0.02}}
2024-05-15 15:28:22,279 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:22,279 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4330101691350361
2024-05-15 15:28:22,349 - MainProcess - INFO - text_logger.py - 51 - Train epoch #53
2024-05-15 15:28:22,351 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.7046e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2815e-01, 0.0000e+00,
        5.5707e-02, 4.8250e-03, 3.6947e-01, 0.0000e+00, 9.7838e-03, 3.8373e-03,
        0.0000e+00, 0.0000e+00, 6.6349e-03, 2.0325e-03, 0.0000e+00, 0.0000e+00,
        4.7114e-03, 1.2539e-03, 0.0000e+00, 0.0000e+00, 3.6491e-03, 7.4801e-04,
        0.0000e+00, 0.0000e+00, 3.6980e-03, 4.4119e-04, 0.0000e+00, 0.0000e+00,
        2.6908e-03, 1.0643e-04, 0.0000e+00, 0.0000e+00, 1.7137e-03, 2.2841e-04,
        0.0000e+00, 0.0000e+00, 2.7813e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2787e-05, 0.0000e+00, 0.0000e+00])  tensor([3.0576e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2294e-01, 0.0000e+00,
        9.3034e-02, 9.3650e-03, 7.5776e-02, 0.0000e+00, 2.8158e-02, 7.9409e-03,
        0.0000e+00, 0.0000e+00, 2.2937e-02, 5.9631e-03, 0.0000e+00, 0.0000e+00,
        1.8234e-02, 4.4760e-03, 0.0000e+00, 0.0000e+00, 1.5299e-02, 3.4627e-03,
        0.0000e+00, 0.0000e+00, 1.5729e-02, 2.6425e-03, 0.0000e+00, 0.0000e+00,
        1.2306e-02, 1.3748e-03, 0.0000e+00, 0.0000e+00, 8.1597e-03, 2.5782e-03,
        0.0000e+00, 0.0000e+00, 2.2356e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.3314e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:22,366 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4335798722047957
2024-05-15 15:28:22,368 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.551490.10705
2024-05-15 15:28:22,413 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #54: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4523809523809524, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.18, '(min, 1)': 0.49, '(rev, 1)': 0.03, '(rev, 2)': 0.03, '(rev, 4)': 0.02, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-15 15:28:22,414 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:22,414 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.433419125393106
2024-05-15 15:28:22,430 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #54: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6363636363636364, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 5)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.36, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.03, '(rev, 4)': 0.02, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-15 15:28:22,430 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:22,431 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.433419125393106
2024-05-15 15:28:22,624 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #54: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.15555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 7)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.39, '(rev, 1)': 0.06, '(rev, 3)': 0.01}}
2024-05-15 15:28:22,624 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:22,625 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.433419125393106
2024-05-15 15:28:22,892 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #54: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7857142857142857, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 4)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.29, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-15 15:28:22,892 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:22,893 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.433419125393106
2024-05-15 15:28:22,952 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #54: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 9, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 8, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.47368421052631576, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(min, 0)': 0.21, '(min, 1)': 0.43, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:28:22,952 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:22,953 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.433419125393106
2024-05-15 15:28:22,970 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #54: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.38636363636363635, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(min, 0)': 0.48, '(min, 1)': 0.13, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.05}}
2024-05-15 15:28:22,970 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:22,971 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.433419125393106
2024-05-15 15:28:24,016 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #54: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.15384615384615385, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.05, '(ado, 5)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.42, '(rev, 1)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-15 15:28:24,017 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:24,017 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.433419125393106
2024-05-15 15:28:24,090 - MainProcess - INFO - text_logger.py - 51 - Train epoch #54
2024-05-15 15:28:24,092 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.3155e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0670e-01, 0.0000e+00,
        6.4310e-02, 5.0441e-03, 3.8153e-01, 0.0000e+00, 1.1692e-02, 3.5197e-03,
        0.0000e+00, 0.0000e+00, 7.0833e-03, 2.1090e-03, 0.0000e+00, 0.0000e+00,
        4.6380e-03, 1.3144e-03, 0.0000e+00, 0.0000e+00, 3.4514e-03, 6.2476e-04,
        0.0000e+00, 0.0000e+00, 3.1840e-03, 4.6936e-04, 0.0000e+00, 0.0000e+00,
        2.2642e-03, 2.5836e-04, 0.0000e+00, 0.0000e+00, 1.5286e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.2337e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.7310e-05, 0.0000e+00, 0.0000e+00])  tensor([1.9280e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1308e-01, 0.0000e+00,
        8.2645e-02, 9.5476e-03, 7.1158e-02, 0.0000e+00, 2.8564e-02, 7.5056e-03,
        0.0000e+00, 0.0000e+00, 2.2691e-02, 5.7452e-03, 0.0000e+00, 0.0000e+00,
        1.8018e-02, 4.8627e-03, 0.0000e+00, 0.0000e+00, 1.5290e-02, 3.0530e-03,
        0.0000e+00, 0.0000e+00, 1.4599e-02, 2.9039e-03, 0.0000e+00, 0.0000e+00,
        1.0953e-02, 2.3999e-03, 0.0000e+00, 0.0000e+00, 7.8551e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.0605e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.2786e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:24,106 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43326516835104767
2024-05-15 15:28:24,108 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.313770.15992
2024-05-15 15:28:24,234 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #55: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.26666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.02, '(min, 0)': 0.15, '(min, 1)': 0.41, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-15 15:28:24,234 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:24,235 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4335798722047957
2024-05-15 15:28:24,603 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #55: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.2, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 6)': 0.01}}
2024-05-15 15:28:24,603 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:24,603 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4335798722047957
2024-05-15 15:28:24,667 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #55: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 4)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.26, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.02, '(rev, 6)': 0.01}}
2024-05-15 15:28:24,667 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:24,668 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4335798722047957
2024-05-15 15:28:24,728 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #55: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 3, 0, 0),(rev, 4)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '4/4', 'revenue': 0.723404255319149, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(min, 0)': 0.36, '(min, 1)': 0.29, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.07, '(rev, 4)': 0.05}}
2024-05-15 15:28:24,729 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:24,729 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4335798722047957
2024-05-15 15:28:25,013 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #55: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 1),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 2, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.7111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.06, '(min, 1)': 0.57, '(rev, 1)': 0.12, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-05-15 15:28:25,013 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:25,013 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4335798722047957
2024-05-15 15:28:25,184 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #55: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 5, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 4, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.37209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(min, 0)': 0.38, '(min, 1)': 0.29, '(rev, 1)': 0.02, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:28:25,184 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:25,185 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4335798722047957
2024-05-15 15:28:26,041 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #55: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24390243902439024, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 7)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.38, '(rev, 1)': 0.03, '(rev, 2)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:28:26,041 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:26,042 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4335798722047957
2024-05-15 15:28:26,118 - MainProcess - INFO - text_logger.py - 51 - Train epoch #55
2024-05-15 15:28:26,120 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.1923e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9486e-01, 0.0000e+00,
        7.6800e-02, 4.1114e-03, 3.6307e-01, 0.0000e+00, 1.6038e-02, 2.4869e-03,
        0.0000e+00, 0.0000e+00, 1.1245e-02, 1.3042e-03, 0.0000e+00, 0.0000e+00,
        8.1422e-03, 9.8946e-04, 0.0000e+00, 0.0000e+00, 6.3933e-03, 5.7649e-04,
        0.0000e+00, 0.0000e+00, 5.5593e-03, 2.0258e-04, 0.0000e+00, 0.0000e+00,
        4.7936e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5853e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.5348e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8769e-04, 0.0000e+00, 0.0000e+00])  tensor([2.0153e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4004e-01, 0.0000e+00,
        9.0705e-02, 9.0911e-03, 9.0018e-02, 0.0000e+00, 3.5382e-02, 6.4220e-03,
        0.0000e+00, 0.0000e+00, 2.9216e-02, 4.6350e-03, 0.0000e+00, 0.0000e+00,
        2.4816e-02, 4.1828e-03, 0.0000e+00, 0.0000e+00, 2.0835e-02, 3.3317e-03,
        0.0000e+00, 0.0000e+00, 1.8836e-02, 1.8521e-03, 0.0000e+00, 0.0000e+00,
        1.6716e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.7176e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.5301e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7275e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:26,142 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43329024082727063
2024-05-15 15:28:26,145 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.483650.23975
2024-05-15 15:28:26,284 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #56: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4523809523809524, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.2, '(rev, 1)': 0.14, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:28:26,284 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:26,284 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43326516835104767
2024-05-15 15:28:26,367 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #56: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 3)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.41, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.03}}
2024-05-15 15:28:26,367 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:26,368 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43326516835104767
2024-05-15 15:28:26,425 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #56: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.29545454545454547, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.28, '(rev, 1)': 0.11, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:28:26,425 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:26,426 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43326516835104767
2024-05-15 15:28:27,017 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #56: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36363636363636365, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.42, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:28:27,017 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:27,018 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43326516835104767
2024-05-15 15:28:27,048 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #56: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 5)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.28, '(rev, 1)': 0.08, '(rev, 4)': 0.01}}
2024-05-15 15:28:27,049 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:27,049 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43326516835104767
2024-05-15 15:28:27,194 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #56: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3902439024390244, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.43, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:28:27,195 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:27,195 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43326516835104767
2024-05-15 15:28:27,933 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #56: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(min, 0)': 0.4, '(min, 1)': 0.22, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 4)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-15 15:28:27,933 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:27,934 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43326516835104767
2024-05-15 15:28:28,008 - MainProcess - INFO - text_logger.py - 51 - Train epoch #56
2024-05-15 15:28:28,011 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-8.4694e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  5.0568e-01,
         0.0000e+00,  7.1448e-02,  4.5858e-03,  3.8496e-01,  0.0000e+00,
         1.0374e-02,  3.0817e-03,  0.0000e+00,  0.0000e+00,  6.1425e-03,
         1.5045e-03,  0.0000e+00,  0.0000e+00,  3.9272e-03,  5.1647e-04,
         0.0000e+00,  0.0000e+00,  2.6775e-03,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  2.1462e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         1.6636e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1145e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4439e-04,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.0769e-05,  0.0000e+00,  0.0000e+00])  tensor([1.4802e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0299e-01, 0.0000e+00,
        7.5939e-02, 9.5103e-03, 6.2443e-02, 0.0000e+00, 2.6818e-02, 7.5404e-03,
        0.0000e+00, 0.0000e+00, 2.0626e-02, 5.1342e-03, 0.0000e+00, 0.0000e+00,
        1.6469e-02, 3.4787e-03, 0.0000e+00, 0.0000e+00, 1.2604e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1259e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.1846e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2273e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.6556e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.8802e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:28,028 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43304346115460457
2024-05-15 15:28:28,030 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.347730.05227
2024-05-15 15:28:28,093 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #57: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40476190476190477, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.26, '(min, 1)': 0.34, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-15 15:28:28,093 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:28,094 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43329024082727063
2024-05-15 15:28:28,223 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #57: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36363636363636365, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.14, '(min, 1)': 0.47, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 7)': 0.01, '(rev, 8)': 0.01}}
2024-05-15 15:28:28,223 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:28,223 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43329024082727063
2024-05-15 15:28:28,345 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #57: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7027027027027027, 'length': 100, 'actions': {'(ado, 1)': 0.09, '(ado, 2)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.31, '(rev, 1)': 0.12, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.02}}
2024-05-15 15:28:28,345 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:28,346 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43329024082727063
2024-05-15 15:28:28,848 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #57: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3617021276595745, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.47, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 7)': 0.01, '(rev, 8)': 0.01}}
2024-05-15 15:28:28,849 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:28,849 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43329024082727063
2024-05-15 15:28:28,852 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #57: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3617021276595745, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.28, '(rev, 1)': 0.07, '(rev, 2)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 7)': 0.01}}
2024-05-15 15:28:28,852 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:28,852 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43329024082727063
2024-05-15 15:28:29,367 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #57: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2653061224489796, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.03, '(min, 0)': 0.46, '(min, 1)': 0.11, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-15 15:28:29,368 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:29,368 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43329024082727063
2024-05-15 15:28:29,552 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #57: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.22, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 5)': 0.02}}
2024-05-15 15:28:29,552 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:29,553 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43329024082727063
2024-05-15 15:28:29,689 - MainProcess - INFO - text_logger.py - 51 - Train epoch #57
2024-05-15 15:28:29,691 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0844e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4038e-01, 0.0000e+00,
        5.2713e-02, 5.0531e-03, 3.8055e-01, 0.0000e+00, 5.4900e-03, 3.7189e-03,
        0.0000e+00, 0.0000e+00, 2.5312e-03, 2.2204e-03, 0.0000e+00, 0.0000e+00,
        1.0874e-03, 1.8590e-03, 0.0000e+00, 0.0000e+00, 4.3162e-04, 1.5009e-03,
        0.0000e+00, 0.0000e+00, 1.4820e-04, 9.3969e-04, 0.0000e+00, 0.0000e+00,
        7.0523e-05, 7.4857e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5111e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.6849e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.4061e-02, 0.0000e+00,
        8.3042e-02, 9.7892e-03, 3.8066e-02, 0.0000e+00, 1.5235e-02, 7.8811e-03,
        0.0000e+00, 0.0000e+00, 1.0235e-02, 5.8614e-03, 0.0000e+00, 0.0000e+00,
        6.2598e-03, 5.3358e-03, 0.0000e+00, 0.0000e+00, 3.6088e-03, 4.8574e-03,
        0.0000e+00, 0.0000e+00, 1.6558e-03, 3.7375e-03, 0.0000e+00, 0.0000e+00,
        1.1167e-03, 3.4112e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5325e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:29,706 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43277129496369493
2024-05-15 15:28:29,709 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.335030.06973
2024-05-15 15:28:29,840 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #58: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1590909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.03, '(ado, 3)': 0.02, '(min, 0)': 0.37, '(min, 1)': 0.23, '(rev, 1)': 0.09, '(rev, 2)': 0.01}}
2024-05-15 15:28:29,840 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:29,841 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43304346115460457
2024-05-15 15:28:30,298 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #58: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6363636363636364, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 3)': 0.01, '(min, 0)': 0.12, '(min, 1)': 0.47, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-15 15:28:30,298 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:30,299 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43304346115460457
2024-05-15 15:28:30,691 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #58: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5306122448979592, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.03, '(ado, 4)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.41, '(rev, 1)': 0.06, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-15 15:28:30,691 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:30,691 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43304346115460457
2024-05-15 15:28:30,942 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #58: {'transition': '(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 2, 6, 1, 1),(min, 0)->(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, rel, 1, 2, 7, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.3170731707317073, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.17, '(min, 1)': 0.49, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-15 15:28:30,942 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:30,942 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43304346115460457
2024-05-15 15:28:31,054 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #58: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.42, '(min, 1)': 0.23, '(rev, 1)': 0.03, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-05-15 15:28:31,054 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:31,055 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43304346115460457
2024-05-15 15:28:31,266 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #58: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6428571428571429, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.26, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-15 15:28:31,267 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:31,267 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43304346115460457
2024-05-15 15:28:31,503 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #58: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.425, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 4)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.27, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-15 15:28:31,503 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:31,503 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43304346115460457
2024-05-15 15:28:31,636 - MainProcess - INFO - text_logger.py - 51 - Train epoch #58
2024-05-15 15:28:31,639 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.5619e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9517e-01, 0.0000e+00,
        7.2724e-02, 5.0066e-03, 3.7806e-01, 0.0000e+00, 1.4500e-02, 3.9404e-03,
        0.0000e+00, 0.0000e+00, 8.8893e-03, 1.8587e-03, 0.0000e+00, 0.0000e+00,
        5.7673e-03, 9.6552e-04, 0.0000e+00, 0.0000e+00, 4.4258e-03, 5.8635e-04,
        0.0000e+00, 0.0000e+00, 3.6978e-03, 2.5196e-04, 0.0000e+00, 0.0000e+00,
        2.4382e-03, 3.4483e-05, 0.0000e+00, 0.0000e+00, 1.4715e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.7171e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.1746e-05, 0.0000e+00, 0.0000e+00])  tensor([1.9504e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2343e-01, 0.0000e+00,
        8.6693e-02, 9.9874e-03, 7.5393e-02, 0.0000e+00, 3.3923e-02, 8.5943e-03,
        0.0000e+00, 0.0000e+00, 2.5429e-02, 5.4450e-03, 0.0000e+00, 0.0000e+00,
        1.9350e-02, 4.0087e-03, 0.0000e+00, 0.0000e+00, 1.7197e-02, 2.9857e-03,
        0.0000e+00, 0.0000e+00, 1.5656e-02, 2.3442e-03, 0.0000e+00, 0.0000e+00,
        1.1920e-02, 7.7106e-04, 0.0000e+00, 0.0000e+00, 7.4987e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.7502e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.0986e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:31,656 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4331082815247951
2024-05-15 15:28:31,659 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.639610.00325
2024-05-15 15:28:31,668 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #59: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.4791666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.44, '(rev, 1)': 0.05, '(rev, 2)': 0.08, '(rev, 3)': 0.04}}
2024-05-15 15:28:31,668 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:31,669 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43277129496369493
2024-05-15 15:28:32,074 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #59: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6511627906976745, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(min, 0)': 0.31, '(min, 1)': 0.34, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.03, '(rev, 7)': 0.01, '(rev, 8)': 0.01}}
2024-05-15 15:28:32,074 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:32,075 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43277129496369493
2024-05-15 15:28:32,092 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #59: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.18, '(min, 1)': 0.41, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-15 15:28:32,092 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:32,093 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43277129496369493
2024-05-15 15:28:32,615 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #59: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.27450980392156865, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.31, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-05-15 15:28:32,615 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:32,615 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43277129496369493
2024-05-15 15:28:32,678 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #59: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5348837209302325, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(min, 0)': 0.22, '(min, 1)': 0.4, '(rev, 1)': 0.13, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-15 15:28:32,678 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:32,679 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43277129496369493
2024-05-15 15:28:33,148 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #59: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.08695652173913043, 'length': 100, 'actions': {'(ado, 1)': 0.38, '(ado, 2)': 0.02, '(min, 0)': 0.22, '(min, 1)': 0.33, '(rev, 1)': 0.05}}
2024-05-15 15:28:33,148 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:33,149 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43277129496369493
2024-05-15 15:28:33,296 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #59: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.39215686274509803, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.39, '(min, 1)': 0.21, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 5)': 0.01}}
2024-05-15 15:28:33,296 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:33,297 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43277129496369493
2024-05-15 15:28:33,431 - MainProcess - INFO - text_logger.py - 51 - Train epoch #59
2024-05-15 15:28:33,434 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.6486e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.9808e-01,
         0.0000e+00,  7.5711e-02,  5.4752e-03,  3.5751e-01,  0.0000e+00,
         1.6264e-02,  2.9164e-03,  0.0000e+00,  0.0000e+00,  1.1456e-02,
         9.4398e-04,  0.0000e+00,  0.0000e+00,  8.6552e-03,  2.9231e-04,
         0.0000e+00,  0.0000e+00,  7.3292e-03,  4.8529e-05,  0.0000e+00,
         0.0000e+00,  6.1485e-03,  2.3529e-05,  0.0000e+00,  0.0000e+00,
         5.3694e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.2389e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.7568e-04,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.8966e-05,  0.0000e+00,  0.0000e+00])  tensor([1.6221e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5121e-01, 0.0000e+00,
        9.5577e-02, 1.0378e-02, 9.8408e-02, 0.0000e+00, 4.0650e-02, 7.9513e-03,
        0.0000e+00, 0.0000e+00, 3.1706e-02, 4.4535e-03, 0.0000e+00, 0.0000e+00,
        2.4913e-02, 2.5209e-03, 0.0000e+00, 0.0000e+00, 2.1744e-02, 7.6690e-04,
        0.0000e+00, 0.0000e+00, 1.9012e-02, 5.2613e-04, 0.0000e+00, 0.0000e+00,
        1.7314e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0698e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.9692e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0893e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:33,448 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4333520938183025
2024-05-15 15:28:33,450 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.593020.05814
2024-05-15 15:28:33,485 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #60: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.34, '(min, 1)': 0.21, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-05-15 15:28:33,485 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:33,486 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331082815247951
2024-05-15 15:28:33,510 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #60: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32558139534883723, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.25, '(rev, 1)': 0.08, '(rev, 2)': 0.07}}
2024-05-15 15:28:33,510 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:33,510 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #60: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(min, 0)': 0.22, '(min, 1)': 0.43, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-15 15:28:33,511 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:33,511 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331082815247951
2024-05-15 15:28:33,511 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331082815247951
2024-05-15 15:28:34,128 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #60: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.2, '(min, 1)': 0.41, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03}}
2024-05-15 15:28:34,128 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:34,129 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331082815247951
2024-05-15 15:28:34,221 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #60: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.42857142857142855, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(min, 0)': 0.47, '(min, 1)': 0.13, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-15 15:28:34,221 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:34,222 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331082815247951
2024-05-15 15:28:35,126 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #60: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.39, '(min, 1)': 0.24, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 6)': 0.01}}
2024-05-15 15:28:35,127 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:35,127 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331082815247951
2024-05-15 15:28:35,353 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #60: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.18421052631578946, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(min, 0)': 0.37, '(min, 1)': 0.25, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-15 15:28:35,353 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:35,353 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331082815247951
2024-05-15 15:28:35,496 - MainProcess - INFO - text_logger.py - 51 - Train epoch #60
2024-05-15 15:28:35,498 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.2521e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0984e-01, 0.0000e+00,
        6.0588e-02, 5.9973e-03, 3.9417e-01, 0.0000e+00, 9.2310e-03, 4.0167e-03,
        0.0000e+00, 0.0000e+00, 4.5869e-03, 1.7681e-03, 0.0000e+00, 0.0000e+00,
        2.5643e-03, 8.5119e-04, 0.0000e+00, 0.0000e+00, 1.8348e-03, 4.9869e-04,
        0.0000e+00, 0.0000e+00, 1.5833e-03, 3.5480e-04, 0.0000e+00, 0.0000e+00,
        1.2319e-03, 1.5487e-04, 0.0000e+00, 0.0000e+00, 5.9611e-04, 2.6316e-05,
        0.0000e+00, 0.0000e+00, 6.3492e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5714e-05, 0.0000e+00, 0.0000e+00])  tensor([1.6832e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.4960e-02, 0.0000e+00,
        7.2058e-02, 1.0735e-02, 5.6777e-02, 0.0000e+00, 2.7297e-02, 9.1146e-03,
        0.0000e+00, 0.0000e+00, 1.9800e-02, 5.7591e-03, 0.0000e+00, 0.0000e+00,
        1.4333e-02, 3.8367e-03, 0.0000e+00, 0.0000e+00, 1.0950e-02, 2.7191e-03,
        0.0000e+00, 0.0000e+00, 9.8622e-03, 2.6243e-03, 0.0000e+00, 0.0000e+00,
        8.4485e-03, 1.5674e-03, 0.0000e+00, 0.0000e+00, 4.4561e-03, 5.8844e-04,
        0.0000e+00, 0.0000e+00, 1.0107e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.9860e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:35,513 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43316401242410213
2024-05-15 15:28:35,515 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.377080.05150
2024-05-15 15:28:35,527 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #61: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(min, 0)': 0.32, '(min, 1)': 0.28, '(rev, 1)': 0.08, '(rev, 2)': 0.02, '(rev, 3)': 0.03}}
2024-05-15 15:28:35,527 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:35,527 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #61: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 1, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 3)': 0.01, '(min, 0)': 0.5, '(min, 1)': 0.19, '(rev, 1)': 0.05, '(rev, 2)': 0.04}}
2024-05-15 15:28:35,528 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:35,528 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4333520938183025
2024-05-15 15:28:35,528 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4333520938183025
2024-05-15 15:28:35,556 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #61: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.9230769230769231, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(min, 0)': 0.35, '(min, 1)': 0.3, '(rev, 1)': 0.15, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-15 15:28:35,556 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:35,557 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4333520938183025
2024-05-15 15:28:35,656 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #61: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.43, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-15 15:28:35,657 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:35,657 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4333520938183025
2024-05-15 15:28:35,839 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #61: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 3)': 0.02, '(min, 0)': 0.47, '(min, 1)': 0.15, '(rev, 1)': 0.02, '(rev, 2)': 0.01}}
2024-05-15 15:28:35,840 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:35,840 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4333520938183025
2024-05-15 15:28:36,791 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #61: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3191489361702128, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(min, 0)': 0.2, '(min, 1)': 0.4, '(rev, 1)': 0.05, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:28:36,791 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:36,791 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4333520938183025
2024-05-15 15:28:37,367 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #61: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.24, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(ado, 3)': 0.03, '(ado, 5)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.21, '(rev, 1)': 0.05, '(rev, 2)': 0.01}}
2024-05-15 15:28:37,367 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:37,367 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4333520938183025
2024-05-15 15:28:37,514 - MainProcess - INFO - text_logger.py - 51 - Train epoch #61
2024-05-15 15:28:37,517 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-5.4623e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.5976e-01,
         0.0000e+00,  9.7643e-02,  4.9134e-03,  3.3965e-01,  0.0000e+00,
         2.8841e-02,  3.2865e-03,  0.0000e+00,  0.0000e+00,  1.8407e-02,
         1.0259e-03,  0.0000e+00,  0.0000e+00,  1.2855e-02,  1.9904e-04,
         0.0000e+00,  0.0000e+00,  1.0970e-02,  1.4304e-04,  0.0000e+00,
         0.0000e+00,  9.5333e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         7.5044e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.7146e-03,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.8013e-04,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  6.8622e-05,  0.0000e+00,  0.0000e+00])  tensor([1.5781e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7973e-01, 0.0000e+00,
        1.1772e-01, 1.0322e-02, 1.1733e-01, 0.0000e+00, 5.5604e-02, 9.2139e-03,
        0.0000e+00, 0.0000e+00, 3.8275e-02, 4.7951e-03, 0.0000e+00, 0.0000e+00,
        2.8720e-02, 2.0159e-03, 0.0000e+00, 0.0000e+00, 2.6522e-02, 2.0098e-03,
        0.0000e+00, 0.0000e+00, 2.3822e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.0100e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2938e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.9799e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0859e-03, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:37,541 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4331448551290584
2024-05-15 15:28:37,543 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.461540.46154
2024-05-15 15:28:37,555 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #62: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.08333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 3)': 0.01, '(min, 0)': 0.58, '(min, 1)': 0.07, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-15 15:28:37,556 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:37,557 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43316401242410213
2024-05-15 15:28:37,562 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #62: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35714285714285715, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.02, '(ado, 3)': 0.03, '(min, 0)': 0.27, '(min, 1)': 0.35, '(rev, 1)': 0.15, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-15 15:28:37,562 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:37,563 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43316401242410213
2024-05-15 15:28:37,594 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #62: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3023255813953488, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(min, 0)': 0.14, '(min, 1)': 0.48, '(rev, 1)': 0.11, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:28:37,594 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:37,595 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43316401242410213
2024-05-15 15:28:37,605 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #62: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.0, 'length': 100, 'actions': {'(ado, 1)': 0.43, '(min, 0)': 0.4, '(min, 1)': 0.17}}
2024-05-15 15:28:37,606 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:37,606 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43316401242410213
2024-05-15 15:28:37,909 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #62: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.26, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.35, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:28:37,909 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:37,910 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43316401242410213
2024-05-15 15:28:38,857 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #62: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.31, '(min, 1)': 0.29, '(rev, 1)': 0.16, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-15 15:28:38,857 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:38,857 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43316401242410213
2024-05-15 15:28:39,053 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #62: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 8)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.29, '(rev, 1)': 0.11, '(rev, 3)': 0.02}}
2024-05-15 15:28:39,053 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:39,054 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43316401242410213
2024-05-15 15:28:39,202 - MainProcess - INFO - text_logger.py - 51 - Train epoch #62
2024-05-15 15:28:39,205 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.5594e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8152e-01, 0.0000e+00,
        7.7883e-02, 6.6277e-03, 3.7524e-01, 0.0000e+00, 1.5282e-02, 5.5533e-03,
        0.0000e+00, 0.0000e+00, 9.6708e-03, 1.6858e-03, 0.0000e+00, 0.0000e+00,
        6.6060e-03, 3.6947e-04, 0.0000e+00, 0.0000e+00, 6.0992e-03, 1.6840e-04,
        0.0000e+00, 0.0000e+00, 5.3566e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.4257e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0082e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.7358e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2258e-05, 0.0000e+00, 0.0000e+00])  tensor([1.5064e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3636e-01, 0.0000e+00,
        9.5828e-02, 1.1598e-02, 9.2634e-02, 0.0000e+00, 3.8923e-02, 1.1292e-02,
        0.0000e+00, 0.0000e+00, 2.9359e-02, 6.1333e-03, 0.0000e+00, 0.0000e+00,
        2.2207e-02, 2.4944e-03, 0.0000e+00, 0.0000e+00, 2.0934e-02, 2.0867e-03,
        0.0000e+00, 0.0000e+00, 1.8526e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6100e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1119e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.9609e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.2131e-04, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:39,218 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43228595424427124
2024-05-15 15:28:39,220 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.041670.04167
2024-05-15 15:28:39,234 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #63: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4489795918367347, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(ado, 4)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.15, '(rev, 1)': 0.06, '(rev, 2)': 0.04}}
2024-05-15 15:28:39,234 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:39,235 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331448551290584
2024-05-15 15:28:39,264 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #63: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0),(ado, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/3', 'revenue': 0.26666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(ado, 3)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.18, '(rev, 1)': 0.11, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-05-15 15:28:39,264 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:39,265 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331448551290584
2024-05-15 15:28:39,534 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #63: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6136363636363636, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.02, '(ado, 5)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.37, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-15 15:28:39,535 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:39,535 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331448551290584
2024-05-15 15:28:39,562 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #63: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40425531914893614, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.47, '(min, 1)': 0.15, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-15 15:28:39,563 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:39,564 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331448551290584
2024-05-15 15:28:39,621 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #63: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 1, 0, 1),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 1, 2, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.46938775510204084, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.21, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-15 15:28:39,621 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:39,622 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331448551290584
2024-05-15 15:28:40,194 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #63: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3125, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(min, 0)': 0.35, '(min, 1)': 0.22, '(rev, 1)': 0.03, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-15 15:28:40,194 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:40,194 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331448551290584
2024-05-15 15:28:40,394 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #63: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22916666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.05, '(min, 0)': 0.46, '(min, 1)': 0.11, '(rev, 1)': 0.07, '(rev, 2)': 0.04}}
2024-05-15 15:28:40,394 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:40,394 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4331448551290584
2024-05-15 15:28:40,541 - MainProcess - INFO - text_logger.py - 51 - Train epoch #63
2024-05-15 15:28:40,543 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.4918e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3037e-01, 0.0000e+00,
        5.1452e-02, 6.4486e-03, 3.9650e-01, 0.0000e+00, 5.2904e-03, 4.5945e-03,
        0.0000e+00, 0.0000e+00, 2.0778e-03, 1.5239e-03, 0.0000e+00, 0.0000e+00,
        7.8588e-04, 2.7694e-04, 0.0000e+00, 0.0000e+00, 3.7702e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.4144e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.6667e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.1477, 0.0000, 0.0000, 0.0000, 0.0673, 0.0000, 0.0612, 0.0117, 0.0303,
        0.0000, 0.0176, 0.0108, 0.0000, 0.0000, 0.0106, 0.0059, 0.0000, 0.0000,
        0.0061, 0.0025, 0.0000, 0.0000, 0.0045, 0.0000, 0.0000, 0.0000, 0.0038,
        0.0000, 0.0000, 0.0000, 0.0015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-05-15 15:28:40,558 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43226208737308947
2024-05-15 15:28:40,560 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.459180.01020
2024-05-15 15:28:40,587 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #64: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.15555555555555556, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.1, '(min, 1)': 0.48, '(rev, 1)': 0.09, '(rev, 2)': 0.02}}
2024-05-15 15:28:40,587 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:40,588 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43228595424427124
2024-05-15 15:28:40,991 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #64: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.02, '(min, 0)': 0.03, '(min, 1)': 0.53, '(rev, 1)': 0.08, '(rev, 2)': 0.03}}
2024-05-15 15:28:40,991 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:40,992 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43228595424427124
2024-05-15 15:28:41,409 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #64: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(min, 0)': 0.18, '(min, 1)': 0.41, '(rev, 1)': 0.09, '(rev, 2)': 0.02, '(rev, 3)': 0.06}}
2024-05-15 15:28:41,409 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:41,410 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43228595424427124
2024-05-15 15:28:41,428 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #64: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8157894736842105, 'length': 100, 'actions': {'(ado, 1)': 0.09, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(min, 0)': 0.15, '(min, 1)': 0.49, '(rev, 1)': 0.17, '(rev, 2)': 0.04, '(rev, 3)': 0.03}}
2024-05-15 15:28:41,428 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:41,429 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43228595424427124
2024-05-15 15:28:41,466 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #64: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4878048780487805, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.51, '(min, 1)': 0.14, '(rev, 1)': 0.04, '(rev, 2)': 0.02, '(rev, 7)': 0.01}}
2024-05-15 15:28:41,466 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:41,467 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43228595424427124
2024-05-15 15:28:42,229 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #64: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 1, 10, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 0, 9, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3611111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(min, 0)': 0.39, '(min, 1)': 0.26, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-15 15:28:42,229 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:42,230 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43228595424427124
2024-05-15 15:28:43,262 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #64: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4146341463414634, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 3)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.28, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:28:43,262 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:43,262 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43228595424427124
2024-05-15 15:28:43,402 - MainProcess - INFO - text_logger.py - 51 - Train epoch #64
2024-05-15 15:28:43,404 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.4939e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9517e-01, 0.0000e+00,
        7.1044e-02, 5.3553e-03, 3.8347e-01, 0.0000e+00, 1.2661e-02, 5.4033e-03,
        0.0000e+00, 0.0000e+00, 7.1581e-03, 1.7150e-03, 0.0000e+00, 0.0000e+00,
        4.4814e-03, 6.2033e-04, 0.0000e+00, 0.0000e+00, 3.9262e-03, 2.7066e-04,
        0.0000e+00, 0.0000e+00, 3.5127e-03, 1.1174e-04, 0.0000e+00, 0.0000e+00,
        2.9530e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8993e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.5342e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.1150e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2350e-01, 0.0000e+00,
        9.6430e-02, 1.0935e-02, 8.2323e-02, 0.0000e+00, 3.7387e-02, 1.1890e-02,
        0.0000e+00, 0.0000e+00, 2.4543e-02, 6.0097e-03, 0.0000e+00, 0.0000e+00,
        1.8012e-02, 3.5734e-03, 0.0000e+00, 0.0000e+00, 1.6431e-02, 2.3057e-03,
        0.0000e+00, 0.0000e+00, 1.5180e-02, 1.2769e-03, 0.0000e+00, 0.0000e+00,
        1.3162e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.7691e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.1843e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:43,417 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43249654692190653
2024-05-15 15:28:43,420 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.588350.10054
2024-05-15 15:28:43,467 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #65: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.17391304347826086, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.22, '(min, 1)': 0.4, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-15 15:28:43,467 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #65: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 0, 5, 8, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 5, 9, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5517241379310345, 'length': 100, 'actions': {'(ado, 1)': 0.07, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.47, '(rev, 1)': 0.12, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.02, '(rev, 6)': 0.01}}
2024-05-15 15:28:43,467 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:43,467 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:43,468 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43226208737308947
2024-05-15 15:28:43,468 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43226208737308947
2024-05-15 15:28:43,481 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #65: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 7)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.28, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-15 15:28:43,482 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:43,482 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43226208737308947
2024-05-15 15:28:43,778 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #65: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.18181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 3)': 0.03, '(ado, 4)': 0.01, '(ado, 5)': 0.02, '(min, 0)': 0.22, '(min, 1)': 0.41, '(rev, 1)': 0.06, '(rev, 2)': 0.01, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:28:43,778 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:43,778 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43226208737308947
2024-05-15 15:28:44,351 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #65: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 2, 0, 1),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 3, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.19230769230769232, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.04, '(ado, 8)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.46, '(rev, 1)': 0.06, '(rev, 2)': 0.04}}
2024-05-15 15:28:44,352 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:44,353 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43226208737308947
2024-05-15 15:28:44,376 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #65: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 1, 8, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 2, 8, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10526315789473684, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 8)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.35, '(rev, 1)': 0.02, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-15 15:28:44,377 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:44,377 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43226208737308947
2024-05-15 15:28:45,098 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #65: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 5, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5945945945945946, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.02, '(min, 0)': 0.44, '(min, 1)': 0.19, '(rev, 1)': 0.14, '(rev, 2)': 0.05, '(rev, 3)': 0.04, '(rev, 6)': 0.01}}
2024-05-15 15:28:45,098 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:45,099 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43226208737308947
2024-05-15 15:28:45,247 - MainProcess - INFO - text_logger.py - 51 - Train epoch #65
2024-05-15 15:28:45,250 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.5621e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7693e-01, 0.0000e+00,
        8.5262e-02, 5.4491e-03, 3.7158e-01, 0.0000e+00, 1.6683e-02, 6.6789e-03,
        0.0000e+00, 0.0000e+00, 9.8635e-03, 2.6669e-03, 0.0000e+00, 0.0000e+00,
        6.6180e-03, 8.7762e-04, 0.0000e+00, 0.0000e+00, 5.7335e-03, 4.9350e-04,
        0.0000e+00, 0.0000e+00, 4.8993e-03, 3.3674e-04, 0.0000e+00, 0.0000e+00,
        3.3800e-03, 2.1674e-04, 0.0000e+00, 0.0000e+00, 2.0927e-03, 4.2553e-05,
        0.0000e+00, 0.0000e+00, 1.9242e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.9437e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3930e-01, 0.0000e+00,
        1.0697e-01, 1.0892e-02, 9.3586e-02, 0.0000e+00, 4.2538e-02, 1.2931e-02,
        0.0000e+00, 0.0000e+00, 2.8320e-02, 7.3146e-03, 0.0000e+00, 0.0000e+00,
        2.0220e-02, 3.8689e-03, 0.0000e+00, 0.0000e+00, 1.9097e-02, 2.9193e-03,
        0.0000e+00, 0.0000e+00, 1.7409e-02, 2.5205e-03, 0.0000e+00, 0.0000e+00,
        1.3279e-02, 2.3301e-03, 0.0000e+00, 0.0000e+00, 8.9086e-03, 9.5152e-04,
        0.0000e+00, 0.0000e+00, 1.9578e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:45,266 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4319040203061252
2024-05-15 15:28:45,268 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.174850.06959
2024-05-15 15:28:45,296 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #66: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 3)': 0.03, '(min, 0)': 0.22, '(min, 1)': 0.38, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.05}}
2024-05-15 15:28:45,296 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:45,297 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43249654692190653
2024-05-15 15:28:45,327 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #66: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 3)': 0.01, '(min, 0)': 0.1, '(min, 1)': 0.46, '(rev, 1)': 0.09, '(rev, 2)': 0.05}}
2024-05-15 15:28:45,328 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:45,328 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43249654692190653
2024-05-15 15:28:45,573 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #66: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5609756097560976, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.03, '(min, 0)': 0.4, '(min, 1)': 0.24, '(rev, 1)': 0.13, '(rev, 2)': 0.02, '(rev, 3)': 0.06}}
2024-05-15 15:28:45,574 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:45,574 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43249654692190653
2024-05-15 15:28:45,580 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #66: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.27, '(rev, 1)': 0.11, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-05-15 15:28:45,580 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:45,580 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43249654692190653
2024-05-15 15:28:46,037 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #66: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3584905660377358, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.56, '(min, 1)': 0.02, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:28:46,037 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:46,038 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43249654692190653
2024-05-15 15:28:46,433 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #66: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.14893617021276595, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(ado, 3)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.47, '(rev, 1)': 0.08, '(rev, 2)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:28:46,433 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:46,434 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43249654692190653
2024-05-15 15:28:47,337 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #66: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 4, 6, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 5, 6, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.725, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.01, '(ado, 3)': 0.03, '(min, 0)': 0.18, '(min, 1)': 0.47, '(rev, 1)': 0.14, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-15 15:28:47,337 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:47,338 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43249654692190653
2024-05-15 15:28:47,491 - MainProcess - INFO - text_logger.py - 51 - Train epoch #66
2024-05-15 15:28:47,494 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([9.0636e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1289e-01, 0.0000e+00,
        5.7769e-02, 6.1697e-03, 3.9390e-01, 0.0000e+00, 8.0397e-03, 6.1704e-03,
        0.0000e+00, 0.0000e+00, 3.9249e-03, 2.2736e-03, 0.0000e+00, 0.0000e+00,
        2.3498e-03, 7.9026e-04, 0.0000e+00, 0.0000e+00, 1.5911e-03, 3.3914e-04,
        0.0000e+00, 0.0000e+00, 1.4686e-03, 1.8765e-04, 0.0000e+00, 0.0000e+00,
        1.1227e-03, 6.0181e-05, 0.0000e+00, 0.0000e+00, 7.8604e-04, 3.0769e-05,
        0.0000e+00, 0.0000e+00, 1.1217e-04, 3.0769e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.9742e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.3073e-02, 0.0000e+00,
        7.0567e-02, 1.1112e-02, 5.7506e-02, 0.0000e+00, 2.8101e-02, 1.2143e-02,
        0.0000e+00, 0.0000e+00, 1.7499e-02, 6.8300e-03, 0.0000e+00, 0.0000e+00,
        1.3187e-02, 3.8153e-03, 0.0000e+00, 0.0000e+00, 1.0268e-02, 2.3186e-03,
        0.0000e+00, 0.0000e+00, 9.6187e-03, 1.7279e-03, 0.0000e+00, 0.0000e+00,
        8.0800e-03, 9.5083e-04, 0.0000e+00, 0.0000e+00, 5.5454e-03, 6.8802e-04,
        0.0000e+00, 0.0000e+00, 1.4859e-03, 6.8802e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:47,507 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43172936756313324
2024-05-15 15:28:47,509 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.383790.02530
2024-05-15 15:28:47,523 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #67: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4883720930232558, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.03, '(min, 0)': 0.22, '(min, 1)': 0.39, '(rev, 1)': 0.11, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-05-15 15:28:47,523 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:47,524 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319040203061252
2024-05-15 15:28:47,571 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #67: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6097560975609756, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(min, 0)': 0.22, '(min, 1)': 0.42, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.03, '(rev, 5)': 0.01}}
2024-05-15 15:28:47,571 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:47,571 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #67: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.41, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:28:47,572 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:47,572 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319040203061252
2024-05-15 15:28:47,572 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319040203061252
2024-05-15 15:28:47,822 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #67: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.8222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.1, '(min, 1)': 0.49, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-15 15:28:47,822 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:47,822 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #67: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.30434782608695654, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.41, '(min, 1)': 0.15, '(rev, 1)': 0.09, '(rev, 2)': 0.06}}
2024-05-15 15:28:47,822 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:47,823 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319040203061252
2024-05-15 15:28:47,823 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319040203061252
2024-05-15 15:28:48,621 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #67: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.8809523809523809, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(min, 0)': 0.31, '(min, 1)': 0.34, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-15 15:28:48,621 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:48,622 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319040203061252
2024-05-15 15:28:49,545 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #67: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.47058823529411764, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.03, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.12, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-15 15:28:49,545 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:49,545 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319040203061252
2024-05-15 15:28:49,716 - MainProcess - INFO - text_logger.py - 51 - Train epoch #67
2024-05-15 15:28:49,720 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.0560e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3522e-01, 0.0000e+00,
        4.0954e-02, 5.8785e-03, 4.0462e-01, 0.0000e+00, 2.2134e-03, 5.0837e-03,
        0.0000e+00, 0.0000e+00, 8.5810e-04, 1.8770e-03, 0.0000e+00, 0.0000e+00,
        2.7785e-04, 1.3600e-03, 0.0000e+00, 0.0000e+00, 1.8071e-04, 5.5199e-04,
        0.0000e+00, 0.0000e+00, 1.4897e-04, 4.6099e-04, 0.0000e+00, 0.0000e+00,
        6.8966e-05, 2.1333e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2258e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.4701e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3840e-02, 0.0000e+00,
        5.0122e-02, 1.0648e-02, 2.4064e-02, 0.0000e+00, 1.1470e-02, 1.1231e-02,
        0.0000e+00, 0.0000e+00, 6.2351e-03, 6.1312e-03, 0.0000e+00, 0.0000e+00,
        3.6828e-03, 5.1645e-03, 0.0000e+00, 0.0000e+00, 2.4620e-03, 2.9947e-03,
        0.0000e+00, 0.0000e+00, 2.3595e-03, 2.6805e-03, 0.0000e+00, 0.0000e+00,
        1.5421e-03, 1.8322e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2131e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:49,737 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4322191116647958
2024-05-15 15:28:49,739 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.715990.10623
2024-05-15 15:28:49,747 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #68: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 2, 0, 0),(rev, 3)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '3/3', 'revenue': 0.5625, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 3)': 0.02, '(min, 0)': 0.14, '(min, 1)': 0.48, '(rev, 1)': 0.1, '(rev, 2)': 0.08, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-05-15 15:28:49,747 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #68: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.07, '(min, 1)': 0.54, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-15 15:28:49,747 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:49,748 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:49,748 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43172936756313324
2024-05-15 15:28:49,748 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43172936756313324
2024-05-15 15:28:49,756 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #68: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.574468085106383, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.23, '(min, 1)': 0.33, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 4)': 0.01}}
2024-05-15 15:28:49,756 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:49,756 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43172936756313324
2024-05-15 15:28:49,778 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #68: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.17, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-15 15:28:49,779 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:49,779 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #68: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(min, 0)': 0.51, '(min, 1)': 0.09, '(rev, 1)': 0.06, '(rev, 2)': 0.06, '(rev, 3)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:28:49,779 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:49,779 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43172936756313324
2024-05-15 15:28:49,780 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43172936756313324
2024-05-15 15:28:50,087 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #68: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.09, '(min, 1)': 0.46, '(rev, 1)': 0.1, '(rev, 2)': 0.02}}
2024-05-15 15:28:50,087 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:50,088 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43172936756313324
2024-05-15 15:28:51,855 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #68: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.7142857142857143, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.26, '(min, 1)': 0.4, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 7)': 0.01}}
2024-05-15 15:28:51,856 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:51,856 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43172936756313324
2024-05-15 15:28:52,005 - MainProcess - INFO - text_logger.py - 51 - Train epoch #68
2024-05-15 15:28:52,008 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.8827e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2709e-01, 0.0000e+00,
        5.1183e-02, 6.2517e-03, 4.0236e-01, 0.0000e+00, 3.2930e-03, 4.5905e-03,
        0.0000e+00, 0.0000e+00, 1.1483e-03, 1.6880e-03, 0.0000e+00, 0.0000e+00,
        2.3332e-04, 1.0456e-03, 0.0000e+00, 0.0000e+00, 8.8440e-05, 4.2456e-04,
        0.0000e+00, 0.0000e+00, 3.3898e-05, 2.7008e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.9254e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7408e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2908e-02, 0.0000e+00,
        7.0644e-02, 1.0794e-02, 2.5846e-02, 0.0000e+00, 1.0973e-02, 1.0902e-02,
        0.0000e+00, 0.0000e+00, 6.3269e-03, 6.0251e-03, 0.0000e+00, 0.0000e+00,
        2.2974e-03, 4.6528e-03, 0.0000e+00, 0.0000e+00, 1.1488e-03, 2.7476e-03,
        0.0000e+00, 0.0000e+00, 7.5799e-04, 2.1364e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.3712e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:52,021 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4321774324883033
2024-05-15 15:28:52,023 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.450280.12419
2024-05-15 15:28:52,052 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #69: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(min, 0)': 0.35, '(min, 1)': 0.24, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-15 15:28:52,053 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:52,053 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #69: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.41, '(min, 1)': 0.22, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-05-15 15:28:52,053 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:52,053 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:52,053 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4322191116647958
2024-05-15 15:28:52,053 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4322191116647958
2024-05-15 15:28:52,054 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4322191116647958
2024-05-15 15:28:52,069 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #69: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.14583333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.01, '(ado, 4)': 0.02, '(min, 0)': 0.27, '(min, 1)': 0.31, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-05-15 15:28:52,069 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:52,069 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4322191116647958
2024-05-15 15:28:52,083 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #69: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.717391304347826, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.17, '(min, 1)': 0.43, '(rev, 1)': 0.08, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-05-15 15:28:52,083 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:52,083 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #69: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(min, 0)': 0.16, '(min, 1)': 0.43, '(rev, 1)': 0.13, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 5)': 0.02}}
2024-05-15 15:28:52,084 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:52,084 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4322191116647958
2024-05-15 15:28:52,084 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4322191116647958
2024-05-15 15:28:53,075 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #69: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.1111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.07, '(min, 0)': 0.24, '(min, 1)': 0.33, '(rev, 1)': 0.09, '(rev, 2)': 0.01}}
2024-05-15 15:28:53,075 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:53,075 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4322191116647958
2024-05-15 15:28:53,222 - MainProcess - INFO - text_logger.py - 51 - Train epoch #69
2024-05-15 15:28:53,224 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.4583e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3718e-01, 0.0000e+00,
        4.1492e-02, 6.0478e-03, 4.0824e-01, 0.0000e+00, 2.2865e-03, 2.8400e-03,
        0.0000e+00, 0.0000e+00, 4.5949e-04, 8.3019e-04, 0.0000e+00, 0.0000e+00,
        1.3350e-04, 1.7108e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0128e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3114e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.3114e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3114e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5049e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9417e-02, 0.0000e+00,
        4.6503e-02, 1.0797e-02, 1.3820e-02, 0.0000e+00, 9.2200e-03, 8.6238e-03,
        0.0000e+00, 0.0000e+00, 4.2385e-03, 4.3473e-03, 0.0000e+00, 0.0000e+00,
        1.8739e-03, 1.7234e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3166e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1579e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.1579e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1579e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:53,239 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4319735821085666
2024-05-15 15:28:53,241 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.369190.14192
2024-05-15 15:28:53,330 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #70: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.26666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(min, 0)': 0.32, '(min, 1)': 0.23, '(rev, 1)': 0.07, '(rev, 2)': 0.05}}
2024-05-15 15:28:53,330 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:53,331 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321774324883033
2024-05-15 15:28:53,365 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #70: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.29, '(min, 1)': 0.32, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-15 15:28:53,365 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:53,365 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321774324883033
2024-05-15 15:28:53,391 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #70: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.06, '(min, 0)': 0.33, '(min, 1)': 0.26, '(rev, 1)': 0.11, '(rev, 2)': 0.06}}
2024-05-15 15:28:53,391 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:53,392 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321774324883033
2024-05-15 15:28:53,393 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #70: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.4888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(min, 0)': 0.3, '(min, 1)': 0.29, '(rev, 1)': 0.11, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-05-15 15:28:53,393 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:53,393 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321774324883033
2024-05-15 15:28:53,758 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #70: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5813953488372093, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.27, '(min, 1)': 0.32, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-15 15:28:53,758 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:53,759 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321774324883033
2024-05-15 15:28:53,920 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #70: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, irr, 0, 3, 9, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, irr, 0, 0, 8, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.25, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-15 15:28:53,920 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:53,920 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321774324883033
2024-05-15 15:28:54,688 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #70: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.03, '(min, 0)': 0.24, '(min, 1)': 0.38, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 6)': 0.01}}
2024-05-15 15:28:54,688 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:54,689 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321774324883033
2024-05-15 15:28:54,851 - MainProcess - INFO - text_logger.py - 51 - Train epoch #70
2024-05-15 15:28:54,854 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([-3.2711e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  5.1596e-01,
         0.0000e+00,  6.5149e-02,  5.5637e-03,  3.9351e-01,  0.0000e+00,
         7.0318e-03,  3.0848e-03,  0.0000e+00,  0.0000e+00,  3.0964e-03,
         9.7623e-04,  0.0000e+00,  0.0000e+00,  1.7377e-03,  3.9413e-04,
         0.0000e+00,  0.0000e+00,  1.0720e-03,  1.9025e-04,  0.0000e+00,
         0.0000e+00,  1.0464e-03,  4.0000e-05,  0.0000e+00,  0.0000e+00,
         5.3636e-04,  4.0000e-05,  0.0000e+00,  0.0000e+00,  4.7389e-04,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0021e-04,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00])  tensor([1.4442e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.6017e-02, 0.0000e+00,
        9.6620e-02, 1.0307e-02, 5.6611e-02, 0.0000e+00, 2.3570e-02, 8.7641e-03,
        0.0000e+00, 0.0000e+00, 1.4525e-02, 4.5599e-03, 0.0000e+00, 0.0000e+00,
        1.0047e-02, 2.9542e-03, 0.0000e+00, 0.0000e+00, 7.4624e-03, 1.7851e-03,
        0.0000e+00, 0.0000e+00, 7.2308e-03, 8.9443e-04, 0.0000e+00, 0.0000e+00,
        4.5200e-03, 8.9443e-04, 0.0000e+00, 0.0000e+00, 4.0395e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.3259e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:54,870 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4318384185975168
2024-05-15 15:28:54,872 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.403540.08535
2024-05-15 15:28:54,913 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #71: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2553191489361702, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.02, '(min, 0)': 0.09, '(min, 1)': 0.48, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-15 15:28:54,914 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:54,914 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319735821085666
2024-05-15 15:28:55,052 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #71: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-15 15:28:55,053 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:55,053 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319735821085666
2024-05-15 15:28:55,159 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #71: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3023255813953488, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.34, '(min, 1)': 0.25, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-15 15:28:55,160 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:55,160 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319735821085666
2024-05-15 15:28:55,242 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #71: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5434782608695652, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.04, '(min, 0)': 0.23, '(min, 1)': 0.38, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-15 15:28:55,242 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:55,243 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319735821085666
2024-05-15 15:28:55,296 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #71: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.43478260869565216, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.26, '(rev, 1)': 0.05, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-05-15 15:28:55,296 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:55,297 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319735821085666
2024-05-15 15:28:55,874 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #71: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46296296296296297, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.13, '(rev, 1)': 0.04, '(rev, 2)': 0.07}}
2024-05-15 15:28:55,874 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:55,875 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319735821085666
2024-05-15 15:28:56,873 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #71: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.2, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-05-15 15:28:56,873 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:56,873 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4319735821085666
2024-05-15 15:28:57,035 - MainProcess - INFO - text_logger.py - 51 - Train epoch #71
2024-05-15 15:28:57,037 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.3312e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2493e-01, 0.0000e+00,
        4.7920e-02, 5.8275e-03, 4.0741e-01, 0.0000e+00, 3.5264e-03, 4.4477e-03,
        0.0000e+00, 0.0000e+00, 1.3589e-03, 1.9544e-03, 0.0000e+00, 0.0000e+00,
        7.7924e-04, 5.3234e-04, 0.0000e+00, 0.0000e+00, 3.0187e-04, 1.6261e-04,
        0.0000e+00, 0.0000e+00, 2.2550e-04, 5.7700e-05, 0.0000e+00, 0.0000e+00,
        2.2550e-04, 5.7700e-05, 0.0000e+00, 0.0000e+00, 1.4550e-04, 5.7700e-05,
        0.0000e+00, 0.0000e+00, 8.0000e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.6320e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6109e-02, 0.0000e+00,
        5.9366e-02, 1.1019e-02, 2.8960e-02, 0.0000e+00, 1.3942e-02, 1.1044e-02,
        0.0000e+00, 0.0000e+00, 7.7537e-03, 6.5602e-03, 0.0000e+00, 0.0000e+00,
        6.4892e-03, 3.2114e-03, 0.0000e+00, 0.0000e+00, 3.1439e-03, 1.6559e-03,
        0.0000e+00, 0.0000e+00, 2.9087e-03, 9.1257e-04, 0.0000e+00, 0.0000e+00,
        2.9087e-03, 9.1257e-04, 0.0000e+00, 0.0000e+00, 2.2987e-03, 9.1257e-04,
        0.0000e+00, 0.0000e+00, 1.7889e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:57,053 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43193966264026573
2024-05-15 15:28:57,057 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.521740.02174
2024-05-15 15:28:57,067 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #72: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.47, '(min, 1)': 0.08, '(rev, 1)': 0.11, '(rev, 2)': 0.07}}
2024-05-15 15:28:57,068 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:57,068 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318384185975168
2024-05-15 15:28:57,082 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #72: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5918367346938775, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 3)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.2, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-15 15:28:57,083 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #72: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 3)': 0.01, '(min, 0)': 0.33, '(min, 1)': 0.27, '(rev, 1)': 0.09, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-05-15 15:28:57,083 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:57,083 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:57,083 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318384185975168
2024-05-15 15:28:57,084 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318384185975168
2024-05-15 15:28:57,114 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #72: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.48, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.04, '(rev, 4)': 0.01}}
2024-05-15 15:28:57,114 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:57,115 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318384185975168
2024-05-15 15:28:57,175 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #72: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.7045454545454546, 'length': 100, 'actions': {'(ado, 1)': 0.11, '(ado, 2)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.28, '(rev, 1)': 0.1, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.03, '(rev, 5)': 0.01}}
2024-05-15 15:28:57,175 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:57,176 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318384185975168
2024-05-15 15:28:57,841 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #72: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(min, 0)': 0.33, '(min, 1)': 0.26, '(rev, 1)': 0.08, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-05-15 15:28:57,841 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:57,842 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318384185975168
2024-05-15 15:28:58,395 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #72: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.18, '(rev, 1)': 0.06, '(rev, 2)': 0.09, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:28:58,395 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:58,396 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4318384185975168
2024-05-15 15:28:58,550 - MainProcess - INFO - text_logger.py - 51 - Train epoch #72
2024-05-15 15:28:58,552 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.6049e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3233e-01, 0.0000e+00,
        4.7311e-02, 7.6463e-03, 4.0276e-01, 0.0000e+00, 2.3659e-03, 4.6951e-03,
        0.0000e+00, 0.0000e+00, 7.4133e-04, 1.5187e-03, 0.0000e+00, 0.0000e+00,
        2.4170e-04, 2.7119e-04, 0.0000e+00, 0.0000e+00, 3.9216e-05, 7.9278e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.3138e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8011e-02, 0.0000e+00,
        5.8219e-02, 1.3136e-02, 1.9054e-02, 0.0000e+00, 9.1446e-03, 1.1828e-02,
        0.0000e+00, 0.0000e+00, 4.8661e-03, 6.1003e-03, 0.0000e+00, 0.0000e+00,
        2.5156e-03, 2.6081e-03, 0.0000e+00, 0.0000e+00, 8.7689e-04, 1.2528e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:28:58,568 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43210197387669064
2024-05-15 15:28:58,571 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.552270.15227
2024-05-15 15:28:58,672 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #73: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 3, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.27906976744186046, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 4)': 0.01, '(min, 0)': 0.15, '(min, 1)': 0.45, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-15 15:28:58,673 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:58,674 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43193966264026573
2024-05-15 15:28:58,696 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #73: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.5333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.39, '(min, 1)': 0.25, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:28:58,696 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:58,697 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43193966264026573
2024-05-15 15:28:58,724 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #73: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.28, '(min, 1)': 0.35, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:28:58,724 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:58,725 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43193966264026573
2024-05-15 15:28:58,791 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #73: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6744186046511628, 'length': 100, 'actions': {'(ado, 1)': 0.1, '(ado, 2)': 0.02, '(min, 0)': 0.25, '(min, 1)': 0.42, '(rev, 1)': 0.1, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 8)': 0.01}}
2024-05-15 15:28:58,791 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:58,791 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43193966264026573
2024-05-15 15:28:59,200 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #73: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7346938775510204, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(ado, 9)': 0.01, '(min, 0)': 0.12, '(min, 1)': 0.53, '(rev, 1)': 0.05, '(rev, 2)': 0.06, '(rev, 4)': 0.01}}
2024-05-15 15:28:59,201 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:59,201 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43193966264026573
2024-05-15 15:28:59,479 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #73: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 1, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6585365853658537, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.17, '(min, 1)': 0.47, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-15 15:28:59,479 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:28:59,479 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43193966264026573
2024-05-15 15:29:00,064 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #73: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.41304347826086957, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(ado, 4)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.48, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:29:00,064 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:00,065 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43193966264026573
2024-05-15 15:29:00,353 - MainProcess - INFO - text_logger.py - 51 - Train epoch #73
2024-05-15 15:29:00,356 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.7098e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0185e-01, 0.0000e+00,
        6.7076e-02, 8.2400e-03, 4.0219e-01, 0.0000e+00, 4.4519e-03, 7.8142e-03,
        0.0000e+00, 0.0000e+00, 1.6032e-03, 3.4520e-03, 0.0000e+00, 0.0000e+00,
        6.8056e-04, 1.2108e-03, 0.0000e+00, 0.0000e+00, 2.8567e-04, 4.9294e-04,
        0.0000e+00, 0.0000e+00, 2.1292e-04, 1.2603e-04, 0.0000e+00, 0.0000e+00,
        7.6923e-05, 3.7037e-05, 0.0000e+00, 0.0000e+00, 7.6923e-05, 8.7037e-05,
        0.0000e+00, 0.0000e+00, 3.8462e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.0125e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.7161e-02, 0.0000e+00,
        1.0425e-01, 1.3766e-02, 4.5395e-02, 0.0000e+00, 1.3889e-02, 1.6117e-02,
        0.0000e+00, 0.0000e+00, 7.6909e-03, 9.5549e-03, 0.0000e+00, 0.0000e+00,
        5.0662e-03, 4.7954e-03, 0.0000e+00, 0.0000e+00, 3.2133e-03, 2.8638e-03,
        0.0000e+00, 0.0000e+00, 3.0059e-03, 1.4138e-03, 0.0000e+00, 0.0000e+00,
        1.7201e-03, 8.2817e-04, 0.0000e+00, 0.0000e+00, 1.7201e-03, 1.3900e-03,
        0.0000e+00, 0.0000e+00, 8.6003e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:29:00,372 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43197214275934526
2024-05-15 15:29:00,375 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.406200.12713
2024-05-15 15:29:00,541 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #74: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.45652173913043476, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.01, '(min, 0)': 0.04, '(min, 1)': 0.55, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-05-15 15:29:00,541 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:00,542 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210197387669064
2024-05-15 15:29:00,643 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #74: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.45, '(min, 1)': 0.13, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:29:00,644 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:00,645 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210197387669064
2024-05-15 15:29:00,755 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #74: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8478260869565217, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.06, '(min, 0)': 0.19, '(min, 1)': 0.42, '(rev, 1)': 0.1, '(rev, 2)': 0.08}}
2024-05-15 15:29:00,755 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:00,756 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210197387669064
2024-05-15 15:29:01,102 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #74: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4883720930232558, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.15, '(min, 1)': 0.49, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-15 15:29:01,102 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:01,102 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210197387669064
2024-05-15 15:29:01,962 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #74: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.32, '(min, 1)': 0.28, '(rev, 1)': 0.04, '(rev, 2)': 0.02}}
2024-05-15 15:29:01,963 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:01,963 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210197387669064
2024-05-15 15:29:01,978 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #74: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7555555555555555, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.29, '(min, 1)': 0.35, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-05-15 15:29:01,978 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:01,979 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210197387669064
2024-05-15 15:29:02,024 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #74: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, rel, 0, 0, 9, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, rel, 0, 0, 10, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.17073170731707318, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.49, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-05-15 15:29:02,024 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:02,025 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210197387669064
2024-05-15 15:29:02,135 - MainProcess - INFO - text_logger.py - 51 - Train epoch #74
2024-05-15 15:29:02,137 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.1799e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0907e-01, 0.0000e+00,
        7.1241e-02, 8.2611e-03, 3.9056e-01, 0.0000e+00, 5.8473e-03, 5.4103e-03,
        0.0000e+00, 0.0000e+00, 2.5680e-03, 2.1349e-03, 0.0000e+00, 0.0000e+00,
        1.6287e-03, 5.2272e-04, 0.0000e+00, 0.0000e+00, 1.0689e-03, 7.0846e-05,
        0.0000e+00, 0.0000e+00, 8.1960e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.4111e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8455e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.8986e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7026e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0226e-01, 0.0000e+00,
        1.2582e-01, 1.3770e-02, 6.1084e-02, 0.0000e+00, 1.8554e-02, 1.2957e-02,
        0.0000e+00, 0.0000e+00, 1.1174e-02, 7.4809e-03, 0.0000e+00, 0.0000e+00,
        8.3295e-03, 3.0012e-03, 0.0000e+00, 0.0000e+00, 6.5926e-03, 1.1195e-03,
        0.0000e+00, 0.0000e+00, 5.7203e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.9429e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1743e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0898e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:29:02,152 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43155480691520837
2024-05-15 15:29:02,155 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.262450.09172
2024-05-15 15:29:02,427 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #75: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(ado, 3)': 0.01, '(min, 0)': 0.15, '(min, 1)': 0.45, '(rev, 1)': 0.09, '(rev, 2)': 0.06}}
2024-05-15 15:29:02,427 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:02,428 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43197214275934526
2024-05-15 15:29:02,579 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #75: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37209302325581395, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.36, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:29:02,579 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:02,580 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43197214275934526
2024-05-15 15:29:02,618 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #75: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7391304347826086, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.53, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-05-15 15:29:02,620 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:02,621 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43197214275934526
2024-05-15 15:29:03,075 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #75: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.68, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(ado, 3)': 0.02, '(min, 0)': 0.18, '(min, 1)': 0.42, '(rev, 1)': 0.06, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-15 15:29:03,075 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:03,075 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43197214275934526
2024-05-15 15:29:03,466 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #75: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2978723404255319, 'length': 100, 'actions': {'(ado, 1)': 0.33, '(min, 0)': 0.26, '(min, 1)': 0.32, '(rev, 1)': 0.04, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:29:03,466 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:03,467 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43197214275934526
2024-05-15 15:29:03,658 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #75: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.24561403508771928, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.03, '(ado, 8)': 0.01, '(min, 0)': 0.49, '(min, 1)': 0.08, '(rev, 1)': 0.05, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-15 15:29:03,658 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:03,659 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43197214275934526
2024-05-15 15:29:03,669 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #75: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.24444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(min, 0)': 0.27, '(min, 1)': 0.32, '(rev, 1)': 0.02, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-15 15:29:03,669 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:03,670 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43197214275934526
2024-05-15 15:29:03,838 - MainProcess - INFO - text_logger.py - 51 - Train epoch #75
2024-05-15 15:29:03,840 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.2526e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1725e-01, 0.0000e+00,
        4.8838e-02, 6.5418e-03, 4.1385e-01, 0.0000e+00, 3.1914e-03, 4.7114e-03,
        0.0000e+00, 0.0000e+00, 1.5224e-03, 2.1542e-03, 0.0000e+00, 0.0000e+00,
        7.5135e-04, 4.9101e-04, 0.0000e+00, 0.0000e+00, 3.9993e-04, 4.0816e-05,
        0.0000e+00, 0.0000e+00, 2.1302e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.2553e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.6439e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5298e-02, 0.0000e+00,
        6.3091e-02, 1.2653e-02, 2.4353e-02, 0.0000e+00, 1.0429e-02, 1.2741e-02,
        0.0000e+00, 0.0000e+00, 6.8038e-03, 7.9512e-03, 0.0000e+00, 0.0000e+00,
        4.3630e-03, 3.1002e-03, 0.0000e+00, 0.0000e+00, 3.1069e-03, 9.1268e-04,
        0.0000e+00, 0.0000e+00, 2.1491e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.5152e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:29:03,856 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4315973171669582
2024-05-15 15:29:03,858 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.492370.24676
2024-05-15 15:29:04,234 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #76: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.35555555555555557, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(min, 0)': 0.18, '(min, 1)': 0.41, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 5)': 0.01}}
2024-05-15 15:29:04,234 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:04,235 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43155480691520837
2024-05-15 15:29:04,295 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #76: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.14583333333333334, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.05, '(min, 0)': 0.13, '(min, 1)': 0.42, '(rev, 1)': 0.06, '(rev, 2)': 0.03}}
2024-05-15 15:29:04,295 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:04,296 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43155480691520837
2024-05-15 15:29:04,376 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #76: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(min, 0)': 0.13, '(min, 1)': 0.46, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-15 15:29:04,376 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:04,377 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43155480691520837
2024-05-15 15:29:04,488 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #76: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6444444444444445, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(min, 0)': 0.26, '(min, 1)': 0.36, '(rev, 1)': 0.09, '(rev, 2)': 0.07, '(rev, 3)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:29:04,488 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:04,489 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43155480691520837
2024-05-15 15:29:04,842 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #76: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 3, 0, 0),(rev, 4)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '4/4', 'revenue': 0.4772727272727273, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.28, '(min, 1)': 0.33, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:29:04,842 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:04,842 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43155480691520837
2024-05-15 15:29:04,993 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #76: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(min, 0)': 0.46, '(min, 1)': 0.11, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-15 15:29:04,994 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:04,995 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43155480691520837
2024-05-15 15:29:06,031 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #76: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.09, '(min, 1)': 0.49, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.02, '(rev, 5)': 0.01}}
2024-05-15 15:29:06,032 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:06,032 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43155480691520837
2024-05-15 15:29:06,205 - MainProcess - INFO - text_logger.py - 51 - Train epoch #76
2024-05-15 15:29:06,207 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.6600e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2699e-01, 0.0000e+00,
        5.0214e-02, 6.5798e-03, 4.0120e-01, 0.0000e+00, 2.3768e-03, 6.5598e-03,
        0.0000e+00, 0.0000e+00, 5.7227e-04, 2.9863e-03, 0.0000e+00, 0.0000e+00,
        2.8318e-04, 1.1428e-03, 0.0000e+00, 0.0000e+00, 3.7736e-05, 6.2918e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4586e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.1808e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7614e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.7365e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.0620e-02, 0.0000e+00,
        6.3120e-02, 1.2451e-02, 2.3568e-02, 0.0000e+00, 8.0800e-03, 1.6006e-02,
        0.0000e+00, 0.0000e+00, 3.5804e-03, 8.8042e-03, 0.0000e+00, 0.0000e+00,
        2.4214e-03, 4.7382e-03, 0.0000e+00, 0.0000e+00, 8.4380e-04, 3.3711e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9770e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.3406e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0711e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:29:06,222 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.431299527393282
2024-05-15 15:29:06,224 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.322220.03333
2024-05-15 15:29:06,268 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #77: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 7, 2, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 7, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(min, 0)': 0.34, '(min, 1)': 0.27, '(rev, 1)': 0.12, '(rev, 2)': 0.02}}
2024-05-15 15:29:06,268 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:06,269 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315973171669582
2024-05-15 15:29:06,370 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #77: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.16, '(rev, 1)': 0.09, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-05-15 15:29:06,370 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:06,371 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315973171669582
2024-05-15 15:29:06,394 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #77: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.40816326530612246, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 3)': 0.01, '(min, 0)': 0.18, '(min, 1)': 0.43, '(rev, 1)': 0.04, '(rev, 2)': 0.08}}
2024-05-15 15:29:06,394 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:06,395 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315973171669582
2024-05-15 15:29:06,599 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #77: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8372093023255814, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.34, '(min, 1)': 0.29, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 3)': 0.03}}
2024-05-15 15:29:06,600 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:06,600 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315973171669582
2024-05-15 15:29:06,676 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #77: {'transition': '(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 1, 1, 1, 1),(min, 0)->(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 2, 1, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.17777777777777778, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.03, '(min, 0)': 0.04, '(min, 1)': 0.52, '(rev, 1)': 0.08, '(rev, 2)': 0.02}}
2024-05-15 15:29:06,676 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:06,677 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315973171669582
2024-05-15 15:29:07,049 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #77: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6444444444444445, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 3)': 0.01, '(min, 0)': 0.24, '(min, 1)': 0.41, '(rev, 1)': 0.09, '(rev, 2)': 0.04, '(rev, 3)': 0.03, '(rev, 4)': 0.02, '(rev, 5)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-15 15:29:07,049 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:07,050 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315973171669582
2024-05-15 15:29:08,175 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #77: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3953488372093023, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.04, '(min, 0)': 0.3, '(min, 1)': 0.32, '(rev, 1)': 0.1, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-15 15:29:08,176 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:08,178 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315973171669582
2024-05-15 15:29:08,375 - MainProcess - INFO - text_logger.py - 51 - Train epoch #77
2024-05-15 15:29:08,378 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([8.9062e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1326e-01, 0.0000e+00,
        4.4297e-02, 8.0292e-03, 4.1886e-01, 0.0000e+00, 1.8459e-03, 7.6687e-03,
        0.0000e+00, 0.0000e+00, 1.7739e-04, 4.1579e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 9.8894e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1623e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7415e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.9827e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0303e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.0482e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6354e-02, 0.0000e+00,
        4.8532e-02, 1.3875e-02, 1.7972e-02, 0.0000e+00, 7.0985e-03, 1.9734e-02,
        0.0000e+00, 0.0000e+00, 2.0983e-03, 1.0608e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.0168e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4834e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5910e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.1591e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7760e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:29:08,397 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4314099008849121
2024-05-15 15:29:08,400 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.526300.11814
2024-05-15 15:29:08,621 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #78: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.05, '(min, 0)': 0.1, '(min, 1)': 0.46, '(rev, 1)': 0.09, '(rev, 2)': 0.02}}
2024-05-15 15:29:08,621 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:08,622 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431299527393282
2024-05-15 15:29:08,698 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #78: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5625, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 4)': 0.01, '(min, 0)': 0.31, '(min, 1)': 0.32, '(rev, 1)': 0.11, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-15 15:29:08,698 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:08,699 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431299527393282
2024-05-15 15:29:08,903 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #78: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.16, '(min, 1)': 0.41, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 4)': 0.01}}
2024-05-15 15:29:08,903 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:08,904 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431299527393282
2024-05-15 15:29:10,214 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #78: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7674418604651163, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.41, '(rev, 1)': 0.11, '(rev, 2)': 0.07, '(rev, 4)': 0.01}}
2024-05-15 15:29:10,215 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:10,216 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431299527393282
2024-05-15 15:29:10,301 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #78: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46938775510204084, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.03, '(min, 0)': 0.18, '(min, 1)': 0.41, '(rev, 1)': 0.02, '(rev, 2)': 0.06}}
2024-05-15 15:29:10,301 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:10,302 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431299527393282
2024-05-15 15:29:11,620 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #78: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8666666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(min, 0)': 0.48, '(min, 1)': 0.18, '(rev, 1)': 0.08, '(rev, 2)': 0.08, '(rev, 3)': 0.01, '(rev, 8)': 0.01}}
2024-05-15 15:29:11,620 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:11,621 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431299527393282
2024-05-15 15:29:12,576 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #78: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5217391304347826, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.01, '(min, 0)': 0.08, '(min, 1)': 0.53, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-15 15:29:12,576 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:12,577 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.431299527393282
2024-05-15 15:29:12,777 - MainProcess - INFO - text_logger.py - 51 - Train epoch #78
2024-05-15 15:29:12,779 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.1697e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2973e-01, 0.0000e+00,
        5.0194e-02, 6.9670e-03, 4.0072e-01, 0.0000e+00, 2.2460e-03, 5.4403e-03,
        0.0000e+00, 0.0000e+00, 7.2327e-04, 2.2451e-03, 0.0000e+00, 0.0000e+00,
        3.6806e-04, 6.9591e-04, 0.0000e+00, 0.0000e+00, 1.6476e-04, 2.4191e-04,
        0.0000e+00, 0.0000e+00, 8.7996e-05, 9.5868e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.0000e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.6056e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5706e-02, 0.0000e+00,
        7.4104e-02, 1.2512e-02, 3.0796e-02, 0.0000e+00, 9.0852e-03, 1.5274e-02,
        0.0000e+00, 0.0000e+00, 4.6151e-03, 8.2853e-03, 0.0000e+00, 0.0000e+00,
        3.3525e-03, 3.7614e-03, 0.0000e+00, 0.0000e+00, 1.8730e-03, 2.1042e-03,
        0.0000e+00, 0.0000e+00, 1.3982e-03, 1.2395e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.7889e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:29:12,809 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43210177519392323
2024-05-15 15:29:12,811 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.817050.04961
2024-05-15 15:29:12,840 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #79: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 3, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(min, 0)': 0.04, '(min, 1)': 0.51, '(rev, 1)': 0.1, '(rev, 2)': 0.04}}
2024-05-15 15:29:12,841 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:12,842 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4314099008849121
2024-05-15 15:29:12,872 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #79: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(min, 0)': 0.18, '(min, 1)': 0.41, '(rev, 1)': 0.08, '(rev, 2)': 0.05}}
2024-05-15 15:29:12,873 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:12,873 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4314099008849121
2024-05-15 15:29:12,900 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #79: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.7291666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.09, '(min, 1)': 0.5, '(rev, 1)': 0.08, '(rev, 2)': 0.09, '(rev, 3)': 0.01}}
2024-05-15 15:29:12,900 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:12,901 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4314099008849121
2024-05-15 15:29:13,349 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #79: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.5333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.01, '(min, 0)': 0.38, '(min, 1)': 0.22, '(rev, 1)': 0.11, '(rev, 2)': 0.09}}
2024-05-15 15:29:13,349 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:13,349 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4314099008849121
2024-05-15 15:29:13,725 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #79: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 2, 1, 0, 1)', 'reward_ratio': '0/0', 'revenue': 0.425, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.02, '(min, 0)': 0.25, '(min, 1)': 0.36, '(rev, 1)': 0.13, '(rev, 2)': 0.05}}
2024-05-15 15:29:13,725 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:13,725 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4314099008849121
2024-05-15 15:29:14,674 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #79: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5957446808510638, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.04, '(ado, 4)': 0.01, '(min, 0)': 0.18, '(min, 1)': 0.43, '(rev, 1)': 0.1, '(rev, 2)': 0.07}}
2024-05-15 15:29:14,674 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:14,675 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4314099008849121
2024-05-15 15:29:15,037 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #79: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.48936170212765956, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.01, '(ado, 7)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.46, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 5)': 0.01}}
2024-05-15 15:29:15,038 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:15,039 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4314099008849121
2024-05-15 15:29:15,138 - MainProcess - INFO - text_logger.py - 51 - Train epoch #79
2024-05-15 15:29:15,140 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.4353e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1683e-01, 0.0000e+00,
        4.2944e-02, 7.1793e-03, 4.2783e-01, 0.0000e+00, 1.1143e-03, 3.1274e-03,
        0.0000e+00, 0.0000e+00, 1.5710e-04, 6.9480e-04, 0.0000e+00, 0.0000e+00,
        4.0816e-05, 8.3370e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.2742e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8011e-02, 0.0000e+00,
        4.6847e-02, 1.1908e-02, 1.1392e-02, 0.0000e+00, 5.9475e-03, 9.2649e-03,
        0.0000e+00, 0.0000e+00, 2.1209e-03, 4.7944e-03, 0.0000e+00, 0.0000e+00,
        9.1268e-04, 1.3172e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:29:15,156 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4321822360112636
2024-05-15 15:29:15,158 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.511350.02199
2024-05-15 15:29:15,200 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #80: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.8043478260869565, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(min, 0)': 0.38, '(min, 1)': 0.22, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:29:15,200 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:15,201 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210177519392323
2024-05-15 15:29:15,215 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #80: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 9, 5, 0, 0),(rev, 6)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0)', 'reward_ratio': '6/6', 'revenue': 0.5813953488372093, 'length': 100, 'actions': {'(ado, 1)': 0.12, '(ado, 2)': 0.03, '(min, 0)': 0.15, '(min, 1)': 0.51, '(rev, 1)': 0.1, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 6)': 0.01}}
2024-05-15 15:29:15,216 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:15,216 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210177519392323
2024-05-15 15:29:15,352 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #80: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4318181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.21, '(min, 1)': 0.41, '(rev, 1)': 0.05, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.02}}
2024-05-15 15:29:15,352 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:15,352 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210177519392323
2024-05-15 15:29:15,396 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #80: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(min, 0)': 0.42, '(min, 1)': 0.16, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-15 15:29:15,396 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:15,397 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210177519392323
2024-05-15 15:29:15,741 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #80: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(ado, 6)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.43, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-15 15:29:15,741 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:15,742 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210177519392323
2024-05-15 15:29:16,450 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #80: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3404255319148936, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.06, '(min, 0)': 0.08, '(min, 1)': 0.51, '(rev, 1)': 0.09, '(rev, 2)': 0.07}}
2024-05-15 15:29:16,450 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:16,451 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210177519392323
2024-05-15 15:29:17,331 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #80: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(min, 0)': 0.45, '(min, 1)': 0.13, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:29:17,331 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:17,332 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43210177519392323
2024-05-15 15:29:17,415 - MainProcess - INFO - text_logger.py - 51 - Train epoch #80
2024-05-15 15:29:17,418 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.2698e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2971e-01, 0.0000e+00,
        5.0744e-02, 6.8435e-03, 3.9641e-01, 0.0000e+00, 2.4503e-03, 6.1745e-03,
        0.0000e+00, 0.0000e+00, 4.7945e-04, 4.0000e-03, 0.0000e+00, 0.0000e+00,
        1.6053e-04, 1.1412e-03, 0.0000e+00, 0.0000e+00, 7.5565e-05, 7.6743e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.1656e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.6444e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6993e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.2982e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5352e-02, 0.0000e+00,
        7.0629e-02, 1.2045e-02, 2.6752e-02, 0.0000e+00, 7.6390e-03, 1.5282e-02,
        0.0000e+00, 0.0000e+00, 2.8879e-03, 1.1403e-02, 0.0000e+00, 0.0000e+00,
        1.6301e-03, 4.4150e-03, 0.0000e+00, 0.0000e+00, 1.1999e-03, 3.5105e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7779e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.1020e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0736e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:29:17,437 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4321719462375876
2024-05-15 15:29:17,439 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.465970.11181
2024-05-15 15:29:17,445 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #81: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.48936170212765956, 'length': 100, 'actions': {'(ado, 1)': 0.18, '(ado, 2)': 0.03, '(min, 0)': 0.12, '(min, 1)': 0.51, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-15 15:29:17,446 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:17,447 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321822360112636
2024-05-15 15:29:17,672 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #81: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(min, 0)': 0.52, '(min, 1)': 0.07, '(rev, 1)': 0.09, '(rev, 2)': 0.06}}
2024-05-15 15:29:17,673 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:17,673 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321822360112636
2024-05-15 15:29:17,725 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #81: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.02, '(min, 0)': 0.13, '(min, 1)': 0.46, '(rev, 1)': 0.09, '(rev, 2)': 0.08, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:29:17,725 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:17,726 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321822360112636
2024-05-15 15:29:17,795 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #81: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 2, 0, 0),(ado, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/2', 'revenue': 0.3191489361702128, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.03, '(min, 0)': 0.13, '(min, 1)': 0.46, '(rev, 1)': 0.05, '(rev, 2)': 0.07}}
2024-05-15 15:29:17,795 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:17,795 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321822360112636
2024-05-15 15:29:18,285 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #81: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.52, '(min, 1)': 0.07, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-15 15:29:18,285 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:18,286 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321822360112636
2024-05-15 15:29:19,259 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #81: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.21, '(rev, 1)': 0.06, '(rev, 2)': 0.05}}
2024-05-15 15:29:19,259 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:19,260 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321822360112636
2024-05-15 15:29:19,283 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #81: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(min, 0)': 0.36, '(min, 1)': 0.25, '(rev, 1)': 0.08, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-05-15 15:29:19,283 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:19,284 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321822360112636
2024-05-15 15:29:19,451 - MainProcess - INFO - text_logger.py - 51 - Train epoch #81
2024-05-15 15:29:19,454 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([3.8111e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0588e-01, 0.0000e+00,
        4.6375e-02, 7.6501e-03, 4.2980e-01, 0.0000e+00, 2.4208e-03, 4.5294e-03,
        0.0000e+00, 0.0000e+00, 9.1783e-04, 1.3893e-03, 0.0000e+00, 0.0000e+00,
        5.1472e-04, 2.2558e-04, 0.0000e+00, 0.0000e+00, 1.8986e-04, 7.0667e-05,
        0.0000e+00, 0.0000e+00, 4.0816e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.6993e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6959e-02, 0.0000e+00,
        5.7200e-02, 1.2982e-02, 2.0109e-02, 0.0000e+00, 8.6151e-03, 1.2487e-02,
        0.0000e+00, 0.0000e+00, 4.9533e-03, 6.6518e-03, 0.0000e+00, 0.0000e+00,
        3.6517e-03, 2.0597e-03, 0.0000e+00, 0.0000e+00, 2.2805e-03, 1.1296e-03,
        0.0000e+00, 0.0000e+00, 9.1268e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:29:19,469 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43209927723685826
2024-05-15 15:29:19,471 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.434780.04348
2024-05-15 15:29:19,483 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #82: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.46808510638297873, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(min, 0)': 0.22, '(min, 1)': 0.39, '(rev, 1)': 0.06, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-15 15:29:19,483 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:19,484 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321719462375876
2024-05-15 15:29:19,515 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #82: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.29, '(ado, 2)': 0.02, '(min, 0)': 0.08, '(min, 1)': 0.5, '(rev, 1)': 0.05, '(rev, 2)': 0.06}}
2024-05-15 15:29:19,515 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #82: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.03, '(min, 0)': 0.04, '(min, 1)': 0.53, '(rev, 1)': 0.09, '(rev, 2)': 0.06}}
2024-05-15 15:29:19,515 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:19,515 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:19,516 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321719462375876
2024-05-15 15:29:19,516 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321719462375876
2024-05-15 15:29:19,684 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #82: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0),(min, 0)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.02, '(min, 0)': 0.24, '(min, 1)': 0.38, '(rev, 1)': 0.12, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-05-15 15:29:19,684 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:19,685 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321719462375876
2024-05-15 15:29:20,070 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #82: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.21, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 5)': 0.01, '(rev, 6)': 0.01}}
2024-05-15 15:29:20,070 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:20,070 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321719462375876
2024-05-15 15:29:20,734 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #82: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5531914893617021, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(min, 0)': 0.05, '(min, 1)': 0.56, '(rev, 1)': 0.07, '(rev, 2)': 0.11}}
2024-05-15 15:29:20,734 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:20,734 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321719462375876
2024-05-15 15:29:21,319 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #82: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7045454545454546, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.45, '(min, 1)': 0.14, '(rev, 1)': 0.12, '(rev, 2)': 0.03, '(rev, 3)': 0.03}}
2024-05-15 15:29:21,319 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:21,320 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4321719462375876
2024-05-15 15:29:21,390 - MainProcess - INFO - text_logger.py - 51 - Train epoch #82
2024-05-15 15:29:21,393 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.6678e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3643e-01, 0.0000e+00,
        4.9837e-02, 8.0855e-03, 3.9309e-01, 0.0000e+00, 1.7817e-03, 5.7171e-03,
        0.0000e+00, 0.0000e+00, 5.6448e-04, 3.2547e-03, 0.0000e+00, 0.0000e+00,
        2.1278e-04, 5.5775e-04, 0.0000e+00, 0.0000e+00, 6.9151e-05, 1.7603e-04,
        0.0000e+00, 0.0000e+00, 3.6364e-05, 1.2633e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.3333e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3333e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5134e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6575e-02, 0.0000e+00,
        6.1671e-02, 1.3420e-02, 2.8095e-02, 0.0000e+00, 7.3558e-03, 1.3511e-02,
        0.0000e+00, 0.0000e+00, 4.1012e-03, 1.0553e-02, 0.0000e+00, 0.0000e+00,
        2.2306e-03, 3.3600e-03, 0.0000e+00, 0.0000e+00, 1.0937e-03, 1.6141e-03,
        0.0000e+00, 0.0000e+00, 8.1312e-04, 1.4149e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.4536e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.4536e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:29:21,417 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4323398493428483
2024-05-15 15:29:21,419 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.591400.11314
2024-05-15 15:29:21,470 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #83: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.22727272727272727, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.06, '(min, 0)': 0.2, '(min, 1)': 0.38, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-15 15:29:21,470 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #83: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(min, 0)': 0.09, '(min, 1)': 0.46, '(rev, 1)': 0.1, '(rev, 2)': 0.05}}
2024-05-15 15:29:21,470 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:21,470 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:21,471 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43209927723685826
2024-05-15 15:29:21,471 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43209927723685826
2024-05-15 15:29:21,486 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #83: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.22916666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.05, '(min, 0)': 0.04, '(min, 1)': 0.53, '(rev, 1)': 0.06, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-15 15:29:21,487 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:21,488 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43209927723685826
2024-05-15 15:29:21,529 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #83: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.625, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.36, '(min, 1)': 0.23, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:29:21,529 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:21,530 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43209927723685826
2024-05-15 15:29:22,079 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #83: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.16666666666666666, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(ado, 2)': 0.01, '(ado, 6)': 0.01, '(min, 0)': 0.19, '(min, 1)': 0.39, '(rev, 1)': 0.05, '(rev, 2)': 0.03}}
2024-05-15 15:29:22,079 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:22,079 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43209927723685826
2024-05-15 15:29:23,088 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #83: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 1.2708333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(min, 0)': 0.13, '(min, 1)': 0.46, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 4)': 0.01}}
2024-05-15 15:29:23,088 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:23,089 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43209927723685826
2024-05-15 15:29:23,102 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #83: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(min, 0)': 0.14, '(min, 1)': 0.47, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02, '(rev, 4)': 0.02}}
2024-05-15 15:29:23,102 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:23,103 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43209927723685826
2024-05-15 15:29:23,260 - MainProcess - INFO - text_logger.py - 51 - Train epoch #83
2024-05-15 15:29:23,263 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.4308e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9760e-01, 0.0000e+00,
        4.7119e-02, 5.6586e-03, 4.4373e-01, 0.0000e+00, 1.5622e-03, 2.7793e-03,
        0.0000e+00, 0.0000e+00, 1.5951e-04, 9.7299e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.1381e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.0418, 0.0000, 0.0000, 0.0000, 0.0536, 0.0000, 0.0590, 0.0110, 0.0198,
        0.0000, 0.0067, 0.0085, 0.0000, 0.0000, 0.0022, 0.0053, 0.0000, 0.0000,
        0.0000, 0.0029, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-05-15 15:29:23,276 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43195558613922047
2024-05-15 15:29:23,279 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.278990.11232
2024-05-15 15:29:23,291 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #84: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6170212765957447, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.13, '(min, 1)': 0.44, '(rev, 1)': 0.08, '(rev, 2)': 0.08}}
2024-05-15 15:29:23,291 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:23,292 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323398493428483
2024-05-15 15:29:23,321 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #84: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.03, '(min, 0)': 0.18, '(min, 1)': 0.4, '(rev, 1)': 0.07, '(rev, 2)': 0.07}}
2024-05-15 15:29:23,321 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
sition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3111111111111111, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(min, 1)': 0.57, '(rev, 1)': 0.09, '(rev, 2)': 0.05}}
2024-05-15 15:29:23,322 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:23,322 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323398493428483
2024-05-15 15:29:23,322 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323398493428483
2024-05-15 15:29:23,351 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #84: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5116279069767442, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.02, '(min, 0)': 0.45, '(min, 1)': 0.16, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.02, '(rev, 6)': 0.01, '(rev, 7)': 0.01}}
2024-05-15 15:29:23,351 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:23,351 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323398493428483
2024-05-15 15:29:23,832 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #84: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6818181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(min, 0)': 0.23, '(min, 1)': 0.35, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:29:23,833 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:23,833 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323398493428483
2024-05-15 15:29:24,500 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #84: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.06, '(min, 0)': 0.15, '(min, 1)': 0.41, '(rev, 1)': 0.14, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-15 15:29:24,501 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:24,501 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323398493428483
2024-05-15 15:29:24,594 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #84: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.16, '(min, 1)': 0.46, '(rev, 1)': 0.09, '(rev, 2)': 0.09, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-15 15:29:24,594 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:24,595 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4323398493428483
2024-05-15 15:29:24,670 - MainProcess - INFO - text_logger.py - 51 - Train epoch #84
2024-05-15 15:29:24,672 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.8999e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4546e-01, 0.0000e+00,
        5.0490e-02, 7.2953e-03, 3.8893e-01, 0.0000e+00, 1.2570e-03, 3.9870e-03,
        0.0000e+00, 0.0000e+00, 1.2489e-04, 1.8685e-03, 0.0000e+00, 0.0000e+00,
        4.0816e-05, 2.8420e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4607e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2787e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.0000e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.2632e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6476e-02, 0.0000e+00,
        7.2800e-02, 1.2740e-02, 3.1949e-02, 0.0000e+00, 5.9603e-03, 1.1274e-02,
        0.0000e+00, 0.0000e+00, 1.6356e-03, 8.2457e-03, 0.0000e+00, 0.0000e+00,
        9.1268e-04, 2.2844e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6492e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3314e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.7889e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:29:24,688 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43231739232514044
2024-05-15 15:29:24,690 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.652020.02980
2024-05-15 15:29:24,796 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #85: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.10638297872340426, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.06, '(min, 0)': 0.03, '(min, 1)': 0.53, '(rev, 1)': 0.06, '(rev, 2)': 0.02}}
2024-05-15 15:29:24,796 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:24,797 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195558613922047
2024-05-15 15:29:24,872 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #85: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.20930232558139536, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(min, 0)': 0.44, '(min, 1)': 0.12, '(rev, 1)': 0.09, '(rev, 2)': 0.03}}
2024-05-15 15:29:24,872 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:24,872 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195558613922047
2024-05-15 15:29:24,935 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #85: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.574468085106383, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(min, 0)': 0.38, '(min, 1)': 0.2, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:29:24,935 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:24,936 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195558613922047
2024-05-15 15:29:25,314 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #85: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1702127659574468, 'length': 100, 'actions': {'(ado, 1)': 0.31, '(ado, 2)': 0.04, '(min, 0)': 0.48, '(min, 1)': 0.07, '(rev, 1)': 0.06, '(rev, 2)': 0.04}}
2024-05-15 15:29:25,314 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:25,314 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195558613922047
2024-05-15 15:29:25,379 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #85: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3617021276595745, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.03, '(min, 1)': 0.58, '(rev, 1)': 0.04, '(rev, 2)': 0.08}}
2024-05-15 15:29:25,379 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:25,380 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195558613922047
2024-05-15 15:29:26,147 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #85: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4883720930232558, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.15, '(min, 1)': 0.46, '(rev, 1)': 0.12, '(rev, 2)': 0.08}}
2024-05-15 15:29:26,147 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:26,147 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195558613922047
2024-05-15 15:29:26,664 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #85: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4090909090909091, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.03, '(min, 0)': 0.18, '(min, 1)': 0.39, '(rev, 1)': 0.12, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-05-15 15:29:26,664 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:26,666 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195558613922047
2024-05-15 15:29:26,732 - MainProcess - INFO - text_logger.py - 51 - Train epoch #85
2024-05-15 15:29:26,734 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.2710e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9280e-01, 0.0000e+00,
        4.6705e-02, 7.3843e-03, 4.4701e-01, 0.0000e+00, 1.4496e-03, 3.1359e-03,
        0.0000e+00, 0.0000e+00, 2.5874e-04, 8.7702e-04, 0.0000e+00, 0.0000e+00,
        1.1489e-04, 2.3190e-04, 0.0000e+00, 0.0000e+00, 3.2787e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.0472e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1576e-02, 0.0000e+00,
        5.7067e-02, 1.3315e-02, 1.9874e-02, 0.0000e+00, 6.3801e-03, 9.8495e-03,
        0.0000e+00, 0.0000e+00, 2.4346e-03, 5.4536e-03, 0.0000e+00, 0.0000e+00,
        1.5024e-03, 2.4424e-03, 0.0000e+00, 0.0000e+00, 7.3314e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:29:26,761 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43195446178206814
2024-05-15 15:29:26,763 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.289650.11944
2024-05-15 15:29:26,804 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #86: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3829787234042553, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.05, '(min, 0)': 0.24, '(min, 1)': 0.36, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 8)': 0.01}}
2024-05-15 15:29:26,804 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:26,805 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43231739232514044
2024-05-15 15:29:26,989 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #86: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5454545454545454, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(min, 0)': 0.17, '(min, 1)': 0.44, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 4)': 0.03}}
2024-05-15 15:29:26,989 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:26,989 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43231739232514044
2024-05-15 15:29:27,119 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #86: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.6818181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.01, '(min, 0)': 0.4, '(min, 1)': 0.18, '(rev, 1)': 0.11, '(rev, 2)': 0.05, '(rev, 3)': 0.03}}
2024-05-15 15:29:27,119 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:27,120 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43231739232514044
2024-05-15 15:29:27,230 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #86: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.21739130434782608, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.06, '(ado, 3)': 0.01, '(min, 0)': 0.11, '(min, 1)': 0.5, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-15 15:29:27,230 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:27,231 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43231739232514044
2024-05-15 15:29:27,442 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #86: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(min, 0)': 0.43, '(min, 1)': 0.14, '(rev, 1)': 0.11, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:29:27,442 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:27,443 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43231739232514044
2024-05-15 15:29:28,584 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #86: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.34, '(min, 1)': 0.26, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:29:28,584 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:28,584 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43231739232514044
2024-05-15 15:29:28,727 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #86: {'transition': '(exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, irr, 1, 5, 7, 1, 1),(min, 1)->(exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, rel, 1, 5, 8, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(min, 0)': 0.25, '(min, 1)': 0.38, '(rev, 1)': 0.07, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-15 15:29:28,727 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:28,727 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43231739232514044
2024-05-15 15:29:28,801 - MainProcess - INFO - text_logger.py - 51 - Train epoch #86
2024-05-15 15:29:28,803 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.3707e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2186e-01, 0.0000e+00,
        6.5090e-02, 7.0690e-03, 3.8736e-01, 0.0000e+00, 3.2494e-03, 7.5197e-03,
        0.0000e+00, 0.0000e+00, 1.1676e-03, 4.8299e-03, 0.0000e+00, 0.0000e+00,
        5.4724e-04, 8.4363e-04, 0.0000e+00, 0.0000e+00, 2.2377e-04, 2.0774e-04,
        0.0000e+00, 0.0000e+00, 3.9216e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.8513e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8407e-02, 0.0000e+00,
        8.0764e-02, 1.3712e-02, 4.0253e-02, 0.0000e+00, 1.0590e-02, 2.0367e-02,
        0.0000e+00, 0.0000e+00, 5.6348e-03, 1.4540e-02, 0.0000e+00, 0.0000e+00,
        3.9306e-03, 4.1079e-03, 0.0000e+00, 0.0000e+00, 2.2525e-03, 1.7610e-03,
        0.0000e+00, 0.0000e+00, 8.7689e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:29:28,817 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43189101544273545
2024-05-15 15:29:28,819 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.439390.10606
2024-05-15 15:29:28,834 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #87: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.03, '(min, 0)': 0.45, '(min, 1)': 0.11, '(rev, 1)': 0.1, '(rev, 2)': 0.05}}
2024-05-15 15:29:28,834 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:28,834 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195446178206814
2024-05-15 15:29:28,835 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #87: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.44680851063829785, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(min, 0)': 0.24, '(min, 1)': 0.36, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.02}}
2024-05-15 15:29:28,835 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #87: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4878048780487805, 'length': 100, 'actions': {'(ado, 1)': 0.13, '(ado, 2)': 0.04, '(min, 0)': 0.18, '(min, 1)': 0.42, '(rev, 1)': 0.15, '(rev, 2)': 0.05, '(rev, 3)': 0.03}}
2024-05-15 15:29:28,835 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:28,835 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:28,835 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195446178206814
2024-05-15 15:29:28,836 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195446178206814
2024-05-15 15:29:28,864 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #87: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5681818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.03, '(min, 0)': 0.05, '(min, 1)': 0.54, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.01}}
2024-05-15 15:29:28,864 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:28,865 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195446178206814
2024-05-15 15:29:28,917 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #87: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.575, 'length': 100, 'actions': {'(ado, 1)': 0.17, '(min, 0)': 0.09, '(min, 1)': 0.52, '(rev, 1)': 0.13, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-05-15 15:29:28,917 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:28,918 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195446178206814
2024-05-15 15:29:30,232 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #87: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(ado, 7)': 0.01, '(min, 0)': 0.08, '(min, 1)': 0.49, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-15 15:29:30,232 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:30,233 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195446178206814
2024-05-15 15:29:30,245 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #87: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(min, 0)': 0.06, '(min, 1)': 0.51, '(rev, 1)': 0.1, '(rev, 2)': 0.07}}
2024-05-15 15:29:30,245 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:30,245 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43195446178206814
2024-05-15 15:29:30,427 - MainProcess - INFO - text_logger.py - 51 - Train epoch #87
2024-05-15 15:29:30,429 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([7.2795e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8964e-01, 0.0000e+00,
        5.6258e-02, 1.0032e-02, 4.2756e-01, 0.0000e+00, 1.6630e-03, 8.6526e-03,
        0.0000e+00, 0.0000e+00, 3.2772e-04, 4.7710e-03, 0.0000e+00, 0.0000e+00,
        9.4246e-05, 7.9547e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0172e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5016, 0.0000, 0.0000, 0.0000, 0.0604, 0.0000, 0.0679, 0.0164, 0.0330,
        0.0000, 0.0068, 0.0203, 0.0000, 0.0000, 0.0032, 0.0138, 0.0000, 0.0000,
        0.0016, 0.0040, 0.0000, 0.0000, 0.0000, 0.0017, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) (500)
2024-05-15 15:29:30,443 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4315710034468371
2024-05-15 15:29:30,445 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.311110.02222
2024-05-15 15:29:30,474 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #88: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4166666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(min, 0)': 0.09, '(min, 1)': 0.5, '(rev, 1)': 0.06, '(rev, 2)': 0.09}}
2024-05-15 15:29:30,474 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
sition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.391304347826087, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.48, '(min, 1)': 0.11, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 4)': 0.01}}
2024-05-15 15:29:30,474 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:30,475 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43189101544273545
2024-05-15 15:29:30,475 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43189101544273545
2024-05-15 15:29:30,491 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #88: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4888888888888889, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.06, '(min, 1)': 0.53, '(rev, 1)': 0.1, '(rev, 2)': 0.09}}
2024-05-15 15:29:30,491 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:30,492 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43189101544273545
2024-05-15 15:29:30,599 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #88: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3541666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.2, '(ado, 2)': 0.03, '(ado, 5)': 0.01, '(min, 0)': 0.06, '(min, 1)': 0.55, '(rev, 1)': 0.07, '(rev, 2)': 0.07, '(rev, 3)': 0.01}}
2024-05-15 15:29:30,599 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:30,600 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43189101544273545
2024-05-15 15:29:30,684 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #88: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 0, 0, 0, 0),(min, 1)->(exi, wit, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 2, 1, 0, 1, 0)', 'reward_ratio': '0/0', 'revenue': 0.6875, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.26, '(min, 1)': 0.34, '(rev, 1)': 0.05, '(rev, 2)': 0.09, '(rev, 3)': 0.01}}
2024-05-15 15:29:30,684 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:30,685 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43189101544273545
2024-05-15 15:29:31,623 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #88: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(min, 1)': 0.57, '(rev, 1)': 0.11, '(rev, 2)': 0.07}}
2024-05-15 15:29:31,624 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:31,625 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43189101544273545
2024-05-15 15:29:31,784 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #88: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3695652173913043, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.04, '(min, 0)': 0.23, '(min, 1)': 0.38, '(rev, 1)': 0.04, '(rev, 2)': 0.07, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-15 15:29:31,784 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:31,785 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43189101544273545
2024-05-15 15:29:31,954 - MainProcess - INFO - text_logger.py - 51 - Train epoch #88
2024-05-15 15:29:31,956 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.6435e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3186e-01, 0.0000e+00,
        4.6263e-02, 8.3972e-03, 4.0595e-01, 0.0000e+00, 1.0414e-03, 4.6626e-03,
        0.0000e+00, 0.0000e+00, 1.3783e-04, 1.3975e-03, 0.0000e+00, 0.0000e+00,
        6.5045e-05, 2.0074e-04, 0.0000e+00, 0.0000e+00, 3.2258e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.1857e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9963e-02, 0.0000e+00,
        6.2525e-02, 1.4038e-02, 2.9993e-02, 0.0000e+00, 5.2306e-03, 1.1483e-02,
        0.0000e+00, 0.0000e+00, 1.5431e-03, 6.8082e-03, 0.0000e+00, 0.0000e+00,
        1.0275e-03, 2.2054e-03, 0.0000e+00, 0.0000e+00, 7.2131e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:29:31,977 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43149543589538314
2024-05-15 15:29:31,980 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.433330.05556
2024-05-15 15:29:31,994 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #89: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.3673469387755102, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(min, 0)': 0.22, '(min, 1)': 0.35, '(rev, 1)': 0.07, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-15 15:29:31,994 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:31,995 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315710034468371
2024-05-15 15:29:32,019 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #89: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3488372093023256, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.09, '(min, 1)': 0.49, '(rev, 1)': 0.1, '(rev, 2)': 0.05}}
2024-05-15 15:29:32,019 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:32,020 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315710034468371
2024-05-15 15:29:32,061 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #89: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.46511627906976744, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.12, '(min, 1)': 0.48, '(rev, 1)': 0.08, '(rev, 2)': 0.05, '(rev, 3)': 0.02, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:29:32,061 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:32,061 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315710034468371
2024-05-15 15:29:32,114 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #89: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4444444444444444, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(min, 0)': 0.26, '(min, 1)': 0.34, '(rev, 1)': 0.07, '(rev, 2)': 0.09, '(rev, 3)': 0.01}}
2024-05-15 15:29:32,114 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:32,115 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315710034468371
2024-05-15 15:29:32,842 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #89: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.01, '(ado, 3)': 0.01, '(min, 0)': 0.44, '(min, 1)': 0.18, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.02}}
2024-05-15 15:29:32,843 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:32,843 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315710034468371
2024-05-15 15:29:33,308 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #89: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.44680851063829785, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.02, '(min, 0)': 0.06, '(min, 1)': 0.53, '(rev, 1)': 0.07, '(rev, 2)': 0.09, '(rev, 3)': 0.01}}
2024-05-15 15:29:33,309 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:33,310 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315710034468371
2024-05-15 15:29:33,513 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #89: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.28888888888888886, 'length': 100, 'actions': {'(ado, 1)': 0.32, '(min, 0)': 0.32, '(min, 1)': 0.24, '(rev, 1)': 0.07, '(rev, 2)': 0.02, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-15 15:29:33,513 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:33,513 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4315710034468371
2024-05-15 15:29:33,693 - MainProcess - INFO - text_logger.py - 51 - Train epoch #89
2024-05-15 15:29:33,696 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([2.8506e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0324e-01, 0.0000e+00,
        5.3437e-02, 8.0002e-03, 4.2776e-01, 0.0000e+00, 1.3432e-03, 4.1991e-03,
        0.0000e+00, 0.0000e+00, 1.3880e-04, 1.6251e-03, 0.0000e+00, 0.0000e+00,
        3.3898e-05, 2.2959e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5816e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5490e-02, 0.0000e+00,
        6.8451e-02, 1.3173e-02, 2.9987e-02, 0.0000e+00, 6.1484e-03, 1.0961e-02,
        0.0000e+00, 0.0000e+00, 1.8788e-03, 7.2889e-03, 0.0000e+00, 0.0000e+00,
        7.5799e-04, 2.4190e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:29:33,716 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43146512646697066
2024-05-15 15:29:33,717 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.455960.00915
2024-05-15 15:29:33,755 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #90: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34782608695652173, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.46, '(min, 1)': 0.12, '(rev, 1)': 0.08, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:29:33,755 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #90: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.01, '(min, 0)': 0.16, '(min, 1)': 0.41, '(rev, 1)': 0.08, '(rev, 2)': 0.04, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-15 15:29:33,755 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:33,755 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:33,756 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43149543589538314
2024-05-15 15:29:33,756 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43149543589538314
2024-05-15 15:29:33,772 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #90: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 3, 0, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.32608695652173914, 'length': 100, 'actions': {'(ado, 1)': 0.27, '(ado, 2)': 0.02, '(min, 0)': 0.09, '(min, 1)': 0.5, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.01}}
2024-05-15 15:29:33,772 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:33,772 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43149543589538314
2024-05-15 15:29:34,227 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #90: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(ado, 2)': 0.06, '(min, 0)': 0.26, '(min, 1)': 0.37, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 3)': 0.01}}
2024-05-15 15:29:34,227 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:34,228 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43149543589538314
2024-05-15 15:29:34,478 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #90: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0),(rev, 2)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '2/2', 'revenue': 0.2826086956521739, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 9)': 0.01, '(min, 0)': 0.3, '(min, 1)': 0.32, '(rev, 1)': 0.06, '(rev, 2)': 0.06, '(rev, 4)': 0.01}}
2024-05-15 15:29:34,478 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:34,478 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43149543589538314
2024-05-15 15:29:34,870 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #90: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.01, '(min, 0)': 0.42, '(min, 1)': 0.18, '(rev, 1)': 0.1, '(rev, 2)': 0.06, '(rev, 3)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:29:34,870 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:34,871 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43149543589538314
2024-05-15 15:29:34,908 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #90: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.18181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.05, '(min, 0)': 0.17, '(min, 1)': 0.39, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.01}}
2024-05-15 15:29:34,909 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:34,909 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43149543589538314
2024-05-15 15:29:35,043 - MainProcess - INFO - text_logger.py - 51 - Train epoch #90
2024-05-15 15:29:35,046 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([1.6964e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0844e-01, 0.0000e+00,
        6.3233e-02, 8.1384e-03, 4.1096e-01, 0.0000e+00, 1.7504e-03, 4.6571e-03,
        0.0000e+00, 0.0000e+00, 2.8962e-04, 1.8241e-03, 0.0000e+00, 0.0000e+00,
        1.1890e-04, 4.0713e-04, 0.0000e+00, 0.0000e+00, 3.5714e-05, 1.5037e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.2038e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.6004e-02, 0.0000e+00,
        1.1055e-01, 1.3674e-02, 4.8604e-02, 0.0000e+00, 7.8226e-03, 1.2268e-02,
        0.0000e+00, 0.0000e+00, 2.7441e-03, 8.1944e-03, 0.0000e+00, 0.0000e+00,
        1.5406e-03, 3.1336e-03, 0.0000e+00, 0.0000e+00, 7.9860e-04, 2.0723e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:29:35,060 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.4310525365176248
2024-05-15 15:29:35,062 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.264820.08300
2024-05-15 15:29:35,364 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #91: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36363636363636365, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.23, '(min, 1)': 0.35, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-15 15:29:35,364 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:35,364 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43146512646697066
2024-05-15 15:29:35,522 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #91: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.2978723404255319, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(ado, 5)': 0.01, '(min, 0)': 0.18, '(min, 1)': 0.42, '(rev, 1)': 0.07, '(rev, 2)': 0.05}}
2024-05-15 15:29:35,523 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:35,524 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43146512646697066
2024-05-15 15:29:35,662 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #91: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(min, 0)': 0.48, '(min, 1)': 0.13, '(rev, 1)': 0.07, '(rev, 2)': 0.05, '(rev, 3)': 0.03, '(rev, 4)': 0.01}}
2024-05-15 15:29:35,662 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:35,662 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43146512646697066
2024-05-15 15:29:35,813 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #91: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.1956521739130435, 'length': 100, 'actions': {'(ado, 1)': 0.35, '(ado, 2)': 0.01, '(min, 0)': 0.04, '(min, 1)': 0.5, '(rev, 1)': 0.07, '(rev, 2)': 0.03}}
2024-05-15 15:29:35,813 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:35,814 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43146512646697066
2024-05-15 15:29:35,889 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #91: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0),(rev, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.5531914893617021, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(ado, 3)': 0.01, '(min, 0)': 0.21, '(min, 1)': 0.38, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-15 15:29:35,889 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:35,890 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43146512646697066
2024-05-15 15:29:36,524 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #91: {'transition': '(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 3, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4318181818181818, 'length': 100, 'actions': {'(ado, 1)': 0.21, '(ado, 2)': 0.02, '(min, 0)': 0.4, '(min, 1)': 0.22, '(rev, 1)': 0.06, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-05-15 15:29:36,524 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:36,525 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43146512646697066
2024-05-15 15:29:36,860 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #91: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 0)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4222222222222222, 'length': 100, 'actions': {'(ado, 1)': 0.14, '(ado, 2)': 0.03, '(ado, 6)': 0.01, '(min, 0)': 0.35, '(min, 1)': 0.26, '(rev, 1)': 0.13, '(rev, 2)': 0.08}}
2024-05-15 15:29:36,861 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:36,861 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43146512646697066
2024-05-15 15:29:37,033 - MainProcess - INFO - text_logger.py - 51 - Train epoch #91
2024-05-15 15:29:37,035 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([4.0725e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0039e-01, 0.0000e+00,
        6.0106e-02, 8.6110e-03, 4.1489e-01, 0.0000e+00, 1.7821e-03, 7.6861e-03,
        0.0000e+00, 0.0000e+00, 5.3915e-04, 4.7007e-03, 0.0000e+00, 0.0000e+00,
        2.8594e-04, 6.1234e-04, 0.0000e+00, 0.0000e+00, 1.1250e-04, 6.6667e-05,
        0.0000e+00, 0.0000e+00, 1.5505e-04, 3.3333e-05, 0.0000e+00, 0.0000e+00,
        3.1250e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.5489e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8002e-02, 0.0000e+00,
        8.4864e-02, 1.5191e-02, 4.3121e-02, 0.0000e+00, 7.5230e-03, 2.2263e-02,
        0.0000e+00, 0.0000e+00, 3.9116e-03, 1.6298e-02, 0.0000e+00, 0.0000e+00,
        2.6844e-03, 3.6206e-03, 0.0000e+00, 0.0000e+00, 1.7880e-03, 1.0530e-03,
        0.0000e+00, 0.0000e+00, 2.0230e-03, 7.4536e-04, 0.0000e+00, 0.0000e+00,
        6.9877e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:29:37,049 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43083999282174795
2024-05-15 15:29:37,051 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.364850.06697
2024-05-15 15:29:37,084 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #92: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0)', 'reward_ratio': '1/1', 'revenue': 0.3333333333333333, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.03, '(min, 0)': 0.01, '(min, 1)': 0.58, '(rev, 1)': 0.16}}
2024-05-15 15:29:37,084 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:37,085 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310525365176248
2024-05-15 15:29:37,096 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #92: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.2765957446808511, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.02, '(min, 0)': 0.07, '(min, 1)': 0.5, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-15 15:29:37,097 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:37,097 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310525365176248
2024-05-15 15:29:37,233 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #92: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5813953488372093, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(min, 0)': 0.45, '(min, 1)': 0.16, '(rev, 1)': 0.1, '(rev, 2)': 0.01, '(rev, 3)': 0.02}}
2024-05-15 15:29:37,233 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:37,234 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310525365176248
2024-05-15 15:29:37,530 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #92: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.7674418604651163, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(min, 0)': 0.09, '(min, 1)': 0.49, '(rev, 1)': 0.09, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-05-15 15:29:37,530 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:37,531 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310525365176248
2024-05-15 15:29:37,866 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #92: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.3877551020408163, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(ado, 2)': 0.01, '(min, 0)': 0.07, '(min, 1)': 0.49, '(rev, 1)': 0.06, '(rev, 2)': 0.08, '(rev, 3)': 0.01}}
2024-05-15 15:29:37,867 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:37,868 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310525365176248
2024-05-15 15:29:37,916 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #92: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 2, 1, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.4878048780487805, 'length': 100, 'actions': {'(ado, 1)': 0.15, '(ado, 2)': 0.04, '(ado, 8)': 0.01, '(min, 0)': 0.15, '(min, 1)': 0.49, '(rev, 1)': 0.14, '(rev, 2)': 0.01, '(rev, 3)': 0.01}}
2024-05-15 15:29:37,917 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:37,918 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310525365176248
2024-05-15 15:29:38,851 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #92: {'transition': '(exi, wit, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 1, 2, 5, 1, 1),(min, 0)->(exi, wit, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, wit, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 1, 3, 5, 1, 1)', 'reward_ratio': '0/0', 'revenue': 0.3902439024390244, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.24, '(min, 1)': 0.36, '(rev, 1)': 0.07, '(rev, 2)': 0.03, '(rev, 3)': 0.03, '(rev, 4)': 0.01, '(rev, 5)': 0.01}}
2024-05-15 15:29:38,852 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:38,852 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.4310525365176248
2024-05-15 15:29:39,028 - MainProcess - INFO - text_logger.py - 51 - Train epoch #92
2024-05-15 15:29:39,030 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([6.5768e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9458e-01, 0.0000e+00,
        6.6621e-02, 8.1883e-03, 4.1780e-01, 0.0000e+00, 1.7978e-03, 6.9124e-03,
        0.0000e+00, 0.0000e+00, 3.5618e-04, 2.9933e-03, 0.0000e+00, 0.0000e+00,
        1.4390e-04, 3.1235e-04, 0.0000e+00, 0.0000e+00, 7.3698e-05, 1.2040e-04,
        0.0000e+00, 0.0000e+00, 3.9216e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8966e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([2.1442e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9025e-02, 0.0000e+00,
        9.3173e-02, 1.5084e-02, 4.2557e-02, 0.0000e+00, 6.7184e-03, 1.8222e-02,
        0.0000e+00, 0.0000e+00, 2.6924e-03, 1.1229e-02, 0.0000e+00, 0.0000e+00,
        1.6063e-03, 2.6441e-03, 0.0000e+00, 0.0000e+00, 1.1665e-03, 1.9741e-03,
        0.0000e+00, 0.0000e+00, 8.7689e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5421e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:29:39,046 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.430562109450349
2024-05-15 15:29:39,048 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.332180.05558
2024-05-15 15:29:39,075 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #93: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.782608695652174, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.02, '(min, 0)': 0.11, '(min, 1)': 0.47, '(rev, 1)': 0.1, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-15 15:29:39,075 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:39,076 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43083999282174795
2024-05-15 15:29:39,091 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #93: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 6, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 6, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.5238095238095238, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.03, '(min, 0)': 0.36, '(min, 1)': 0.22, '(rev, 1)': 0.11, '(rev, 2)': 0.04}}
2024-05-15 15:29:39,091 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:39,092 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43083999282174795
2024-05-15 15:29:39,106 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #93: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3409090909090909, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(ado, 2)': 0.02, '(min, 0)': 0.1, '(min, 1)': 0.48, '(rev, 1)': 0.11, '(rev, 2)': 0.02, '(rev, 3)': 0.02}}
2024-05-15 15:29:39,106 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:39,107 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43083999282174795
2024-05-15 15:29:39,569 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #93: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.4791666666666667, 'length': 100, 'actions': {'(ado, 1)': 0.25, '(min, 0)': 0.4, '(min, 1)': 0.2, '(rev, 1)': 0.05, '(rev, 2)': 0.06, '(rev, 3)': 0.03, '(rev, 5)': 0.01}}
2024-05-15 15:29:39,570 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:39,570 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43083999282174795
2024-05-15 15:29:39,654 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #93: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 4, 1, 0, 0),(rev, 1)->(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6, 'length': 100, 'actions': {'(ado, 1)': 0.16, '(min, 0)': 0.41, '(min, 1)': 0.19, '(rev, 1)': 0.15, '(rev, 2)': 0.07, '(rev, 3)': 0.01, '(rev, 4)': 0.01}}
2024-05-15 15:29:39,655 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:39,655 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43083999282174795
2024-05-15 15:29:39,688 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #93: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0),(ado, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0)', 'reward_ratio': '0/1', 'revenue': 0.5714285714285714, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.04, '(min, 0)': 0.1, '(min, 1)': 0.51, '(rev, 1)': 0.06, '(rev, 2)': 0.03, '(rev, 3)': 0.01, '(rev, 4)': 0.02}}
2024-05-15 15:29:39,688 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:39,689 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43083999282174795
2024-05-15 15:29:41,711 - Train Agent 5 - INFO - text_logger.py - 51 - Train Episode #93: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 1, 0, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.6170212765957447, 'length': 100, 'actions': {'(ado, 1)': 0.26, '(ado, 2)': 0.01, '(min, 0)': 0.09, '(min, 1)': 0.48, '(rev, 1)': 0.1, '(rev, 2)': 0.04, '(rev, 3)': 0.02}}
2024-05-15 15:29:41,712 - Train Agent 5 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:41,712 - Train Agent 5 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.43083999282174795
2024-05-15 15:29:41,902 - MainProcess - INFO - text_logger.py - 51 - Train epoch #93
2024-05-15 15:29:41,905 - MainProcess - INFO - text_logger.py - 51 - Target Values tensor([5.6723e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0143e-01, 0.0000e+00,
        6.3560e-02, 8.8409e-03, 4.1081e-01, 0.0000e+00, 2.7047e-03, 6.6874e-03,
        0.0000e+00, 0.0000e+00, 5.3325e-04, 4.6408e-03, 0.0000e+00, 0.0000e+00,
        1.1152e-04, 5.8987e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.4295e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00])  tensor([1.9167e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5516e-02, 0.0000e+00,
        8.2949e-02, 1.5640e-02, 3.7776e-02, 0.0000e+00, 8.3454e-03, 1.7394e-02,
        0.0000e+00, 0.0000e+00, 3.6486e-03, 1.3876e-02, 0.0000e+00, 0.0000e+00,
        1.4519e-03, 3.3950e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3321e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]) (500)
2024-05-15 15:29:41,921 - MainProcess - INFO - text_logger.py - 51 - Base Value Approximation 0.43074368475603797
2024-05-15 15:29:41,924 - MainProcess - INFO - text_logger.py - 51 - Test Policy Revenue 0.561900.03810
2024-05-15 15:29:41,933 - Test Agent 2 - INFO - text_logger.py - 51 - Test Episode #94: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.36, 'length': 100, 'actions': {'(ado, 1)': 0.3, '(ado, 2)': 0.01, '(min, 0)': 0.37, '(min, 1)': 0.2, '(rev, 1)': 0.04, '(rev, 2)': 0.05, '(rev, 3)': 0.03}}
2024-05-15 15:29:41,933 - Test Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:41,934 - Test Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430562109450349
2024-05-15 15:29:41,948 - Train Agent 2 - INFO - text_logger.py - 51 - Train Episode #94: {'transition': '(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 0, 0, 0, 0),(min, 1)->(nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 0, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3181818181818182, 'length': 100, 'actions': {'(ado, 1)': 0.22, '(ado, 2)': 0.04, '(min, 0)': 0.32, '(min, 1)': 0.27, '(rev, 1)': 0.11, '(rev, 2)': 0.03, '(rev, 3)': 0.01}}
2024-05-15 15:29:41,948 - Train Agent 2 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:41,949 - Train Agent 2 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430562109450349
2024-05-15 15:29:41,964 - Train Agent 3 - INFO - text_logger.py - 51 - Train Episode #94: {'transition': '(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 6, 2, 0, 0),(min, 0)->(exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 7, 2, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.34146341463414637, 'length': 100, 'actions': {'(ado, 1)': 0.19, '(ado, 2)': 0.04, '(min, 0)': 0.09, '(min, 1)': 0.53, '(rev, 1)': 0.08, '(rev, 2)': 0.06, '(rev, 5)': 0.01}}
2024-05-15 15:29:41,964 - Train Agent 3 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:41,965 - Train Agent 3 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430562109450349
2024-05-15 15:29:42,053 - Train Agent 4 - INFO - text_logger.py - 51 - Train Episode #94: {'transition': '(exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 4, 1, 0, 0),(min, 1)->(exi, not, exi, not, exi, not, exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 5, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.3170731707317073, 'length': 100, 'actions': {'(ado, 1)': 0.28, '(min, 0)': 0.27, '(min, 1)': 0.31, '(rev, 1)': 0.08, '(rev, 2)': 0.06}}
2024-05-15 15:29:42,054 - Train Agent 4 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:42,054 - Train Agent 4 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430562109450349
2024-05-15 15:29:42,089 - Train Agent 1 - INFO - text_logger.py - 51 - Train Episode #94: {'transition': '(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 1, 1, 0, 0),(rev, 1)->(exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, act, 0, 1, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.37777777777777777, 'length': 100, 'actions': {'(ado, 1)': 0.24, '(ado, 2)': 0.02, '(min, 0)': 0.2, '(min, 1)': 0.41, '(rev, 1)': 0.06, '(rev, 2)': 0.05, '(rev, 3)': 0.02}}
2024-05-15 15:29:42,090 - Train Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:42,090 - Train Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430562109450349
2024-05-15 15:29:42,165 - Test Agent 1 - INFO - text_logger.py - 51 - Test Episode #94: {'transition': '(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, irr, 0, 2, 0, 0, 0),(min, 1)->(exi, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, exi, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, nob, not, rel, 0, 2, 1, 0, 0)', 'reward_ratio': '0/0', 'revenue': 0.425531914893617, 'length': 100, 'actions': {'(ado, 1)': 0.23, '(ado, 2)': 0.02, '(min, 0)': 0.02, '(min, 1)': 0.57, '(rev, 1)': 0.05, '(rev, 2)': 0.08, '(rev, 3)': 0.02, '(rev, 4)': 0.01}}
2024-05-15 15:29:42,165 - Test Agent 1 - INFO - text_logger.py - 51 - State value cache empty
2024-05-15 15:29:42,166 - Test Agent 1 - INFO - text_logger.py - 51 - Agent Base Value Approximation 0.430562109450349
2024-05-16 03:45:04,422 - MainProcess - INFO - util.py - 54 - process shutting down
